{"2024-11-12T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2411.08019v1","updated":"2024-11-12T18:50:35Z","published":"2024-11-12T18:50:35Z","title":"Language Models as Causal Effect Generators","summary":"  We present a framework for large language model (LLM) based data generation\nwith controllable causal structure. In particular, we define a procedure for\nturning any language model and any directed acyclic graph (DAG) into a\nsequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM\nis a causal model with user-defined structure and LLM-defined structural\nequations. We characterize how an SD-SCM allows sampling from observational,\ninterventional, and counterfactual distributions according to the desired\ncausal structure. We then leverage this procedure to propose a new type of\nbenchmark for causal inference methods, generating individual-level\ncounterfactual data without needing to manually specify functional\nrelationships between variables. We create an example benchmark consisting of\nthousands of datasets, and test a suite of popular estimation methods on these\ndatasets for average, conditional average, and individual treatment effect\nestimation, both with and without hidden confounding. Apart from generating\ndata, the same procedure also allows us to test for the presence of a causal\neffect that might be encoded in an LLM. This procedure can underpin auditing\nLLMs for misinformation, discrimination, or otherwise undesirable behavior. We\nbelieve SD-SCMs can serve as a useful tool in any application that would\nbenefit from sequential data with controllable causal structure.\n","authors":["Lucius E. J. Bynum","Kyunghyun Cho"],"pdf_url":"https://arxiv.org/pdf/2411.08019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08010v1","updated":"2024-11-12T18:35:28Z","published":"2024-11-12T18:35:28Z","title":"ExpressivityArena: Can LLMs Express Information Implicitly?","summary":"  While Large Language Models (LLMs) have demonstrated remarkable performance\nin certain dimensions, their ability to express implicit language cues that\nhuman use for effective communication remains unclear. This paper presents\nExpressivityArena, a Python library for measuring the implicit communication\nabilities of LLMs. We provide a comprehensive framework to evaluate\nexpressivity of arbitrary LLMs and explore its practical implications. To this\nend, we refine the definition and measurements of ``expressivity,'' and use our\nframework in a set of small experiments. These experiments test LLMs in\ncreative and logical tasks such as poetry, coding, and emotion-based responses.\nThey are then evaluated by an automated grader, through ExpressivityArena,\nwhich we verify to be the most pragmatic for testing expressivity. Building on\nthese experiments, we deepen our understanding of the expressivity of LLMs by\nassessing their ability to remain expressive in conversations. Our findings\nindicate that LLMs are capable of generating and understanding expressive\ncontent, however, with some limitations. These insights will inform the future\ndevelopment and deployment of expressive LLMs. We provide the code for\nExpressivityArena alongside our paper.\n","authors":["Joshua Tint","Som Sagar","Aditya Taparia","Kelly Raines","Bimsara Pathiraja","Caleb Liu","Ransalu Senanayake"],"pdf_url":"https://arxiv.org/pdf/2411.08010v1.pdf","comment":"8 pages, 22 figures"},{"id":"http://arxiv.org/abs/2411.08003v1","updated":"2024-11-12T18:28:57Z","published":"2024-11-12T18:28:57Z","title":"Can adversarial attacks by large language models be attributed?","summary":"  Attributing outputs from Large Language Models (LLMs) in adversarial\nsettings-such as cyberattacks and disinformation-presents significant\nchallenges that are likely to grow in importance. We investigate this\nattribution problem using formal language theory, specifically language\nidentification in the limit as introduced by Gold and extended by Angluin. By\nmodeling LLM outputs as formal languages, we analyze whether finite text\nsamples can uniquely pinpoint the originating model. Our results show that due\nto the non-identifiability of certain language classes, under some mild\nassumptions about overlapping outputs from fine-tuned models it is\ntheoretically impossible to attribute outputs to specific LLMs with certainty.\nThis holds also when accounting for expressivity limitations of Transformer\narchitectures. Even with direct model access or comprehensive monitoring,\nsignificant computational hurdles impede attribution efforts. These findings\nhighlight an urgent need for proactive measures to mitigate risks posed by\nadversarial LLM use as their influence continues to expand.\n","authors":["Manuel Cebrian","Jan Arne Telle"],"pdf_url":"https://arxiv.org/pdf/2411.08003v1.pdf","comment":"7 pages, 1 figure"},{"id":"http://arxiv.org/abs/2411.07990v1","updated":"2024-11-12T18:15:19Z","published":"2024-11-12T18:15:19Z","title":"Derivational Morphology Reveals Analogical Generalization in Large\n  Language Models","summary":"  What mechanisms underlie linguistic generalization in large language models\n(LLMs)? This question has attracted considerable attention, with most studies\nanalyzing the extent to which the language skills of LLMs resemble rules. As of\nyet, it is not known whether linguistic generalization in LLMs could equally\nwell be explained as the result of analogical processes, which can be\nformalized as similarity operations on stored exemplars. A key shortcoming of\nprior research is its focus on linguistic phenomena with a high degree of\nregularity, for which rule-based and analogical approaches make the same\npredictions. Here, we instead examine derivational morphology, specifically\nEnglish adjective nominalization, which displays notable variability. We\nintroduce a new method for investigating linguistic generalization in LLMs:\nfocusing on GPT-J, we fit cognitive models that instantiate rule-based and\nanalogical learning to the LLM training data and compare their predictions on a\nset of nonce adjectives with those of the LLM, allowing us to draw direct\nconclusions regarding underlying mechanisms. As expected, rule-based and\nanalogical models explain the predictions of GPT-J equally well for adjectives\nwith regular nominalization patterns. However, for adjectives with variable\nnominalization patterns, the analogical model provides a much better match.\nFurthermore, GPT-J's behavior is sensitive to the individual word frequencies,\neven for regular forms, a behavior that is consistent with an analogical\naccount of regular forms but not a rule-based one. These findings refute the\nhypothesis that GPT-J's linguistic generalization on adjective nominalization\ninvolves rules, suggesting similarity operations on stored exemplars as the\nunderlying mechanism. Overall, our study suggests that analogical processes\nplay a bigger role in the linguistic generalization of LLMs than previously\nthought.\n","authors":["Valentin Hofmann","Leonie Weissweiler","David Mortensen","Hinrich Sch√ºtze","Janet Pierrehumbert"],"pdf_url":"https://arxiv.org/pdf/2411.07990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07975v1","updated":"2024-11-12T17:55:10Z","published":"2024-11-12T17:55:10Z","title":"JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified\n  Multimodal Understanding and Generation","summary":"  We present JanusFlow, a powerful framework that unifies image understanding\nand generation in a single model. JanusFlow introduces a minimalist\narchitecture that integrates autoregressive language models with rectified\nflow, a state-of-the-art method in generative modeling. Our key finding\ndemonstrates that rectified flow can be straightforwardly trained within the\nlarge language model framework, eliminating the need for complex architectural\nmodifications. To further improve the performance of our unified model, we\nadopt two key strategies: (i) decoupling the understanding and generation\nencoders, and (ii) aligning their representations during unified training.\nExtensive experiments show that JanusFlow achieves comparable or superior\nperformance to specialized models in their respective domains, while\nsignificantly outperforming existing unified approaches across standard\nbenchmarks. This work represents a step toward more efficient and versatile\nvision-language models.\n","authors":["Yiyang Ma","Xingchao Liu","Xiaokang Chen","Wen Liu","Chengyue Wu","Zhiyu Wu","Zizheng Pan","Zhenda Xie","Haowei Zhang","Xingkai yu","Liang Zhao","Yisong Wang","Jiaying Liu","Chong Ruan"],"pdf_url":"https://arxiv.org/pdf/2411.07975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07965v1","updated":"2024-11-12T17:41:16Z","published":"2024-11-12T17:41:16Z","title":"From General to Specific: Utilizing General Hallucation to Automatically\n  Measure the Role Relationship Fidelity for Specific Role-Play Agents","summary":"  The advanced role-playing capabilities of Large Language Models (LLMs) have\npaved the way for developing Role-Playing Agents (RPAs). However, existing\nbenchmarks, such as HPD, which incorporates manually scored character\nrelationships into the context for LLMs to sort coherence, and SocialBench,\nwhich uses specific profiles generated by LLMs in the context of\nmultiple-choice tasks to assess character preferences, face limitations like\npoor generalizability, implicit and inaccurate judgments, and excessive context\nlength. To address the above issues, we propose an automatic, scalable, and\ngeneralizable paradigm. Specifically, we construct a benchmark by extracting\nrelations from a general knowledge graph and leverage RPA's inherent\nhallucination properties to prompt it to interact across roles, employing\nChatGPT for stance detection and defining relationship hallucination along with\nthree related metrics. Extensive experiments validate the effectiveness and\nstability of our metrics. Our findings further explore factors influencing\nthese metrics and discuss the trade-off between relationship hallucination and\nfactuality.\n","authors":["Chuyi Kong","Ziyang Luo","Hongzhan Lin","Zhiyuan Fan","Yaxin Fan","Yuxi Sun","Jing Ma"],"pdf_url":"https://arxiv.org/pdf/2411.07965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08479v5","updated":"2024-11-12T17:38:29Z","published":"2024-02-13T14:12:32Z","title":"Plausible Extractive Rationalization through Semi-Supervised Entailment\n  Signal","summary":"  The increasing use of complex and opaque black box models requires the\nadoption of interpretable measures, one such option is extractive rationalizing\nmodels, which serve as a more interpretable alternative. These models, also\nknown as Explain-Then-Predict models, employ an explainer model to extract\nrationales and subsequently condition the predictor with the extracted\ninformation. Their primary objective is to provide precise and faithful\nexplanations, represented by the extracted rationales. In this paper, we take a\nsemi-supervised approach to optimize for the plausibility of extracted\nrationales. We adopt a pre-trained natural language inference (NLI) model and\nfurther fine-tune it on a small set of supervised rationales ($10\\%$). The NLI\npredictor is leveraged as a source of supervisory signals to the explainer via\nentailment alignment. We show that, by enforcing the alignment agreement\nbetween the explanation and answer in a question-answering task, the\nperformance can be improved without access to ground truth labels. We evaluate\nour approach on the ERASER dataset and show that our approach achieves\ncomparable results with supervised extractive models and outperforms\nunsupervised approaches by $> 100\\%$.\n","authors":["Wei Jie Yeo","Ranjan Satapathy","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2402.08479v5.pdf","comment":"ACL Findings 2024"},{"id":"http://arxiv.org/abs/2406.11275v2","updated":"2024-11-12T17:37:10Z","published":"2024-06-17T07:25:09Z","title":"Self-training Large Language Models through Knowledge Detection","summary":"  Large language models (LLMs) often necessitate extensive labeled datasets and\ntraining compute to achieve impressive performance across downstream tasks.\nThis paper explores a self-training paradigm, where the LLM autonomously\ncurates its own labels and selectively trains on unknown data samples\nidentified through a reference-free consistency method. Empirical evaluations\ndemonstrate significant improvements in reducing hallucination in generation\nacross multiple subjects. Furthermore, the selective training framework\nmitigates catastrophic forgetting in out-of-distribution benchmarks, addressing\na critical limitation in training LLMs. Our findings suggest that such an\napproach can substantially reduce the dependency on large labeled datasets,\npaving the way for more scalable and cost-effective language model training.\n","authors":["Wei Jie Yeo","Teddy Ferdinan","Przemyslaw Kazienko","Ranjan Satapathy","Erik Cambria"],"pdf_url":"https://arxiv.org/pdf/2406.11275v2.pdf","comment":"EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2411.07917v1","updated":"2024-11-12T16:49:51Z","published":"2024-11-12T16:49:51Z","title":"CryptoLLM: Unleashing the Power of Prompted LLMs for SmartQnA and\n  Classification of Crypto Posts","summary":"  The rapid growth of social media has resulted in an large volume of\nuser-generated content, particularly in niche domains such as cryptocurrency.\nThis task focuses on developing robust classification models to accurately\ncategorize cryptocurrency-related social media posts into predefined classes,\nincluding but not limited to objective, positive, negative, etc. Additionally,\nthe task requires participants to identify the most relevant answers from a set\nof posts in response to specific questions. By leveraging advanced LLMs, this\nresearch aims to enhance the understanding and filtering of cryptocurrency\ndiscourse, thereby facilitating more informed decision-making in this volatile\nsector. We have used a prompt-based technique to solve the classification task\nfor reddit posts and twitter posts. Also, we have used 64-shot technique along\nwith prompts on GPT-4-Turbo model to determine whether a answer is relevant to\na question or not.\n","authors":["Aniket Deroy","Subhankar Maity"],"pdf_url":"https://arxiv.org/pdf/2411.07917v1.pdf","comment":"Accepted at FIRE 2024 (Track: Opinion Extraction and Question\n  Answering from CryptoCurrency-Related Tweets and Reddit posts (CryptOQA))"},{"id":"http://arxiv.org/abs/2406.13230v2","updated":"2024-11-12T16:47:49Z","published":"2024-06-19T05:33:34Z","title":"Enhancing Language Model Factuality via Activation-Based Confidence\n  Calibration and Guided Decoding","summary":"  Calibrating language models (LMs) aligns their generation confidence with the\nactual likelihood of answer correctness, which can inform users about LMs'\nreliability and mitigate hallucinated content. However, prior calibration\nmethods, such as self-consistency-based and logit-based approaches, are either\nlimited in inference-time efficiency or fall short of providing informative\nsignals. Moreover, simply filtering out low-confidence responses reduces the\nLM's helpfulness when the answers are correct. Therefore, effectively using\ncalibration techniques to enhance an LM's factuality remains an unsolved\nchallenge. In this paper, we first propose an activation-based calibration\nmethod, ActCab, which trains a linear layer on top of the LM's last-layer\nactivations that can better capture the representations of knowledge. Built on\ntop of ActCab, we further propose CoDec, a confidence-guided decoding strategy\nto elicit truthful answers with high confidence from LMs. By evaluating on five\npopular QA benchmarks, ActCab achieves superior calibration performance than\nall competitive baselines, e.g., by reducing the average expected calibration\nerror (ECE) score by up to 39%. Further experiments on CoDec show consistent\nimprovements in several LMs' factuality on challenging QA datasets, such as\nTruthfulQA, highlighting the value of confidence signals in enhancing\nfactuality.\n","authors":["Xin Liu","Farima Fatahi Bayat","Lu Wang"],"pdf_url":"https://arxiv.org/pdf/2406.13230v2.pdf","comment":"EMNLP 2024 Camera Ready"},{"id":"http://arxiv.org/abs/2310.10429v2","updated":"2024-11-12T16:39:55Z","published":"2023-10-16T14:13:38Z","title":"Exploiting User Comments for Early Detection of Fake News Prior to\n  Users' Commenting","summary":"  Both accuracy and timeliness are key factors in detecting fake news on social\nmedia. However, most existing methods encounter an accuracy-timeliness dilemma:\nContent-only methods guarantee timeliness but perform moderately because of\nlimited available information, while social con-text-based ones generally\nperform better but inevitably lead to latency because of social context\naccumulation needs. To break such a dilemma, a feasible but not well-studied\nsolution is to leverage social contexts (e.g., comments) from historical news\nfor training a detection model and apply it to newly emerging news without\nsocial contexts. This requires the model to (1) sufficiently learn helpful\nknowledge from social contexts, and (2) be well compatible with situations that\nsocial contexts are available or not. To achieve this goal, we propose to\nabsorb and parameterize useful knowledge from comments in historical news and\nthen inject it into a content-only detection model. Specifically, we design the\nComments ASsisted FakE News Detection method (CAS-FEND), which transfers useful\nknowledge from a comment-aware teacher model to a content-only student model\nand detects newly emerging news with the student model. Experiments show that\nthe CAS-FEND student model outperforms all content-only methods and even\ncomment-aware ones with 1/4 comments as inputs, demonstrating its superiority\nfor early detection.\n","authors":["Qiong Nan","Qiang Sheng","Juan Cao","Yongchun Zhu","Danding Wang","Guang Yang","Jintao Li"],"pdf_url":"https://arxiv.org/pdf/2310.10429v2.pdf","comment":"19 pages, 6 figures, 7 tables. The article has been accepted by\n  Frontiers of Computer Science (FCS), with the DOI:\n  {10.1007/s11704-024-40674-6}"},{"id":"http://arxiv.org/abs/2406.11813v3","updated":"2024-11-12T16:38:37Z","published":"2024-06-17T17:54:40Z","title":"How Do Large Language Models Acquire Factual Knowledge During\n  Pretraining?","summary":"  Despite the recent observation that large language models (LLMs) can store\nsubstantial factual knowledge, there is a limited understanding of the\nmechanisms of how they acquire factual knowledge through pretraining. This work\naddresses this gap by studying how LLMs acquire factual knowledge during\npretraining. The findings reveal several important insights into the dynamics\nof factual knowledge acquisition during pretraining. First, counterintuitively,\nwe observe that pretraining on more data shows no significant improvement in\nthe model's capability to acquire and maintain factual knowledge. Next, there\nis a power-law relationship between training steps and forgetting of\nmemorization and generalization of factual knowledge, and LLMs trained with\nduplicated training data exhibit faster forgetting. Third, training LLMs with\nlarger batch sizes can enhance the models' robustness to forgetting. Overall,\nour observations suggest that factual knowledge acquisition in LLM pretraining\noccurs by progressively increasing the probability of factual knowledge\npresented in the pretraining data at each step. However, this increase is\ndiluted by subsequent forgetting. Based on this interpretation, we demonstrate\nthat we can provide plausible explanations for recently observed behaviors of\nLLMs, such as the poor performance of LLMs on long-tail knowledge and the\nbenefits of deduplicating the pretraining corpus.\n","authors":["Hoyeon Chang","Jinho Park","Seonghyeon Ye","Sohee Yang","Youngkyung Seo","Du-Seong Chang","Minjoon Seo"],"pdf_url":"https://arxiv.org/pdf/2406.11813v3.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.06855v2","updated":"2024-11-12T16:03:24Z","published":"2024-11-11T10:37:11Z","title":"A Unified Multi-Task Learning Architecture for Hate Detection Leveraging\n  User-Based Information","summary":"  Hate speech, offensive language, aggression, racism, sexism, and other\nabusive language are common phenomena in social media. There is a need for\nArtificial Intelligence(AI)based intervention which can filter hate content at\nscale. Most existing hate speech detection solutions have utilized the features\nby treating each post as an isolated input instance for the classification.\nThis paper addresses this issue by introducing a unique model that improves\nhate speech identification for the English language by utilising intra-user and\ninter-user-based information. The experiment is conducted over single-task\nlearning (STL) and multi-task learning (MTL) paradigms that use deep neural\nnetworks, such as convolutional neural networks (CNN), gated recurrent unit\n(GRU), bidirectional encoder representations from the transformer (BERT), and A\nLite BERT (ALBERT). We use three benchmark datasets and conclude that combining\ncertain user features with textual features gives significant improvements in\nmacro-F1 and weighted-F1.\n","authors":["Prashant Kapil","Asif Ekbal"],"pdf_url":"https://arxiv.org/pdf/2411.06855v2.pdf","comment":"7 pages, 1 figure, and two tables. Accepted at the 20th International\n  Conference on Natural Language Processing (ICON) 2023.\n  https://aclanthology.org/2023.icon-1.53"},{"id":"http://arxiv.org/abs/2411.07892v1","updated":"2024-11-12T15:56:48Z","published":"2024-11-12T15:56:48Z","title":"Mapping the Podcast Ecosystem with the Structured Podcast Research\n  Corpus","summary":"  Podcasts provide highly diverse content to a massive listener base through a\nunique on-demand modality. However, limited data has prevented large-scale\ncomputational analysis of the podcast ecosystem. To fill this gap, we introduce\na massive dataset of over 1.1M podcast transcripts that is largely\ncomprehensive of all English language podcasts available through public RSS\nfeeds from May and June of 2020. This data is not limited to text, but rather\nincludes audio features and speaker turns for a subset of 370K episodes, and\nspeaker role inferences and other metadata for all 1.1M episodes. Using this\ndata, we also conduct a foundational investigation into the content, structure,\nand responsiveness of this ecosystem. Together, our data and analyses open the\ndoor to continued computational research of this popular and impactful medium.\n","authors":["Benjamin Litterer","David Jurgens","Dallas Card"],"pdf_url":"https://arxiv.org/pdf/2411.07892v1.pdf","comment":"9 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.05508v2","updated":"2024-11-12T15:36:04Z","published":"2024-11-08T12:08:17Z","title":"An Early FIRST Reproduction and Improvements to Single-Token Decoding\n  for Fast Listwise Reranking","summary":"  Recent advances have demonstrated that large language models (LLMs) excel as\nlistwise rerankers, but their high computational demands remain a barrier to\nwidespread adoption. Further, the traditional language modeling (LM) objective\nis not ideally suited for reranking tasks. FIRST is a novel approach that\naddresses these challenges by integrating a learning-to-rank objective and\nleveraging the logits of only the first generated token, thereby significantly\nreducing inference latency compared to traditional LLM rerankers. In this\nstudy, we extend the evaluation of FIRST to the TREC Deep Learning datasets\n(DL19-22), validating its robustness across diverse domains. We investigate the\ninfluence of different first-stage retrievers on FIRST rerankers, observing\ndiminishing returns and patterns consistent with traditional LLM rerankers.\nThrough applying the FIRST objective to a broader range of backbone models, we\nachieve effectiveness surpassing the original implementation. Our experiments\nconfirm that fast reranking with single-token logits does not compromise\nout-of-domain reranking quality. To better quantify the computational savings\nin the original study, we measure and compare latency to find a 21%-42% gain\nacross various models and benchmarks. Moreover, while LM training implicitly\nimproves zero-shot single-token reranking, our experiments also raise questions\nabout whether LM pre-training may hinder subsequent fine-tuning with the FIRST\nobjective. These findings pave the way for more efficient and effective\nlistwise reranking in future applications.\n","authors":["Zijian Chen","Ronak Pradeep","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05508v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07870v1","updated":"2024-11-12T15:26:17Z","published":"2024-11-12T15:26:17Z","title":"Trustful LLMs: Customizing and Grounding Text Generation with Knowledge\n  Bases and Dual Decoders","summary":"  Although people are impressed by the content generation skills of large\nlanguage models, the use of LLMs, such as ChatGPT, is limited by the domain\ngrounding of the content. The correctness and groundedness of the generated\ncontent need to be based on a verified context, such as results from\nRetrieval-Augmented Generation (RAG). One important issue when adapting LLMs to\na customized domain is that the generated responses are often incomplete, or\nthe additions are not verified and may even be hallucinated. Prior studies on\nhallucination detection have focused on evaluation metrics, which are not\neasily adaptable to dynamic domains and can be vulnerable to attacks like\njail-breaking. In this work, we propose 1) a post-processing algorithm that\nleverages knowledge triplets in RAG context to correct hallucinations and 2) a\ndual-decoder model that fuses RAG context to guide the generation process.\n","authors":["Xiaofeng Zhu","Jaya Krishna Mandivarapu"],"pdf_url":"https://arxiv.org/pdf/2411.07870v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07858v1","updated":"2024-11-12T15:15:20Z","published":"2024-11-12T15:15:20Z","title":"Verbosity $\\neq$ Veracity: Demystify Verbosity Compensation Behavior of\n  Large Language Models","summary":"  When unsure about an answer, humans often respond with more words than\nnecessary, hoping that part of the response will be correct. We observe a\nsimilar behavior in large language models (LLMs), which we term \"Verbosity\nCompensation\" (VC). VC is harmful because it confuses the user understanding,\nleading to low efficiency, and influences the LLM services by increasing the\nlatency and cost of generating useless tokens. In this paper, we present the\nfirst work that defines and analyzes Verbosity Compensation, explores its\ncauses, and proposes a simple mitigating approach. We define Verbosity\nCompensation as the behavior of generating responses that can be compressed\nwithout information loss when prompted to write concisely. Our experiments,\nconducted on five datasets of knowledge and reasoning-based QA tasks with 14\nnewly developed LLMs, reveal three conclusions. 1) We reveal a pervasive\npresence of verbosity compensation across all models and all datasets. Notably,\nGPT-4 exhibits a VC frequency of 50.40%. 2) We reveal the large performance gap\nbetween verbose and concise responses, with a notable difference of 27.61% on\nthe Qasper dataset. We also demonstrate that this difference does not naturally\ndiminish as LLM capability increases. Both 1) and 2) highlight the urgent need\nto mitigate the frequency of VC behavior and disentangle verbosity with\nveracity. We propose a simple yet effective cascade algorithm that replaces the\nverbose responses with the other model-generated responses. The results show\nthat our approach effectively alleviates the VC of the Mistral model from\n63.81% to 16.16% on the Qasper dataset. 3) We also find that verbose responses\nexhibit higher uncertainty across all five datasets, suggesting a strong\nconnection between verbosity and model uncertainty. Our dataset and code are\navailable at https://github.com/psunlpgroup/VerbosityLLM.\n","authors":["Yusen Zhang","Sarkar Snigdha Sarathi Das","Rui Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07858v1.pdf","comment":"19 pages, 6 figures"},{"id":"http://arxiv.org/abs/2411.07854v1","updated":"2024-11-12T15:06:06Z","published":"2024-11-12T15:06:06Z","title":"Tucano: Advancing Neural Text Generation for Portuguese","summary":"  Significant advances have been made in natural language processing in recent\nyears. However, our current deep learning approach to language modeling\nrequires substantial resources in terms of data and computation. One of the\nside effects of this data-hungry paradigm is the current schism between\nlanguages, separating those considered high-resource, where most of the\ndevelopment happens and resources are available, and the low-resource ones,\nwhich struggle to attain the same level of performance and autonomy. This study\naims to introduce a new set of resources to stimulate the future development of\nneural text generation in Portuguese. In this work, we document the development\nof GigaVerbo, a concatenation of deduplicated Portuguese text corpora amounting\nto 200 billion tokens. Via this corpus, we trained a series of\ndecoder-transformers named Tucano. Our models perform equal or superior to\nother Portuguese and multilingual language models of similar size in several\nPortuguese benchmarks. The evaluation of our models also reveals that model\nperformance on many currently available benchmarks used by the Portuguese NLP\ncommunity has little to no correlation with the scaling of token ingestion\nduring training, highlighting the limitations of such evaluations when it comes\nto the assessment of Portuguese generative language models. All derivatives of\nour study are openly released on GitHub and Hugging Face. See\nhttps://nkluge-correa.github.io/Tucano/\n","authors":["Nicholas Kluge Corr√™a","Aniket Sen","Sophia Falk","Shiza Fatimah"],"pdf_url":"https://arxiv.org/pdf/2411.07854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07850v1","updated":"2024-11-12T15:01:47Z","published":"2024-11-12T15:01:47Z","title":"IAE: Irony-based Adversarial Examples for Sentiment Analysis Systems","summary":"  Adversarial examples, which are inputs deliberately perturbed with\nimperceptible changes to induce model errors, have raised serious concerns for\nthe reliability and security of deep neural networks (DNNs). While adversarial\nattacks have been extensively studied in continuous data domains such as\nimages, the discrete nature of text presents unique challenges. In this paper,\nwe propose Irony-based Adversarial Examples (IAE), a method that transforms\nstraightforward sentences into ironic ones to create adversarial text. This\napproach exploits the rhetorical device of irony, where the intended meaning is\nopposite to the literal interpretation, requiring a deeper understanding of\ncontext to detect. The IAE method is particularly challenging due to the need\nto accurately locate evaluation words, substitute them with appropriate\ncollocations, and expand the text with suitable ironic elements while\nmaintaining semantic coherence. Our research makes the following key\ncontributions: (1) We introduce IAE, a strategy for generating textual\nadversarial examples using irony. This method does not rely on pre-existing\nirony corpora, making it a versatile tool for creating adversarial text in\nvarious NLP tasks. (2) We demonstrate that the performance of several\nstate-of-the-art deep learning models on sentiment analysis tasks significantly\ndeteriorates when subjected to IAE attacks. This finding underscores the\nsusceptibility of current NLP systems to adversarial manipulation through\nirony. (3) We compare the impact of IAE on human judgment versus NLP systems,\nrevealing that humans are less susceptible to the effects of irony in text.\n","authors":["Xiaoyin Yi","Jiacheng Huang"],"pdf_url":"https://arxiv.org/pdf/2411.07850v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07845v1","updated":"2024-11-12T14:53:12Z","published":"2024-11-12T14:53:12Z","title":"Ethical Concern Identification in NLP: A Corpus of ACL Anthology Ethics\n  Statements","summary":"  What ethical concerns, if any, do LLM researchers have? We introduce EthiCon,\na corpus of 1,580 ethical concern statements extracted from scientific papers\npublished in the ACL Anthology. We extract ethical concern keywords from the\nstatements and show promising results in automating the concern identification\nprocess. Through a survey, we compare the ethical concerns of the corpus to the\nconcerns listed by the general public and professionals in the field. Finally,\nwe compare our retrieved ethical concerns with existing taxonomies pointing to\ngaps and future research directions.\n","authors":["Antonia Karamolegkou","Sandrine Schiller Hansen","Ariadni Christopoulou","Filippos Stamatiou","Anne Lauscher","Anders S√∏gaard"],"pdf_url":"https://arxiv.org/pdf/2411.07845v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07843v1","updated":"2024-11-12T14:51:41Z","published":"2024-11-12T14:51:41Z","title":"Chain Association-based Attacking and Shielding Natural Language\n  Processing Systems","summary":"  Association as a gift enables people do not have to mention something in\ncompletely straightforward words and allows others to understand what they\nintend to refer to. In this paper, we propose a chain association-based\nadversarial attack against natural language processing systems, utilizing the\ncomprehension gap between humans and machines. We first generate a chain\nassociation graph for Chinese characters based on the association paradigm for\nbuilding search space of potential adversarial examples. Then, we introduce an\ndiscrete particle swarm optimization algorithm to search for the optimal\nadversarial examples. We conduct comprehensive experiments and show that\nadvanced natural language processing models and applications, including large\nlanguage models, are vulnerable to our attack, while humans appear good at\nunderstanding the perturbed text. We also explore two methods, including\nadversarial training and associative graph-based recovery, to shield systems\nfrom chain association-based attack. Since a few examples that use some\nderogatory terms, this paper contains materials that may be offensive or\nupsetting to some people.\n","authors":["Jiacheng Huang","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07843v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20178v2","updated":"2024-11-12T14:45:18Z","published":"2024-10-26T13:19:57Z","title":"LLMs Can Evolve Continually on Modality for X-Modal Reasoning","summary":"  Multimodal Large Language Models (MLLMs) have gained significant attention\ndue to their impressive capabilities in multimodal understanding. However,\nexisting methods rely heavily on extensive modal-specific pretraining and\njoint-modal tuning, leading to significant computational burdens when expanding\nto new modalities. In this paper, we propose PathWeave, a flexible and scalable\nframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs\nto continually EVolve on modalities for $\\mathbb{X}$-modal reasoning. We\nleverage the concept of Continual Learning and develop an incremental training\nstrategy atop pre-trained MLLMs, enabling their expansion to new modalities\nusing uni-modal data, without executing joint-modal pretraining. In detail, a\nnovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and\ncross-modal adapters are seamlessly integrated to facilitate efficient modality\nalignment and collaboration. Additionally, an MoE-based gating module is\napplied between two types of adapters to further enhance the multimodal\ninteraction. To investigate the proposed method, we establish a challenging\nbenchmark called Continual Learning of Modality (MCL), which consists of\nhigh-quality QA data from five distinct modalities: image, video, audio, depth\nand point cloud. Extensive experiments demonstrate the effectiveness of the\nproposed AnA framework on learning plasticity and memory stability during\ncontinual learning. Furthermore, PathWeave performs comparably to\nstate-of-the-art MLLMs while concurrently reducing parameter training burdens\nby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave\n","authors":["Jiazuo Yu","Haomiao Xiong","Lu Zhang","Haiwen Diao","Yunzhi Zhuge","Lanqing Hong","Dong Wang","Huchuan Lu","You He","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2410.20178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06008v2","updated":"2024-11-12T14:30:28Z","published":"2024-11-08T23:02:59Z","title":"The Dark Patterns of Personalized Persuasion in Large Language Models:\n  Exposing Persuasive Linguistic Features for Big Five Personality Traits in\n  LLMs Responses","summary":"  This study explores how the Large Language Models (LLMs) adjust linguistic\nfeatures to create personalized persuasive outputs. While research showed that\nLLMs personalize outputs, a gap remains in understanding the linguistic\nfeatures of their persuasive capabilities. We identified 13 linguistic features\ncrucial for influencing personalities across different levels of the Big Five\nmodel of personality. We analyzed how prompts with personality trait\ninformation influenced the output of 19 LLMs across five model families. The\nfindings show that models use more anxiety-related words for neuroticism,\nincrease achievement-related words for conscientiousness, and employ fewer\ncognitive processes words for openness to experience. Some model families excel\nat adapting language for openness to experience, others for conscientiousness,\nwhile only one model adapts language for neuroticism. Our findings show how\nLLMs tailor responses based on personality cues in prompts, indicating their\npotential to create persuasive content affecting the mind and well-being of the\nrecipients.\n","authors":["Wiktoria Mieleszczenko-Kowszewicz","Dawid P≈Çudowski","Filip Ko≈Çodziejczyk","Jakub ≈öwistak","Julian Sienkiewicz","Przemys≈Çaw Biecek"],"pdf_url":"https://arxiv.org/pdf/2411.06008v2.pdf","comment":"31 pages"},{"id":"http://arxiv.org/abs/2411.07820v1","updated":"2024-11-12T14:12:45Z","published":"2024-11-12T14:12:45Z","title":"Query Optimization for Parametric Knowledge Refinement in\n  Retrieval-Augmented Large Language Models","summary":"  We introduce the \\textit{Extract-Refine-Retrieve-Read} (ERRR) framework, a\nnovel approach designed to bridge the pre-retrieval information gap in\nRetrieval-Augmented Generation (RAG) systems through query optimization\ntailored to meet the specific knowledge requirements of Large Language Models\n(LLMs). Unlike conventional query optimization techniques used in RAG, the ERRR\nframework begins by extracting parametric knowledge from LLMs, followed by\nusing a specialized query optimizer for refining these queries. This process\nensures the retrieval of only the most pertinent information essential for\ngenerating accurate responses. Moreover, to enhance flexibility and reduce\ncomputational costs, we propose a trainable scheme for our pipeline that\nutilizes a smaller, tunable model as the query optimizer, which is refined\nthrough knowledge distillation from a larger teacher model. Our evaluations on\nvarious question-answering (QA) datasets and with different retrieval systems\nshow that ERRR consistently outperforms existing baselines, proving to be a\nversatile and cost-effective module for improving the utility and accuracy of\nRAG systems.\n","authors":["Youan Cong","Cheng Wang","Pritom Saha Akash","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2411.07820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.05894v3","updated":"2024-11-12T14:06:49Z","published":"2024-05-09T16:45:27Z","title":"Efficient LLM Comparative Assessment: a Product of Experts Framework for\n  Pairwise Comparisons","summary":"  LLM-as-a-judge approaches are a practical and effective way of assessing a\nrange of text tasks. However, when using pairwise comparisons to rank a set of\ncandidates, the computational cost scales quadratically with the number of\ncandidates, which has practical limitations. This paper introduces a Product of\nExpert (PoE) framework for efficient LLM Comparative Assessment. Here\nindividual comparisons are considered experts that provide information on a\npair's score difference. The PoE framework combines the information from these\nexperts to yield an expression that can be maximized with respect to the\nunderlying set of candidates, and is highly flexible where any form of expert\ncan be assumed. When Gaussian experts are used one can derive simple\nclosed-form solutions for the optimal candidate ranking, and expressions for\nselecting which comparisons should be made to maximize the probability of this\nranking. Our approach enables efficient comparative assessment, where by using\nonly a small subset of the possible comparisons, one can generate score\npredictions that correlate well with human judgements. We evaluate the approach\non multiple NLG tasks and demonstrate that our framework can yield considerable\ncomputational savings when performing pairwise comparative assessment. With\nmany candidate texts, using as few as 2% of comparisons the PoE solution can\nachieve similar performance to when all comparisons are used.\n","authors":["Adian Liusie","Vatsal Raina","Yassir Fathullah","Mark Gales"],"pdf_url":"https://arxiv.org/pdf/2405.05894v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12186v3","updated":"2024-11-12T13:24:25Z","published":"2024-09-18T17:57:57Z","title":"Qwen2.5-Coder Technical Report","summary":"  In this report, we introduce the Qwen2.5-Coder series, a significant upgrade\nfrom its predecessor, CodeQwen1.5. This series includes six models:\nQwen2.5-Coder-(0.5B/1.5B/3B/7B/14B/32B). As a code-specific model,\nQwen2.5-Coder is built upon the Qwen2.5 architecture and continues pretrained\non a vast corpus of over 5.5 trillion tokens. Through meticulous data cleaning,\nscalable synthetic data generation, and balanced data mixing, Qwen2.5-Coder\ndemonstrates impressive code generation capabilities while retaining general\nand math skills. These models have been evaluated on a wide range of\ncode-related tasks, achieving state-of-the-art (SOTA) performance across more\nthan 10 benchmarks, including code generation, completion, reasoning, and\nrepair, consistently outperforming larger models of the same model size. We\nbelieve that the release of the Qwen2.5-Coder series will advance research in\ncode intelligence and, with its permissive licensing, support wider adoption by\ndevelopers in real-world applications.\n","authors":["Binyuan Hui","Jian Yang","Zeyu Cui","Jiaxi Yang","Dayiheng Liu","Lei Zhang","Tianyu Liu","Jiajun Zhang","Bowen Yu","Keming Lu","Kai Dang","Yang Fan","Yichang Zhang","An Yang","Rui Men","Fei Huang","Bo Zheng","Yibo Miao","Shanghaoran Quan","Yunlong Feng","Xingzhang Ren","Xuancheng Ren","Jingren Zhou","Junyang Lin"],"pdf_url":"https://arxiv.org/pdf/2409.12186v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07773v1","updated":"2024-11-12T13:14:09Z","published":"2024-11-12T13:14:09Z","title":"Likelihood as a Performance Gauge for Retrieval-Augmented Generation","summary":"  Recent work finds that retrieval-augmented generation with large language\nmodels is prone to be influenced by the order of retrieved documents in the\ncontext. However, the lack of in-depth analysis limits the use of this\nphenomenon for prompt engineering in practice. In this study, we posit that\nlikelihoods serve as an effective gauge for language model performance. Through\nexperiments on two question-answering datasets with a variety of\nstate-of-the-art language models, we reveal correlations between answer\naccuracy and the likelihood of the question at both the corpus level and the\ninstance level. In addition, we find that question likelihood can also indicate\nthe position of the task-relevant information in the context. Based on these\nfindings, we propose two methods that use question likelihood as a gauge for\nselecting and constructing prompts that lead to better performance. We\ndemonstrate their effectiveness with experiments. In addition, our\nlikelihood-based methods are efficient, as they only need to compute the\nlikelihood of the input, requiring much fewer language model passes than\nheuristic prompt engineering methods that require generating responses. Our\nanalysis deepens our understanding of how input prompts affect model\nperformance and provides a promising direction for efficient prompt\noptimization.\n","authors":["Tianyu Liu","Jirui Qi","Paul He","Arianna Bisazza","Mrinmaya Sachan","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07773v1.pdf","comment":"Under review at NAACL 2025. Code is available at\n  https://github.com/lyutyuh/poptimizer"},{"id":"http://arxiv.org/abs/2411.07772v1","updated":"2024-11-12T13:13:20Z","published":"2024-11-12T13:13:20Z","title":"Automatic Album Sequencing","summary":"  Album sequencing is a critical part of the album production process.\nRecently, a data-driven approach was proposed that sequences general\ncollections of independent media by extracting the narrative essence of the\nitems in the collections. While this approach implies an album sequencing\ntechnique, it is not widely accessible to a less technical audience, requiring\nadvanced knowledge of machine learning techniques to use. To address this, we\nintroduce a new user-friendly web-based tool that allows a less technical\naudience to upload music tracks, execute this technique in one click, and\nsubsequently presents the result in a clean visualization to the user. To both\nincrease the number of templates available to the user and address shortcomings\nof previous work, we also introduce a new direct transformer-based album\nsequencing method. We find that our more direct method outperforms a random\nbaseline but does not reach the same performance as the narrative essence\napproach. Both methods are included in our web-based user interface, and this\n-- alongside a full copy of our implementation -- is publicly available at\nhttps://github.com/dylanashley/automatic-album-sequencing\n","authors":["Vincent Herrmann","Dylan R. Ashley","J√ºrgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2411.07772v1.pdf","comment":"presented as a late breaking demo in the 25th International Society\n  for Music Information Retrieval Conference; 3 pages in main text, 3 figures\n  in main text; source code available at\n  https://github.com/dylanashley/automatic-album-sequencing"},{"id":"http://arxiv.org/abs/2411.04799v2","updated":"2024-11-12T12:57:58Z","published":"2024-11-07T15:38:25Z","title":"Kwai-STaR: Transform LLMs into State-Transition Reasoners","summary":"  Mathematical reasoning presents a significant challenge to the cognitive\ncapabilities of LLMs. Various methods have been proposed to enhance the\nmathematical ability of LLMs. However, few recognize the value of state\ntransition for LLM reasoning. In this work, we define mathematical\nproblem-solving as a process of transiting from an initial unsolved state to\nthe final resolved state, and propose Kwai-STaR framework, which transforms\nLLMs into State-Transition Reasoners to improve their intuitive reasoning\ncapabilities. Our approach comprises three main steps: (1) Define the state\nspace tailored to the mathematical reasoning. (2) Generate state-transition\ndata based on the state space. (3) Convert original LLMs into State-Transition\nReasoners via a curricular training strategy. Our experiments validate the\neffectiveness of Kwai-STaR in enhancing mathematical reasoning: After training\non the small-scale Kwai-STaR dataset, general LLMs, including Mistral-7B and\nLLaMA-3, achieve considerable performance gain on the GSM8K and GSM-Hard\ndataset. Additionally, the state transition-based design endows Kwai-STaR with\nremarkable training and inference efficiency. Further experiments are underway\nto establish the generality of Kwai-STaR.\n","authors":["Xingyu Lu","Yuhang Hu","Changyi Liu","Tianke Zhang","Zhenyu Yang","Zhixiang Ding","Shengsheng Qian","Meng Du","Ruiwen Kang","Kaiyu Tang","Fan Yang","Tingting Gao","Di Zhang","Hai-Tao Zheng","Bin Wen"],"pdf_url":"https://arxiv.org/pdf/2411.04799v2.pdf","comment":"6 pages, 2 figures"},{"id":"http://arxiv.org/abs/2411.07763v1","updated":"2024-11-12T12:52:17Z","published":"2024-11-12T12:52:17Z","title":"Spider 2.0: Evaluating Language Models on Real-World Enterprise\n  Text-to-SQL Workflows","summary":"  Real-world enterprise text-to-SQL workflows often involve complex cloud or\nlocal data across various database systems, multiple SQL queries in various\ndialects, and diverse operations from data transformation to analytics. We\nintroduce Spider 2.0, an evaluation framework comprising 632 real-world\ntext-to-SQL workflow problems derived from enterprise-level database use cases.\nThe databases in Spider 2.0 are sourced from real data applications, often\ncontaining over 1,000 columns and stored in local or cloud database systems\nsuch as BigQuery and Snowflake. We show that solving problems in Spider 2.0\nfrequently requires understanding and searching through database metadata,\ndialect documentation, and even project-level codebases. This challenge calls\nfor models to interact with complex SQL workflow environments, process\nextremely long contexts, perform intricate reasoning, and generate multiple SQL\nqueries with diverse operations, often exceeding 100 lines, which goes far\nbeyond traditional text-to-SQL challenges. Our evaluations indicate that based\non o1-preview, our code agent framework successfully solves only 17.0% of the\ntasks, compared with 91.2% on Spider 1.0 and 73.0% on BIRD. Our results on\nSpider 2.0 show that while language models have demonstrated remarkable\nperformance in code generation -- especially in prior text-to-SQL benchmarks --\nthey require significant improvement in order to achieve adequate performance\nfor real-world enterprise usage. Progress on Spider 2.0 represents crucial\nsteps towards developing intelligent, autonomous, code agents for real-world\nenterprise settings. Our code, baseline models, and data are available at\nhttps://spider2-sql.github.io.\n","authors":["Fangyu Lei","Jixuan Chen","Yuxiao Ye","Ruisheng Cao","Dongchan Shin","Hongjin Su","Zhaoqing Suo","Hongcheng Gao","Wenjing Hu","Pengcheng Yin","Victor Zhong","Caiming Xiong","Ruoxi Sun","Qian Liu","Sida Wang","Tao Yu"],"pdf_url":"https://arxiv.org/pdf/2411.07763v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.00722v2","updated":"2024-11-12T11:49:33Z","published":"2024-04-26T11:57:21Z","title":"LLMs for Generating and Evaluating Counterfactuals: A Comprehensive\n  Study","summary":"  As NLP models become more complex, understanding their decisions becomes more\ncrucial. Counterfactuals (CFs), where minimal changes to inputs flip a model's\nprediction, offer a way to explain these models. While Large Language Models\n(LLMs) have shown remarkable performance in NLP tasks, their efficacy in\ngenerating high-quality CFs remains uncertain. This work fills this gap by\ninvestigating how well LLMs generate CFs for two NLU tasks. We conduct a\ncomprehensive comparison of several common LLMs, and evaluate their CFs,\nassessing both intrinsic metrics, and the impact of these CFs on data\naugmentation. Moreover, we analyze differences between human and LLM-generated\nCFs, providing insights for future research directions. Our results show that\nLLMs generate fluent CFs, but struggle to keep the induced changes minimal.\nGenerating CFs for Sentiment Analysis (SA) is less challenging than NLI where\nLLMs show weaknesses in generating CFs that flip the original label. This also\nreflects on the data augmentation performance, where we observe a large gap\nbetween augmenting with human and LLMs CFs. Furthermore, we evaluate LLMs'\nability to assess CFs in a mislabelled data setting, and show that they have a\nstrong bias towards agreeing with the provided labels. GPT4 is more robust\nagainst this bias and its scores correlate well with automatic metrics. Our\nfindings reveal several limitations and point to potential future work\ndirections.\n","authors":["Van Bach Nguyen","Paul Youssef","Christin Seifert","J√∂rg Schl√∂tterer"],"pdf_url":"https://arxiv.org/pdf/2405.00722v2.pdf","comment":"Accepted to EMNLP Findings 2024"},{"id":"http://arxiv.org/abs/2405.07863v3","updated":"2024-11-12T11:18:43Z","published":"2024-05-13T15:50:39Z","title":"RLHF Workflow: From Reward Modeling to Online RLHF","summary":"  We present the workflow of Online Iterative Reinforcement Learning from Human\nFeedback (RLHF) in this technical report, which is widely reported to\noutperform its offline counterpart by a large margin in the recent large\nlanguage model (LLM) literature. However, existing open-source RLHF projects\nare still largely confined to the offline learning setting. In this technical\nreport, we aim to fill in this gap and provide a detailed recipe that is easy\nto reproduce for online iterative RLHF. In particular, since online human\nfeedback is usually infeasible for open-source communities with limited\nresources, we start by constructing preference models using a diverse set of\nopen-source datasets and use the constructed proxy preference model to\napproximate human feedback. Then, we discuss the theoretical insights and\nalgorithmic principles behind online iterative RLHF, followed by a detailed\npractical implementation. Our trained LLM achieves impressive performance on\nLLM chatbot benchmarks, including AlpacaEval-2, Arena-Hard, and MT-Bench, as\nwell as other academic benchmarks such as HumanEval and TruthfulQA. We have\nshown that supervised fine-tuning (SFT) and iterative RLHF can obtain\nstate-of-the-art performance with fully open-source datasets. Further, we have\nmade our models, curated datasets, and comprehensive step-by-step code\nguidebooks publicly available. Please refer to\nhttps://github.com/RLHFlow/RLHF-Reward-Modeling and\nhttps://github.com/RLHFlow/Online-RLHF for more detailed information.\n","authors":["Hanze Dong","Wei Xiong","Bo Pang","Haoxiang Wang","Han Zhao","Yingbo Zhou","Nan Jiang","Doyen Sahoo","Caiming Xiong","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.07863v3.pdf","comment":"Published in Transactions on Machine Learning Research (09/2024)"},{"id":"http://arxiv.org/abs/2407.14192v2","updated":"2024-11-12T11:09:35Z","published":"2024-07-19T10:40:10Z","title":"LeKUBE: A Legal Knowledge Update BEnchmark","summary":"  Recent advances in Large Language Models (LLMs) have significantly shaped the\napplications of AI in multiple fields, including the studies of legal\nintelligence. Trained on extensive legal texts, including statutes and legal\ndocuments, the legal LLMs can capture important legal knowledge/concepts\neffectively and provide important support for downstream legal applications\nsuch as legal consultancy. Yet, the dynamic nature of legal statutes and\ninterpretations also poses new challenges to the use of LLMs in legal\napplications. Particularly, how to update the legal knowledge of LLMs\neffectively and efficiently has become an important research problem in\npractice. Existing benchmarks for evaluating knowledge update methods are\nmostly designed for the open domain and cannot address the specific challenges\nof the legal domain, such as the nuanced application of new legal knowledge,\nthe complexity and lengthiness of legal regulations, and the intricate nature\nof legal reasoning. To address this gap, we introduce the Legal Knowledge\nUpdate BEnchmark, i.e. LeKUBE, which evaluates knowledge update methods for\nlegal LLMs across five dimensions. Specifically, we categorize the needs of\nknowledge updates in the legal domain with the help of legal professionals, and\nthen hire annotators from law schools to create synthetic updates to the\nChinese Criminal and Civil Code as well as sets of questions of which the\nanswers would change after the updates. Through a comprehensive evaluation of\nstate-of-the-art knowledge update methods, we reveal a notable gap between\nexisting knowledge update methods and the unique needs of the legal domain,\nemphasizing the need for further research and development of knowledge update\nmechanisms tailored for legal LLMs.\n","authors":["Changyue Wang","Weihang Su","Hu Yiran","Qingyao Ai","Yueyue Wu","Cheng Luo","Yiqun Liu","Min Zhang","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2407.14192v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12036v2","updated":"2024-11-12T10:12:49Z","published":"2024-07-01T05:37:17Z","title":"Exploring Advanced Large Language Models with LLMsuite","summary":"  This tutorial explores the advancements and challenges in the development of\nLarge Language Models (LLMs) such as ChatGPT and Gemini. It addresses inherent\nlimitations like temporal knowledge cutoffs, mathematical inaccuracies, and the\ngeneration of incorrect information, proposing solutions like Retrieval\nAugmented Generation (RAG), Program-Aided Language Models (PAL), and frameworks\nsuch as ReAct and LangChain. The integration of these techniques enhances LLM\nperformance and reliability, especially in multi-step reasoning and complex\ntask execution. The paper also covers fine-tuning strategies, including\ninstruction fine-tuning, parameter-efficient methods like LoRA, and\nReinforcement Learning from Human Feedback (RLHF) as well as Reinforced\nSelf-Training (ReST). Additionally, it provides a comprehensive survey of\ntransformer architectures and training techniques for LLMs. The source code can\nbe accessed by contacting the author via email for a request.\n","authors":["Giorgio Roffo"],"pdf_url":"https://arxiv.org/pdf/2407.12036v2.pdf","comment":"Keywords: Language Model Benchmarking, Pre-Trained LLM Comparison,\n  LLM Performance Analysis, NLP Model Evaluation Tools, Public Dataset\n  Inference for LLMs, BLEU and ROUGE Metrics for LLM, Open Source LLM Testing\n  Tools, Large Language Model Evaluation Software, NLP Benchmarking Suite,\n  Comprehensive LLM Evaluation Toolkit"},{"id":"http://arxiv.org/abs/2406.16620v3","updated":"2024-11-12T10:02:12Z","published":"2024-06-24T13:05:39Z","title":"OmAgent: A Multi-modal Agent Framework for Complex Video Understanding\n  with Task Divide-and-Conquer","summary":"  Recent advancements in Large Language Models (LLMs) have expanded their\ncapabilities to multimodal contexts, including comprehensive video\nunderstanding. However, processing extensive videos such as 24-hour CCTV\nfootage or full-length films presents significant challenges due to the vast\ndata and processing demands. Traditional methods, like extracting key frames or\nconverting frames to text, often result in substantial information loss. To\naddress these shortcomings, we develop OmAgent, efficiently stores and\nretrieves relevant video frames for specific queries, preserving the detailed\ncontent of videos. Additionally, it features an Divide-and-Conquer Loop capable\nof autonomous reasoning, dynamically invoking APIs and tools to enhance query\nprocessing and accuracy. This approach ensures robust video understanding,\nsignificantly reducing information loss. Experimental results affirm OmAgent's\nefficacy in handling various types of videos and complex tasks. Moreover, we\nhave endowed it with greater autonomy and a robust tool-calling system,\nenabling it to accomplish even more intricate tasks.\n","authors":["Lu Zhang","Tiancheng Zhao","Heting Ying","Yibo Ma","Kyusong Lee"],"pdf_url":"https://arxiv.org/pdf/2406.16620v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07656v1","updated":"2024-11-12T09:14:16Z","published":"2024-11-12T09:14:16Z","title":"Mitigating Bias in Queer Representation within Large Language Models: A\n  Collaborative Agent Approach","summary":"  Large Language Models (LLMs) often perpetuate biases in pronoun usage,\nleading to misrepresentation or exclusion of queer individuals. This paper\naddresses the specific problem of biased pronoun usage in LLM outputs,\nparticularly the inappropriate use of traditionally gendered pronouns (\"he,\"\n\"she\") when inclusive language is needed to accurately represent all\nidentities. We introduce a collaborative agent pipeline designed to mitigate\nthese biases by analyzing and optimizing pronoun usage for inclusivity. Our\nmulti-agent framework includes specialized agents for both bias detection and\ncorrection. Experimental evaluations using the Tango dataset-a benchmark\nfocused on gender pronoun usage-demonstrate that our approach significantly\nimproves inclusive pronoun classification, achieving a 32.6 percentage point\nincrease over GPT-4o in correctly disagreeing with inappropriate traditionally\ngendered pronouns $(\\chi^2 = 38.57, p < 0.0001)$. These results accentuate the\npotential of agent-driven frameworks in enhancing fairness and inclusivity in\nAI-generated content, demonstrating their efficacy in reducing biases and\npromoting socially responsible AI.\n","authors":["Tianyi Huang","Arya Somasundaram"],"pdf_url":"https://arxiv.org/pdf/2411.07656v1.pdf","comment":"NeurIPS 2024 Queer in AI Workshop"},{"id":"http://arxiv.org/abs/2409.18412v3","updated":"2024-11-12T09:11:37Z","published":"2024-09-27T03:00:29Z","title":"SciDFM: A Large Language Model with Mixture-of-Experts for Science","summary":"  Recently, there has been a significant upsurge of interest in leveraging\nlarge language models (LLMs) to assist scientific discovery. However, most LLMs\nonly focus on general science, while they lack domain-specific knowledge, such\nas chemical molecules and amino acid sequences. To bridge these gaps, we\nintroduce SciDFM, a mixture-of-experts LLM, which is trained from scratch and\nis able to conduct college-level scientific reasoning and understand molecules\nand amino acid sequences. We collect a large-scale training corpus containing\nnumerous scientific papers and books from different disciplines as well as data\nfrom domain-specific databases. We further fine-tune the pre-trained model on\nlots of instruction data to improve performances on downstream benchmarks. From\nexperiment results, we show that SciDFM achieves strong performance on general\nscientific benchmarks such as SciEval and SciQ, and it reaches a SOTA\nperformance on domain-specific benchmarks among models of similar size. We\nfurther analyze the expert layers and show that the results of expert selection\nvary with data from different disciplines. To benefit the broader research\ncommunity, we open-source SciDFM at\nhttps://huggingface.co/OpenDFM/SciDFM-MoE-A5.6B-v1.0.\n","authors":["Liangtai Sun","Danyu Luo","Da Ma","Zihan Zhao","Baocai Chen","Zhennan Shen","Su Zhu","Lu Chen","Xin Chen","Kai Yu"],"pdf_url":"https://arxiv.org/pdf/2409.18412v3.pdf","comment":"12 pages, 1 figure, 9 tables. Technical Report, accepted by NeurIPS\n  2024 Workshop FM4Science"},{"id":"http://arxiv.org/abs/2404.12866v2","updated":"2024-11-12T08:59:30Z","published":"2024-04-19T13:05:37Z","title":"How Does the Textual Information Affect the Retrieval of Multimodal\n  In-Context Learning?","summary":"  The increase in parameter size of multimodal large language models (MLLMs)\nintroduces significant capabilities, particularly in-context learning, where\nMLLMs enhance task performance without updating pre-trained parameters. This\neffectiveness, however, hinges on the appropriate selection of in-context\nexamples, a process that is currently biased towards visual data, overlooking\ntextual information. Furthermore, the area of supervised retrievers for MLLMs,\ncrucial for optimal in-context example selection, continues to be\nuninvestigated. Our study offers an in-depth evaluation of the impact of\ntextual information on the unsupervised selection of in-context examples in\nmultimodal contexts, uncovering a notable sensitivity of retriever performance\nto the employed modalities. Responding to this, we introduce a novel supervised\nMLLM-retriever MSIER that employs a neural network to select examples that\nenhance multimodal in-context learning efficiency. This approach is validated\nthrough extensive testing across three distinct tasks, demonstrating the\nmethod's effectiveness. Additionally, we investigate the influence of\nmodalities on our supervised retrieval method's training and pinpoint factors\ncontributing to our model's success. This exploration paves the way for future\nadvancements, highlighting the potential for refined in-context learning in\nMLLMs through the strategic use of multimodal data.\n","authors":["Yang Luo","Zangwei Zheng","Zirui Zhu","Yang You"],"pdf_url":"https://arxiv.org/pdf/2404.12866v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2311.10944v5","updated":"2024-11-12T08:31:22Z","published":"2023-11-18T02:44:33Z","title":"Deception Detection from Linguistic and Physiological Data Streams Using\n  Bimodal Convolutional Neural Networks","summary":"  Deception detection is gaining increasing interest due to ethical and\nsecurity concerns. This paper explores the application of convolutional neural\nnetworks for the purpose of multimodal deception detection. We use a dataset\nbuilt by interviewing 104 subjects about two topics, with one truthful and one\nfalsified response from each subject about each topic. In particular, we make\nthree main contributions. First, we extract linguistic and physiological\nfeatures from this data to train and construct the neural network models.\nSecond, we propose a fused convolutional neural network model using both\nmodalities in order to achieve an improved overall performance. Third, we\ncompare our new approach with earlier methods designed for multimodal deception\ndetection. We find that our system outperforms regular classification methods;\nour results indicate the feasibility of using neural networks for deception\ndetection even in the presence of limited amounts of data.\n","authors":["Panfeng Li","Mohamed Abouelenien","Rada Mihalcea","Zhicheng Ding","Qikai Yang","Yiming Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.10944v5.pdf","comment":"Accepted by 2024 5th International Conference on Information Science,\n  Parallel and Distributed Systems"},{"id":"http://arxiv.org/abs/2405.06219v3","updated":"2024-11-12T08:18:45Z","published":"2024-05-10T03:06:24Z","title":"SKVQ: Sliding-window Key and Value Cache Quantization for Large Language\n  Models","summary":"  Large language models (LLMs) can now handle longer sequences of tokens,\nenabling complex tasks like book understanding and generating lengthy novels.\nHowever, the key-value (KV) cache required for LLMs consumes substantial memory\nas context length increasing, becoming the bottleneck for deployment. In this\npaper, we present a strategy called SKVQ, which stands for sliding-window KV\ncache quantization, to address the issue of extremely low bitwidth KV cache\nquantization. To achieve this, SKVQ rearranges the channels of the KV cache in\norder to improve the similarity of channels in quantization groups, and applies\nclipped dynamic quantization at the group level. Additionally, SKVQ ensures\nthat the most recent window tokens in the KV cache are preserved with high\nprecision. This helps maintain the accuracy of a small but important portion of\nthe KV cache.SKVQ achieves high compression ratios while maintaining accuracy.\nOur evaluation on LLMs demonstrates that SKVQ surpasses previous quantization\napproaches, allowing for quantization of the KV cache to 2-bit keys and 1.5-bit\nvalues with minimal loss of accuracy. With SKVQ, it is possible to process\ncontext lengths of up to 1M on an 80GB memory GPU for a 7b model and up to 7\ntimes faster decoding.\n","authors":["Haojie Duanmu","Zhihang Yuan","Xiuhong Li","Jiangfei Duan","Xingcheng Zhang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2405.06219v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07623v1","updated":"2024-11-12T08:10:54Z","published":"2024-11-12T08:10:54Z","title":"Annotating Constructions with UD: the experience of the Italian\n  Constructicon","summary":"  The paper descirbes a first attempt of linking the Italian constructicon to\nUD resources\n","authors":["Ludovica Pannitto","Beatrice Bernasconi","Lucia Busso","Flavio Pisciotta","Giulia Rambelli","Francesca Masini"],"pdf_url":"https://arxiv.org/pdf/2411.07623v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07618v1","updated":"2024-11-12T07:54:13Z","published":"2024-11-12T07:54:13Z","title":"Direct Preference Optimization Using Sparse Feature-Level Constraints","summary":"  The alignment of large language models (LLMs) with human preferences remains\na key challenge. While post-training techniques like Reinforcement Learning\nfrom Human Feedback (RLHF) and Direct Preference Optimization (DPO) have\nachieved notable success, they often introduce computational inefficiencies and\ntraining instability. In this paper, we propose Feature-level constrained\nPreference Optimization (FPO), a novel method designed to simplify the\nalignment process while ensuring stability. FPO leverages pre-trained Sparse\nAutoencoders (SAEs) and introduces feature-level constraints, allowing for\nefficient, sparsity-enforced alignment. Our approach enjoys efficiency by using\nsparse features activated in a well-trained sparse autoencoder and the quality\nof sequential KL divergence by using the feature-level offline reference.\nExperimental results on benchmark datasets demonstrate that FPO achieves a\n5.08% absolute improvement in win rate with much lower computational cost\ncompared to state-of-the-art baselines, making it a promising solution for\nefficient and controllable LLM alignments.\n","authors":["Qingyu Yin","Chak Tou Leong","Hongbo Zhang","Minjun Zhu","Hanqi Yan","Qiang Zhang","Yulan He","Wenjie Li","Jun Wang","Yue Zhang","Linyi Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07618v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06634v2","updated":"2024-11-12T07:52:33Z","published":"2024-08-13T04:53:31Z","title":"Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM\n  Approach","summary":"  Accurate stock market predictions following earnings reports are crucial for\ninvestors. Traditional methods, particularly classical machine learning models,\nstruggle with these predictions because they cannot effectively process and\ninterpret extensive textual data contained in earnings reports and often\noverlook nuances that influence market movements. This paper introduces an\nadvanced approach by employing Large Language Models (LLMs) instruction\nfine-tuned with a novel combination of instruction-based techniques and\nquantized low-rank adaptation (QLoRA) compression. Our methodology integrates\n'base factors', such as financial metric growth and earnings transcripts, with\n'external factors', including recent market indices performances and analyst\ngrades, to create a rich, supervised dataset. This comprehensive dataset\nenables our models to achieve superior predictive performance in terms of\naccuracy, weighted F1, and Matthews correlation coefficient (MCC), especially\nevident in the comparison with benchmarks such as GPT-4. We specifically\nhighlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases\nsignificant improvements over baseline models. The paper also discusses the\npotential of expanding the output capabilities to include a 'Hold' option and\nextending the prediction horizon, aiming to accommodate various investment\nstyles and time frames. This study not only demonstrates the power of\nintegrating cutting-edge AI with fine-tuned financial data but also paves the\nway for future research in enhancing AI-driven financial analysis tools.\n","authors":["Haowei Ni","Shuchen Meng","Xupeng Chen","Ziqing Zhao","Andi Chen","Panfeng Li","Shiyao Zhang","Qifu Yin","Yuanqing Wang","Yuxi Chan"],"pdf_url":"https://arxiv.org/pdf/2408.06634v2.pdf","comment":"Accepted by 2024 6th International Conference on Data-driven\n  Optimization of Complex Systems"},{"id":"http://arxiv.org/abs/2411.07611v1","updated":"2024-11-12T07:34:56Z","published":"2024-11-12T07:34:56Z","title":"Multimodal Clinical Reasoning through Knowledge-augmented Rationale\n  Generation","summary":"  Clinical rationales play a pivotal role in accurate disease diagnosis;\nhowever, many models predominantly use discriminative methods and overlook the\nimportance of generating supportive rationales. Rationale distillation is a\nprocess that transfers knowledge from large language models (LLMs) to smaller\nlanguage models (SLMs), thereby enhancing the latter's ability to break down\ncomplex tasks. Despite its benefits, rationale distillation alone is inadequate\nfor addressing domain knowledge limitations in tasks requiring specialized\nexpertise, such as disease diagnosis. Effectively embedding domain knowledge in\nSLMs poses a significant challenge. While current LLMs are primarily geared\ntoward processing textual data, multimodal LLMs that incorporate time series\ndata, especially electronic health records (EHRs), are still evolving. To\ntackle these limitations, we introduce ClinRaGen, an SLM optimized for\nmultimodal rationale generation in disease diagnosis. ClinRaGen incorporates a\nunique knowledge-augmented attention mechanism to merge domain knowledge with\ntime series EHR data, utilizing a stepwise rationale distillation strategy to\nproduce both textual and time series-based clinical rationales. Our evaluations\nshow that ClinRaGen markedly improves the SLM's capability to interpret\nmultimodal EHR data and generate accurate clinical rationales, supporting more\nreliable disease diagnosis, advancing LLM applications in healthcare, and\nnarrowing the performance divide between LLMs and SLMs.\n","authors":["Shuai Niu","Jing Ma","Liang Bai","Zhihua Wang","Yida Xu","Yunya Song","Xian Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07611v1.pdf","comment":"11 pages. 4 figures"},{"id":"http://arxiv.org/abs/2411.07602v1","updated":"2024-11-12T07:24:41Z","published":"2024-11-12T07:24:41Z","title":"Circuit Complexity Bounds for RoPE-based Transformer Architecture","summary":"  Characterizing the express power of the Transformer architecture is critical\nto understanding its capacity limits and scaling law. Recent works provide the\ncircuit complexity bounds to Transformer-like architecture. On the other hand,\nRotary Position Embedding ($\\mathsf{RoPE}$) has emerged as a crucial technique\nin modern large language models, offering superior performance in capturing\npositional information compared to traditional position embeddings, which shows\ngreat potential in application prospects, particularly for the long context\nscenario. Empirical evidence also suggests that $\\mathsf{RoPE}$-based\nTransformer architectures demonstrate greater generalization capabilities\ncompared to conventional Transformer models. In this work, we establish a\ntighter circuit complexity bound for Transformers with $\\mathsf{RoPE}$\nattention. Our key contribution is that we show that unless $\\mathsf{TC}^0 =\n\\mathsf{NC}^1$, a $\\mathsf{RoPE}$-based Transformer with\n$\\mathrm{poly}(n)$-precision, $O(1)$ layers, hidden dimension $d \\leq O(n)$\ncannot solve the arithmetic problem or the Boolean formula value problem. This\nresult significantly demonstrates the fundamental limitation of the\nexpressivity of the $\\mathsf{RoPE}$-based Transformer architecture, although it\nachieves giant empirical success. Our theoretical framework not only\nestablishes tighter complexity bounds but also may instruct further work on the\n$\\mathsf{RoPE}$-based Transformer.\n","authors":["Bo Chen","Xiaoyu Li","Yingyu Liang","Jiangxuan Long","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2411.07602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12196v2","updated":"2024-11-12T07:22:21Z","published":"2024-07-16T21:43:47Z","title":"MASIVE: Open-Ended Affective State Identification in English and Spanish","summary":"  In the field of emotion analysis, much NLP research focuses on identifying a\nlimited number of discrete emotion categories, often applied across languages.\nThese basic sets, however, are rarely designed with textual data in mind, and\nculture, language, and dialect can influence how particular emotions are\ninterpreted. In this work, we broaden our scope to a practically unbounded set\nof \\textit{affective states}, which includes any terms that humans use to\ndescribe their experiences of feeling. We collect and publish MASIVE, a dataset\nof Reddit posts in English and Spanish containing over 1,000 unique affective\nstates each. We then define the new problem of \\textit{affective state\nidentification} for language generation models framed as a masked span\nprediction task. On this task, we find that smaller finetuned multilingual\nmodels outperform much larger LLMs, even on region-specific Spanish affective\nstates. Additionally, we show that pretraining on MASIVE improves model\nperformance on existing emotion benchmarks. Finally, through machine\ntranslation experiments, we find that native speaker-written data is vital to\ngood performance on this task.\n","authors":["Nicholas Deas","Elsbeth Turcan","Iv√°n P√©rez Mej√≠a","Kathleen McKeown"],"pdf_url":"https://arxiv.org/pdf/2407.12196v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2404.13565v3","updated":"2024-11-12T07:21:04Z","published":"2024-04-21T07:34:44Z","title":"Exploring Diverse Methods in Visual Question Answering","summary":"  This study explores innovative methods for improving Visual Question\nAnswering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and\nattention mechanisms. Leveraging a balanced VQA dataset, we investigate three\ndistinct strategies. Firstly, GAN-based approaches aim to generate answer\nembeddings conditioned on image and question inputs, showing potential but\nstruggling with more complex tasks. Secondly, autoencoder-based techniques\nfocus on learning optimal embeddings for questions and images, achieving\ncomparable results with GAN due to better ability on complex questions. Lastly,\nattention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB),\naddress language priors and attention modeling, albeit with a\ncomplexity-performance trade-off. This study underscores the challenges and\nopportunities in VQA and suggests avenues for future research, including\nalternative GAN formulations and attentional mechanisms.\n","authors":["Panfeng Li","Qikai Yang","Xieming Geng","Wenjing Zhou","Zhicheng Ding","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13565v3.pdf","comment":"Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence"},{"id":"http://arxiv.org/abs/2411.07598v1","updated":"2024-11-12T07:16:51Z","published":"2024-11-12T07:16:51Z","title":"Problem-Oriented Segmentation and Retrieval: Case Study on Tutoring\n  Conversations","summary":"  Many open-ended conversations (e.g., tutoring lessons or business meetings)\nrevolve around pre-defined reference materials, like worksheets or meeting\nbullets. To provide a framework for studying such conversation structure, we\nintroduce Problem-Oriented Segmentation & Retrieval (POSR), the task of jointly\nbreaking down conversations into segments and linking each segment to the\nrelevant reference item. As a case study, we apply POSR to education where\neffectively structuring lessons around problems is critical yet difficult. We\npresent LessonLink, the first dataset of real-world tutoring lessons, featuring\n3,500 segments, spanning 24,300 minutes of instruction and linked to 116 SAT\nmath problems. We define and evaluate several joint and independent approaches\nfor POSR, including segmentation (e.g., TextTiling), retrieval (e.g., ColBERT),\nand large language models (LLMs) methods. Our results highlight that modeling\nPOSR as one joint task is essential: POSR methods outperform independent\nsegmentation and retrieval pipelines by up to +76% on joint metrics and surpass\ntraditional segmentation methods by up to +78% on segmentation metrics. We\ndemonstrate POSR's practical impact on downstream education applications,\nderiving new insights on the language and time use in real-world lesson\nstructures.\n","authors":["Rose E. Wang","Pawan Wirawarn","Kenny Lam","Omar Khattab","Dorottya Demszky"],"pdf_url":"https://arxiv.org/pdf/2411.07598v1.pdf","comment":"EMNLP 2024 Findings. Our code and dataset are open-sourced at\n  https://github.com/rosewang2008/posr"},{"id":"http://arxiv.org/abs/2411.07595v1","updated":"2024-11-12T07:09:44Z","published":"2024-11-12T07:09:44Z","title":"Entropy Controllable Direct Preference Optimization","summary":"  In the post-training of large language models (LLMs), Reinforcement Learning\nfrom Human Feedback (RLHF) is an effective approach to achieve generation\naligned with human preferences. Direct Preference Optimization (DPO) allows for\npolicy training with a simple binary cross-entropy loss without a reward model.\nThe objective of DPO is regularized by reverse KL divergence that encourages\nmode-seeking fitting to the reference policy. Nonetheless, we indicate that\nminimizing reverse KL divergence could fail to capture a mode of the reference\ndistribution, which may hurt the policy's performance. Based on this\nobservation, we propose a simple modification to DPO, H-DPO, which allows for\ncontrol over the entropy of the resulting policy, enhancing the distribution's\nsharpness and thereby enabling mode-seeking fitting more effectively. In our\nexperiments, we show that H-DPO outperformed DPO across various tasks,\ndemonstrating superior results in pass@$k$ evaluations for mathematical tasks.\nMoreover, H-DPO is simple to implement, requiring only minor modifications to\nthe loss calculation of DPO, which makes it highly practical and promising for\nwide-ranging applications in the training of LLMs.\n","authors":["Motoki Omura","Yasuhiro Fujita","Toshiki Kataoka"],"pdf_url":"https://arxiv.org/pdf/2411.07595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.09059v2","updated":"2024-11-12T06:15:50Z","published":"2024-03-14T02:56:38Z","title":"LAMP: A Language Model on the Map","summary":"  Large Language Models (LLMs) are poised to play an increasingly important\nrole in our lives, providing assistance across a wide array of tasks. In the\ngeospatial domain, LLMs have demonstrated the ability to answer generic\nquestions, such as identifying a country's capital; nonetheless, their utility\nis hindered when it comes to answering fine-grained questions about specific\nplaces, such as grocery stores or restaurants, which constitute essential\naspects of people's everyday lives. This is mainly because the places in our\ncities haven't been systematically fed into LLMs, so as to understand and\nmemorize them. This study introduces a novel framework for fine-tuning a\npre-trained model on city-specific data, to enable it to provide accurate\nrecommendations, while minimizing hallucinations. We share our model, LAMP, and\nthe data used to train it. We conduct experiments to analyze its ability to\ncorrectly retrieving spatial objects, and compare it to well-known open- and\nclosed- source language models, such as GPT-4. Finally, we explore its emerging\ncapabilities through a case study on day planning.\n","authors":["Pasquale Balsebre","Weiming Huang","Gao Cong"],"pdf_url":"https://arxiv.org/pdf/2403.09059v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05990v2","updated":"2024-11-12T05:46:46Z","published":"2024-11-08T22:02:22Z","title":"Game-theoretic LLM: Agent Workflow for Negotiation Games","summary":"  This paper investigates the rationality of large language models (LLMs) in\nstrategic decision-making contexts, specifically within the framework of game\ntheory. We evaluate several state-of-the-art LLMs across a spectrum of\ncomplete-information and incomplete-information games. Our findings reveal that\nLLMs frequently deviate from rational strategies, particularly as the\ncomplexity of the game increases with larger payoff matrices or deeper\nsequential trees.\n  To address these limitations, we design multiple game-theoretic workflows\nthat guide the reasoning and decision-making processes of LLMs. These workflows\naim to enhance the models' ability to compute Nash Equilibria and make rational\nchoices, even under conditions of uncertainty and incomplete information.\nExperimental results demonstrate that the adoption of these workflows\nsignificantly improves the rationality and robustness of LLMs in game-theoretic\ntasks. Specifically, with the workflow, LLMs exhibit marked improvements in\nidentifying optimal strategies, achieving near-optimal allocations in\nnegotiation scenarios, and reducing susceptibility to exploitation during\nnegotiations. Furthermore, we explore the meta-strategic considerations of\nwhether it is rational for agents to adopt such workflows, recognizing that the\ndecision to use or forgo the workflow constitutes a game-theoretic issue in\nitself.\n  Our research contributes to a deeper understanding of LLMs' decision-making\ncapabilities in strategic contexts and provides insights into enhancing their\nrationality through structured workflows. The findings have implications for\nthe development of more robust and strategically sound AI agents capable of\nnavigating complex interactive environments. Code and data supporting this\nstudy are available at \\url{https://github.com/Wenyueh/game_theory}.\n","authors":["Wenyue Hua","Ollie Liu","Lingyao Li","Alfonso Amayuelas","Julie Chen","Lucas Jiang","Mingyu Jin","Lizhou Fan","Fei Sun","William Wang","Xintong Wang","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05990v2.pdf","comment":"45 pages, 12 figures"},{"id":"http://arxiv.org/abs/2408.11856v2","updated":"2024-11-12T05:37:15Z","published":"2024-08-15T19:13:38Z","title":"Dynamic Adaptive Optimization for Effective Sentiment Analysis\n  Fine-Tuning on Large Language Models","summary":"  Sentiment analysis plays a crucial role in various domains, such as business\nintelligence and financial forecasting. Large language models (LLMs) have\nbecome a popular paradigm for sentiment analysis, leveraging multi-task\nlearning to address specific tasks concurrently. However, LLMs with fine-tuning\nfor sentiment analysis often underperforms due to the inherent challenges in\nmanaging diverse task complexities. Moreover, constant-weight approaches in\nmulti-task learning struggle to adapt to variations in data characteristics,\nfurther complicating model effectiveness. To address these issues, we propose a\nnovel multi-task learning framework with a dynamic adaptive optimization (DAO)\nmodule. This module is designed as a plug-and-play component that can be\nseamlessly integrated into existing models, providing an effective and flexible\nsolution for multi-task learning. The key component of the DAO module is\ndynamic adaptive loss, which dynamically adjusts the weights assigned to\ndifferent tasks based on their relative importance and data characteristics\nduring training. Sentiment analyses on a standard and customized financial text\ndataset demonstrate that the proposed framework achieves superior performance.\nSpecifically, this work improves the Mean Squared Error (MSE) and Accuracy\n(ACC) by 15.58% and 1.24% respectively, compared with previous work.\n","authors":["Hongcheng Ding","Xuanze Zhao","Shamsul Nahar Abdullah","Deshinta Arrova Dewi","Zixiao Jiang","Xiangyu Shi"],"pdf_url":"https://arxiv.org/pdf/2408.11856v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10839v3","updated":"2024-11-12T05:33:05Z","published":"2024-06-16T08:20:12Z","title":"Reminding Multimodal Large Language Models of Object-aware Knowledge\n  with Retrieved Tags","summary":"  Despite recent advances in the general visual instruction-following ability\nof Multimodal Large Language Models (MLLMs), they still struggle with critical\nproblems when required to provide a precise and detailed response to a visual\ninstruction: (1) failure to identify novel objects or entities, (2) mention of\nnon-existent objects, and (3) neglect of object's attributed details. Intuitive\nsolutions include improving the size and quality of data or using larger\nfoundation models. They show effectiveness in mitigating these issues, but at\nan expensive cost of collecting a vast amount of new data and introducing a\nsignificantly larger model. Standing at the intersection of these approaches,\nwe examine the three object-oriented problems from the perspective of the\nimage-to-text mapping process by the multimodal connector. In this paper, we\nfirst identify the limitations of multimodal connectors stemming from\ninsufficient training data. Driven by this, we propose to enhance the mapping\nwith retrieval-augmented tag tokens, which contain rich object-aware\ninformation such as object names and attributes. With our Tag-grounded visual\ninstruction tuning with retrieval Augmentation (TUNA), we outperform baselines\nthat share the same language model and training data on 12 benchmarks.\nFurthermore, we show the zero-shot capability of TUNA when provided with\nspecific datastores.\n","authors":["Daiqing Qi","Handong Zhao","Zijun Wei","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.10839v3.pdf","comment":"Main Conference at EMNLP 2024"},{"id":"http://arxiv.org/abs/2401.12585v6","updated":"2024-11-12T05:09:34Z","published":"2024-01-23T09:33:31Z","title":"SLANG: New Concept Comprehension of Large Language Models","summary":"  The dynamic nature of language, particularly evident in the realm of slang\nand memes on the Internet, poses serious challenges to the adaptability of\nlarge language models (LLMs). Traditionally anchored to static datasets, these\nmodels often struggle to keep up with the rapid linguistic evolution\ncharacteristic of online communities. This research aims to bridge this gap by\nenhancing LLMs' comprehension of the evolving new concepts on the Internet,\nwithout the high cost of continual retraining. In pursuit of this goal, we\nintroduce $\\textbf{SLANG}$, a benchmark designed to autonomously integrate\nnovel data and assess LLMs' ability to comprehend emerging concepts, alongside\n$\\textbf{FOCUS}$, an approach uses causal inference to enhance LLMs to\nunderstand new phrases and their colloquial context. Our benchmark and approach\ninvolves understanding real-world instances of linguistic shifts, serving as\ncontextual beacons, to form more precise and contextually relevant connections\nbetween newly emerging expressions and their meanings. The empirical analysis\nshows that our causal inference-based approach outperforms the baseline methods\nin terms of precision and relevance in the comprehension of Internet slang and\nmemes.\n","authors":["Lingrui Mei","Shenghua Liu","Yiwei Wang","Baolong Bi","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2401.12585v6.pdf","comment":"EMNLP 2024 Main"},{"id":"http://arxiv.org/abs/2411.07546v1","updated":"2024-11-12T04:50:10Z","published":"2024-11-12T04:50:10Z","title":"Contrastive Language Prompting to Ease False Positives in Medical\n  Anomaly Detection","summary":"  A pre-trained visual-language model, contrastive language-image pre-training\n(CLIP), successfully accomplishes various downstream tasks with text prompts,\nsuch as finding images or localizing regions within the image. Despite CLIP's\nstrong multi-modal data capabilities, it remains limited in specialized\nenvironments, such as medical applications. For this purpose, many CLIP\nvariants-i.e., BioMedCLIP, and MedCLIP-SAMv2-have emerged, but false positives\nrelated to normal regions persist. Thus, we aim to present a simple yet\nimportant goal of reducing false positives in medical anomaly detection. We\nintroduce a Contrastive LAnguage Prompting (CLAP) method that leverages both\npositive and negative text prompts. This straightforward approach identifies\npotential lesion regions by visual attention to the positive prompts in the\ngiven image. To reduce false positives, we attenuate attention on normal\nregions using negative prompts. Extensive experiments with the BMAD dataset,\nincluding six biomedical benchmarks, demonstrate that CLAP method enhances\nanomaly detection performance. Our future plans include developing an automated\nfine prompting method for more practical usage.\n","authors":["YeongHyeon Park","Myung Jin Kim","Hyeong Seok Kim"],"pdf_url":"https://arxiv.org/pdf/2411.07546v1.pdf","comment":"4 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2407.01523v3","updated":"2024-11-12T04:37:44Z","published":"2024-07-01T17:59:26Z","title":"MMLongBench-Doc: Benchmarking Long-context Document Understanding with\n  Visualizations","summary":"  Understanding documents with rich layouts and multi-modal components is a\nlong-standing and practical task. Recent Large Vision-Language Models (LVLMs)\nhave made remarkable strides in various tasks, particularly in single-page\ndocument understanding (DU). However, their abilities on long-context DU remain\nan open problem. This work presents MMLongBench-Doc, a long-context,\nmulti-modal benchmark comprising 1,062 expert-annotated questions. Distinct\nfrom previous datasets, it is constructed upon 130 lengthy PDF-formatted\ndocuments with an average of 49.4 pages and 20,971 textual tokens. Towards\ncomprehensive evaluation, answers to these questions rely on pieces of evidence\nfrom (1) different sources (text, image, chart, table, and layout structure)\nand (2) various locations (i.e. page number). Moreover, 33.2% of the questions\nare cross-page questions requiring evidence across multiple pages. 22.8% of the\nquestions are designed to be unanswerable for detecting potential\nhallucinations. Experiments on 14 LVLMs demonstrate that long-context DU\ngreatly challenges current models. Notably, the best-performing model, GPT-4o,\nachieves an F1 score of only 42.7%, while the second-best, GPT-4V, scores\n31.4%. Furthermore, 12 LVLMs (all except GPT-4o and GPT-4V) even present worse\nperformance than their LLM counterparts which are fed with lossy-parsed OCR\ndocuments. These results validate the necessity of future research toward more\ncapable long-context LVLMs. Project Page:\nhttps://mayubo2333.github.io/MMLongBench-Doc\n","authors":["Yubo Ma","Yuhang Zang","Liangyu Chen","Meiqi Chen","Yizhu Jiao","Xinze Li","Xinyuan Lu","Ziyu Liu","Yan Ma","Xiaoyi Dong","Pan Zhang","Liangming Pan","Yu-Gang Jiang","Jiaqi Wang","Yixin Cao","Aixin Sun"],"pdf_url":"https://arxiv.org/pdf/2407.01523v3.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Spotlight)"},{"id":"http://arxiv.org/abs/2410.09982v3","updated":"2024-11-12T04:20:00Z","published":"2024-10-13T19:53:40Z","title":"Self-Data Distillation for Recovering Quality in Pruned Large Language\n  Models","summary":"  Large language models have driven significant progress in natural language\nprocessing, but their deployment requires substantial compute and memory\nresources. As models scale, compression techniques become essential for\nbalancing model quality with computational efficiency. Structured pruning,\nwhich removes less critical components of the model, is a promising strategy\nfor reducing complexity. However, one-shot pruning often results in significant\nquality degradation, particularly in tasks requiring multi-step reasoning. To\nrecover lost quality, supervised fine-tuning (SFT) is commonly applied, but it\ncan lead to catastrophic forgetting by shifting the model's learned data\ndistribution. Therefore, addressing the degradation from both pruning and SFT\nis essential to preserve the original model's quality. In this work, we utilize\nself-data distilled fine-tuning to address these challenges. Our approach\nleverages the original, unpruned model to generate a distilled dataset that\npreserves semantic richness and mitigates catastrophic forgetting by\nmaintaining alignment with the base model's knowledge. Empirically, we\ndemonstrate that self-data distillation consistently outperforms standard SFT,\nimproving average accuracy by up to 8% on the HuggingFace OpenLLM Leaderboard\nv1. Specifically, when pruning six decoder blocks on Llama3.1-8B Instruct\n(i.e., 32 to 26 layers, reducing the model size from 8.03B to 6.72B\nparameters), our method retains 91.2% of the original model's accuracy compared\nto 81.7% with SFT, while reducing real-world FLOPs by 16.3%. Furthermore,\ncombining self-data distilled models through model merging yields enhanced\nquality retention. Additionally, leveraging these pruned models in speculative\ndecoding increases token acceptance rates, thereby improving inference\nefficiency in applied settings.\n","authors":["Vithursan Thangarasa","Ganesh Venkatesh","Mike Lasby","Nish Sinnadurai","Sean Lie"],"pdf_url":"https://arxiv.org/pdf/2410.09982v3.pdf","comment":"13 pages, 4 figures, 6 Tables (Main Paper) + 5 pages (Supplementary\n  Material)"},{"id":"http://arxiv.org/abs/2411.07533v1","updated":"2024-11-12T04:16:44Z","published":"2024-11-12T04:16:44Z","title":"Large Language Models as Neurolinguistic Subjects: Identifying Internal\n  Representations for Form and Meaning","summary":"  This study investigates the linguistic understanding of Large Language Models\n(LLMs) regarding signifier (form) and signified (meaning) by distinguishing two\nLLM evaluation paradigms: psycholinguistic and neurolinguistic. Traditional\npsycholinguistic evaluations often reflect statistical biases that may\nmisrepresent LLMs' true linguistic capabilities. We introduce a neurolinguistic\napproach, utilizing a novel method that combines minimal pair and diagnostic\nprobing to analyze activation patterns across model layers. This method allows\nfor a detailed examination of how LLMs represent form and meaning, and whether\nthese representations are consistent across languages. Our contributions are\nthree-fold: (1) We compare neurolinguistic and psycholinguistic methods,\nrevealing distinct patterns in LLM assessment; (2) We demonstrate that LLMs\nexhibit higher competence in form compared to meaning, with the latter largely\ncorrelated to the former; (3) We present new conceptual minimal pair datasets\nfor Chinese (COMPS-ZH) and German (COMPS-DE), complementing existing English\ndatasets.\n","authors":["Linyang He","Ercong Nie","Helmut Schmid","Hinrich Sch√ºtze","Nima Mesgarani","Jonathan Brennan"],"pdf_url":"https://arxiv.org/pdf/2411.07533v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07070v2","updated":"2024-11-12T04:12:32Z","published":"2024-11-11T15:46:07Z","title":"On Active Privacy Auditing in Supervised Fine-tuning for White-Box\n  Language Models","summary":"  The pretraining and fine-tuning approach has become the leading technique for\nvarious NLP applications. However, recent studies reveal that fine-tuning data,\ndue to their sensitive nature, domain-specific characteristics, and\nidentifiability, pose significant privacy concerns. To help develop more\nprivacy-resilient fine-tuning models, we introduce a novel active privacy\nauditing framework, dubbed Parsing, designed to identify and quantify privacy\nleakage risks during the supervised fine-tuning (SFT) of language models (LMs).\nThe framework leverages improved white-box membership inference attacks (MIAs)\nas the core technology, utilizing novel learning objectives and a two-stage\npipeline to monitor the privacy of the LMs' fine-tuning process, maximizing the\nexposure of privacy risks. Additionally, we have improved the effectiveness of\nMIAs on large LMs including GPT-2, Llama2, and certain variants of them. Our\nresearch aims to provide the SFT community of LMs with a reliable, ready-to-use\nprivacy auditing tool, and to offer valuable insights into safeguarding privacy\nduring the fine-tuning process. Experimental results confirm the framework's\nefficiency across various models and tasks, emphasizing notable privacy\nconcerns in the fine-tuning process. Project code available for\nhttps://anonymous.4open.science/r/PARSING-4817/.\n","authors":["Qian Sun","Hanpeng Wu","Xi Sheryl Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07070v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07133v2","updated":"2024-11-12T04:05:54Z","published":"2024-11-11T17:06:48Z","title":"Stronger Models are NOT Stronger Teachers for Instruction Tuning","summary":"  Instruction tuning has been widely adopted to ensure large language models\n(LLMs) follow user instructions effectively. The resulting\ninstruction-following capabilities of LLMs heavily rely on the instruction\ndatasets used for tuning. Recently, synthetic instruction datasets have emerged\nas an economically viable solution to provide LLMs diverse and high-quality\ninstructions. However, existing approaches typically assume that larger or\nstronger models are stronger teachers for instruction tuning, and hence simply\nadopt these models as response generators to the synthetic instructions. In\nthis paper, we challenge this commonly-adopted assumption. Our extensive\nexperiments across five base models and twenty response generators reveal that\nlarger and stronger models are not necessarily stronger teachers of smaller\nmodels. We refer to this phenomenon as the Larger Models' Paradox. We observe\nthat existing metrics cannot precisely predict the effectiveness of response\ngenerators since they ignore the compatibility between teachers and base models\nbeing fine-tuned. We thus develop a novel metric, named as\nCompatibility-Adjusted Reward (CAR) to measure the effectiveness of response\ngenerators. Our experiments across five base models demonstrate that CAR\noutperforms almost all baselines.\n","authors":["Zhangchen Xu","Fengqing Jiang","Luyao Niu","Bill Yuchen Lin","Radha Poovendran"],"pdf_url":"https://arxiv.org/pdf/2411.07133v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07528v1","updated":"2024-11-12T03:56:07Z","published":"2024-11-12T03:56:07Z","title":"SecEncoder: Logs are All You Need in Security","summary":"  Large and Small Language Models (LMs) are typically pretrained using\nextensive volumes of text, which are sourced from publicly accessible platforms\nsuch as Wikipedia, Book Corpus, or through web scraping. These models, due to\ntheir exposure to a wide range of language data, exhibit impressive\ngeneralization capabilities and can perform a multitude of tasks\nsimultaneously. However, they often fall short when it comes to domain-specific\ntasks due to their broad training data. This paper introduces SecEncoder, a\nspecialized small language model that is pretrained using security logs.\nSecEncoder is designed to address the domain-specific limitations of general\nLMs by focusing on the unique language and patterns found in security logs.\nExperimental results indicate that SecEncoder outperforms other LMs, such as\nBERTlarge, DeBERTa-v3-large and OpenAI's Embedding (textembedding-ada-002)\nmodels, which are pretrained mainly on natural language, across various tasks.\nFurthermore, although SecEncoder is primarily pretrained on log data, it\noutperforms models pretrained on natural language for a range of tasks beyond\nlog analysis, such as incident prioritization and threat intelligence document\nretrieval. This suggests that domain specific pretraining with logs can\nsignificantly enhance the performance of LMs in security. These findings pave\nthe way for future research into security-specific LMs and their potential\napplications.\n","authors":["Muhammed Fatih Bulut","Yingqi Liu","Naveed Ahmad","Maximilian Turner","Sami Ait Ouahmane","Cameron Andrews","Lloyd Greenwald"],"pdf_url":"https://arxiv.org/pdf/2411.07528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07527v1","updated":"2024-11-12T03:55:27Z","published":"2024-11-12T03:55:27Z","title":"Prompt-enhanced Network for Hateful Meme Classification","summary":"  The dynamic expansion of social media has led to an inundation of hateful\nmemes on media platforms, accentuating the growing need for efficient\nidentification and removal. Acknowledging the constraints of conventional\nmultimodal hateful meme classification, which heavily depends on external\nknowledge and poses the risk of including irrelevant or redundant content, we\ndeveloped Pen -- a prompt-enhanced network framework based on the prompt\nlearning approach. Specifically, after constructing the sequence through the\nprompt method and encoding it with a language model, we performed region\ninformation global extraction on the encoded sequence for multi-view\nperception. By capturing global information about inference instances and\ndemonstrations, Pen facilitates category selection by fully leveraging sequence\ninformation. This approach significantly improves model classification\naccuracy. Additionally, to bolster the model's reasoning capabilities in the\nfeature space, we introduced prompt-aware contrastive learning into the\nframework to improve the quality of sample feature distributions. Through\nextensive ablation experiments on two public datasets, we evaluate the\neffectiveness of the Pen framework, concurrently comparing it with\nstate-of-the-art model baselines. Our research findings highlight that Pen\nsurpasses manual prompt methods, showcasing superior generalization and\nclassification accuracy in hateful meme classification tasks. Our code is\navailable at https://github.com/juszzi/Pen.\n","authors":["Junxi Liu","Yanyan Feng","Jiehai Chen","Yun Xue","Fenghuan Li"],"pdf_url":"https://arxiv.org/pdf/2411.07527v1.pdf","comment":"Published in Proceedings of the Thirty-Third International Joint\n  Conference on Artificial Intelligence Main Track. Pages 6397-6405"},{"id":"http://arxiv.org/abs/2411.07521v1","updated":"2024-11-12T03:37:53Z","published":"2024-11-12T03:37:53Z","title":"Fair Summarization: Bridging Quality and Diversity in Extractive\n  Summaries","summary":"  Fairness in multi-document summarization of user-generated content remains a\ncritical challenge in natural language processing (NLP). Existing summarization\nmethods often fail to ensure equitable representation across different social\ngroups, leading to biased outputs. In this paper, we introduce two novel\nmethods for fair extractive summarization: FairExtract, a clustering-based\napproach, and FairGPT, which leverages GPT-3.5-turbo with fairness constraints.\nWe evaluate these methods using Divsumm summarization dataset of White-aligned,\nHispanic, and African-American dialect tweets and compare them against relevant\nbaselines. The results obtained using a comprehensive set of summarization\nquality metrics such as SUPERT, BLANC, SummaQA, BARTScore, and UniEval, as well\nas a fairness metric F, demonstrate that FairExtract and FairGPT achieve\nsuperior fairness while maintaining competitive summarization quality.\nAdditionally, we introduce composite metrics (e.g., SUPERT+F, BLANC+F) that\nintegrate quality and fairness into a single evaluation framework, offering a\nmore nuanced understanding of the trade-offs between these objectives. This\nwork highlights the importance of fairness in summarization and sets a\nbenchmark for future research in fairness-aware NLP models.\n","authors":["Sina Bagheri Nezhad","Sayan Bandyapadhyay","Ameeta Agrawal"],"pdf_url":"https://arxiv.org/pdf/2411.07521v1.pdf","comment":"Accepted at Algorithmic Fairness through the Lens of Metrics and\n  Evaluation Workshop @ NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07516v1","updated":"2024-11-12T03:25:33Z","published":"2024-11-12T03:25:33Z","title":"SparrowVQE: Visual Question Explanation for Course Content Understanding","summary":"  Visual Question Answering (VQA) research seeks to create AI systems to answer\nnatural language questions in images, yet VQA methods often yield overly\nsimplistic and short answers. This paper aims to advance the field by\nintroducing Visual Question Explanation (VQE), which enhances the ability of\nVQA to provide detailed explanations rather than brief responses and address\nthe need for more complex interaction with visual content. We first created an\nMLVQE dataset from a 14-week streamed video machine learning course, including\n885 slide images, 110,407 words of transcripts, and 9,416 designed\nquestion-answer (QA) pairs. Next, we proposed a novel SparrowVQE, a small 3\nbillion parameters multimodal model. We trained our model with a three-stage\ntraining mechanism consisting of multimodal pre-training (slide images and\ntranscripts feature alignment), instruction tuning (tuning the pre-trained\nmodel with transcripts and QA pairs), and domain fine-tuning (fine-tuning slide\nimage and QA pairs). Eventually, our SparrowVQE can understand and connect\nvisual information using the SigLIP model with transcripts using the Phi-2\nlanguage model with an MLP adapter. Experimental results demonstrate that our\nSparrowVQE achieves better performance in our developed MLVQE dataset and\noutperforms state-of-the-art methods in the other five benchmark VQA datasets.\nThe source code is available at\n\\url{https://github.com/YoushanZhang/SparrowVQE}.\n","authors":["Jialu Li","Manish Kumar Thota","Ruslan Gokhman","Radek Holik","Youshan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07494v1","updated":"2024-11-12T02:44:49Z","published":"2024-11-12T02:44:49Z","title":"Rapid Response: Mitigating LLM Jailbreaks with a Few Examples","summary":"  As large language models (LLMs) grow more powerful, ensuring their safety\nagainst misuse becomes crucial. While researchers have focused on developing\nrobust defenses, no method has yet achieved complete invulnerability to\nattacks. We propose an alternative approach: instead of seeking perfect\nadversarial robustness, we develop rapid response techniques to look to block\nwhole classes of jailbreaks after observing only a handful of attacks. To study\nthis setting, we develop RapidResponseBench, a benchmark that measures a\ndefense's robustness against various jailbreak strategies after adapting to a\nfew observed examples. We evaluate five rapid response methods, all of which\nuse jailbreak proliferation, where we automatically generate additional\njailbreaks similar to the examples observed. Our strongest method, which\nfine-tunes an input classifier to block proliferated jailbreaks, reduces attack\nsuccess rate by a factor greater than 240 on an in-distribution set of\njailbreaks and a factor greater than 15 on an out-of-distribution set, having\nobserved just one example of each jailbreaking strategy. Moreover, further\nstudies suggest that the quality of proliferation model and number of\nproliferated examples play an key role in the effectiveness of this defense.\nOverall, our results highlight the potential of responding rapidly to novel\njailbreaks to limit LLM misuse.\n","authors":["Alwin Peng","Julian Michael","Henry Sleight","Ethan Perez","Mrinank Sharma"],"pdf_url":"https://arxiv.org/pdf/2411.07494v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.00774v2","updated":"2024-11-12T02:18:38Z","published":"2024-11-01T17:59:51Z","title":"Freeze-Omni: A Smart and Low Latency Speech-to-speech Dialogue Model\n  with Frozen LLM","summary":"  Rapidly developing large language models (LLMs) have brought tremendous\nintelligent applications. GPT-4o's excellent duplex speech interaction ability\nhas recently brought impressive experience to users. Researchers have recently\nproposed several multi-modal LLMs in this direction that can achieve\nspeech-to-speech dialogue. This paper proposes a novel speech-text multimodal\nLLM architecture called Freeze-Omni. Our main contribution is that the speech\ninput and output modalities can be easily connected to a textual LLM while\nkeeping the LLM's parameters frozen throughout the training process. We\ndesigned 3-stage training strategies both for the modeling of speech input and\noutput, enabling Freeze-Omni to obtain speech-to-speech dialogue ability using\ntext-speech paired data (such as ASR and TTS data) and only 60,000 multi-round\ntext Q&A data on 8 GPUs. Moreover, we can effectively ensure that the\nintelligence of the Freeze-Omni in the speech modality is at the same level\ncompared with that in the text modality of its backbone LLM, while the\nend-to-end latency of the spoken response achieves a low level. In addition, we\nalso designed a method to achieve duplex dialogue ability through multi-task\ntraining, making Freeze-Omni have a more natural style of dialogue ability\nbetween the users. Freeze-Omni mainly provides a possibility for researchers to\nconduct multimodal LLM under the condition of a frozen LLM, avoiding various\nimpacts caused by the catastrophic forgetting of LLM caused by fewer data and\ntraining resources.\n","authors":["Xiong Wang","Yangze Li","Chaoyou Fu","Yunhang Shen","Lei Xie","Ke Li","Xing Sun","Long Ma"],"pdf_url":"https://arxiv.org/pdf/2411.00774v2.pdf","comment":"Project Page: https://freeze-omni.github.io/"},{"id":"http://arxiv.org/abs/2409.13755v2","updated":"2024-11-12T02:01:37Z","published":"2024-09-15T10:50:51Z","title":"Entity-Aware Self-Attention and Contextualized GCN for Enhanced Relation\n  Extraction in Long Sentences","summary":"  Relation extraction as an important natural Language processing (NLP) task is\nto identify relations between named entities in text. Recently, graph\nconvolutional networks over dependency trees have been widely used to capture\nsyntactic features and achieved attractive performance. However, most existing\ndependency-based approaches ignore the positive influence of the words outside\nthe dependency trees, sometimes conveying rich and useful information on\nrelation extraction. In this paper, we propose a novel model, Entity-aware\nSelf-attention Contextualized GCN (ESC-GCN), which efficiently incorporates\nsyntactic structure of input sentences and semantic context of sequences. To be\nspecific, relative position self-attention obtains the overall semantic\npairwise correlation related to word position, and contextualized graph\nconvolutional networks capture rich intra-sentence dependencies between words\nby adequately pruning operations. Furthermore, entity-aware attention layer\ndynamically selects which token is more decisive to make final relation\nprediction. In this way, our proposed model not only reduces the noisy impact\nfrom dependency trees, but also obtains easily-ignored entity-related semantic\nrepresentation. Extensive experiments on various tasks demonstrate that our\nmodel achieves encouraging performance as compared to existing dependency-based\nand sequence-based models. Specially, our model excels in extracting relations\nbetween entities of long sentences.\n","authors":["Xin Wang","Xinyi Bai"],"pdf_url":"https://arxiv.org/pdf/2409.13755v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.00625v2","updated":"2024-11-12T01:47:40Z","published":"2024-09-01T05:59:54Z","title":"Entity-Aware Biaffine Attention Model for Improved Constituent Parsing\n  with Reduced Entity Violations","summary":"  Constituency parsing involves analyzing a sentence by breaking it into\nsub-phrases, or constituents. While many deep neural models have achieved\nstate-of-the-art performance in this task, they often overlook the\nentity-violating issue, where an entity fails to form a complete sub-tree in\nthe resultant parsing tree. To address this, we propose an entity-aware\nbiaffine attention model for constituent parsing. This model incorporates\nentity information into the biaffine attention mechanism by using additional\nentity role vectors for potential phrases, which enhances the parsing accuracy.\nWe introduce a new metric, the Entity Violating Rate (EVR), to quantify the\nextent of entity violations in parsing results. Experiments on three popular\ndatasets-ONTONOTES, PTB, and CTB-demonstrate that our model achieves the lowest\nEVR while maintaining high precision, recall, and F1-scores comparable to\nexisting models. Further evaluation in downstream tasks, such as sentence\nsentiment analysis, highlights the effectiveness of our model and the validity\nof the proposed EVR metric.\n","authors":["Xinyi Bai"],"pdf_url":"https://arxiv.org/pdf/2409.00625v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07474v1","updated":"2024-11-12T01:26:41Z","published":"2024-11-12T01:26:41Z","title":"Controlled Evaluation of Syntactic Knowledge in Multilingual Language\n  Models","summary":"  Language models (LMs) are capable of acquiring elements of human-like\nsyntactic knowledge. Targeted syntactic evaluation tests have been employed to\nmeasure how well they form generalizations about syntactic phenomena in\nhigh-resource languages such as English. However, we still lack a thorough\nunderstanding of LMs' capacity for syntactic generalizations in low-resource\nlanguages, which are responsible for much of the diversity of syntactic\npatterns worldwide. In this study, we develop targeted syntactic evaluation\ntests for three low-resource languages (Basque, Hindi, and Swahili) and use\nthem to evaluate five families of open-access multilingual Transformer LMs. We\nfind that some syntactic tasks prove relatively easy for LMs while others\n(agreement in sentences containing indirect objects in Basque, agreement across\na prepositional phrase in Swahili) are challenging. We additionally uncover\nissues with publicly available Transformers, including a bias toward the\nhabitual aspect in Hindi in multilingual BERT and underperformance compared to\nsimilar-sized models in XGLM-4.5B.\n","authors":["Daria Kryvosheieva","Roger Levy"],"pdf_url":"https://arxiv.org/pdf/2411.07474v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.01332v3","updated":"2024-11-12T01:06:22Z","published":"2024-03-29T22:49:43Z","title":"Explaining Large Language Models Decisions Using Shapley Values","summary":"  The emergence of large language models (LLMs) has opened up exciting\npossibilities for simulating human behavior and cognitive processes, with\npotential applications in various domains, including marketing research and\nconsumer behavior analysis. However, the validity of utilizing LLMs as\nstand-ins for human subjects remains uncertain due to glaring divergences that\nsuggest fundamentally different underlying processes at play and the\nsensitivity of LLM responses to prompt variations. This paper presents a novel\napproach based on Shapley values from cooperative game theory to interpret LLM\nbehavior and quantify the relative contribution of each prompt component to the\nmodel's output. Through two applications - a discrete choice experiment and an\ninvestigation of cognitive biases - we demonstrate how the Shapley value method\ncan uncover what we term \"token noise\" effects, a phenomenon where LLM\ndecisions are disproportionately influenced by tokens providing minimal\ninformative content. This phenomenon raises concerns about the robustness and\ngeneralizability of insights obtained from LLMs in the context of human\nbehavior simulation. Our model-agnostic approach extends its utility to\nproprietary LLMs, providing a valuable tool for practitioners and researchers\nto strategically optimize prompts and mitigate apparent cognitive biases. Our\nfindings underscore the need for a more nuanced understanding of the factors\ndriving LLM responses before relying on them as substitutes for human subjects\nin survey settings. We emphasize the importance of researchers reporting\nresults conditioned on specific prompt templates and exercising caution when\ndrawing parallels between human behavior and LLMs.\n","authors":["Behnam Mohammadi"],"pdf_url":"https://arxiv.org/pdf/2404.01332v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07466v1","updated":"2024-11-12T01:05:55Z","published":"2024-11-12T01:05:55Z","title":"IdentifyMe: A Challenging Long-Context Mention Resolution Benchmark","summary":"  Recent evaluations of LLMs on coreference resolution have revealed that\ntraditional output formats and evaluation metrics do not fully capture the\nmodels' referential understanding. To address this, we introduce IdentifyMe, a\nnew benchmark for mention resolution presented in a multiple-choice question\n(MCQ) format, commonly used for evaluating LLMs. IdentifyMe features long\nnarratives and employs heuristics to exclude easily identifiable mentions,\ncreating a more challenging task. The benchmark also consists of a curated\nmixture of different mention types and corresponding entities, allowing for a\nfine-grained analysis of model performance. We evaluate both closed- and open\nsource LLMs on IdentifyMe and observe a significant performance gap (20-30%)\nbetween the state-of-the-art sub-10B open models vs. closed ones. We observe\nthat pronominal mentions, which have limited surface information, are typically\nmuch harder for models to resolve than nominal mentions. Additionally, we find\nthat LLMs often confuse entities when their mentions overlap in nested\nstructures. The highest-scoring model, GPT-4o, achieves 81.9% accuracy,\nhighlighting the strong referential capabilities of state-of-the-art LLMs while\nalso indicating room for further improvement.\n","authors":["Kawshik Manikantan","Makarand Tapaswi","Vineet Gandhi","Shubham Toshniwal"],"pdf_url":"https://arxiv.org/pdf/2411.07466v1.pdf","comment":"9 pages, 5 figures"},{"id":"http://arxiv.org/abs/2311.04916v4","updated":"2024-11-12T01:01:32Z","published":"2023-11-02T04:01:04Z","title":"Explainable Identification of Hate Speech towards Islam using Graph\n  Neural Networks","summary":"  Islamophobic language on online platforms fosters intolerance, making\ndetection and elimination crucial for promoting harmony. Traditional hate\nspeech detection models rely on NLP techniques like tokenization,\npart-of-speech tagging, and encoder-decoder models. However, Graph Neural\nNetworks (GNNs), with their ability to utilize relationships between data\npoints, offer more effective detection and greater explainability. In this\nwork, we represent speeches as nodes and connect them with edges based on their\ncontext and similarity to develop the graph. This study introduces a novel\nparadigm using GNNs to identify and explain hate speech towards Islam. Our\nmodel leverages GNNs to understand the context and patterns of hate speech by\nconnecting texts via pretrained NLP-generated word embeddings, achieving\nstate-of-the-art performance and enhancing detection accuracy while providing\nvaluable explanations. This highlights the potential of GNNs in combating\nonline hate speech and fostering a safer, more inclusive online environment.\n","authors":["Azmine Toushik Wasi"],"pdf_url":"https://arxiv.org/pdf/2311.04916v4.pdf","comment":"Accepted in: (i) NeurIPS 2023 : Muslims in ML Workshop (Non-archival)\n  (https://www.musiml.org/schedule/#:~:text=Azmine%20Toushik%20Wasi) (ii) EMNLP\n  2024 : NLP for Positive Impact Workshop (Archival; ACL Anthology:\n  https://aclanthology.org/2024.nlp4pi-1.23/)"},{"id":"http://arxiv.org/abs/2407.02885v5","updated":"2024-11-12T01:00:53Z","published":"2024-07-03T07:59:52Z","title":"CogErgLLM: Exploring Large Language Model Systems Design Perspective\n  Using Cognitive Ergonomics","summary":"  Integrating cognitive ergonomics with LLMs is crucial for improving safety,\nreliability, and user satisfaction in human-AI interactions. Current LLM\ndesigns often lack this integration, resulting in systems that may not fully\nalign with human cognitive capabilities and limitations. This oversight\nexacerbates biases in LLM outputs and leads to suboptimal user experiences due\nto inconsistent application of user-centered design principles. Researchers are\nincreasingly leveraging NLP, particularly LLMs, to model and understand human\nbehavior across social sciences, psychology, psychiatry, health, and\nneuroscience. Our position paper explores the need to integrate cognitive\nergonomics into LLM design, providing a comprehensive framework and practical\nguidelines for ethical development. By addressing these challenges, we aim to\nadvance safer, more reliable, and ethically sound human-AI interactions.\n","authors":["Azmine Toushik Wasi","Mst Rafia Islam"],"pdf_url":"https://arxiv.org/pdf/2407.02885v5.pdf","comment":"10 Page, 3 Figures. Accepted in: (i) ICML'24: LLMs & Cognition\n  Workshop (Non-archival; OpenReview:\n  https://openreview.net/forum?id=63C9YSc77p) (ii) EMNLP'24 : NLP for Science\n  Workshop (Archival; ACL Anthology:\n  https://aclanthology.org/2024.nlp4science-1.22/)"},{"id":"http://arxiv.org/abs/2411.07464v1","updated":"2024-11-12T00:57:30Z","published":"2024-11-12T00:57:30Z","title":"BudgetMLAgent: A Cost-Effective LLM Multi-Agent system for Automating\n  Machine Learning Tasks","summary":"  Large Language Models (LLMs) excel in diverse applications including\ngeneration of code snippets, but often struggle with generating code for\ncomplex Machine Learning (ML) tasks. Although existing LLM single-agent based\nsystems give varying performance depending on the task complexity, they purely\nrely on larger and expensive models such as GPT-4. Our investigation reveals\nthat no-cost and low-cost models such as Gemini-Pro, Mixtral and CodeLlama\nperform far worse than GPT-4 in a single-agent setting. With the motivation of\ndeveloping a cost-efficient LLM based solution for solving ML tasks, we propose\nan LLM Multi-Agent based system which leverages combination of experts using\nprofiling, efficient retrieval of past observations, LLM cascades, and\nask-the-expert calls. Through empirical analysis on ML engineering tasks in the\nMLAgentBench benchmark, we demonstrate the effectiveness of our system, using\nno-cost models, namely Gemini as the base LLM, paired with GPT-4 in cascade and\nexpert to serve occasional ask-the-expert calls for planning. With 94.2\\%\nreduction in the cost (from \\$0.931 per run cost averaged over all tasks for\nGPT-4 single agent system to \\$0.054), our system is able to yield better\naverage success rate of 32.95\\% as compared to GPT-4 single-agent system\nyielding 22.72\\% success rate averaged over all the tasks of MLAgentBench.\n","authors":["Shubham Gandhi","Manasi Patwardhan","Lovekesh Vig","Gautam Shroff"],"pdf_url":"https://arxiv.org/pdf/2411.07464v1.pdf","comment":"Presented at AIMLSystems '24"},{"id":"http://arxiv.org/abs/2411.07457v1","updated":"2024-11-12T00:48:01Z","published":"2024-11-12T00:48:01Z","title":"DecoPrompt : Decoding Prompts Reduces Hallucinations when Large Language\n  Models Meet False Premises","summary":"  While large language models (LLMs) have demonstrated increasing power, they\nhave also called upon studies on their hallucinated outputs that deviate from\nfactually correct statements. In this paper, we focus on one important scenario\nof false premises, where LLMs are distracted by misaligned claims although the\nmodel possesses the required factual knowledge to answer original questions\naccurately. Inspired by the observation that entropy of the false-premise\nprompt is closely related to its likelihood to elicit hallucination generation,\nwe propose a new prompting algorithm, named DecoPrompt, to mitigate\nhallucination. DecoPrompt leverages LLMs to \"decode\" the false-premise prompts\nwithout really eliciting hallucination output from LLMs. We perform experiments\non two datasets, demonstrating that DecoPrompt can reduce hallucinations\neffectively on outputs from different LLMs. Moreover, DecoPrompt exhibits\ncross-model transferability, which facilitates its applications to scenarios\nsuch as LLMs of large sizes or unavailable model logits.\n","authors":["Nan Xu","Xuezhe Ma"],"pdf_url":"https://arxiv.org/pdf/2411.07457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07446v1","updated":"2024-11-12T00:07:29Z","published":"2024-11-12T00:07:29Z","title":"Efficient and Accurate Prompt Optimization: the Benefit of Memory in\n  Exemplar-Guided Reflection","summary":"  Automatic prompt engineering aims to enhance the generation quality of large\nlanguage models (LLMs). Recent works utilize feedbacks generated from erroneous\ncases to guide the prompt optimization. During inference, they may further\nretrieve several semantically-related exemplars and concatenate them to the\noptimized prompts to improve the performance. However, those works only utilize\nthe feedback at the current step, ignoring historical and unseleccted feedbacks\nwhich are potentially beneficial. Moreover, the selection of exemplars only\nconsiders the general semantic relationship and may not be optimal in terms of\ntask performance and matching with the optimized prompt. In this work, we\npropose an Exemplar-Guided Reflection with Memory mechanism (ERM) to realize\nmore efficient and accurate prompt optimization. Specifically, we design an\nexemplar-guided reflection mechanism where the feedback generation is\nadditionally guided by the generated exemplars. We further build two kinds of\nmemory to fully utilize the historical feedback information and support more\neffective exemplar retrieval. Empirical evaluations show our method surpasses\nprevious state-of-the-arts with less optimization steps, i.e., improving F1\nscore by 10.1 on LIAR dataset, and reducing half of the optimization steps on\nProTeGi.\n","authors":["Cilin Yan","Jingyun Wang","Lin Zhang","Ruihui Zhao","Xiaopu Wu","Kai Xiong","Qingsong Liu","Guoliang Kang","Yangyang Kang"],"pdf_url":"https://arxiv.org/pdf/2411.07446v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2411.08037v1","updated":"2024-11-12T18:59:59Z","published":"2024-11-12T18:59:59Z","title":"Material Transforms from Disentangled NeRF Representations","summary":"  In this paper, we first propose a novel method for transferring material\ntransformations across different scenes. Building on disentangled Neural\nRadiance Field (NeRF) representations, our approach learns to map Bidirectional\nReflectance Distribution Functions (BRDF) from pairs of scenes observed in\nvarying conditions, such as dry and wet. The learned transformations can then\nbe applied to unseen scenes with similar materials, therefore effectively\nrendering the transformation learned with an arbitrary level of intensity.\nExtensive experiments on synthetic scenes and real-world objects validate the\neffectiveness of our approach, showing that it can learn various\ntransformations such as wetness, painting, coating, etc. Our results highlight\nnot only the versatility of our method but also its potential for practical\napplications in computer graphics. We publish our method implementation, along\nwith our synthetic/real datasets on\nhttps://github.com/astra-vision/BRDFTransform\n","authors":["Ivan Lopes","Jean-Fran√ßois Lalonde","Raoul de Charette"],"pdf_url":"https://arxiv.org/pdf/2411.08037v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08034v1","updated":"2024-11-12T18:59:35Z","published":"2024-11-12T18:59:35Z","title":"Scaling Properties of Diffusion Models for Perceptual Tasks","summary":"  In this paper, we argue that iterative computation with diffusion models\noffers a powerful paradigm for not only generation but also visual perception\ntasks. We unify tasks such as depth estimation, optical flow, and segmentation\nunder image-to-image translation, and show how diffusion models benefit from\nscaling training and test-time compute for these perception tasks. Through a\ncareful analysis of these scaling behaviors, we present various techniques to\nefficiently train diffusion models for visual perception tasks. Our models\nachieve improved or comparable performance to state-of-the-art methods using\nsignificantly less data and compute. To use our code and models, see\nhttps://scaling-diffusion-perception.github.io .\n","authors":["Rahul Ravishankar","Zeeshan Patel","Jathushan Rajasegaran","Jitendra Malik"],"pdf_url":"https://arxiv.org/pdf/2411.08034v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08033v1","updated":"2024-11-12T18:59:32Z","published":"2024-11-12T18:59:32Z","title":"GaussianAnything: Interactive Point Cloud Latent Diffusion for 3D\n  Generation","summary":"  While 3D content generation has advanced significantly, existing methods\nstill face challenges with input formats, latent space design, and output\nrepresentations. This paper introduces a novel 3D generation framework that\naddresses these challenges, offering scalable, high-quality 3D generation with\nan interactive Point Cloud-structured Latent space. Our framework employs a\nVariational Autoencoder (VAE) with multi-view posed RGB-D(epth)-N(ormal)\nrenderings as input, using a unique latent space design that preserves 3D shape\ninformation, and incorporates a cascaded latent diffusion model for improved\nshape-texture disentanglement. The proposed method, GaussianAnything, supports\nmulti-modal conditional 3D generation, allowing for point cloud, caption, and\nsingle/multi-view image inputs. Notably, the newly proposed latent space\nnaturally enables geometry-texture disentanglement, thus allowing 3D-aware\nediting. Experimental results demonstrate the effectiveness of our approach on\nmultiple datasets, outperforming existing methods in both text- and\nimage-conditioned 3D generation.\n","authors":["Yushi Lan","Shangchen Zhou","Zhaoyang Lyu","Fangzhou Hong","Shuai Yang","Bo Dai","Xingang Pan","Chen Change Loy"],"pdf_url":"https://arxiv.org/pdf/2411.08033v1.pdf","comment":"project page: https://nirvanalan.github.io/projects/GA/"},{"id":"http://arxiv.org/abs/2411.08027v1","updated":"2024-11-12T18:56:58Z","published":"2024-11-12T18:56:58Z","title":"LLMPhy: Complex Physical Reasoning Using Large Language Models and World\n  Models","summary":"  Physical reasoning is an important skill needed for robotic agents when\noperating in the real world. However, solving such reasoning problems often\ninvolves hypothesizing and reflecting over complex multi-body interactions\nunder the effect of a multitude of physical forces and thus learning all such\ninteractions poses a significant hurdle for state-of-the-art machine learning\nframeworks, including large language models (LLMs). To study this problem, we\npropose a new physical reasoning task and a dataset, dubbed TraySim. Our task\ninvolves predicting the dynamics of several objects on a tray that is given an\nexternal impact -- the domino effect of the ensued object interactions and\ntheir dynamics thus offering a challenging yet controlled setup, with the goal\nof reasoning being to infer the stability of the objects after the impact. To\nsolve this complex physical reasoning task, we present LLMPhy, a zero-shot\nblack-box optimization framework that leverages the physics knowledge and\nprogram synthesis abilities of LLMs, and synergizes these abilities with the\nworld models built into modern physics engines. Specifically, LLMPhy uses an\nLLM to generate code to iteratively estimate the physical hyperparameters of\nthe system (friction, damping, layout, etc.) via an implicit\nanalysis-by-synthesis approach using a (non-differentiable) simulator in the\nloop and uses the inferred parameters to imagine the dynamics of the scene\ntowards solving the reasoning task. To show the effectiveness of LLMPhy, we\npresent experiments on our TraySim dataset to predict the steady-state poses of\nthe objects. Our results show that the combination of the LLM and the physics\nengine leads to state-of-the-art zero-shot physical reasoning performance,\nwhile demonstrating superior convergence against standard black-box\noptimization methods and better estimation of the physical parameters.\n","authors":["Anoop Cherian","Radu Corcodel","Siddarth Jain","Diego Romeres"],"pdf_url":"https://arxiv.org/pdf/2411.08027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.17245v6","updated":"2024-11-12T18:50:19Z","published":"2023-11-28T21:39:20Z","title":"LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and\n  200+ FPS","summary":"  Recent advances in real-time neural rendering using point-based techniques\nhave enabled broader adoption of 3D representations. However, foundational\napproaches like 3D Gaussian Splatting impose substantial storage overhead, as\nStructure-from-Motion (SfM) points can grow to millions, often requiring\ngigabyte-level disk space for a single unbounded scene. This growth presents\nscalability challenges and hinders splatting efficiency. To address this, we\nintroduce LightGaussian, a method for transforming 3D Gaussians into a more\ncompact format. Inspired by Network Pruning, LightGaussian identifies Gaussians\nwith minimal global significance on scene reconstruction, and applies a pruning\nand recovery process to reduce redundancy while preserving visual quality.\nKnowledge distillation and pseudo-view augmentation then transfer spherical\nharmonic coefficients to a lower degree, yielding compact representations.\nGaussian Vector Quantization, based on each Gaussian's global significance,\nfurther lowers bitwidth with minimal accuracy loss. LightGaussian achieves an\naverage 15x compression rate while boosting FPS from 144 to 237 within the\n3D-GS framework, enabling efficient complex scene representation on the\nMip-NeRF 360 and Tank & Temple datasets. The proposed Gaussian pruning approach\nis also adaptable to other 3D representations (e.g., Scaffold-GS),\ndemonstrating strong generalization capabilities.\n","authors":["Zhiwen Fan","Kevin Wang","Kairun Wen","Zehao Zhu","Dejia Xu","Zhangyang Wang"],"pdf_url":"https://arxiv.org/pdf/2311.17245v6.pdf","comment":"NeurIPS 2024, Project page: https://lightgaussian.github.io/"},{"id":"http://arxiv.org/abs/2411.08017v1","updated":"2024-11-12T18:49:06Z","published":"2024-11-12T18:49:06Z","title":"Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model\n  with Compact Wavelet Encodings","summary":"  Large-scale 3D generative models require substantial computational resources\nyet often fall short in capturing fine details and complex geometries at high\nresolutions. We attribute this limitation to the inefficiency of current\nrepresentations, which lack the compactness required to model the generative\nmodels effectively. To address this, we introduce a novel approach called\nWavelet Latent Diffusion, or WaLa, that encodes 3D shapes into wavelet-based,\ncompact latent encodings. Specifically, we compress a $256^3$ signed distance\nfield into a $12^3 \\times 4$ latent grid, achieving an impressive 2427x\ncompression ratio with minimal loss of detail. This high level of compression\nallows our method to efficiently train large-scale generative networks without\nincreasing the inference time. Our models, both conditional and unconditional,\ncontain approximately one billion parameters and successfully generate\nhigh-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapid\ninference, producing shapes within two to four seconds depending on the\ncondition, despite the model's scale. We demonstrate state-of-the-art\nperformance across multiple datasets, with significant improvements in\ngeneration quality, diversity, and computational efficiency. We open-source our\ncode and, to the best of our knowledge, release the largest pretrained 3D\ngenerative models across different modalities.\n","authors":["Aditya Sanghi","Aliasghar Khani","Pradyumna Reddy","Arianna Rampini","Derek Cheung","Kamal Rahimi Malekshan","Kanika Madan","Hooman Shayani"],"pdf_url":"https://arxiv.org/pdf/2411.08017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20099v2","updated":"2024-11-12T18:46:33Z","published":"2024-06-28T17:59:51Z","title":"Odd-One-Out: Anomaly Detection by Comparing with Neighbors","summary":"  This paper introduces a novel anomaly detection (AD) problem that focuses on\nidentifying `odd-looking' objects relative to the other instances in a given\nscene. In contrast to the traditional AD benchmarks, anomalies in our task are\nscene-specific, defined by the regular instances that make up the majority.\nSince object instances may be only partly visible from a single viewpoint, our\nsetting employs multiple views of each scene as input. To provide a testbed for\nfuture research in this task, we introduce two benchmarks, ToysAD-8K and\nPartsAD-15K. We propose a novel method that constructs 3D object-centric\nrepresentations from multiple 2D views for each instance and detects the\nanomalous ones through a cross-instance comparison. We rigorously analyze our\nmethod quantitatively and qualitatively on the presented benchmarks.\n","authors":["Ankan Bhunia","Changjian Li","Hakan Bilen"],"pdf_url":"https://arxiv.org/pdf/2406.20099v2.pdf","comment":"Codes & Dataset at https://github.com/VICO-UoE/OddOneOutAD"},{"id":"http://arxiv.org/abs/2411.08014v1","updated":"2024-11-12T18:44:13Z","published":"2024-11-12T18:44:13Z","title":"Artistic Neural Style Transfer Algorithms with Activation Smoothing","summary":"  The works of Gatys et al. demonstrated the capability of Convolutional Neural\nNetworks (CNNs) in creating artistic style images. This process of transferring\ncontent images in different styles is called Neural Style Transfer (NST). In\nthis paper, we re-implement image-based NST, fast NST, and arbitrary NST. We\nalso explore to utilize ResNet with activation smoothing in NST. Extensive\nexperimental results demonstrate that smoothing transformation can greatly\nimprove the quality of stylization results.\n","authors":["Xiangtian Li","Han Cao","Zhaoyang Zhang","Jiacheng Hu","Yuhui Jin","Zihao Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.08014v1.pdf","comment":"8 pages,7 figures"},{"id":"http://arxiv.org/abs/2411.07976v1","updated":"2024-11-12T17:55:39Z","published":"2024-11-12T17:55:39Z","title":"DINO-LG: A Task-Specific DINO Model for Coronary Calcium Scoring","summary":"  Coronary artery disease (CAD), one of the most common cause of mortality in\nthe world. Coronary artery calcium (CAC) scoring using computed tomography (CT)\nis key for risk assessment to prevent coronary disease. Previous studies on\nrisk assessment and calcification detection in CT scans primarily use\napproaches based on UNET architecture, frequently implemented on pre-built\nmodels. However, these models are limited by the availability of annotated CT\nscans containing CAC and suffering from imbalanced dataset, decreasing\nperformance of CAC segmentation and scoring. In this study, we extend this\napproach by incorporating the self-supervised learning (SSL) technique of DINO\n(self-distillation with no labels) to eliminate limitations of scarce annotated\ndata in CT scans. The DINO model's ability to train without requiring CAC area\nannotations enhances its robustness in generating distinct features. The DINO\nmodel is trained on to focus specifically on calcified areas by using labels,\naiming to generate features that effectively capture and highlight key\ncharacteristics. The label-guided DINO (DINO-LG) enhances classification by\ndistinguishing CT slices that contain calcification from those that do not,\nperforming 57% better than the standard DINO model in this task. CAC scoring\nand segmentation tasks are performed by a basic U-NET architecture, fed\nspecifically with CT slices containing calcified areas as identified by the\nDINO-LG model. This targeted identification performed by DINO-LG model improves\nCAC segmentation performance by approximately 10% and significant increase in\nCAC scoring accuracy.\n","authors":["Mahmut S. Gokmen","Cody Bumgardner","Caner Ozcan"],"pdf_url":"https://arxiv.org/pdf/2411.07976v1.pdf","comment":"Developed by Center for Applied Artificial Intelligence (CAAI),\n  University of Kentucky"},{"id":"http://arxiv.org/abs/2411.07975v1","updated":"2024-11-12T17:55:10Z","published":"2024-11-12T17:55:10Z","title":"JanusFlow: Harmonizing Autoregression and Rectified Flow for Unified\n  Multimodal Understanding and Generation","summary":"  We present JanusFlow, a powerful framework that unifies image understanding\nand generation in a single model. JanusFlow introduces a minimalist\narchitecture that integrates autoregressive language models with rectified\nflow, a state-of-the-art method in generative modeling. Our key finding\ndemonstrates that rectified flow can be straightforwardly trained within the\nlarge language model framework, eliminating the need for complex architectural\nmodifications. To further improve the performance of our unified model, we\nadopt two key strategies: (i) decoupling the understanding and generation\nencoders, and (ii) aligning their representations during unified training.\nExtensive experiments show that JanusFlow achieves comparable or superior\nperformance to specialized models in their respective domains, while\nsignificantly outperforming existing unified approaches across standard\nbenchmarks. This work represents a step toward more efficient and versatile\nvision-language models.\n","authors":["Yiyang Ma","Xingchao Liu","Xiaokang Chen","Wen Liu","Chengyue Wu","Zhiyu Wu","Zizheng Pan","Zhenda Xie","Haowei Zhang","Xingkai yu","Liang Zhao","Yisong Wang","Jiaying Liu","Chong Ruan"],"pdf_url":"https://arxiv.org/pdf/2411.07975v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07956v1","updated":"2024-11-12T17:31:51Z","published":"2024-11-12T17:31:51Z","title":"Commissioning An All-Sky Infrared Camera Array for Detection Of Airborne\n  Objects","summary":"  To date there is little publicly available scientific data on Unidentified\nAerial Phenomena (UAP) whose properties and kinematics purportedly reside\noutside the performance envelope of known phenomena. To address this\ndeficiency, the Galileo Project is designing, building, and commissioning a\nmulti-modal ground-based observatory to continuously monitor the sky and\nconduct a rigorous long-term aerial census of all aerial phenomena, including\nnatural and human-made. One of the key instruments is an all-sky infrared\ncamera array using eight uncooled long-wave infrared FLIR Boson 640 cameras.\nTheir calibration includes a novel extrinsic calibration method using airplane\npositions from Automatic Dependent Surveillance-Broadcast (ADS-B) data. We\nestablish a first baseline for the system performance over five months of field\noperation, using a real-world dataset derived from ADS-B data, synthetic 3-D\ntrajectories, and a hand-labelled real-world dataset. We report acceptance\nrates (e.g. viewable airplanes that are recorded) and detection efficiencies\n(e.g. recorded airplanes which are successfully detected) for a variety of\nweather conditions, range and aircraft size. We reconstruct $\\sim$500,000\ntrajectories of aerial objects from this commissioning period. A toy outlier\nsearch focused on large sinuosity of the 2-D reconstructed trajectories flags\nabout 16% of trajectories as outliers. After manual review, 144 trajectories\nremain ambiguous: they are likely mundane objects but cannot be elucidated at\nthis stage of development without distance and kinematics estimation or other\nsensor modalities. Our observed count of ambiguous outliers combined with\nsystematic uncertainties yields an upper limit of 18,271 outliers count for the\nfive-month interval at a 95% confidence level. This likelihood-based method to\nevaluate significance is applicable to all of our future outlier searches.\n","authors":["Laura Domin√©","Ankit Biswas","Richard Cloete","Alex Delacroix","Andriy Fedorenko","Lucas Jacaruso","Ezra Kelderman","Eric Keto","Sarah Little","Abraham Loeb","Eric Masson","Mike Prior","Forrest Schultz","Matthew Szenher","Wes Watters","Abby White"],"pdf_url":"https://arxiv.org/pdf/2411.07956v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07945v1","updated":"2024-11-12T17:17:33Z","published":"2024-11-12T17:17:33Z","title":"SimBase: A Simple Baseline for Temporal Video Grounding","summary":"  This paper presents SimBase, a simple yet effective baseline for temporal\nvideo grounding. While recent advances in temporal grounding have led to\nimpressive performance, they have also driven network architectures toward\ngreater complexity, with a range of methods to (1) capture temporal\nrelationships and (2) achieve effective multimodal fusion. In contrast, this\npaper explores the question: How effective can a simplified approach be? To\ninvestigate, we design SimBase, a network that leverages lightweight,\none-dimensional temporal convolutional layers instead of complex temporal\nstructures. For cross-modal interaction, SimBase only employs an element-wise\nproduct instead of intricate multimodal fusion. Remarkably, SimBase achieves\nstate-of-the-art results on two large-scale datasets. As a simple yet powerful\nbaseline, we hope SimBase will spark new ideas and streamline future\nevaluations in temporal video grounding.\n","authors":["Peijun Bao","Alex C. Kot"],"pdf_url":"https://arxiv.org/pdf/2411.07945v1.pdf","comment":"Technical report"},{"id":"http://arxiv.org/abs/2411.07941v1","updated":"2024-11-12T17:11:18Z","published":"2024-11-12T17:11:18Z","title":"DuoLift-GAN:Reconstructing CT from Single-view and Biplanar X-Rays with\n  Generative Adversarial Networks","summary":"  Computed tomography (CT) provides highly detailed three-dimensional (3D)\nmedical images but is costly, time-consuming, and often inaccessible in\nintraoperative settings (Organization et al. 2011). Recent advancements have\nexplored reconstructing 3D chest volumes from sparse 2D X-rays, such as\nsingle-view or orthogonal double-view images. However, current models tend to\nprocess 2D images in a planar manner, prioritizing visual realism over\nstructural accuracy. In this work, we introduce DuoLift Generative Adversarial\nNetworks (DuoLift-GAN), a novel architecture with dual branches that\nindependently elevate 2D images and their features into 3D representations.\nThese 3D outputs are merged into a unified 3D feature map and decoded into a\ncomplete 3D chest volume, enabling richer 3D information capture. We also\npresent a masked loss function that directs reconstruction towards critical\nanatomical regions, improving structural accuracy and visual quality. This\npaper demonstrates that DuoLift-GAN significantly enhances reconstruction\naccuracy while achieving superior visual realism compared to existing methods.\n","authors":["Zhaoxi Zhang","Yueliang Ying"],"pdf_url":"https://arxiv.org/pdf/2411.07941v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07940v1","updated":"2024-11-12T17:09:20Z","published":"2024-11-12T17:09:20Z","title":"Automatic dataset shift identification to support root cause analysis of\n  AI performance drift","summary":"  Shifts in data distribution can substantially harm the performance of\nclinical AI models. Hence, various methods have been developed to detect the\npresence of such shifts at deployment time. However, root causes of dataset\nshifts are varied, and the choice of shift mitigation strategies is highly\ndependent on the precise type of shift encountered at test time. As such,\ndetecting test-time dataset shift is not sufficient: precisely identifying\nwhich type of shift has occurred is critical. In this work, we propose the\nfirst unsupervised dataset shift identification framework, effectively\ndistinguishing between prevalence shift (caused by a change in the label\ndistribution), covariate shift (caused by a change in input characteristics)\nand mixed shifts (simultaneous prevalence and covariate shifts). We discuss the\nimportance of self-supervised encoders for detecting subtle covariate shifts\nand propose a novel shift detector leveraging both self-supervised encoders and\ntask model outputs for improved shift detection. We report promising results\nfor the proposed shift identification framework across three different imaging\nmodalities (chest radiography, digital mammography, and retinal fundus images)\non five types of real-world dataset shifts, using four large publicly available\ndatasets.\n","authors":["M√©lanie Roschewitz","Raghav Mehta","Charles Jones","Ben Glocker"],"pdf_url":"https://arxiv.org/pdf/2411.07940v1.pdf","comment":"Code available at\n  https://github.com/biomedia-mira/shift_identification"},{"id":"http://arxiv.org/abs/2411.07936v1","updated":"2024-11-12T17:05:18Z","published":"2024-11-12T17:05:18Z","title":"Learning Disentangled Representations for Perceptual Point Cloud Quality\n  Assessment via Mutual Information Minimization","summary":"  No-Reference Point Cloud Quality Assessment (NR-PCQA) aims to objectively\nassess the human perceptual quality of point clouds without relying on\npristine-quality point clouds for reference. It is becoming increasingly\nsignificant with the rapid advancement of immersive media applications such as\nvirtual reality (VR) and augmented reality (AR). However, current NR-PCQA\nmodels attempt to indiscriminately learn point cloud content and distortion\nrepresentations within a single network, overlooking their distinct\ncontributions to quality information. To address this issue, we propose DisPA,\na novel disentangled representation learning framework for NR-PCQA. The\nframework trains a dual-branch disentanglement network to minimize mutual\ninformation (MI) between representations of point cloud content and distortion.\nSpecifically, to fully disentangle representations, the two branches adopt\ndifferent philosophies: the content-aware encoder is pretrained by a masked\nauto-encoding strategy, which can allow the encoder to capture semantic\ninformation from rendered images of distorted point clouds; the\ndistortion-aware encoder takes a mini-patch map as input, which forces the\nencoder to focus on low-level distortion patterns. Furthermore, we utilize an\nMI estimator to estimate the tight upper bound of the actual MI and further\nminimize it to achieve explicit representation disentanglement. Extensive\nexperimental results demonstrate that DisPA outperforms state-of-the-art\nmethods on multiple PCQA datasets.\n","authors":["Ziyu Shan","Yujie Zhang","Yipeng Liu","Yiling Xu"],"pdf_url":"https://arxiv.org/pdf/2411.07936v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07918v1","updated":"2024-11-12T16:50:13Z","published":"2024-11-12T16:50:13Z","title":"Isometric Transformations for Image Augmentation in Mueller Matrix\n  Polarimetry","summary":"  Mueller matrix polarimetry captures essential information about polarized\nlight interactions with a sample, presenting unique challenges for data\naugmentation in deep learning due to its distinct structure. While\naugmentations are an effective and affordable way to enhance dataset diversity\nand reduce overfitting, standard transformations like rotations and flips do\nnot preserve the polarization properties in Mueller matrix images. To this end,\nwe introduce a versatile simulation framework that applies physically\nconsistent rotations and flips to Mueller matrices, tailored to maintain\npolarization fidelity. Our experimental results across multiple datasets reveal\nthat conventional augmentations can lead to misleading results when applied to\npolarimetric data, underscoring the necessity of our physics-based approach. In\nour experiments, we first compare our polarization-specific augmentations\nagainst real-world captures to validate their physical consistency. We then\napply these augmentations in a semantic segmentation task, achieving\nsubstantial improvements in model generalization and performance. This study\nunderscores the necessity of physics-informed data augmentation for\npolarimetric imaging in deep learning (DL), paving the way for broader adoption\nand more robust applications across diverse research in the field. In\nparticular, our framework unlocks the potential of DL models for polarimetric\ndatasets with limited sample sizes. Our code implementation is available at\ngithub.com/hahnec/polar_augment.\n","authors":["Christopher Hahne","Omar Rodriguez-Nunez","√âl√©a Gros","Th√©otim Lucas","Ekkehard Hewer","Tatiana Novikova","Theoni Maragkou","Philippe Schucht","Richard McKinley"],"pdf_url":"https://arxiv.org/pdf/2411.07918v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2411.05747v3","updated":"2024-11-12T16:42:02Z","published":"2024-11-08T18:08:33Z","title":"WavShadow: Wavelet Based Shadow Segmentation and Removal","summary":"  Shadow removal and segmentation remain challenging tasks in computer vision,\nparticularly in complex real world scenarios. This study presents a novel\napproach that enhances the ShadowFormer model by incorporating Masked\nAutoencoder (MAE) priors and Fast Fourier Convolution (FFC) blocks, leading to\nsignificantly faster convergence and improved performance. We introduce key\ninnovations: (1) integration of MAE priors trained on Places2 dataset for\nbetter context understanding, (2) adoption of Haar wavelet features for\nenhanced edge detection and multiscale analysis, and (3) implementation of a\nmodified SAM Adapter for robust shadow segmentation. Extensive experiments on\nthe challenging DESOBA dataset demonstrate that our approach achieves state of\nthe art results, with notable improvements in both convergence speed and shadow\nremoval quality.\n","authors":["Shreyans Jain","Viraj Vekaria","Karan Gandhi","Aadya Arora"],"pdf_url":"https://arxiv.org/pdf/2411.05747v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.07155v2","updated":"2024-11-12T16:39:29Z","published":"2024-05-12T04:18:10Z","title":"Meta-Learned Modality-Weighted Knowledge Distillation for Robust\n  Multi-Modal Learning with Missing Data","summary":"  In multi-modal learning, some modalities are more influential than others,\nand their absence can have a significant impact on classification/segmentation\naccuracy. Addressing this challenge, we propose a novel approach called\nMeta-learned Modality-weighted Knowledge Distillation (MetaKD), which enables\nmulti-modal models to maintain high accuracy even when key modalities are\nmissing. MetaKD adaptively estimates the importance weight of each modality\nthrough a meta-learning process. These learned importance weights guide a\npairwise modality-weighted knowledge distillation process, allowing\nhigh-importance modalities to transfer knowledge to lower-importance ones,\nresulting in robust performance despite missing inputs. Unlike previous methods\nin the field, which are often task-specific and require significant\nmodifications, our approach is designed to work in multiple tasks (e.g.,\nsegmentation and classification) with minimal adaptation. Experimental results\non five prevalent datasets, including three Brain Tumor Segmentation datasets\n(BraTS2018, BraTS2019 and BraTS2020), the Alzheimer's Disease Neuroimaging\nInitiative (ADNI) classification dataset and the Audiovision-MNIST\nclassification dataset, demonstrate the proposed model is able to outperform\nthe compared models by a large margin.\n","authors":["Hu Wang","Salma Hassan","Yuyuan Liu","Congbo Ma","Yuanhong Chen","Yutong Xie","Mostafa Salem","Yu Tian","Jodie Avery","Louise Hull","Ian Reid","Mohammad Yaqub","Gustavo Carneiro"],"pdf_url":"https://arxiv.org/pdf/2405.07155v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07901v1","updated":"2024-11-12T16:15:25Z","published":"2024-11-12T16:15:25Z","title":"TLDR: Traffic Light Detection using Fourier Domain Adaptation in Hostile\n  WeatheR","summary":"  The scarcity of comprehensive datasets in the traffic light detection and\nrecognition domain and the poor performance of state-of-the-art models under\nhostile weather conditions present significant challenges. To address these\nissues, this paper proposes a novel approach by merging two widely used\ndatasets, LISA and S2TLD. The merged dataset is further processed to tackle\nclass imbalance, a common problem in this domain. This merged dataset becomes\nour source domain. Synthetic rain and fog are added to the dataset to create\nour target domain. We employ Fourier Domain Adaptation (FDA) to create a final\ndataset with a minimized domain gap between the two datasets, helping the model\ntrained on this final dataset adapt to rainy and foggy weather conditions.\nAdditionally, we explore Semi-Supervised Learning (SSL) techniques to leverage\nthe available data more effectively. Experimental results demonstrate that\nmodels trained on FDA-augmented images outperform those trained without FDA\nacross confidence-dependent and independent metrics, like mAP50, mAP50-95,\nPrecision, and Recall. The best-performing model, YOLOv8, achieved a Precision\nincrease of 5.1860%, Recall increase of 14.8009%, mAP50 increase of 9.5074%,\nand mAP50-95 increase of 19.5035%. On average, percentage increases of 7.6892%\nin Precision, 19.9069% in Recall, 15.8506% in mAP50, and 23.8099% in mAP50-95\nwere observed across all models, highlighting the effectiveness of FDA in\nmitigating the impact of adverse weather conditions on model performance. These\nimprovements pave the way for real-world applications where reliable\nperformance in challenging environmental conditions is critical.\n","authors":["Ishaan Gakhar","Aryesh Guha","Aryaman Gupta","Amit Agarwal","Durga Toshniwal","Ujjwal Verma"],"pdf_url":"https://arxiv.org/pdf/2411.07901v1.pdf","comment":"Under Review at IEEE Transactions of Artificial Intelligence. 10\n  Pages, 7 Figures"},{"id":"http://arxiv.org/abs/2411.07899v1","updated":"2024-11-12T16:12:51Z","published":"2024-11-12T16:12:51Z","title":"Rendering-Oriented 3D Point Cloud Attribute Compression using Sparse\n  Tensor-based Transformer","summary":"  The evolution of 3D visualization techniques has fundamentally transformed\nhow we interact with digital content. At the forefront of this change is point\ncloud technology, offering an immersive experience that surpasses traditional\n2D representations. However, the massive data size of point clouds presents\nsignificant challenges in data compression. Current methods for lossy point\ncloud attribute compression (PCAC) generally focus on reconstructing the\noriginal point clouds with minimal error. However, for point cloud\nvisualization scenarios, the reconstructed point clouds with distortion still\nneed to undergo a complex rendering process, which affects the final\nuser-perceived quality. In this paper, we propose an end-to-end deep learning\nframework that seamlessly integrates PCAC with differentiable rendering,\ndenoted as rendering-oriented PCAC (RO-PCAC), directly targeting the quality of\nrendered multiview images for viewing. In a differentiable manner, the impact\nof the rendering process on the reconstructed point clouds is taken into\naccount. Moreover, we characterize point clouds as sparse tensors and propose a\nsparse tensor-based transformer, called SP-Trans. By aligning with the local\ndensity of the point cloud and utilizing an enhanced local attention mechanism,\nSP-Trans captures the intricate relationships within the point cloud, further\nimproving feature analysis and synthesis within the framework. Extensive\nexperiments demonstrate that the proposed RO-PCAC achieves state-of-the-art\ncompression performance, compared to existing reconstruction-oriented methods,\nincluding traditional, learning-based, and hybrid methods.\n","authors":["Xiao Huo","Junhui Ho","Shuai Wan","Fuzheng Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07893v1","updated":"2024-11-12T15:58:09Z","published":"2024-11-12T15:58:09Z","title":"Joint multi-dimensional dynamic attention and transformer for general\n  image restoration","summary":"  Outdoor images often suffer from severe degradation due to rain, haze, and\nnoise, impairing image quality and challenging high-level tasks. Current image\nrestoration methods struggle to handle complex degradation while maintaining\nefficiency. This paper introduces a novel image restoration architecture that\ncombines multi-dimensional dynamic attention and self-attention within a U-Net\nframework. To leverage the global modeling capabilities of transformers and the\nlocal modeling capabilities of convolutions, we integrate sole CNNs in the\nencoder-decoder and sole transformers in the latent layer. Additionally, we\ndesign convolutional kernels with selected multi-dimensional dynamic attention\nto capture diverse degraded inputs efficiently. A transformer block with\ntransposed self-attention further enhances global feature extraction while\nmaintaining efficiency. Extensive experiments demonstrate that our method\nachieves a better balance between performance and computational complexity\nacross five image restoration tasks: deraining, deblurring, denoising,\ndehazing, and enhancement, as well as superior performance for high-level\nvision tasks. The source code will be available at\nhttps://github.com/House-yuyu/MDDA-former.\n","authors":["Huan Zhang","Xu Zhang","Nian Cai","Jianglei Di","Yun Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07893v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07885v1","updated":"2024-11-12T15:47:17Z","published":"2024-11-12T15:47:17Z","title":"INTRABENCH: Interactive Radiological Benchmark","summary":"  Current interactive segmentation approaches, inspired by the success of\nMETA's Segment Anything model, have achieved notable advancements, however,\nthey come with substantial limitations that hinder their practical application\nin real clinical scenarios. These include unrealistic human interaction\nrequirements, such as slice-by-slice operations for 2D models on 3D data, a\nlack of iterative refinement, and insufficient evaluation experiments. These\nshortcomings prevent accurate assessment of model performance and lead to\ninconsistent outcomes across studies. IntRaBench overcomes these challenges by\noffering a comprehensive and reproducible framework for evaluating interactive\nsegmentation methods in realistic, clinically relevant scenarios. It includes\ndiverse datasets, target structures, and segmentation models, and provides a\nflexible codebase that allows seamless integration of new models and prompting\nstrategies. Additionally, we introduce advanced techniques to minimize\nclinician interaction, ensuring fair comparisons between 2D and 3D models. By\nopen-sourcing IntRaBench, we invite the research community to integrate their\nmodels and prompting techniques, ensuring continuous and transparent evaluation\nof interactive segmentation models in 3D medical imaging.\n","authors":["Constantin Ulrich","Tassilo Wald","Emily Tempus","Maximilian Rokuss","Paul F. Jaeger","Klaus Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2411.07885v1.pdf","comment":"Undergoing Peer-Review"},{"id":"http://arxiv.org/abs/2411.07873v1","updated":"2024-11-12T15:29:50Z","published":"2024-11-12T15:29:50Z","title":"Diverse capability and scaling of diffusion and auto-regressive models\n  when learning abstract rules","summary":"  Humans excel at discovering regular structures from limited samples and\napplying inferred rules to novel settings. We investigate whether modern\ngenerative models can similarly learn underlying rules from finite samples and\nperform reasoning through conditional sampling. Inspired by Raven's Progressive\nMatrices task, we designed GenRAVEN dataset, where each sample consists of\nthree rows, and one of 40 relational rules governing the object position,\nnumber, or attributes applies to all rows. We trained generative models to\nlearn the data distribution, where samples are encoded as integer arrays to\nfocus on rule learning. We compared two generative model families: diffusion\n(EDM, DiT, SiT) and autoregressive models (GPT2, Mamba). We evaluated their\nability to generate structurally consistent samples and perform panel\ncompletion via unconditional and conditional sampling. We found diffusion\nmodels excel at unconditional generation, producing more novel and consistent\nsamples from scratch and memorizing less, but performing less well in panel\ncompletion, even with advanced conditional sampling methods. Conversely,\nautoregressive models excel at completing missing panels in a rule-consistent\nmanner but generate less consistent samples unconditionally. We observe diverse\ndata scaling behaviors: for both model families, rule learning emerges at a\ncertain dataset size - around 1000s examples per rule. With more training data,\ndiffusion models improve both their unconditional and conditional generation\ncapabilities. However, for autoregressive models, while panel completion\nimproves with more training data, unconditional generation consistency\ndeclines. Our findings highlight complementary capabilities and limitations of\ndiffusion and autoregressive models in rule learning and reasoning tasks,\nsuggesting avenues for further research into their mechanisms and potential for\nhuman-like reasoning.\n","authors":["Binxu Wang","Jiaqi Shang","Haim Sompolinsky"],"pdf_url":"https://arxiv.org/pdf/2411.07873v1.pdf","comment":"12 pages, 5 figures. Accepted to NeurIPS2024 Workshop on System 2\n  Reasoning At Scale as long paper"},{"id":"http://arxiv.org/abs/2411.07863v1","updated":"2024-11-12T15:22:14Z","published":"2024-11-12T15:22:14Z","title":"CDXFormer: Boosting Remote Sensing Change Detection with Extended Long\n  Short-Term Memory","summary":"  In complex scenes and varied conditions, effectively integrating\nspatial-temporal context is crucial for accurately identifying changes.\nHowever, current RS-CD methods lack a balanced consideration of performance and\nefficiency. CNNs lack global context, Transformers have quadratic computational\ncomplexity, and Mambas are restricted by CUDA acceleration. In this paper, we\npropose CDXFormer, with a core component that is a powerful XLSTM-based feature\nenhancement layer, integrating the advantages of linear computational\ncomplexity, global context perception, and strong interpret-ability.\nSpecifically, we introduce a scale-specific Feature Enhancer layer,\nincorporating a Cross-Temporal Global Perceptron customized for\nsemantic-accurate deep features, and a Cross-Temporal Spatial Refiner\ncustomized for detail-rich shallow features. Additionally, we propose a\nCross-Scale Interactive Fusion module to progressively interact global change\nrepresentations with spatial responses. Extensive experimental results\ndemonstrate that CDXFormer achieves state-of-the-art performance across three\nbenchmark datasets, offering a compelling balance between efficiency and\naccuracy. Code is available at https://github.com/xwmaxwma/rschange.\n","authors":["Zhenkai Wu","Xiaowen Ma","Rongrong Lian","Zhentao Lin","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04492v4","updated":"2024-11-12T15:16:36Z","published":"2024-10-06T14:11:39Z","title":"Interpret Your Decision: Logical Reasoning Regularization for\n  Generalization in Visual Classification","summary":"  Vision models excel in image classification but struggle to generalize to\nunseen data, such as classifying images from unseen domains or discovering\nnovel categories. In this paper, we explore the relationship between logical\nreasoning and deep learning generalization in visual classification. A logical\nregularization termed L-Reg is derived which bridges a logical analysis\nframework to image classification. Our work reveals that L-Reg reduces the\ncomplexity of the model in terms of the feature distribution and classifier\nweights. Specifically, we unveil the interpretability brought by L-Reg, as it\nenables the model to extract the salient features, such as faces to persons,\nfor classification. Theoretical analysis and experiments demonstrate that L-Reg\nenhances generalization across various scenarios, including multi-domain\ngeneralization and generalized category discovery. In complex real-world\nscenarios where images span unknown classes and unseen domains, L-Reg\nconsistently improves generalization, highlighting its practical efficacy.\n","authors":["Zhaorui Tan","Xi Yang","Qiufeng Wang","Anh Nguyen","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.04492v4.pdf","comment":"Accepted by NeurIPS2024 as Spotlight"},{"id":"http://arxiv.org/abs/2407.06001v2","updated":"2024-11-12T15:14:41Z","published":"2024-07-08T14:53:07Z","title":"Pseudo-triplet Guided Few-shot Composed Image Retrieval","summary":"  Composed Image Retrieval (CIR) is a challenging task that aims to retrieve\nthe target image with a multimodal query, i.e., a reference image, and its\ncomplementary modification text. As previous supervised or zero-shot learning\nparadigms all fail to strike a good trade-off between the model's\ngeneralization ability and retrieval performance, recent researchers have\nintroduced the task of few-shot CIR (FS-CIR) and proposed a textual\ninversion-based network based on pretrained CLIP model to realize it. Despite\nits promising performance, the approach encounters two key limitations: simply\nrelying on the few annotated samples for CIR model training and\nindiscriminately selecting training triplets for CIR model fine-tuning. To\naddress these two limitations, we propose a novel two-stage pseudo triplet\nguided few-shot CIR scheme, dubbed PTG-FSCIR. In the first stage, we propose an\nattentive masking and captioning-based pseudo triplet generation method, to\nconstruct pseudo triplets from pure image data and use them to fulfill the\nCIR-task specific pertaining. In the second stage, we propose a challenging\ntriplet-based CIR fine-tuning method, where we design a pseudo modification\ntext-based sample challenging score estimation strategy and a robust top\nrange-based random sampling strategy for sampling robust challenging triplets\nto promote the model fine-tuning. Notably, our scheme is plug-and-play and\ncompatible with any existing supervised CIR models. We test our scheme across\ntwo backbones on three public datasets (i.e., FashionIQ, CIRR, and\nBirds-to-Words), achieving maximum improvements of 13.3%, 22.2%, and 17.4%\nrespectively, demonstrating our scheme's efficacy.\n","authors":["Bohan Hou","Haoqiang Lin","Haokun Wen","Meng Liu","Mingzhu Xu","Xuemeng Song"],"pdf_url":"https://arxiv.org/pdf/2407.06001v2.pdf","comment":"10pages"},{"id":"http://arxiv.org/abs/2411.07848v1","updated":"2024-11-12T15:01:40Z","published":"2024-11-12T15:01:40Z","title":"NL-SLAM for OC-VLN: Natural Language Grounded SLAM for Object-Centric\n  VLN","summary":"  Landmark-based navigation (e.g. go to the wooden desk) and relative\npositional navigation (e.g. move 5 meters forward) are distinct navigation\nchallenges solved very differently in existing robotics navigation methodology.\nWe present a new dataset, OC-VLN, in order to distinctly evaluate grounding\nobject-centric natural language navigation instructions in a method for\nperforming landmark-based navigation. We also propose Natural Language grounded\nSLAM (NL-SLAM), a method to ground natural language instruction to robot\nobservations and poses. We actively perform NL-SLAM in order to follow\nobject-centric natural language navigation instructions. Our methods leverage\npre-trained vision and language foundation models and require no task-specific\ntraining. We construct two strong baselines from state-of-the-art methods on\nrelated tasks, Object Goal Navigation and Vision Language Navigation, and we\nshow that our approach, NL-SLAM, outperforms these baselines across all our\nmetrics of success on OC-VLN. Finally, we successfully demonstrate the\neffectiveness of NL-SLAM for performing navigation instruction following in the\nreal world on a Boston Dynamics Spot robot.\n","authors":["Sonia Raychaudhuri","Duy Ta","Katrina Ashton","Angel X. Chang","Jiuguang Wang","Bernadette Bucher"],"pdf_url":"https://arxiv.org/pdf/2411.07848v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12203v3","updated":"2024-11-12T15:00:37Z","published":"2024-03-18T19:25:57Z","title":"Bootstrapping Reinforcement Learning with Imitation for Vision-Based\n  Agile Flight","summary":"  Learning visuomotor policies for agile quadrotor flight presents significant\ndifficulties, primarily from inefficient policy exploration caused by\nhigh-dimensional visual inputs and the need for precise and low-latency\ncontrol. To address these challenges, we propose a novel approach that combines\nthe performance of Reinforcement Learning (RL) and the sample efficiency of\nImitation Learning (IL) in the task of vision-based autonomous drone racing.\nWhile RL provides a framework for learning high-performance controllers through\ntrial and error, it faces challenges with sample efficiency and computational\ndemands due to the high dimensionality of visual inputs. Conversely, IL\nefficiently learns from visual expert demonstrations, but it remains limited by\nthe expert's performance and state distribution. To overcome these limitations,\nour policy learning framework integrates the strengths of both approaches. Our\nframework contains three phases: training a teacher policy using RL with\nprivileged state information, distilling it into a student policy via IL, and\nadaptive fine-tuning via RL. Testing in both simulated and real-world scenarios\nshows our approach can not only learn in scenarios where RL from scratch fails\nbut also outperforms existing IL methods in both robustness and performance,\nsuccessfully navigating a quadrotor through a race course using only visual\ninformation. Videos of the experiments are available at\nhttps://rpg.ifi.uzh.ch/bootstrap-rl-with-il/index.html.\n","authors":["Jiaxu Xing","Angel Romero","Leonard Bauersfeld","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.12203v3.pdf","comment":"8th Annual Conference on Robot Learning (CoRL)"},{"id":"http://arxiv.org/abs/2401.11796v2","updated":"2024-11-12T14:58:37Z","published":"2024-01-22T09:53:20Z","title":"REVEX: A Unified Framework for Removal-Based Explainable Artificial\n  Intelligence in Video","summary":"  We developed REVEX, a removal-based video explanations framework. This work\nextends fine-grained explanation frameworks for computer vision data and adapts\nsix existing techniques to video by adding temporal information and local\nexplanations. The adapted methods were evaluated across networks, datasets,\nimage classes, and evaluation metrics. By decomposing explanation into steps,\nstrengths and weaknesses were revealed in the studied methods, for example, on\npixel clustering and perturbations in the input. Video LIME outperformed other\nmethods with deletion values up to 31\\% lower and insertion up to 30\\% higher,\ndepending on method and network. Video RISE achieved superior performance in\nthe average drop metric, with values 10\\% lower. In contrast,\nlocalization-based metrics revealed low performance across all methods, with\nsignificant variation depending on network. Pointing game accuracy reached\n53\\%, and IoU-based metrics remained below 20\\%. Drawing on the findings across\nXAI methods, we further examine the limitations of the employed XAI evaluation\nmetrics and highlight their suitability in different applications.\n","authors":["F. Xavier Gaya-Morey","Jose M. Buades-Rubio","I. Scott MacKenzie","Cristina Manresa-Yee"],"pdf_url":"https://arxiv.org/pdf/2401.11796v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00002v2","updated":"2024-11-12T14:55:50Z","published":"2024-07-10T15:03:00Z","title":"Transfer Learning for Wildlife Classification: Evaluating YOLOv8 against\n  DenseNet, ResNet, and VGGNet on a Custom Dataset","summary":"  This study evaluates the performance of various deep learning models,\nspecifically DenseNet, ResNet, VGGNet, and YOLOv8, for wildlife species\nclassification on a custom dataset. The dataset comprises 575 images of 23\nendangered species sourced from reputable online repositories. The study\nutilizes transfer learning to fine-tune pre-trained models on the dataset,\nfocusing on reducing training time and enhancing classification accuracy. The\nresults demonstrate that YOLOv8 outperforms other models, achieving a training\naccuracy of 97.39% and a validation F1-score of 96.50%. These findings suggest\nthat YOLOv8, with its advanced architecture and efficient feature extraction\ncapabilities, holds great promise for automating wildlife monitoring and\nconservation efforts.\n","authors":["Subek Sharma","Sisir Dhakal","Mansi Bhavsar"],"pdf_url":"https://arxiv.org/pdf/2408.00002v2.pdf","comment":"This is published in Journal of Artificial Intelligence and Capsule\n  Networks, December 2024, Volume 6, Issue 4, Pages 415-435"},{"id":"http://arxiv.org/abs/2410.20178v2","updated":"2024-11-12T14:45:18Z","published":"2024-10-26T13:19:57Z","title":"LLMs Can Evolve Continually on Modality for X-Modal Reasoning","summary":"  Multimodal Large Language Models (MLLMs) have gained significant attention\ndue to their impressive capabilities in multimodal understanding. However,\nexisting methods rely heavily on extensive modal-specific pretraining and\njoint-modal tuning, leading to significant computational burdens when expanding\nto new modalities. In this paper, we propose PathWeave, a flexible and scalable\nframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs\nto continually EVolve on modalities for $\\mathbb{X}$-modal reasoning. We\nleverage the concept of Continual Learning and develop an incremental training\nstrategy atop pre-trained MLLMs, enabling their expansion to new modalities\nusing uni-modal data, without executing joint-modal pretraining. In detail, a\nnovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and\ncross-modal adapters are seamlessly integrated to facilitate efficient modality\nalignment and collaboration. Additionally, an MoE-based gating module is\napplied between two types of adapters to further enhance the multimodal\ninteraction. To investigate the proposed method, we establish a challenging\nbenchmark called Continual Learning of Modality (MCL), which consists of\nhigh-quality QA data from five distinct modalities: image, video, audio, depth\nand point cloud. Extensive experiments demonstrate the effectiveness of the\nproposed AnA framework on learning plasticity and memory stability during\ncontinual learning. Furthermore, PathWeave performs comparably to\nstate-of-the-art MLLMs while concurrently reducing parameter training burdens\nby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave\n","authors":["Jiazuo Yu","Haomiao Xiong","Lu Zhang","Haiwen Diao","Yunzhi Zhuge","Lanqing Hong","Dong Wang","Huchuan Lu","You He","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2410.20178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07834v1","updated":"2024-11-12T14:36:06Z","published":"2024-11-12T14:36:06Z","title":"Towards Vision Mixture of Experts for Wildlife Monitoring on the Edge","summary":"  The explosion of IoT sensors in industrial, consumer and remote sensing use\ncases has come with unprecedented demand for computing infrastructure to\ntransmit and to analyze petabytes of data. Concurrently, the world is slowly\nshifting its focus towards more sustainable computing. For these reasons, there\nhas been a recent effort to reduce the footprint of related computing\ninfrastructure, especially by deep learning algorithms, for advanced insight\ngeneration. The `TinyML' community is actively proposing methods to save\ncommunication bandwidth and excessive cloud storage costs while reducing\nalgorithm inference latency and promoting data privacy. Such proposed\napproaches should ideally process multiple types of data, including time\nseries, audio, satellite images, and video, near the network edge as multiple\ndata streams has been shown to improve the discriminative ability of learning\nalgorithms, especially for generating fine grained results. Incidentally, there\nhas been recent work on data driven conditional computation of subnetworks that\nhas shown real progress in using a single model to share parameters among very\ndifferent types of inputs such as images and text, reducing the computation\nrequirement of multi-tower multimodal networks. Inspired by such line of work,\nwe explore similar per patch conditional computation for the first time for\nmobile vision transformers (vision only case), that will eventually be used for\nsingle-tower multimodal edge models. We evaluate the model on Cornell Sap\nSucker Woods 60, a fine grained bird species discrimination dataset. Our\ninitial experiments uses $4X$ fewer parameters compared to MobileViTV2-1.0 with\na $1$% accuracy drop on the iNaturalist '21 birds test data provided as part of\nthe SSW60 dataset.\n","authors":["Emmanuel Azuh Mensah","Anderson Lee","Haoran Zhang","Yitong Shan","Kurtis Heimerl"],"pdf_url":"https://arxiv.org/pdf/2411.07834v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03677v4","updated":"2024-11-12T14:33:36Z","published":"2024-08-07T10:36:26Z","title":"L4DR: LiDAR-4DRadar Fusion for Weather-Robust 3D Object Detection","summary":"  LiDAR-based vision systems are integral for 3D object detection, which is\ncrucial for autonomous navigation. However, they suffer from performance\ndegradation in adverse weather conditions due to the quality deterioration of\nLiDAR point clouds. Fusing LiDAR with the weather-robust 4D radar sensor is\nexpected to solve this problem. However, the fusion of LiDAR and 4D radar is\nchallenging because they differ significantly in terms of data quality and the\ndegree of degradation in adverse weather. To address these issues, we introduce\nL4DR, a weather-robust 3D object detection method that effectively achieves\nLiDAR and 4D Radar fusion. Our L4DR includes Multi-Modal Encoding (MME) and\nForeground-Aware Denoising (FAD) technique to reconcile sensor gaps, which is\nthe first exploration of the complementarity of early fusion between LiDAR and\n4D radar. Additionally, we design an Inter-Modal and Intra-Modal ({IM}2 )\nparallel feature extraction backbone coupled with a Multi-Scale Gated Fusion\n(MSGF) module to counteract the varying degrees of sensor degradation under\nadverse weather conditions. Experimental evaluation on a VoD dataset with\nsimulated fog proves that L4DR is more adaptable to changing weather\nconditions. It delivers a significant performance increase under different fog\nlevels, improving the 3D mAP by up to 20.0% over the traditional LiDAR-only\napproach. Moreover, the results on the K-Radar dataset validate the consistent\nperformance improvement of L4DR in real-world adverse weather conditions.\n","authors":["Xun Huang","Ziyu Xu","Hai Wu","Jinlong Wang","Qiming Xia","Yan Xia","Jonathan Li","Kyle Gao","Chenglu Wen","Cheng Wang"],"pdf_url":"https://arxiv.org/pdf/2408.03677v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.15063v4","updated":"2024-11-12T14:29:09Z","published":"2024-08-27T13:47:31Z","title":"Adapting Segment Anything Model to Multi-modal Salient Object Detection\n  with Semantic Feature Fusion Guidance","summary":"  Although most existing multi-modal salient object detection (SOD) methods\ndemonstrate effectiveness through training models from scratch, the limited\nmulti-modal data hinders these methods from reaching optimality. In this paper,\nwe propose a novel framework to explore and exploit the powerful feature\nrepresentation and zero-shot generalization ability of the pre-trained Segment\nAnything Model (SAM) for multi-modal SOD. Despite serving as a recent vision\nfundamental model, driving the class-agnostic SAM to comprehend and detect\nsalient objects accurately is non-trivial, especially in challenging scenes. To\nthis end, we develop \\underline{SAM} with se\\underline{m}antic\nf\\underline{e}ature fu\\underline{s}ion guidanc\\underline{e} (Sammese), which\nincorporates multi-modal saliency-specific knowledge into SAM to adapt SAM to\nmulti-modal SOD tasks. However, it is difficult for SAM trained on single-modal\ndata to directly mine the complementary benefits of multi-modal inputs and\ncomprehensively utilize them to achieve accurate saliency prediction. To\naddress these issues, we first design a multi-modal complementary fusion module\nto extract robust multi-modal semantic features by integrating information from\nvisible and thermal or depth image pairs. Then, we feed the extracted\nmulti-modal semantic features into both the SAM image encoder and mask decoder\nfor fine-tuning and prompting, respectively. Specifically, in the image\nencoder, a multi-modal adapter is proposed to adapt the single-modal SAM to\nmulti-modal information. In the mask decoder, a semantic-geometric prompt\ngeneration strategy is proposed to produce corresponding embeddings with\nvarious saliency cues. Extensive experiments on both RGB-D and RGB-T SOD\nbenchmarks show the effectiveness of the proposed framework. The code will be\navailable at \\url{https://github.com/Angknpng/Sammese}.\n","authors":["Kunpeng Wang","Danying Lin","Chenglong Li","Zhengzheng Tu","Bin Luo"],"pdf_url":"https://arxiv.org/pdf/2408.15063v4.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2410.23091v3","updated":"2024-11-12T14:13:17Z","published":"2024-10-30T15:06:44Z","title":"CausalDiff: Causality-Inspired Disentanglement via Diffusion Model for\n  Adversarial Defense","summary":"  Despite ongoing efforts to defend neural classifiers from adversarial\nattacks, they remain vulnerable, especially to unseen attacks. In contrast,\nhumans are difficult to be cheated by subtle manipulations, since we make\njudgments only based on essential factors. Inspired by this observation, we\nattempt to model label generation with essential label-causative factors and\nincorporate label-non-causative factors to assist data generation. For an\nadversarial example, we aim to discriminate the perturbations as non-causative\nfactors and make predictions only based on the label-causative factors.\nConcretely, we propose a casual diffusion model (CausalDiff) that adapts\ndiffusion models for conditional data generation and disentangles the two types\nof casual factors by learning towards a novel casual information bottleneck\nobjective. Empirically, CausalDiff has significantly outperformed\nstate-of-the-art defense methods on various unseen attacks, achieving an\naverage robustness of 86.39% (+4.01%) on CIFAR-10, 56.25% (+3.13%) on\nCIFAR-100, and 82.62% (+4.93%) on GTSRB (German Traffic Sign Recognition\nBenchmark).\n","authors":["Mingkun Zhang","Keping Bi","Wei Chen","Quanrun Chen","Jiafeng Guo","Xueqi Cheng"],"pdf_url":"https://arxiv.org/pdf/2410.23091v3.pdf","comment":"accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.03926v2","updated":"2024-11-12T14:04:53Z","published":"2024-11-06T13:57:53Z","title":"Act in Collusion: A Persistent Distributed Multi-Target Backdoor in\n  Federated Learning","summary":"  Federated learning, a novel paradigm designed to protect data privacy, is\nvulnerable to backdoor attacks due to its distributed nature. Current research\noften designs attacks based on a single attacker with a single backdoor,\noverlooking more realistic and complex threats in federated learning. We\npropose a more practical threat model for federated learning: the distributed\nmulti-target backdoor. In this model, multiple attackers control different\nclients, embedding various triggers and targeting different classes,\ncollaboratively implanting backdoors into the global model via central\naggregation. Empirical validation shows that existing methods struggle to\nmaintain the effectiveness of multiple backdoors in the global model. Our key\ninsight is that similar backdoor triggers cause parameter conflicts and\ninjecting new backdoors disrupts gradient directions, significantly weakening\nsome backdoors performance. To solve this, we propose a Distributed\nMulti-Target Backdoor Attack (DMBA), ensuring efficiency and persistence of\nbackdoors from different malicious clients. To avoid parameter conflicts, we\ndesign a multi-channel dispersed frequency trigger strategy to maximize trigger\ndifferences. To mitigate gradient interference, we introduce backdoor replay in\nlocal training to neutralize conflicting gradients. Extensive validation shows\nthat 30 rounds after the attack, Attack Success Rates of three different\nbackdoors from various clients remain above 93%. The code will be made publicly\navailable after the review period.\n","authors":["Tao Liu","Wu Yang","Chen Xu","Jiguang Lv","Huanran Wang","Yuhang Zhang","Shuchun Xu","Dapeng Man"],"pdf_url":"https://arxiv.org/pdf/2411.03926v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07802v1","updated":"2024-11-12T13:57:13Z","published":"2024-11-12T13:57:13Z","title":"Large-scale Remote Sensing Image Target Recognition and Automatic\n  Annotation","summary":"  This paper presents a method for object recognition and automatic labeling in\nlarge-area remote sensing images called LRSAA. The method integrates YOLOv11\nand MobileNetV3-SSD object detection algorithms through ensemble learning to\nenhance model performance. Furthermore, it employs Poisson disk sampling\nsegmentation techniques and the EIOU metric to optimize the training and\ninference processes of segmented images, followed by the integration of\nresults. This approach not only reduces the demand for computational resources\nbut also achieves a good balance between accuracy and speed. The source code\nfor this project has been made publicly available on\nhttps://github.com/anaerovane/LRSAA.\n","authors":["Wuzheng Dong"],"pdf_url":"https://arxiv.org/pdf/2411.07802v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07799v1","updated":"2024-11-12T13:53:22Z","published":"2024-11-12T13:53:22Z","title":"Horticultural Temporal Fruit Monitoring via 3D Instance Segmentation and\n  Re-Identification using Point Clouds","summary":"  Robotic fruit monitoring is a key step toward automated agricultural\nproduction systems. Robots can significantly enhance plant and temporal fruit\nmonitoring by providing precise, high-throughput assessments that overcome the\nlimitations of traditional manual methods. Fruit monitoring is a challenging\ntask due to the significant variation in size, shape, orientation, and\nocclusion of fruits. Also, fruits may be harvested or newly grown between\nrecording sessions. Most methods are 2D image-based and they lack the 3D\nstructure, depth, and spatial information, which represent key aspects of fruit\nmonitoring. 3D colored point clouds, instead, can offer this information but\nthey introduce challenges such as their sparsity and irregularity. In this\npaper, we present a novel approach for temporal fruit monitoring that addresses\npoint clouds collected in a greenhouse over time. Our method segments fruits\nusing a learning-based instance segmentation approach directly on the point\ncloud. Each segmented fruit is processed by a 3D sparse convolutional neural\nnetwork to extract descriptors, which are used in an attention-based matching\nnetwork to associate fruits with their instances from previous data\ncollections. Experimental results on a real dataset of strawberries demonstrate\nthat our approach outperforms other methods for fruits re-identification over\ntime, allowing for precise temporal fruit monitoring in real and complex\nscenarios.\n","authors":["Daniel Fusaro","Federico Magistri","Jens Behley","Alberto Pretto","Cyrill Stachniss"],"pdf_url":"https://arxiv.org/pdf/2411.07799v1.pdf","comment":"Submitted to IEEE Robotics and Automation Letters"},{"id":"http://arxiv.org/abs/2411.07784v1","updated":"2024-11-12T13:33:26Z","published":"2024-11-12T13:33:26Z","title":"Interaction Asymmetry: A General Principle for Learning Composable\n  Abstractions","summary":"  Learning disentangled representations of concepts and re-composing them in\nunseen ways is crucial for generalizing to out-of-domain situations. However,\nthe underlying properties of concepts that enable such disentanglement and\ncompositional generalization remain poorly understood. In this work, we propose\nthe principle of interaction asymmetry which states: \"Parts of the same concept\nhave more complex interactions than parts of different concepts\". We formalize\nthis via block diagonality conditions on the $(n+1)$th order derivatives of the\ngenerator mapping concepts to observed data, where different orders of\n\"complexity\" correspond to different $n$. Using this formalism, we prove that\ninteraction asymmetry enables both disentanglement and compositional\ngeneralization. Our results unify recent theoretical results for learning\nconcepts of objects, which we show are recovered as special cases with\n$n\\!=\\!0$ or $1$. We provide results for up to $n\\!=\\!2$, thus extending these\nprior works to more flexible generator functions, and conjecture that the same\nproof strategies generalize to larger $n$. Practically, our theory suggests\nthat, to disentangle concepts, an autoencoder should penalize its latent\ncapacity and the interactions between concepts during decoding. We propose an\nimplementation of these criteria using a flexible Transformer-based VAE, with a\nnovel regularizer on the attention weights of the decoder. On synthetic image\ndatasets consisting of objects, we provide evidence that this model can achieve\ncomparable object disentanglement to existing models that use more explicit\nobject-centric priors.\n","authors":["Jack Brady","Julius von K√ºgelgen","S√©bastien Lachapelle","Simon Buchholz","Thomas Kipf","Wieland Brendel"],"pdf_url":"https://arxiv.org/pdf/2411.07784v1.pdf","comment":"Preprint, under review"},{"id":"http://arxiv.org/abs/2407.00352v2","updated":"2024-11-12T13:01:48Z","published":"2024-06-29T07:53:47Z","title":"PhyTracker: An Online Tracker for Phytoplankton","summary":"  Phytoplankton, a crucial component of aquatic ecosystems, requires efficient\nmonitoring to understand marine ecological processes and environmental\nconditions. Traditional phytoplankton monitoring methods, relying on non-in\nsitu observations, are time-consuming and resource-intensive, limiting timely\nanalysis. To address these limitations, we introduce PhyTracker, an intelligent\nin situ tracking framework designed for automatic tracking of phytoplankton.\nPhyTracker overcomes significant challenges unique to phytoplankton monitoring,\nsuch as constrained mobility within water flow, inconspicuous appearance, and\nthe presence of impurities. Our method incorporates three innovative modules: a\nTexture-enhanced Feature Extraction (TFE) module, an Attention-enhanced\nTemporal Association (ATA) module, and a Flow-agnostic Movement Refinement\n(FMR) module. These modules enhance feature capture, differentiate between\nphytoplankton and impurities, and refine movement characteristics,\nrespectively. Extensive experiments on the PMOT dataset validate the\nsuperiority of PhyTracker in phytoplankton tracking, and additional tests on\nthe MOT dataset demonstrate its general applicability, outperforming\nconventional tracking methods. This work highlights key differences between\nphytoplankton and traditional objects, offering an effective solution for\nphytoplankton monitoring.\n","authors":["Yang Yu","Qingxuan Lv","Yuezun Li","Zhiqiang Wei","Junyu Dong"],"pdf_url":"https://arxiv.org/pdf/2407.00352v2.pdf","comment":"13pages,eleven figures"},{"id":"http://arxiv.org/abs/2411.07765v1","updated":"2024-11-12T12:58:33Z","published":"2024-11-12T12:58:33Z","title":"Novel View Synthesis with Pixel-Space Diffusion Models","summary":"  Synthesizing a novel view from a single input image is a challenging task.\nTraditionally, this task was approached by estimating scene depth, warping, and\ninpainting, with machine learning models enabling parts of the pipeline. More\nrecently, generative models are being increasingly employed in novel view\nsynthesis (NVS), often encompassing the entire end-to-end system. In this work,\nwe adapt a modern diffusion model architecture for end-to-end NVS in the pixel\nspace, substantially outperforming previous state-of-the-art (SOTA) techniques.\nWe explore different ways to encode geometric information into the network. Our\nexperiments show that while these methods may enhance performance, their impact\nis minor compared to utilizing improved generative models. Moreover, we\nintroduce a novel NVS training scheme that utilizes single-view datasets,\ncapitalizing on their relative abundance compared to their multi-view\ncounterparts. This leads to improved generalization capabilities to scenes with\nout-of-domain content.\n","authors":["Noam Elata","Bahjat Kawar","Yaron Ostrovsky-Berman","Miriam Farber","Ron Sokolovsky"],"pdf_url":"https://arxiv.org/pdf/2411.07765v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09997v5","updated":"2024-11-12T12:56:33Z","published":"2023-07-19T14:10:55Z","title":"TUNeS: A Temporal U-Net with Self-Attention for Video-based Surgical\n  Phase Recognition","summary":"  To enable context-aware computer assistance in the operating room of the\nfuture, cognitive systems need to understand automatically which surgical phase\nis being performed by the medical team. The primary source of information for\nsurgical phase recognition is typically video, which presents two challenges:\nextracting meaningful features from the video stream and effectively modeling\ntemporal information in the sequence of visual features. For temporal modeling,\nattention mechanisms have gained popularity due to their ability to capture\nlong-range dependencies. In this paper, we explore design choices for attention\nin existing temporal models for surgical phase recognition and propose a novel\napproach that uses attention more effectively and does not require hand-crafted\nconstraints: TUNeS, an efficient and simple temporal model that incorporates\nself-attention at the core of a convolutional U-Net structure. In addition, we\npropose to train the feature extractor, a standard CNN, together with an LSTM\non preferably long video segments, i.e., with long temporal context. In our\nexperiments, almost all temporal models performed better on top of feature\nextractors that were trained with longer temporal context. On these\ncontextualized features, TUNeS achieves state-of-the-art results on the\nCholec80 dataset. This study offers new insights on how to use attention\nmechanisms to build accurate and efficient temporal models for surgical phase\nrecognition. Implementing automatic surgical phase recognition is essential to\nautomate the analysis and optimization of surgical workflows and to enable\ncontext-aware computer assistance during surgery, thus ultimately improving\npatient care.\n","authors":["Isabel Funke","Dominik Rivoir","Stefanie Krell","Stefanie Speidel"],"pdf_url":"https://arxiv.org/pdf/2307.09997v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07096v2","updated":"2024-11-12T12:45:03Z","published":"2024-11-11T16:18:28Z","title":"Extreme Rotation Estimation in the Wild","summary":"  We present a technique and benchmark dataset for estimating the relative 3D\norientation between a pair of Internet images captured in an extreme setting,\nwhere the images have limited or non-overlapping field of views. Prior work\ntargeting extreme rotation estimation assume constrained 3D environments and\nemulate perspective images by cropping regions from panoramic views. However,\nreal images captured in the wild are highly diverse, exhibiting variation in\nboth appearance and camera intrinsics. In this work, we propose a\nTransformer-based method for estimating relative rotations in extreme\nreal-world settings, and contribute the ExtremeLandmarkPairs dataset, assembled\nfrom scene-level Internet photo collections. Our evaluation demonstrates that\nour approach succeeds in estimating the relative rotations in a wide variety of\nextreme-view Internet image pairs, outperforming various baselines, including\ndedicated rotation estimation techniques and contemporary 3D reconstruction\nmethods.\n","authors":["Hana Bezalel","Dotan Ankri","Ruojin Cai","Hadar Averbuch-Elor"],"pdf_url":"https://arxiv.org/pdf/2411.07096v2.pdf","comment":"Project webpage:\n  https://tau-vailab.github.io/ExtremeRotationsInTheWild/"},{"id":"http://arxiv.org/abs/2411.07758v1","updated":"2024-11-12T12:35:34Z","published":"2024-11-12T12:35:34Z","title":"AdaSemiCD: An Adaptive Semi-Supervised Change Detection Method Based on\n  Pseudo-Label Evaluation","summary":"  Change Detection (CD) is an essential field in remote sensing, with a primary\nfocus on identifying areas of change in bi-temporal image pairs captured at\nvarying intervals of the same region by a satellite. The data annotation\nprocess for the CD task is both time-consuming and labor-intensive. To make\nbetter use of the scarce labeled data and abundant unlabeled data, we present\nan adaptive dynamic semi-supervised learning method, AdaSemiCD, to improve the\nuse of pseudo-labels and optimize the training process. Initially, due to the\nextreme class imbalance inherent in CD, the model is more inclined to focus on\nthe background class, and it is easy to confuse the boundary of the target\nobject. Considering these two points, we develop a measurable evaluation metric\nfor pseudo-labels that enhances the representation of information entropy by\nclass rebalancing and amplification of confusing areas to give a larger weight\nto prospects change objects. Subsequently, to enhance the reliability of\nsample-wise pseudo-labels, we introduce the AdaFusion module, which is capable\nof dynamically identifying the most uncertain region and substituting it with\nmore trustworthy content. Lastly, to ensure better training stability, we\nintroduce the AdaEMA module, which updates the teacher model using only batches\nof trusted samples. Experimental results from LEVIR-CD, WHU-CD, and CDD\ndatasets validate the efficacy and universality of our proposed adaptive\ntraining framework.\n","authors":["Ran Lingyan","Wen Dongcheng","Zhuo Tao","Zhang Shizhou","Zhang Xiuwei","Zhang Yanning"],"pdf_url":"https://arxiv.org/pdf/2411.07758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07751v1","updated":"2024-11-12T12:23:41Z","published":"2024-11-12T12:23:41Z","title":"SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State\n  Space Model","summary":"  Speech enhancement plays an essential role in various applications, and the\nintegration of visual information has been demonstrated to bring substantial\nadvantages. However, the majority of current research concentrates on the\nexamination of facial and lip movements, which can be compromised or entirely\ninaccessible in scenarios where occlusions occur or when the camera view is\ndistant. Whereas contextual visual cues from the surrounding environment have\nbeen overlooked: for example, when we see a dog bark, our brain has the innate\nability to discern and filter out the barking noise. To this end, in this\npaper, we introduce a novel task, i.e. SAV-SE. To our best knowledge, this is\nthe first proposal to use rich contextual information from synchronized video\nas auxiliary cues to indicate the type of noise, which eventually improves the\nspeech enhancement performance. Specifically, we propose the VC-S$^2$E method,\nwhich incorporates the Conformer and Mamba modules for their complementary\nstrengths. Extensive experiments are conducted on public MUSIC, AVSpeech and\nAudioSet datasets, where the results demonstrate the superiority of VC-S$^2$E\nover other competitive methods. We will make the source code publicly\navailable. Project demo page: https://AVSEPage.github.io/\n","authors":["Xinyuan Qian","Jiaran Gao","Yaodan Zhang","Qiquan Zhang","Hexin Liu","Leibny Paola Garcia","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2411.07751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07750v1","updated":"2024-11-12T12:23:19Z","published":"2024-11-12T12:23:19Z","title":"LapGSR: Laplacian Reconstructive Network for Guided Thermal\n  Super-Resolution","summary":"  In the last few years, the fusion of multi-modal data has been widely studied\nfor various applications such as robotics, gesture recognition, and autonomous\nnavigation. Indeed, high-quality visual sensors are expensive, and\nconsumer-grade sensors produce low-resolution images. Researchers have\ndeveloped methods to combine RGB color images with non-visual data, such as\nthermal, to overcome this limitation to improve resolution. Fusing multiple\nmodalities to produce visually appealing, high-resolution images often requires\ndense models with millions of parameters and a heavy computational load, which\nis commonly attributed to the intricate architecture of the model.\n  We propose LapGSR, a multimodal, lightweight, generative model incorporating\nLaplacian image pyramids for guided thermal super-resolution. This approach\nuses a Laplacian Pyramid on RGB color images to extract vital edge information,\nwhich is then used to bypass heavy feature map computation in the higher layers\nof the model in tandem with a combined pixel and adversarial loss. LapGSR\npreserves the spatial and structural details of the image while also being\nefficient and compact. This results in a model with significantly fewer\nparameters than other SOTA models while demonstrating excellent results on two\ncross-domain datasets viz. ULB17-VT and VGTSR datasets.\n","authors":["Aditya Kasliwal","Ishaan Gakhar","Aryan Kamani","Pratinav Seth","Ujjwal Verma"],"pdf_url":"https://arxiv.org/pdf/2411.07750v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07747v1","updated":"2024-11-12T12:18:18Z","published":"2024-11-12T12:18:18Z","title":"Constraint Learning for Parametric Point Cloud","summary":"  Parametric point clouds are sampled from CAD shapes, have become increasingly\nprevalent in industrial manufacturing. However, most existing point cloud\nlearning methods focus on the geometric features, such as local and global\nfeatures or developing efficient convolution operations, overlooking the\nimportant attribute of constraints inherent in CAD shapes, which limits these\nmethods' ability to fully comprehend CAD shapes. To address this issue, we\nanalyzed the effect of constraints, and proposed its deep learning-friendly\nrepresentation, after that, the Constraint Feature Learning Network (CstNet) is\ndeveloped to extract and leverage constraints. Our CstNet includes two stages.\nThe Stage 1 extracts constraints from B-Rep data or point cloud. The Stage 2\nleverages coordinates and constraints to enhance the comprehend of CAD shapes.\nAdditionally, we built up the Parametric 20,000 Multi-modal Dataset for the\nscarcity of labeled B-Rep datasets. Experiments demonstrate that our CstNet\nachieved state-of-the-art performance on both public and proposed CAD shapes\ndatasets. To the best of our knowledge, CstNet is the first constraint-based\nlearning method tailored for CAD shapes analysis.\n","authors":["Xi Cheng","Ruiqi Lei","Di Huang","Zhichao Liao","Fengyuan Piao","Yan Chen","Pingfa Feng","Long Zeng"],"pdf_url":"https://arxiv.org/pdf/2411.07747v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07742v1","updated":"2024-11-12T12:07:27Z","published":"2024-11-12T12:07:27Z","title":"Efficient 3D Perception on Multi-Sweep Point Cloud with Gumbel Spatial\n  Pruning","summary":"  This paper studies point cloud perception within outdoor environments.\nExisting methods face limitations in recognizing objects located at a distance\nor occluded, due to the sparse nature of outdoor point clouds. In this work, we\nobserve a significant mitigation of this problem by accumulating multiple\ntemporally consecutive LiDAR sweeps, resulting in a remarkable improvement in\nperception accuracy. However, the computation cost also increases, hindering\nprevious approaches from utilizing a large number of LiDAR sweeps. To tackle\nthis challenge, we find that a considerable portion of points in the\naccumulated point cloud is redundant, and discarding these points has minimal\nimpact on perception accuracy. We introduce a simple yet effective Gumbel\nSpatial Pruning (GSP) layer that dynamically prunes points based on a learned\nend-to-end sampling. The GSP layer is decoupled from other network components\nand thus can be seamlessly integrated into existing point cloud network\narchitectures. Without incurring additional computational overhead, we increase\nthe number of LiDAR sweeps from 10, a common practice, to as many as 40.\nConsequently, there is a significant enhancement in perception performance. For\ninstance, in nuScenes 3D object detection and BEV map segmentation tasks, our\npruning strategy improves the vanilla TransL baseline and other baseline\nmethods.\n","authors":["Jianhao Li","Tianyu Sun","Xueqian Zhang","Zhongdao Wang","Bailan Feng","Hengshuang Zhao"],"pdf_url":"https://arxiv.org/pdf/2411.07742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06911v2","updated":"2024-11-12T12:07:00Z","published":"2024-11-11T12:13:58Z","title":"Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI","summary":"  Segmentation of cardiac magnetic resonance images (MRI) is crucial for the\nanalysis and assessment of cardiac function, helping to diagnose and treat\nvarious cardiovascular diseases. Most recent techniques rely on deep learning\nand usually require an extensive amount of labeled data. To overcome this\nproblem, few-shot learning has the capability of reducing data dependency on\nlabeled data. In this work, we introduce a new method that merges few-shot\nlearning with a U-Net architecture and Gaussian Process Emulators (GPEs),\nenhancing data integration from a support set for improved performance. GPEs\nare trained to learn the relation between the support images and the\ncorresponding masks in latent space, facilitating the segmentation of unseen\nquery images given only a small labeled support set at inference. We test our\nmodel with the M&Ms-2 public dataset to assess its ability to segment the heart\nin cardiac magnetic resonance imaging from different orientations, and compare\nit with state-of-the-art unsupervised and few-shot methods. Our architecture\nshows higher DICE coefficients compared to these methods, especially in the\nmore challenging setups where the size of the support set is considerably\nsmall.\n","authors":["Bruno Viti","Franz Thaler","Kathrin Lisa Kapper","Martin Urschler","Martin Holler","Elias Karabelas"],"pdf_url":"https://arxiv.org/pdf/2411.06911v2.pdf","comment":"Accepted at Statistical Atlases and Computational Modeling of the\n  Heart (STACOM) Workshop 2024"},{"id":"http://arxiv.org/abs/2411.07740v1","updated":"2024-11-12T12:04:44Z","published":"2024-11-12T12:04:44Z","title":"3D Focusing-and-Matching Network for Multi-Instance Point Cloud\n  Registration","summary":"  Multi-instance point cloud registration aims to estimate the pose of all\ninstances of a model point cloud in the whole scene. Existing methods all adopt\nthe strategy of first obtaining the global correspondence and then clustering\nto obtain the pose of each instance. However, due to the cluttered and occluded\nobjects in the scene, it is difficult to obtain an accurate correspondence\nbetween the model point cloud and all instances in the scene. To this end, we\npropose a simple yet powerful 3D focusing-and-matching network for\nmulti-instance point cloud registration by learning the multiple pair-wise\npoint cloud registration. Specifically, we first present a 3D multi-object\nfocusing module to locate the center of each object and generate object\nproposals. By using self-attention and cross-attention to associate the model\npoint cloud with structurally similar objects, we can locate potential matching\ninstances by regressing object centers. Then, we propose a 3D dual masking\ninstance matching module to estimate the pose between the model point cloud and\neach object proposal. It performs instance mask and overlap mask masks to\naccurately predict the pair-wise correspondence. Extensive experiments on two\npublic benchmarks, Scan2CAD and ROBI, show that our method achieves a new\nstate-of-the-art performance on the multi-instance point cloud registration\ntask. Code is available at https://github.com/zlynpu/3DFMNet.\n","authors":["Liyuan Zhang","Le Hui","Qi Liu","Bo Li","Yuchao Dai"],"pdf_url":"https://arxiv.org/pdf/2411.07740v1.pdf","comment":"Accepted to NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07728v1","updated":"2024-11-12T11:39:05Z","published":"2024-11-12T11:39:05Z","title":"No-Reference Point Cloud Quality Assessment via Graph Convolutional\n  Network","summary":"  Three-dimensional (3D) point cloud, as an emerging visual media format, is\nincreasingly favored by consumers as it can provide more realistic visual\ninformation than two-dimensional (2D) data. Similar to 2D plane images and\nvideos, point clouds inevitably suffer from quality degradation and information\nloss through multimedia communication systems. Therefore, automatic point cloud\nquality assessment (PCQA) is of critical importance. In this work, we propose a\nnovel no-reference PCQA method by using a graph convolutional network (GCN) to\ncharacterize the mutual dependencies of multi-view 2D projected image contents.\nThe proposed GCN-based PCQA (GC-PCQA) method contains three modules, i.e.,\nmulti-view projection, graph construction, and GCN-based quality prediction.\nFirst, multi-view projection is performed on the test point cloud to obtain a\nset of horizontally and vertically projected images. Then, a\nperception-consistent graph is constructed based on the spatial relations among\ndifferent projected images. Finally, reasoning on the constructed graph is\nperformed by GCN to characterize the mutual dependencies and interactions\nbetween different projected images, and aggregate feature information of\nmulti-view projected images for final quality prediction. Experimental results\non two publicly available benchmark databases show that our proposed GC-PCQA\ncan achieve superior performance than state-of-the-art quality assessment\nmetrics. The code will be available at: https://github.com/chenwuwq/GC-PCQA.\n","authors":["Wu Chen","Qiuping Jiang","Wei Zhou","Feng Shao","Guangtao Zhai","Weisi Lin"],"pdf_url":"https://arxiv.org/pdf/2411.07728v1.pdf","comment":"Accepted by IEEE Transactions on Multimedia"},{"id":"http://arxiv.org/abs/2411.07725v1","updated":"2024-11-12T11:32:56Z","published":"2024-11-12T11:32:56Z","title":"ALOcc: Adaptive Lifting-based 3D Semantic Occupancy and Cost\n  Volume-based Flow Prediction","summary":"  Vision-based semantic occupancy and flow prediction plays a crucial role in\nproviding spatiotemporal cues for real-world tasks, such as autonomous driving.\nExisting methods prioritize higher accuracy to cater to the demands of these\ntasks. In this work, we strive to improve performance by introducing a series\nof targeted improvements for 3D semantic occupancy prediction and flow\nestimation. First, we introduce an occlusion-aware adaptive lifting mechanism\nwith a depth denoising technique to improve the robustness of 2D-to-3D feature\ntransformation and reduce the reliance on depth priors. Second, we strengthen\nthe semantic consistency between 3D features and their original 2D modalities\nby utilizing shared semantic prototypes to jointly constrain both 2D and 3D\nfeatures. This is complemented by confidence- and category-based sampling\nstrategies to tackle long-tail challenges in 3D space. To alleviate the feature\nencoding burden in the joint prediction of semantics and flow, we propose a BEV\ncost volume-based prediction method that links flow and semantic features\nthrough a cost volume and employs a classification-regression supervision\nscheme to address the varying flow scales in dynamic scenes. Our purely\nconvolutional architecture framework, named ALOcc, achieves an optimal tradeoff\nbetween speed and accuracy achieving state-of-the-art results on multiple\nbenchmarks. On Occ3D and training without the camera visible mask, our ALOcc\nachieves an absolute gain of 2.5\\% in terms of RayIoU while operating at a\ncomparable speed compared to the state-of-the-art, using the same input size\n(256$\\times$704) and ResNet-50 backbone. Our method also achieves 2nd place in\nthe CVPR24 Occupancy and Flow Prediction Competition.\n","authors":["Dubing Chen","Jin Fang","Wencheng Han","Xinjing Cheng","Junbo Yin","Chenzhong Xu","Fahad Shahbaz Khan","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2411.07725v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07719v1","updated":"2024-11-12T11:24:18Z","published":"2024-11-12T11:24:18Z","title":"EMPERROR: A Flexible Generative Perception Error Model for Probing\n  Self-Driving Planners","summary":"  To handle the complexities of real-world traffic, learning planners for\nself-driving from data is a promising direction. While recent approaches have\nshown great progress, they typically assume a setting in which the ground-truth\nworld state is available as input. However, when deployed, planning needs to be\nrobust to the long-tail of errors incurred by a noisy perception system, which\nis often neglected in evaluation. To address this, previous work has proposed\ndrawing adversarial samples from a perception error model (PEM) mimicking the\nnoise characteristics of a target object detector. However, these methods use\nsimple PEMs that fail to accurately capture all failure modes of detection. In\nthis paper, we present EMPERROR, a novel transformer-based generative PEM,\napply it to stress-test an imitation learning (IL)-based planner and show that\nit imitates modern detectors more faithfully than previous work. Furthermore,\nit is able to produce realistic noisy inputs that increase the planner's\ncollision rate by up to 85%, demonstrating its utility as a valuable tool for a\nmore complete evaluation of self-driving planners.\n","authors":["Niklas Hanselmann","Simon Doll","Marius Cordts","Hendrik P. A. Lensch","Andreas Geiger"],"pdf_url":"https://arxiv.org/pdf/2411.07719v1.pdf","comment":"Project page: https://lasnik.github.io/emperror/"},{"id":"http://arxiv.org/abs/2410.10563v2","updated":"2024-11-12T11:16:43Z","published":"2024-10-14T14:42:12Z","title":"MEGA-Bench: Scaling Multimodal Evaluation to over 500 Real-World Tasks","summary":"  We present MEGA-Bench, an evaluation suite that scales multimodal evaluation\nto over 500 real-world tasks, to address the highly heterogeneous daily use\ncases of end users. Our objective is to optimize for a set of high-quality data\nsamples that cover a highly diverse and rich set of multimodal tasks, while\nenabling cost-effective and accurate model evaluation. In particular, we\ncollected 505 realistic tasks encompassing over 8,000 samples from 16 expert\nannotators to extensively cover the multimodal task space. Instead of unifying\nthese problems into standard multi-choice questions (like MMMU, MMBench, and\nMMT-Bench), we embrace a wide range of output formats like numbers, phrases,\ncode, \\LaTeX, coordinates, JSON, free-form, etc. To accommodate these formats,\nwe developed over 40 metrics to evaluate these tasks. Unlike existing\nbenchmarks, MEGA-Bench offers a fine-grained capability report across multiple\ndimensions (e.g., application, input type, output format, skill), allowing\nusers to interact with and visualize model capabilities in depth. We evaluate a\nwide variety of frontier vision-language models on MEGA-Bench to understand\ntheir capabilities across these dimensions.\n","authors":["Jiacheng Chen","Tianhao Liang","Sherman Siu","Zhengqing Wang","Kai Wang","Yubo Wang","Yuansheng Ni","Wang Zhu","Ziyan Jiang","Bohan Lyu","Dongfu Jiang","Xuan He","Yuan Liu","Hexiang Hu","Xiang Yue","Wenhu Chen"],"pdf_url":"https://arxiv.org/pdf/2410.10563v2.pdf","comment":"Technical report. Project page:\n  https://tiger-ai-lab.github.io/MEGA-Bench/. v2 includes more evaluated models\n  and a single-image setting"},{"id":"http://arxiv.org/abs/2407.08364v3","updated":"2024-11-12T10:56:38Z","published":"2024-07-11T10:18:54Z","title":"Scalar Function Topology Divergence: Comparing Topology of 3D Objects","summary":"  We propose a new topological tool for computer vision - Scalar Function\nTopology Divergence (SFTD), which measures the dissimilarity of multi-scale\ntopology between sublevel sets of two functions having a common domain.\nFunctions can be defined on an undirected graph or Euclidean space of any\ndimensionality. Most of the existing methods for comparing topology are based\non Wasserstein distance between persistence barcodes and they don't take into\naccount the localization of topological features. The minimization of SFTD\nensures that the corresponding topological features of scalar functions are\nlocated in the same places. The proposed tool provides useful visualizations\ndepicting areas where functions have topological dissimilarities. We provide\napplications of the proposed method to 3D computer vision. In particular,\nexperiments demonstrate that SFTD as an additional loss improves the\nreconstruction of cellular 3D shapes from 2D fluorescence microscopy images,\nand helps to identify topological errors in 3D segmentation. Additionally, we\nshow that SFTD outperforms Betti matching loss in 2D segmentation problems.\n","authors":["Ilya Trofimov","Daria Voronkova","Eduard Tulchinskii","Evgeny Burnaev","Serguei Barannikov"],"pdf_url":"https://arxiv.org/pdf/2407.08364v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.19287v3","updated":"2024-11-12T10:48:21Z","published":"2024-04-30T06:34:21Z","title":"Revisiting the Adversarial Robustness of Vision Language Models: a\n  Multimodal Perspective","summary":"  Pretrained vision-language models (VLMs) like CLIP exhibit exceptional\ngeneralization across diverse downstream tasks. While recent studies reveal\ntheir vulnerability to adversarial attacks, research to date has primarily\nfocused on enhancing the robustness of image encoders against image-based\nattacks, with defenses against text-based and multimodal attacks remaining\nlargely unexplored. To this end, this work presents the first comprehensive\nstudy on improving the adversarial robustness of VLMs against attacks targeting\nimage, text, and multimodal inputs. This is achieved by proposing multimodal\ncontrastive adversarial training (MMCoA). Such an approach strengthens the\nrobustness of both image and text encoders by aligning the clean text\nembeddings with adversarial image embeddings, and adversarial text embeddings\nwith clean image embeddings. The robustness of the proposed MMCoA is examined\nagainst existing defense methods over image, text, and multimodal attacks on\nthe CLIP model. Extensive experiments on 15 datasets across two tasks reveal\nthe characteristics of different adversarial defense methods under distinct\ndistribution shifts and dataset complexities across the three attack types.\nThis paves the way for a unified framework of adversarial robustness against\ndifferent modality attacks, opening up new possibilities for securing VLMs\nagainst multimodal attacks. The code is available at\nhttps://github.com/ElleZWQ/MMCoA.git.\n","authors":["Wanqi Zhou","Shuanghao Bai","Danilo P. Mandic","Qibin Zhao","Badong Chen"],"pdf_url":"https://arxiv.org/pdf/2404.19287v3.pdf","comment":"17 pages, 13 figures"},{"id":"http://arxiv.org/abs/2411.07708v1","updated":"2024-11-12T10:47:31Z","published":"2024-11-12T10:47:31Z","title":"Emotion Classification of Children Expressions","summary":"  This paper proposes a process for a classification model for the facial\nexpressions. The proposed process would aid in specific categorisation of\nchildren's emotions from 2 emotions namely 'Happy' and 'Sad'. Since the\nexisting emotion recognition systems algorithms primarily train on adult faces,\nthe model developed is achieved by using advanced concepts of models with\nSqueeze-andExcitation blocks, Convolutional Block Attention modules, and robust\ndata augmentation. Stable Diffusion image synthesis was used for expanding and\ndiversifying the data set generating realistic and various training samples.\nThe model designed using Batch Normalisation, Dropout, and SE Attention\nmechanisms for the classification of children's emotions achieved an accuracy\nrate of 89\\% due to these methods improving the precision of emotion\nrecognition in children. The relative importance of this issue is raised in\nthis study with an emphasis on the call for a more specific model in emotion\ndetection systems for the young generation with specific direction on how the\nyoung people can be assisted to manage emotions while online.\n","authors":["Sanchayan Vivekananthan"],"pdf_url":"https://arxiv.org/pdf/2411.07708v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12036v2","updated":"2024-11-12T10:12:49Z","published":"2024-07-01T05:37:17Z","title":"Exploring Advanced Large Language Models with LLMsuite","summary":"  This tutorial explores the advancements and challenges in the development of\nLarge Language Models (LLMs) such as ChatGPT and Gemini. It addresses inherent\nlimitations like temporal knowledge cutoffs, mathematical inaccuracies, and the\ngeneration of incorrect information, proposing solutions like Retrieval\nAugmented Generation (RAG), Program-Aided Language Models (PAL), and frameworks\nsuch as ReAct and LangChain. The integration of these techniques enhances LLM\nperformance and reliability, especially in multi-step reasoning and complex\ntask execution. The paper also covers fine-tuning strategies, including\ninstruction fine-tuning, parameter-efficient methods like LoRA, and\nReinforcement Learning from Human Feedback (RLHF) as well as Reinforced\nSelf-Training (ReST). Additionally, it provides a comprehensive survey of\ntransformer architectures and training techniques for LLMs. The source code can\nbe accessed by contacting the author via email for a request.\n","authors":["Giorgio Roffo"],"pdf_url":"https://arxiv.org/pdf/2407.12036v2.pdf","comment":"Keywords: Language Model Benchmarking, Pre-Trained LLM Comparison,\n  LLM Performance Analysis, NLP Model Evaluation Tools, Public Dataset\n  Inference for LLMs, BLEU and ROUGE Metrics for LLM, Open Source LLM Testing\n  Tools, Large Language Model Evaluation Software, NLP Benchmarking Suite,\n  Comprehensive LLM Evaluation Toolkit"},{"id":"http://arxiv.org/abs/2411.07688v1","updated":"2024-11-12T10:12:12Z","published":"2024-11-12T10:12:12Z","title":"Enhancing Ultra High Resolution Remote Sensing Imagery Analysis with\n  ImageRAG","summary":"  Ultra High Resolution (UHR) remote sensing imagery (RSI) (e.g. 100,000\n$\\times$ 100,000 pixels or more) poses a significant challenge for current\nRemote Sensing Multimodal Large Language Models (RSMLLMs). If choose to resize\nthe UHR image to standard input image size, the extensive spatial and\ncontextual information that UHR images contain will be neglected. Otherwise,\nthe original size of these images often exceeds the token limits of standard\nRSMLLMs, making it difficult to process the entire image and capture long-range\ndependencies to answer the query based on the abundant visual context. In this\npaper, we introduce ImageRAG for RS, a training-free framework to address the\ncomplexities of analyzing UHR remote sensing imagery. By transforming UHR\nremote sensing image analysis task to image's long context selection task, we\ndesign an innovative image contextual retrieval mechanism based on the\nRetrieval-Augmented Generation (RAG) technique, denoted as ImageRAG. ImageRAG's\ncore innovation lies in its ability to selectively retrieve and focus on the\nmost relevant portions of the UHR image as visual contexts that pertain to a\ngiven query. Fast path and slow path are proposed in this framework to handle\nthis task efficiently and effectively. ImageRAG allows RSMLLMs to manage\nextensive context and spatial information from UHR RSI, ensuring the analysis\nis both accurate and efficient.\n","authors":["Zilun Zhang","Haozhan Shen","Tiancheng Zhao","Yuhao Wang","Bin Chen","Yuxiang Cai","Yongheng Shang","Jianwei Yin"],"pdf_url":"https://arxiv.org/pdf/2411.07688v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.16620v3","updated":"2024-11-12T10:02:12Z","published":"2024-06-24T13:05:39Z","title":"OmAgent: A Multi-modal Agent Framework for Complex Video Understanding\n  with Task Divide-and-Conquer","summary":"  Recent advancements in Large Language Models (LLMs) have expanded their\ncapabilities to multimodal contexts, including comprehensive video\nunderstanding. However, processing extensive videos such as 24-hour CCTV\nfootage or full-length films presents significant challenges due to the vast\ndata and processing demands. Traditional methods, like extracting key frames or\nconverting frames to text, often result in substantial information loss. To\naddress these shortcomings, we develop OmAgent, efficiently stores and\nretrieves relevant video frames for specific queries, preserving the detailed\ncontent of videos. Additionally, it features an Divide-and-Conquer Loop capable\nof autonomous reasoning, dynamically invoking APIs and tools to enhance query\nprocessing and accuracy. This approach ensures robust video understanding,\nsignificantly reducing information loss. Experimental results affirm OmAgent's\nefficacy in handling various types of videos and complex tasks. Moreover, we\nhave endowed it with greater autonomy and a robust tool-calling system,\nenabling it to accomplish even more intricate tasks.\n","authors":["Lu Zhang","Tiancheng Zhao","Heting Ying","Yibo Ma","Kyusong Lee"],"pdf_url":"https://arxiv.org/pdf/2406.16620v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.14208v2","updated":"2024-11-12T10:00:46Z","published":"2024-07-19T11:13:31Z","title":"Memory-Efficient Pseudo-Labeling for Online Source-Free Universal Domain\n  Adaptation using a Gaussian Mixture Model","summary":"  In practice, domain shifts are likely to occur between training and test\ndata, necessitating domain adaptation (DA) to adjust the pre-trained source\nmodel to the target domain. Recently, universal domain adaptation (UniDA) has\ngained attention for addressing the possibility of an additional category\n(label) shift between the source and target domain. This means new classes can\nappear in the target data, some source classes may no longer be present, or\nboth at the same time. For practical applicability, UniDA methods must handle\nboth source-free and online scenarios, enabling adaptation without access to\nthe source data and performing batch-wise updates in parallel with prediction.\nIn an online setting, preserving knowledge across batches is crucial. However,\nexisting methods often require substantial memory, which is impractical because\nmemory is limited and valuable, in particular on embedded systems. Therefore,\nwe consider memory-efficiency as an additional constraint. To achieve\nmemory-efficient online source-free universal domain adaptation (SF-UniDA), we\npropose a novel method that continuously captures the distribution of known\nclasses in the feature space using a Gaussian mixture model (GMM). This\napproach, combined with entropy-based out-of-distribution detection, allows for\nthe generation of reliable pseudo-labels. Finally, we combine a contrastive\nloss with a KL divergence loss to perform the adaptation. Our approach not only\nachieves state-of-the-art results in all experiments on the DomainNet and\nOffice-Home datasets but also significantly outperforms the existing methods on\nthe challenging VisDA-C dataset, setting a new benchmark for online SF-UniDA.\nOur code is available at https://github.com/pascalschlachter/GMM.\n","authors":["Pascal Schlachter","Simon Wagner","Bin Yang"],"pdf_url":"https://arxiv.org/pdf/2407.14208v2.pdf","comment":"Accepted at IEEE/CVF Winter Conference on Applications of Computer\n  Vision (WACV) 2025"},{"id":"http://arxiv.org/abs/2410.14265v2","updated":"2024-11-12T09:58:13Z","published":"2024-10-18T08:20:37Z","title":"HYPNOS : Highly Precise Foreground-focused Diffusion Finetuning for\n  Inanimate Objects","summary":"  In recent years, personalized diffusion-based text-to-image generative tasks\nhave been a hot topic in computer vision studies. A robust diffusion model is\ndetermined by its ability to perform near-perfect reconstruction of certain\nproduct outcomes given few related input samples. Unfortunately, the current\nprominent diffusion-based finetuning technique falls short in maintaining the\nforeground object consistency while being constrained to produce diverse\nbackgrounds in the image outcome. In the worst scenario, the overfitting issue\nmay occur, meaning that the foreground object is less controllable due to the\ncondition above, for example, the input prompt information is transferred\nambiguously to both foreground and background regions, instead of the supposed\nbackground region only. To tackle the issues above, we proposed Hypnos, a\nhighly precise foreground-focused diffusion finetuning technique. On the image\nlevel, this strategy works best for inanimate object generation tasks, and to\ndo so, Hypnos implements two main approaches, namely: (i) a content-centric\nprompting strategy and (ii) the utilization of our additional\nforeground-focused discriminative module. The utilized module is connected with\nthe diffusion model and finetuned with our proposed set of supervision\nmechanism. Combining the strategies above yielded to the foreground-background\ndisentanglement capability of the diffusion model. Our experimental results\nshowed that the proposed strategy gave a more robust performance and visually\npleasing results compared to the former technique. For better elaborations, we\nalso provided extensive studies to assess the fruitful outcomes above, which\nreveal how personalization behaves in regard to several training conditions.\n","authors":["Oliverio Theophilus Nathanael","Jonathan Samuel Lumentut","Nicholas Hans Muliawan","Edbert Valencio Angky","Felix Indra Kurniadi","Alfi Yusrotis Zakiyyah","Jeklin Harefa"],"pdf_url":"https://arxiv.org/pdf/2410.14265v2.pdf","comment":"26 pages, 12 figures, to appear on the Rich Media with Generative AI\n  workshop in conjunction with Asian Conference on Computer Vision (ACCV) 2024"},{"id":"http://arxiv.org/abs/2411.07685v1","updated":"2024-11-12T09:57:53Z","published":"2024-11-12T09:57:53Z","title":"Fast Disentangled Slim Tensor Learning for Multi-view Clustering","summary":"  Tensor-based multi-view clustering has recently received significant\nattention due to its exceptional ability to explore cross-view high-order\ncorrelations. However, most existing methods still encounter some limitations.\n(1) Most of them explore the correlations among different affinity matrices,\nmaking them unscalable to large-scale data. (2) Although some methods address\nit by introducing bipartite graphs, they may result in sub-optimal solutions\ncaused by an unstable anchor selection process. (3) They generally ignore the\nnegative impact of latent semantic-unrelated information in each view. To\ntackle these issues, we propose a new approach termed fast Disentangled Slim\nTensor Learning (DSTL) for multi-view clustering . Instead of focusing on the\nmulti-view graph structures, DSTL directly explores the high-order correlations\namong multi-view latent semantic representations based on matrix factorization.\nTo alleviate the negative influence of feature redundancy, inspired by robust\nPCA, DSTL disentangles the latent low-dimensional representation into a\nsemantic-unrelated part and a semantic-related part for each view.\nSubsequently, two slim tensors are constructed with tensor-based\nregularization. To further enhance the quality of feature disentanglement, the\nsemantic-related representations are aligned across views through a consensus\nalignment indicator. Our proposed model is computationally efficient and can be\nsolved effectively. Extensive experiments demonstrate the superiority and\nefficiency of DSTL over state-of-the-art approaches. The code of DSTL is\navailable at https://github.com/dengxu-nju/DSTL.\n","authors":["Deng Xu","Chao Zhang","Zechao Li","Chunlin Chen","Huaxiong Li"],"pdf_url":"https://arxiv.org/pdf/2411.07685v1.pdf","comment":"13 pages,6 figures, will be published to IEEE TMM"},{"id":"http://arxiv.org/abs/2411.07684v1","updated":"2024-11-12T09:56:42Z","published":"2024-11-12T09:56:42Z","title":"AI enhanced diagnosis of Peyronies disease a novel approach using\n  Computer Vision","summary":"  This study presents an innovative AI-driven tool for diagnosing Peyronie's\nDisease (PD), a condition that affects between 0.3% and 13.1% of men worldwide.\nOur method uses key point detection on both images and videos to measure penile\ncurvature angles, utilizing advanced computer vision techniques. This tool has\ndemonstrated high accuracy in identifying anatomical landmarks, validated\nagainst conventional goniometer measurements. Traditional PD diagnosis often\ninvolves subjective and invasive methods, which can lead to patient discomfort\nand inaccuracies. Our approach offers a precise, reliable, and non-invasive\ndiagnostic tool to address these drawbacks. The model distinguishes between PD\nand normal anatomical changes with a sensitivity of 96.7% and a specificity of\n100%. This advancement represents a significant improvement in urological\ndiagnostics, greatly enhancing the efficacy and convenience of PD assessment\nfor healthcare providers and patients.\n","authors":["Yudara Kularathne","Janitha Prathapa","Prarththanan Sothyrajah","Salomi Arasaratnam","Sithira Ambepitiya","Thanveer Ahamed","Dinuka Wijesundara"],"pdf_url":"https://arxiv.org/pdf/2411.07684v1.pdf","comment":"8 pages, 6 figures, 4 tables"},{"id":"http://arxiv.org/abs/2305.03989v3","updated":"2024-11-12T09:52:53Z","published":"2023-05-06T09:29:12Z","title":"LEO: Generative Latent Image Animator for Human Video Synthesis","summary":"  Spatio-temporal coherency is a major challenge in synthesizing high quality\nvideos, particularly in synthesizing human videos that contain rich global and\nlocal deformations. To resolve this challenge, previous approaches have\nresorted to different features in the generation process aimed at representing\nappearance and motion. However, in the absence of strict mechanisms to\nguarantee such disentanglement, a separation of motion from appearance has\nremained challenging, resulting in spatial distortions and temporal jittering\nthat break the spatio-temporal coherency. Motivated by this, we here propose\nLEO, a novel framework for human video synthesis, placing emphasis on\nspatio-temporal coherency. Our key idea is to represent motion as a sequence of\nflow maps in the generation process, which inherently isolate motion from\nappearance. We implement this idea via a flow-based image animator and a Latent\nMotion Diffusion Model (LMDM). The former bridges a space of motion codes with\nthe space of flow maps, and synthesizes video frames in a warp-and-inpaint\nmanner. LMDM learns to capture motion prior in the training data by\nsynthesizing sequences of motion codes. Extensive quantitative and qualitative\nanalysis suggests that LEO significantly improves coherent synthesis of human\nvideos over previous methods on the datasets TaichiHD, FaceForensics and\nCelebV-HQ. In addition, the effective disentanglement of appearance and motion\nin LEO allows for two additional tasks, namely infinite-length human video\nsynthesis, as well as content-preserving video editing.\n","authors":["Yaohui Wang","Xin Ma","Xinyuan Chen","Cunjian Chen","Antitza Dantcheva","Bo Dai","Yu Qiao"],"pdf_url":"https://arxiv.org/pdf/2305.03989v3.pdf","comment":"IJCV 2024, Project webpage: https://wyhsirius.github.io/LEO-project/"},{"id":"http://arxiv.org/abs/2411.03239v2","updated":"2024-11-12T09:46:39Z","published":"2024-11-05T16:37:30Z","title":"Decoupling Fine Detail and Global Geometry for Compressed Depth Map\n  Super-Resolution","summary":"  Recovering high-quality depth maps from compressed sources has gained\nsignificant attention due to the limitations of consumer-grade depth cameras\nand the bandwidth restrictions during data transmission. However, current\nmethods still suffer from two challenges. First, bit-depth compression produces\na uniform depth representation in regions with subtle variations, hindering the\nrecovery of detailed information. Second, densely distributed random noise\nreduces the accuracy of estimating the global geometric structure of the scene.\nTo address these challenges, we propose a novel framework, termed\ngeometry-decoupled network (GDNet), for compressed depth map super-resolution\nthat decouples the high-quality depth map reconstruction process by handling\nglobal and detailed geometric features separately. To be specific, we propose\nthe fine geometry detail encoder (FGDE), which is designed to aggregate fine\ngeometry details in high-resolution low-level image features while\nsimultaneously enriching them with complementary information from\nlow-resolution context-level image features. In addition, we develop the global\ngeometry encoder (GGE) that aims at suppressing noise and extracting global\ngeometric information effectively via constructing compact feature\nrepresentation in a low-rank space. We conduct experiments on multiple\nbenchmark datasets, demonstrating that our GDNet significantly outperforms\ncurrent methods in terms of geometric consistency and detail recovery. In the\nECCV 2024 AIM Compressed Depth Upsampling Challenge, our solution won the 1st\nplace award. Our codes will be available.\n","authors":["Huan Zheng","Wencheng Han","Jianbing Shen"],"pdf_url":"https://arxiv.org/pdf/2411.03239v2.pdf","comment":"The 1st place award for the ECCV 2024 AIM Compressed Depth Upsampling\n  Challenge"},{"id":"http://arxiv.org/abs/2407.21341v3","updated":"2024-11-12T09:41:55Z","published":"2024-07-31T05:15:24Z","title":"High-throughput 3D shape completion of potato tubers on a harvester","summary":"  Potato yield is an important metric for farmers to further optimize their\ncultivation practices. Potato yield can be estimated on a harvester using an\nRGB-D camera that can estimate the three-dimensional (3D) volume of individual\npotato tubers. A challenge, however, is that the 3D shape derived from RGB-D\nimages is only partially completed, underestimating the actual volume. To\naddress this issue, we developed a 3D shape completion network, called CoRe++,\nwhich can complete the 3D shape from RGB-D images. CoRe++ is a deep learning\nnetwork that consists of a convolutional encoder and a decoder. The encoder\ncompresses RGB-D images into latent vectors that are used by the decoder to\ncomplete the 3D shape using the deep signed distance field network (DeepSDF).\nTo evaluate our CoRe++ network, we collected partial and complete 3D point\nclouds of 339 potato tubers on an operational harvester in Japan. On the 1425\nRGB-D images in the test set (representing 51 unique potato tubers), our\nnetwork achieved a completion accuracy of 2.8 mm on average. For volumetric\nestimation, the root mean squared error (RMSE) was 22.6 ml, and this was better\nthan the RMSE of the linear regression (31.1 ml) and the base model (36.9 ml).\nWe found that the RMSE can be further reduced to 18.2 ml when performing the 3D\nshape completion in the center of the RGB-D image. With an average 3D shape\ncompletion time of 10 milliseconds per tuber, we can conclude that CoRe++ is\nboth fast and accurate enough to be implemented on an operational harvester for\nhigh-throughput potato yield estimation. CoRe++'s high-throughput and accurate\nprocessing allows it to be applied to other tuber, fruit and vegetable crops,\nthereby enabling versatile, accurate and real-time yield monitoring in\nprecision agriculture. Our code, network weights and dataset are publicly\navailable at https://github.com/UTokyo-FieldPhenomics-Lab/corepp.git.\n","authors":["Pieter M. Blok","Federico Magistri","Cyrill Stachniss","Haozhou Wang","James Burridge","Wei Guo"],"pdf_url":"https://arxiv.org/pdf/2407.21341v3.pdf","comment":"20 pages, 11 figures, 6 tables"},{"id":"http://arxiv.org/abs/2411.07664v1","updated":"2024-11-12T09:30:02Z","published":"2024-11-12T09:30:02Z","title":"Evaluating the Generation of Spatial Relations in Text and Image\n  Generative Models","summary":"  Understanding spatial relations is a crucial cognitive ability for both\nhumans and AI. While current research has predominantly focused on the\nbenchmarking of text-to-image (T2I) models, we propose a more comprehensive\nevaluation that includes \\textit{both} T2I and Large Language Models (LLMs). As\nspatial relations are naturally understood in a visuo-spatial manner, we\ndevelop an approach to convert LLM outputs into an image, thereby allowing us\nto evaluate both T2I models and LLMs \\textit{visually}. We examined the spatial\nrelation understanding of 8 prominent generative models (3 T2I models and 5\nLLMs) on a set of 10 common prepositions, as well as assess the feasibility of\nautomatic evaluation methods. Surprisingly, we found that T2I models only\nachieve subpar performance despite their impressive general image-generation\nabilities. Even more surprisingly, our results show that LLMs are significantly\nmore accurate than T2I models in generating spatial relations, despite being\nprimarily trained on textual data. We examined reasons for model failures and\nhighlight gaps that can be filled to enable more spatially faithful\ngenerations.\n","authors":["Shang Hong Sim","Clarence Lee","Alvin Tan","Cheston Tan"],"pdf_url":"https://arxiv.org/pdf/2411.07664v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07660v1","updated":"2024-11-12T09:22:00Z","published":"2024-11-12T09:22:00Z","title":"HMIL: Hierarchical Multi-Instance Learning for Fine-Grained Whole Slide\n  Image Classification","summary":"  Fine-grained classification of whole slide images (WSIs) is essential in\nprecision oncology, enabling precise cancer diagnosis and personalized\ntreatment strategies. The core of this task involves distinguishing subtle\nmorphological variations within the same broad category of gigapixel-resolution\nimages, which presents a significant challenge. While the multi-instance\nlearning (MIL) paradigm alleviates the computational burden of WSIs, existing\nMIL methods often overlook hierarchical label correlations, treating\nfine-grained classification as a flat multi-class classification task. To\novercome these limitations, we introduce a novel hierarchical multi-instance\nlearning (HMIL) framework. By facilitating on the hierarchical alignment of\ninherent relationships between different hierarchy of labels at instance and\nbag level, our approach provides a more structured and informative learning\nprocess. Specifically, HMIL incorporates a class-wise attention mechanism that\naligns hierarchical information at both the instance and bag levels.\nFurthermore, we introduce supervised contrastive learning to enhance the\ndiscriminative capability for fine-grained classification and a\ncurriculum-based dynamic weighting module to adaptively balance the\nhierarchical feature during training. Extensive experiments on our large-scale\ncytology cervical cancer (CCC) dataset and two public histology datasets, BRACS\nand PANDA, demonstrate the state-of-the-art class-wise and overall performance\nof our HMIL framework. Our source code is available at\nhttps://github.com/ChengJin-git/HMIL.\n","authors":["Cheng Jin","Luyang Luo","Huangjing Lin","Jun Hou","Hao Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07660v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2410.12183v2","updated":"2024-11-12T09:14:03Z","published":"2024-10-16T03:01:44Z","title":"TransAgent: Transfer Vision-Language Foundation Models with\n  Heterogeneous Agent Collaboration","summary":"  Vision-language foundation models (such as CLIP) have recently shown their\npower in transfer learning, owing to large-scale image-text pre-training.\nHowever, target domain data in the downstream tasks can be highly different\nfrom the pre-training phase, which makes it hard for such a single model to\ngeneralize well. Alternatively, there exists a wide range of expert models that\ncontain diversified vision and/or language knowledge pre-trained on different\nmodalities, tasks, networks, and datasets. Unfortunately, these models are\n\"isolated agents\" with heterogeneous structures, and how to integrate their\nknowledge for generalizing CLIP-like models has not been fully explored. To\nbridge this gap, we propose a general and concise TransAgent framework, which\ntransports the knowledge of the isolated agents in a unified manner, and\neffectively guides CLIP to generalize with multi-source knowledge distillation.\nWith such a distinct framework, we flexibly collaborate with 11 heterogeneous\nagents to empower vision-language foundation models, without further cost in\nthe inference phase. Finally, our TransAgent achieves state-of-the-art\nperformance on 11 visual recognition datasets. Under the same low-shot setting,\nit outperforms the popular CoOp with around 10% on average, and 20% on EuroSAT\nwhich contains large domain shifts.\n","authors":["Yiwei Guo","Shaobin Zhuang","Kunchang Li","Yu Qiao","Yali Wang"],"pdf_url":"https://arxiv.org/pdf/2410.12183v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07650v1","updated":"2024-11-12T09:02:11Z","published":"2024-11-12T09:02:11Z","title":"Understanding Audiovisual Deepfake Detection: Techniques, Challenges,\n  Human Factors and Perceptual Insights","summary":"  Deep Learning has been successfully applied in diverse fields, and its impact\non deepfake detection is no exception. Deepfakes are fake yet realistic\nsynthetic content that can be used deceitfully for political impersonation,\nphishing, slandering, or spreading misinformation. Despite extensive research\non unimodal deepfake detection, identifying complex deepfakes through joint\nanalysis of audio and visual streams remains relatively unexplored. To fill\nthis gap, this survey first provides an overview of audiovisual deepfake\ngeneration techniques, applications, and their consequences, and then provides\na comprehensive review of state-of-the-art methods that combine audio and\nvisual modalities to enhance detection accuracy, summarizing and critically\nanalyzing their strengths and limitations. Furthermore, we discuss existing\nopen source datasets for a deeper understanding, which can contribute to the\nresearch community and provide necessary information to beginners who want to\nanalyze deep learning-based audiovisual methods for video forensics. By\nbridging the gap between unimodal and multimodal approaches, this paper aims to\nimprove the effectiveness of deepfake detection strategies and guide future\nresearch in cybersecurity and media integrity.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.12866v2","updated":"2024-11-12T08:59:30Z","published":"2024-04-19T13:05:37Z","title":"How Does the Textual Information Affect the Retrieval of Multimodal\n  In-Context Learning?","summary":"  The increase in parameter size of multimodal large language models (MLLMs)\nintroduces significant capabilities, particularly in-context learning, where\nMLLMs enhance task performance without updating pre-trained parameters. This\neffectiveness, however, hinges on the appropriate selection of in-context\nexamples, a process that is currently biased towards visual data, overlooking\ntextual information. Furthermore, the area of supervised retrievers for MLLMs,\ncrucial for optimal in-context example selection, continues to be\nuninvestigated. Our study offers an in-depth evaluation of the impact of\ntextual information on the unsupervised selection of in-context examples in\nmultimodal contexts, uncovering a notable sensitivity of retriever performance\nto the employed modalities. Responding to this, we introduce a novel supervised\nMLLM-retriever MSIER that employs a neural network to select examples that\nenhance multimodal in-context learning efficiency. This approach is validated\nthrough extensive testing across three distinct tasks, demonstrating the\nmethod's effectiveness. Additionally, we investigate the influence of\nmodalities on our supervised retrieval method's training and pinpoint factors\ncontributing to our model's success. This exploration paves the way for future\nadvancements, highlighting the potential for refined in-context learning in\nMLLMs through the strategic use of multimodal data.\n","authors":["Yang Luo","Zangwei Zheng","Zirui Zhu","Yang You"],"pdf_url":"https://arxiv.org/pdf/2404.12866v2.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.07649v1","updated":"2024-11-12T08:57:21Z","published":"2024-11-12T08:57:21Z","title":"Maritime Search and Rescue Missions with Aerial Images: A Survey","summary":"  The speed of response by search and rescue teams at sea is of vital\nimportance, as survival may depend on it. Recent technological advancements\nhave led to the development of more efficient systems for locating individuals\ninvolved in a maritime incident, such as the use of Unmanned Aerial Vehicles\n(UAVs) equipped with cameras and other integrated sensors. Over the past\ndecade, several researchers have contributed to the development of automatic\nsystems capable of detecting people using aerial images, particularly by\nleveraging the advantages of deep learning. In this article, we provide a\ncomprehensive review of the existing literature on this topic. We analyze the\nmethods proposed to date, including both traditional techniques and more\nadvanced approaches based on machine learning and neural networks.\nAdditionally, we take into account the use of synthetic data to cover a wider\nrange of scenarios without the need to deploy a team to collect data, which is\none of the major obstacles for these systems. Overall, this paper situates the\nreader in the field of detecting people at sea using aerial images by quickly\nidentifying the most suitable methodology for each scenario, as well as\nproviding an in-depth discussion and direction for future trends.\n","authors":["Juan P. Martinez-Esteso","Francisco J. Castellanos","Jorge Calvo-Zaragoza","Antonio Javier Gallego"],"pdf_url":"https://arxiv.org/pdf/2411.07649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07643v1","updated":"2024-11-12T08:53:49Z","published":"2024-11-12T08:53:49Z","title":"xCG: Explainable Cell Graphs for Survival Prediction in Non-Small Cell\n  Lung Cancer","summary":"  Understanding how deep learning models predict oncology patient risk can\nprovide critical insights into disease progression, support clinical\ndecision-making, and pave the way for trustworthy and data-driven precision\nmedicine. Building on recent advances in the spatial modeling of the tumor\nmicroenvironment using graph neural networks, we present an explainable cell\ngraph (xCG) approach for survival prediction. We validate our model on a public\ncohort of imaging mass cytometry (IMC) data for 416 cases of lung\nadenocarcinoma. We explain survival predictions in terms of known phenotypes on\nthe cell level by computing risk attributions over cell graphs, for which we\npropose an efficient grid-based layer-wise relevance propagation (LRP) method.\nOur ablation studies highlight the importance of incorporating the cancer stage\nand model ensembling to improve the quality of risk estimates. Our xCG method,\ntogether with the IMC data, is made publicly available to support further\nresearch.\n","authors":["Marvin Sextro","Gabriel Dernbach","Kai Standvoss","Simon Schallenberg","Frederick Klauschen","Klaus-Robert M√ºller","Maximilian Alber","Lukas Ruff"],"pdf_url":"https://arxiv.org/pdf/2411.07643v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 11 pages"},{"id":"http://arxiv.org/abs/2411.06236v2","updated":"2024-11-12T08:51:40Z","published":"2024-11-09T17:36:53Z","title":"Zero-Shot NAS via the Suppression of Local Entropy Decrease","summary":"  Architecture performance evaluation is the most time-consuming part of neural\narchitecture search (NAS). Zero-Shot NAS accelerates the evaluation by\nutilizing zero-cost proxies instead of training. Though effective, existing\nzero-cost proxies require invoking backpropagations or running networks on\ninput data, making it difficult to further accelerate the computation of\nproxies. To alleviate this issue, architecture topologies are used to evaluate\nthe performance of networks in this study. We prove that particular\narchitectural topologies decrease the local entropy of feature maps, which\ndegrades specific features to a bias, thereby reducing network performance.\nBased on this proof, architectural topologies are utilized to quantify the\nsuppression of local entropy decrease (SED) as a data-free and running-free\nproxy. Experimental results show that SED outperforms most state-of-the-art\nproxies in terms of architecture selection on five benchmarks, with computation\ntime reduced by three orders of magnitude. We further compare the SED-based NAS\nwith state-of-the-art proxies. SED-based NAS selects the architecture with\nhigher accuracy and fewer parameters in only one second. The theoretical\nanalyses of local entropy and experimental results demonstrate that the\nsuppression of local entropy decrease facilitates selecting optimal\narchitectures in Zero-Shot NAS.\n","authors":["Ning Wu","Han Huang","Yueting Xu","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2411.06236v2.pdf","comment":"8 pages, 2 figures. Corrected typos and latex template"},{"id":"http://arxiv.org/abs/2410.05814v2","updated":"2024-11-12T08:50:59Z","published":"2024-10-08T08:44:01Z","title":"CALoR: Towards Comprehensive Model Inversion Defense","summary":"  Model Inversion Attacks (MIAs) aim at recovering privacy-sensitive training\ndata from the knowledge encoded in the released machine learning models. Recent\nadvances in the MIA field have significantly enhanced the attack performance\nunder multiple scenarios, posing serious privacy risks of Deep Neural Networks\n(DNNs). However, the development of defense strategies against MIAs is\nrelatively backward to resist the latest MIAs and existing defenses fail to\nachieve further trade-off between model utility and model robustness. In this\npaper, we provide an in-depth analysis from the perspective of intrinsic\nvulnerabilities of MIAs, comprehensively uncovering the weaknesses inherent in\nthe basic pipeline, which are partially investigated in the previous defenses.\nBuilding upon these new insights, we propose a robust defense mechanism,\nintegrating Confidence Adaptation and Low-Rank compression(CALoR). Our method\nincludes a novel robustness-enhanced classification loss specially-designed for\nmodel inversion defenses and reveals the extraordinary effectiveness of\ncompressing the classification header. With CALoR, we can mislead the\noptimization objective, reduce the leaked information and impede the\nbackpropagation of MIAs, thus mitigating the risk of privacy leakage. Extensive\nexperimental results demonstrate that our method achieves state-of-the-art\n(SOTA) defense performance against MIAs and exhibits superior generalization to\nexisting defenses across various scenarios.\n","authors":["Hongyao Yu","Yixiang Qiu","Hao Fang","Bin Chen","Sijin Yu","Bin Wang","Shu-Tao Xia","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2410.05814v2.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2410.20806v3","updated":"2024-11-12T08:44:12Z","published":"2024-10-28T07:54:07Z","title":"Transformer-Based Tooth Alignment Prediction With Occlusion And\n  Collision Constraints","summary":"  The planning of digital orthodontic treatment requires providing tooth\nalignment, which not only consumes a lot of time and labor to determine\nmanually but also relays clinical experiences heavily. In this work, we\nproposed a lightweight tooth alignment neural network based on\nSwin-transformer. We first re-organized 3D point clouds based on virtual arch\nlines and converted them into order-sorted multi-channel textures, which\nimproves the accuracy and efficiency simultaneously. We then designed two new\nocclusal loss functions that quantitatively evaluate the occlusal relationship\nbetween the upper and lower jaws. They are important clinical constraints,\nfirst introduced to the best of our knowledge, and lead to cutting-edge\nprediction accuracy. To train our network, we collected a large digital\northodontic dataset that has 591 clinical cases, including various complex\nclinical cases. This dataset will benefit the community after its release since\nthere is no open dataset so far. Furthermore, we also proposed two new\northodontic dataset augmentation methods considering tooth spatial distribution\nand occlusion. We evaluated our method with this dataset and extensive\nexperiments, including comparisons with STAT methods and ablation studies, and\ndemonstrate the high prediction accuracy of our method.\n","authors":["ZhenXing Dong","JiaZhou Chen","YangHui Xu"],"pdf_url":"https://arxiv.org/pdf/2410.20806v3.pdf","comment":"Modify formatting errors, optimize content layout"},{"id":"http://arxiv.org/abs/2408.09984v2","updated":"2024-11-12T08:33:22Z","published":"2024-08-19T13:32:51Z","title":"Boosting Open-Domain Continual Learning via Leveraging Intra-domain\n  Category-aware Prototype","summary":"  Despite recent progress in enhancing the efficacy of Open-Domain Continual\nLearning (ODCL) in Vision-Language Models (VLM), failing to (1) correctly\nidentify the Task-ID of a test image and (2) use only the category set\ncorresponding to the Task-ID, while preserving the knowledge related to each\ndomain, cannot address the two primary challenges of ODCL: forgetting old\nknowledge and maintaining zero-shot capabilities, as well as the confusions\ncaused by category-relatedness between domains. In this paper, we propose a\nsimple yet effective solution: leveraging intra-domain category-aware\nprototypes for ODCL in CLIP (DPeCLIP), where the prototype is the key to\nbridging the above two processes. Concretely, we propose a training-free\nTask-ID discriminator method, by utilizing prototypes as classifiers for\nidentifying Task-IDs. Furthermore, to maintain the knowledge corresponding to\neach domain, we incorporate intra-domain category-aware prototypes as domain\nprior prompts into the training process. Extensive experiments conducted on 11\ndifferent datasets demonstrate the effectiveness of our approach, achieving\n2.37% and 1.14% average improvement in class-incremental and task-incremental\nsettings, respectively.\n","authors":["Yadong Lu","Shitian Zhao","Boxiang Yun","Dongsheng Jiang","Yin Li","Qingli Li","Yan Wang"],"pdf_url":"https://arxiv.org/pdf/2408.09984v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07635v1","updated":"2024-11-12T08:30:59Z","published":"2024-11-12T08:30:59Z","title":"Breaking the Low-Rank Dilemma of Linear Attention","summary":"  The Softmax attention mechanism in Transformer models is notoriously\ncomputationally expensive, particularly due to its quadratic complexity, posing\nsignificant challenges in vision applications. In contrast, linear attention\nprovides a far more efficient solution by reducing the complexity to linear\nlevels. However, compared to Softmax attention, linear attention often\nexperiences significant performance degradation. Our experiments indicate that\nthis performance drop is due to the low-rank nature of linear attention's\nfeature map, which hinders its ability to adequately model complex spatial\ninformation. In this paper, to break the low-rank dilemma of linear attention,\nwe conduct rank analysis from two perspectives: the KV buffer and the output\nfeatures. Consequently, we introduce Rank-Augmented Linear Attention (RALA),\nwhich rivals the performance of Softmax attention while maintaining linear\ncomplexity and high efficiency. Based on RALA, we construct the Rank-Augmented\nVision Linear Transformer (RAVLT). Extensive experiments demonstrate that RAVLT\nachieves excellent performance across various vision tasks. Specifically,\nwithout using any additional labels, data, or supervision during training,\nRAVLT achieves an 84.4% Top-1 accuracy on ImageNet-1k with only 26M parameters\nand 4.6G FLOPs. This result significantly surpasses previous linear attention\nmechanisms, fully illustrating the potential of RALA. Code will be available at\nhttps://github.com/qhfan/RALA.\n","authors":["Qihang Fan","Huaibo Huang","Ran He"],"pdf_url":"https://arxiv.org/pdf/2411.07635v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.05128v2","updated":"2024-11-12T08:24:47Z","published":"2024-07-06T16:34:25Z","title":"SCSA: Exploring the Synergistic Effects Between Spatial and Channel\n  Attention","summary":"  Channel and spatial attentions have respectively brought significant\nimprovements in extracting feature dependencies and spatial structure relations\nfor various downstream vision tasks. While their combination is more beneficial\nfor leveraging their individual strengths, the synergy between channel and\nspatial attentions has not been fully explored, lacking in fully harness the\nsynergistic potential of multi-semantic information for feature guidance and\nmitigation of semantic disparities. Our study attempts to reveal the\nsynergistic relationship between spatial and channel attention at multiple\nsemantic levels, proposing a novel Spatial and Channel Synergistic Attention\nmodule (SCSA). Our SCSA consists of two parts: the Shareable Multi-Semantic\nSpatial Attention (SMSA) and the Progressive Channel-wise Self-Attention\n(PCSA). SMSA integrates multi-semantic information and utilizes a progressive\ncompression strategy to inject discriminative spatial priors into PCSA's\nchannel self-attention, effectively guiding channel recalibration.\nAdditionally, the robust feature interactions based on the self-attention\nmechanism in PCSA further mitigate the disparities in multi-semantic\ninformation among different sub-features within SMSA. We conduct extensive\nexperiments on seven benchmark datasets, including classification on\nImageNet-1K, object detection on MSCOCO 2017, segmentation on ADE20K, and four\nother complex scene detection datasets. Our results demonstrate that our\nproposed SCSA not only surpasses the current state-of-the-art attention but\nalso exhibits enhanced generalization capabilities across various task\nscenarios. The code and models are available at:\nhttps://github.com/HZAI-ZJNU/SCSA.\n","authors":["Yunzhong Si","Huiying Xu","Xinzhong Zhu","Wenhao Zhang","Yao Dong","Yuxing Chen","Hongbo Li"],"pdf_url":"https://arxiv.org/pdf/2407.05128v2.pdf","comment":"We added experiments for the classification task and updated the\n  corresponding sections accordingly. The paper formatting has also been\n  revised"},{"id":"http://arxiv.org/abs/2411.07627v1","updated":"2024-11-12T08:17:15Z","published":"2024-11-12T08:17:15Z","title":"Leveraging Previous Steps: A Training-free Fast Solver for Flow\n  Diffusion","summary":"  Flow diffusion models (FDMs) have recently shown potential in generation\ntasks due to the high generation quality. However, the current ordinary\ndifferential equation (ODE) solver for FDMs, e.g., the Euler solver, still\nsuffers from slow generation since ODE solvers need many number function\nevaluations (NFE) to keep high-quality generation. In this paper, we propose a\nnovel training-free flow-solver to reduce NFE while maintaining high-quality\ngeneration. The key insight for the flow-solver is to leverage the previous\nsteps to reduce the NFE, where a cache is created to reuse these results from\nthe previous steps. Specifically, the Taylor expansion is first used to\napproximate the ODE. To calculate the high-order derivatives of Taylor\nexpansion, the flow-solver proposes to use the previous steps and a polynomial\ninterpolation to approximate it, where the number of orders we could\napproximate equals the number of previous steps we cached. We also prove that\nthe flow-solver has a more minor approximation error and faster generation\nspeed. Experimental results on the CIFAR-10, CelebA-HQ, LSUN-Bedroom,\nLSUN-Church, ImageNet, and real text-to-image generation prove the efficiency\nof the flow-solver. Specifically, the flow-solver improves the FID-30K from\n13.79 to 6.75, from 46.64 to 19.49 with $\\text{NFE}=10$ on CIFAR-10 and\nLSUN-Church, respectively.\n","authors":["Kaiyu Song","Hanjiang Lai"],"pdf_url":"https://arxiv.org/pdf/2411.07627v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07625v1","updated":"2024-11-12T08:14:39Z","published":"2024-11-12T08:14:39Z","title":"Unraveling the Connections between Flow Matching and Diffusion\n  Probabilistic Models in Training-free Conditional Generation","summary":"  Training-free conditional generation aims to leverage the unconditional\ndiffusion models to implement the conditional generation, where flow-matching\n(FM) and diffusion probabilistic models (DPMs) are two mature unconditional\ndiffusion models that achieve high-quality generation. Two questions were asked\nin this paper: What are the underlying connections between FM and DPMs in\ntraining-free conditional generation? Can we leverage DPMs to improve the\ntraining-free conditional generation for FM? We first show that a probabilistic\ndiffusion path can be associated with the FM and DPMs. Then, we reformulate the\nordinary differential equation (ODE) of FM based on the score function of DPMs,\nand thus, the conditions in FM can be incorporated as those in DPMs. Finally,\nwe propose two posterior sampling methods to estimate the conditional term and\nachieve a training-free conditional generation of FM. Experimental results show\nthat our proposed method could be implemented for various conditional\ngeneration tasks. Our method can generate higher-quality results than the\nstate-of-the-art methods.\n","authors":["Kaiyu Song","Hanjiang Lai"],"pdf_url":"https://arxiv.org/pdf/2411.07625v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07621v1","updated":"2024-11-12T08:08:31Z","published":"2024-11-12T08:08:31Z","title":"Mix from Failure: Confusion-Pairing Mixup for Long-Tailed Recognition","summary":"  Long-tailed image recognition is a computer vision problem considering a\nreal-world class distribution rather than an artificial uniform. Existing\nmethods typically detour the problem by i) adjusting a loss function, ii)\ndecoupling classifier learning, or iii) proposing a new multi-head architecture\ncalled experts. In this paper, we tackle the problem from a different\nperspective to augment a training dataset to enhance the sample diversity of\nminority classes. Specifically, our method, namely Confusion-Pairing Mixup\n(CP-Mix), estimates the confusion distribution of the model and handles the\ndata deficiency problem by augmenting samples from confusion pairs in\nreal-time. In this way, CP-Mix trains the model to mitigate its weakness and\ndistinguish a pair of classes it frequently misclassifies. In addition, CP-Mix\nutilizes a novel mixup formulation to handle the bias in decision boundaries\nthat originated from the imbalanced dataset. Extensive experiments demonstrate\nthat CP-Mix outperforms existing methods for long-tailed image recognition and\nsuccessfully relieves the confusion of the classifier.\n","authors":["Youngseok Yoon","Sangwoo Hong","Hyungjoon Joo","Yao Qin","Haewon Jeong","Jungwoo Lee"],"pdf_url":"https://arxiv.org/pdf/2411.07621v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07619v1","updated":"2024-11-12T08:05:58Z","published":"2024-11-12T08:05:58Z","title":"Artificial Intelligence for Biomedical Video Generation","summary":"  As a prominent subfield of Artificial Intelligence Generated Content (AIGC),\nvideo generation has achieved notable advancements in recent years. The\nintroduction of Sora-alike models represents a pivotal breakthrough in video\ngeneration technologies, significantly enhancing the quality of synthesized\nvideos. Particularly in the realm of biomedicine, video generation technology\nhas shown immense potential such as medical concept explanation, disease\nsimulation, and biomedical data augmentation. In this article, we thoroughly\nexamine the latest developments in video generation models and explore their\napplications, challenges, and future opportunities in the biomedical sector. We\nhave conducted an extensive review and compiled a comprehensive list of\ndatasets from various sources to facilitate the development and evaluation of\nvideo generative models in biomedicine. Given the rapid progress in this field,\nwe have also created a github repository to regularly update the advances of\nbiomedical video generation at:\nhttps://github.com/Lee728243228/Biomedical-Video-Generation\n","authors":["Linyuan Li","Jianing Qiu","Anujit Saha","Lin Li","Poyuan Li","Mengxian He","Ziyu Guo","Wu Yuan"],"pdf_url":"https://arxiv.org/pdf/2411.07619v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.18252v2","updated":"2024-11-12T08:01:04Z","published":"2024-04-28T17:18:41Z","title":"Improving Training-free Conditional Diffusion Model via Fisher\n  Information","summary":"  Training-free conditional diffusion models have received great attention in\nconditional image generation tasks. However, they require a computationally\nexpensive conditional score estimator to let the intermediate results of each\nstep in the reverse process toward the condition, which causes slow conditional\ngeneration. In this paper, we propose a novel Fisher information-based\nconditional diffusion (FICD) model to generate high-quality samples according\nto the condition. In particular, we further explore the conditional term from\nthe perspective of Fisher information, where we show Fisher information can act\nas a weight to measure the informativeness of the condition in each generation\nstep. According to this new perspective, we can control and gain more\ninformation along the conditional direction in the generation space. Thus, we\npropose the upper bound of the Fisher information to reformulate the\nconditional term, which increases the information gain and decreases the time\ncost. Experimental results also demonstrate that the proposed FICD can offer up\nto 2x speed-ups under the same sampling steps as most baselines. Meanwhile,\nFICD can improve the generation quality in various tasks compared to the\nbaselines with a low computation cost.\n","authors":["Kaiyu Song","Hanjiang Lai"],"pdf_url":"https://arxiv.org/pdf/2404.18252v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.16131v2","updated":"2024-11-12T07:55:34Z","published":"2024-01-29T12:56:11Z","title":"CIMIL-CRC: a clinically-informed multiple instance learning framework\n  for patient-level colorectal cancer molecular subtypes classification from\n  H\\&E stained images","summary":"  Treatment approaches for colorectal cancer (CRC) are highly dependent on the\nmolecular subtype, as immunotherapy has shown efficacy in cases with\nmicrosatellite instability (MSI) but is ineffective for the microsatellite\nstable (MSS) subtype. There is promising potential in utilizing deep neural\nnetworks (DNNs) to automate the differentiation of CRC subtypes by analyzing\nHematoxylin and Eosin (H\\&E) stained whole-slide images (WSIs). Due to the\nextensive size of WSIs, Multiple Instance Learning (MIL) techniques are\ntypically explored. However, existing MIL methods focus on identifying the most\nrepresentative image patches for classification, which may result in the loss\nof critical information. Additionally, these methods often overlook clinically\nrelevant information, like the tendency for MSI class tumors to predominantly\noccur on the proximal (right side) colon. We introduce `CIMIL-CRC', a DNN\nframework that: 1) solves the MSI/MSS MIL problem by efficiently combining a\npre-trained feature extraction model with principal component analysis (PCA) to\naggregate information from all patches, and 2) integrates clinical priors,\nparticularly the tumor location within the colon, into the model to enhance\npatient-level classification accuracy. We assessed our CIMIL-CRC method using\nthe average area under the curve (AUC) from a 5-fold cross-validation\nexperimental setup for model development on the TCGA-CRC-DX cohort, contrasting\nit with a baseline patch-level classification, MIL-only approach, and\nClinically-informed patch-level classification approach. Our CIMIL-CRC\noutperformed all methods (AUROC: $0.92\\pm0.002$ (95\\% CI 0.91-0.92), vs.\n$0.79\\pm0.02$ (95\\% CI 0.76-0.82), $0.86\\pm0.01$ (95\\% CI 0.85-0.88), and\n$0.87\\pm0.01$ (95\\% CI 0.86-0.88), respectively). The improvement was\nstatistically significant.\n","authors":["Hadar Hezi","Matan Gelber","Alexander Balabanov","Yosef E. Maruvka","Moti Freiman"],"pdf_url":"https://arxiv.org/pdf/2401.16131v2.pdf","comment":"Accepted to the journal 'Computer Methods and Programs in\n  Biomedicine'"},{"id":"http://arxiv.org/abs/2406.18054v2","updated":"2024-11-12T07:52:42Z","published":"2024-06-26T04:12:34Z","title":"Leveraging Pre-trained Models for FF-to-FFPE Histopathological Image\n  Translation","summary":"  The two primary types of Hematoxylin and Eosin (H&E) slides in histopathology\nare Formalin-Fixed Paraffin-Embedded (FFPE) and Fresh Frozen (FF). FFPE slides\noffer high quality histopathological images but require a labor-intensive\nacquisition process. In contrast, FF slides can be prepared quickly, but the\nimage quality is relatively poor. Our task is to translate FF images into FFPE\nstyle, thereby improving the image quality for diagnostic purposes. In this\npaper, we propose Diffusion-FFPE, a method for FF-to-FFPE histopathological\nimage translation using a pre-trained diffusion model. Specifically, we employ\na one-step diffusion model as the generator and fine-tune it with LoRA adapters\nusing adversarial learning objectives. To ensure that the model effectively\ncaptures both global structural information and local details, we propose a\nmulti-scale feature fusion (MFF) module. This module utilizes two VAE encoders\nto extract features of varying image sizes and performs feature fusion before\nfeeding them into the UNet. Furthermore, we utilize a pre-trained\nvision-language model for histopathology as the backbone for the discriminator\nto further improve performance We conducted FF-to-FFPE translation experiments\non the TCGA-NSCLC datasets, and our method achieved better performance compared\nto other methods. The code and models are released at\nhttps://github.com/QilaiZhang/Diffusion-FFPE.\n","authors":["Qilai Zhang","Jiawen Li","Peiran Liao","Jiali Hu","Tian Guan","Anjia Han","Yonghong He"],"pdf_url":"https://arxiv.org/pdf/2406.18054v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07232v2","updated":"2024-11-12T07:49:39Z","published":"2024-11-11T18:50:09Z","title":"Add-it: Training-Free Object Insertion in Images With Pretrained\n  Diffusion Models","summary":"  Adding Object into images based on text instructions is a challenging task in\nsemantic image editing, requiring a balance between preserving the original\nscene and seamlessly integrating the new object in a fitting location. Despite\nextensive efforts, existing models often struggle with this balance,\nparticularly with finding a natural location for adding an object in complex\nscenes. We introduce Add-it, a training-free approach that extends diffusion\nmodels' attention mechanisms to incorporate information from three key sources:\nthe scene image, the text prompt, and the generated image itself. Our weighted\nextended-attention mechanism maintains structural consistency and fine details\nwhile ensuring natural object placement. Without task-specific fine-tuning,\nAdd-it achieves state-of-the-art results on both real and generated image\ninsertion benchmarks, including our newly constructed \"Additing Affordance\nBenchmark\" for evaluating object placement plausibility, outperforming\nsupervised methods. Human evaluations show that Add-it is preferred in over 80%\nof cases, and it also demonstrates improvements in various automated metrics.\n","authors":["Yoad Tewel","Rinon Gal","Dvir Samuel","Yuval Atzmon","Lior Wolf","Gal Chechik"],"pdf_url":"https://arxiv.org/pdf/2411.07232v2.pdf","comment":"Project page is at https://research.nvidia.com/labs/par/addit/"},{"id":"http://arxiv.org/abs/2409.00606v3","updated":"2024-11-12T07:38:51Z","published":"2024-09-01T04:07:03Z","title":"Style Transfer: From Stitching to Neural Networks","summary":"  This article compares two style transfer methods in image processing: the\ntraditional method, which synthesizes new images by stitching together small\npatches from existing images, and a modern machine learning-based approach that\nuses a segmentation network to isolate foreground objects and apply style\ntransfer solely to the background. The traditional method excels in creating\nartistic abstractions but can struggle with seamlessness, whereas the machine\nlearning method preserves the integrity of foreground elements while enhancing\nthe background, offering improved aesthetic quality and computational\nefficiency. Our study indicates that machine learning-based methods are more\nsuited for real-world applications where detail preservation in foreground\nelements is essential.\n","authors":["Xinhe Xu","Zhuoer Wang","Yihan Zhang","Yizhou Liu","Zhaoyue Wang","Zhihao Xu","Muhan Zhao","Huaiying Luo"],"pdf_url":"https://arxiv.org/pdf/2409.00606v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07608v1","updated":"2024-11-12T07:30:32Z","published":"2024-11-12T07:30:32Z","title":"Quantum Information-Empowered Graph Neural Network for Hyperspectral\n  Change Detection","summary":"  Change detection (CD) is a critical remote sensing technique for identifying\nchanges in the Earth's surface over time. The outstanding substance\nidentifiability of hyperspectral images (HSIs) has significantly enhanced the\ndetection accuracy, making hyperspectral change detection (HCD) an essential\ntechnology. The detection accuracy can be further upgraded by leveraging the\ngraph structure of HSIs, motivating us to adopt the graph neural networks\n(GNNs) in solving HCD. For the first time, this work introduces quantum deep\nnetwork (QUEEN) into HCD. Unlike GNN and CNN, both extracting the\naffine-computing features, QUEEN provides fundamentally different\nunitary-computing features. We demonstrate that through the unitary feature\nextraction procedure, QUEEN provides radically new information for deciding\nwhether there is a change or not. Hierarchically, a graph feature learning\n(GFL) module exploits the graph structure of the bitemporal HSIs at the\nsuperpixel level, while a quantum feature learning (QFL) module learns the\nquantum features at the pixel level, as a complementary to GFL by preserving\npixel-level detailed spatial information not retained in the superpixels. In\nthe final classification stage, a quantum classifier is designed to cooperate\nwith a traditional fully connected classifier. The superior HCD performance of\nthe proposed QUEEN-empowered GNN (i.e., QUEEN-G) will be experimentally\ndemonstrated on real hyperspectral datasets.\n","authors":["Chia-Hsiang Lin","Tzu-Hsuan Lin","Jocelyn Chanussot"],"pdf_url":"https://arxiv.org/pdf/2411.07608v1.pdf","comment":"This work has been accepted by IEEE Transactions on Geoscience and\n  Remote Sensing (TGRS)"},{"id":"http://arxiv.org/abs/2411.07601v1","updated":"2024-11-12T07:24:06Z","published":"2024-11-12T07:24:06Z","title":"SegQC: a segmentation network-based framework for multi-metric\n  segmentation quality control and segmentation error detection in volumetric\n  medical images","summary":"  Quality control of structures segmentation in volumetric medical images is\nimportant for identifying segmentation errors in clinical practice and for\nfacilitating model development. This paper introduces SegQC, a novel framework\nfor segmentation quality estimation and segmentation error detection. SegQC\ncomputes an estimate measure of the quality of a segmentation in volumetric\nscans and in their individual slices and identifies possible segmentation error\nregions within a slice. The key components include: 1. SegQC-Net, a deep\nnetwork that inputs a scan and its segmentation mask and outputs segmentation\nerror probabilities for each voxel in the scan; 2. three new segmentation\nquality metrics, two overlap metrics and a structure size metric, computed from\nthe segmentation error probabilities; 3. a new method for detecting possible\nsegmentation errors in scan slices computed from the segmentation error\nprobabilities. We introduce a new evaluation scheme to measure segmentation\nerror discrepancies based on an expert radiologist corrections of automatically\nproduced segmentations that yields smaller observer variability and is closer\nto actual segmentation errors. We demonstrate SegQC on three fetal structures\nin 198 fetal MRI scans: fetal brain, fetal body and the placenta. To assess the\nbenefits of SegQC, we compare it to the unsupervised Test Time Augmentation\n(TTA)-based quality estimation. Our studies indicate that SegQC outperforms\nTTA-based quality estimation in terms of Pearson correlation and MAE for fetal\nbody and fetal brain structures segmentation. Our segmentation error detection\nmethod achieved recall and precision rates of 0.77 and 0.48 for fetal body, and\n0.74 and 0.55 for fetal brain segmentation error detection respectively. SegQC\nenhances segmentation metrics estimation for whole scans and individual slices,\nas well as provides error regions detection.\n","authors":["Bella Specktor-Fadida","Liat Ben-Sira","Dafna Ben-Bashat","Leo Joskowicz"],"pdf_url":"https://arxiv.org/pdf/2411.07601v1.pdf","comment":"28 pages, 9 figures"},{"id":"http://arxiv.org/abs/2404.13565v3","updated":"2024-11-12T07:21:04Z","published":"2024-04-21T07:34:44Z","title":"Exploring Diverse Methods in Visual Question Answering","summary":"  This study explores innovative methods for improving Visual Question\nAnswering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and\nattention mechanisms. Leveraging a balanced VQA dataset, we investigate three\ndistinct strategies. Firstly, GAN-based approaches aim to generate answer\nembeddings conditioned on image and question inputs, showing potential but\nstruggling with more complex tasks. Secondly, autoencoder-based techniques\nfocus on learning optimal embeddings for questions and images, achieving\ncomparable results with GAN due to better ability on complex questions. Lastly,\nattention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB),\naddress language priors and attention modeling, albeit with a\ncomplexity-performance trade-off. This study underscores the challenges and\nopportunities in VQA and suggests avenues for future research, including\nalternative GAN formulations and attentional mechanisms.\n","authors":["Panfeng Li","Qikai Yang","Xieming Geng","Wenjing Zhou","Zhicheng Ding","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13565v3.pdf","comment":"Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence"},{"id":"http://arxiv.org/abs/2411.07584v1","updated":"2024-11-12T06:44:24Z","published":"2024-11-12T06:44:24Z","title":"Grounded Video Caption Generation","summary":"  We propose a new task, dataset and model for grounded video caption\ngeneration. This task unifies captioning and object grounding in video, where\nthe objects in the caption are grounded in the video via temporally consistent\nbounding boxes. We introduce the following contributions. First, we present a\ntask definition and a manually annotated test dataset for this task, referred\nto as GROunded Video Caption Generation (GROC). Second, we introduce a\nlarge-scale automatic annotation method leveraging an existing model for\ngrounded still image captioning together with an LLM for summarising\nframe-level captions into temporally consistent captions in video. Furthermore,\nwe prompt the LLM to track by language -- classifying noun phrases from the\nframe-level captions into noun phrases of the video-level generated caption. We\napply this approach to videos from the HowTo100M dataset, which results in a\nnew large-scale training dataset, called HowToGround, with automatically\nannotated captions and spatio-temporally consistent bounding boxes with\ncoherent natural language labels. Third, we introduce a new grounded video\ncaption generation model, called VideoGround, and train the model on the new\nautomatically annotated HowToGround dataset. Finally, results of our\nVideoGround model set the state of the art for the new task of grounded video\ncaption generation. We perform extensive ablations and demonstrate the\nimportance of key technical contributions of our model.\n","authors":["Evangelos Kazakos","Cordelia Schmid","Josef Sivic"],"pdf_url":"https://arxiv.org/pdf/2411.07584v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06390v2","updated":"2024-11-12T06:41:21Z","published":"2024-11-10T08:23:27Z","title":"SplatFormer: Point Transformer for Robust 3D Gaussian Splatting","summary":"  3D Gaussian Splatting (3DGS) has recently transformed photorealistic\nreconstruction, achieving high visual fidelity and real-time performance.\nHowever, rendering quality significantly deteriorates when test views deviate\nfrom the camera angles used during training, posing a major challenge for\napplications in immersive free-viewpoint rendering and navigation. In this\nwork, we conduct a comprehensive evaluation of 3DGS and related novel view\nsynthesis methods under out-of-distribution (OOD) test camera scenarios. By\ncreating diverse test cases with synthetic and real-world datasets, we\ndemonstrate that most existing methods, including those incorporating various\nregularization techniques and data-driven priors, struggle to generalize\neffectively to OOD views. To address this limitation, we introduce SplatFormer,\nthe first point transformer model specifically designed to operate on Gaussian\nsplats. SplatFormer takes as input an initial 3DGS set optimized under limited\ntraining views and refines it in a single forward pass, effectively removing\npotential artifacts in OOD test views. To our knowledge, this is the first\nsuccessful application of point transformers directly on 3DGS sets, surpassing\nthe limitations of previous multi-scene training methods, which could handle\nonly a restricted number of input views during inference. Our model\nsignificantly improves rendering quality under extreme novel views, achieving\nstate-of-the-art performance in these challenging scenarios and outperforming\nvarious 3DGS regularization techniques, multi-scene models tailored for sparse\nview synthesis, and diffusion-based frameworks.\n","authors":["Yutong Chen","Marko Mihajlovic","Xiyi Chen","Yiming Wang","Sergey Prokudin","Siyu Tang"],"pdf_url":"https://arxiv.org/pdf/2411.06390v2.pdf","comment":"Code and dataset: https://github.com/ChenYutongTHU/SplatFormer\n  Project page: https://sergeyprokudin.github.io/splatformer/"},{"id":"http://arxiv.org/abs/2406.01956v3","updated":"2024-11-12T06:36:11Z","published":"2024-06-04T04:31:39Z","title":"Enhance Image-to-Image Generation with LLaVA-generated Prompts","summary":"  This paper presents a novel approach to enhance image-to-image generation by\nleveraging the multimodal capabilities of the Large Language and Vision\nAssistant (LLaVA). We propose a framework where LLaVA analyzes input images and\ngenerates textual descriptions, hereinafter LLaVA-generated prompts. These\nprompts, along with the original image, are fed into the image-to-image\ngeneration pipeline. This enriched representation guides the generation process\ntowards outputs that exhibit a stronger resemblance to the input image.\nExtensive experiments demonstrate the effectiveness of LLaVA-generated prompts\nin promoting image similarity. We observe a significant improvement in the\nvisual coherence between the generated and input images compared to traditional\nmethods. Future work will explore fine-tuning LLaVA prompts for increased\ncontrol over the creative process. By providing more specific details within\nthe prompts, we aim to achieve a delicate balance between faithfulness to the\noriginal image and artistic expression in the generated outputs.\n","authors":["Zhicheng Ding","Panfeng Li","Qikai Yang","Siyang Li"],"pdf_url":"https://arxiv.org/pdf/2406.01956v3.pdf","comment":"Accepted by 2024 5th International Conference on Information Science,\n  Parallel and Distributed Systems"},{"id":"http://arxiv.org/abs/2411.07581v1","updated":"2024-11-12T06:33:09Z","published":"2024-11-12T06:33:09Z","title":"Semantic segmentation on multi-resolution optical and microwave data\n  using deep learning","summary":"  Presently, deep learning and convolutional neural networks (CNNs) are widely\nused in the fields of image processing, image classification, object\nidentification and many more. In this work, we implemented convolutional neural\nnetwork based modified U-Net model and VGG-UNet model to automatically identify\nobjects from satellite imagery captured using high resolution Indian remote\nsensing satellites and then to pixel wise classify satellite data into various\nclasses. In this paper, Cartosat 2S (~1m spatial resolution) datasets were used\nand deep learning models were implemented to detect building shapes and ships\nfrom the test datasets with an accuracy of more than 95%. In another\nexperiment, microwave data (varied resolution) from RISAT-1 was taken as an\ninput and ships and trees were detected with an accuracy of >96% from these\ndatasets. For the classification of images into multiple-classes, deep learning\nmodel was trained on multispectral Cartosat images. Model generated results\nwere then tested using ground truth. Multi-label classification results were\nobtained with an accuracy (IoU) of better than 95%. Total six different\nproblems were attempted using deep learning models and IoU accuracies in the\nrange of 85% to 98% were achieved depending on the degree of complexity.\n","authors":["Jai G Singla","Bakul Vaghela"],"pdf_url":"https://arxiv.org/pdf/2411.07581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07579v1","updated":"2024-11-12T06:29:48Z","published":"2024-11-12T06:29:48Z","title":"Projecting Gaussian Ellipsoids While Avoiding Affine Projection\n  Approximation","summary":"  Recently, 3D Gaussian Splatting has dominated novel-view synthesis with its\nreal-time rendering speed and state-of-the-art rendering quality. However,\nduring the rendering process, the use of the Jacobian of the affine\napproximation of the projection transformation leads to inevitable errors,\nresulting in blurriness, artifacts and a lack of scene consistency in the final\nrendered images. To address this issue, we introduce an ellipsoid-based\nprojection method to calculate the projection of Gaussian ellipsoid on the\nimage plane, witch is the primitive of 3D Gaussian Splatting. As our proposed\nellipsoid-based projection method cannot handle Gaussian ellipsoids with camera\norigins inside them or parts lying below $z=0$ plane in the camera space, we\ndesigned a pre-filtering strategy. Experiments over multiple widely adopted\nbenchmark datasets show that using our ellipsoid-based projection method can\nenhance the rendering quality of 3D Gaussian Splatting and its extensions.\n","authors":["Han Qi","Tao Cai","Xiyue Han"],"pdf_url":"https://arxiv.org/pdf/2411.07579v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07578v1","updated":"2024-11-12T06:29:35Z","published":"2024-11-12T06:29:35Z","title":"Atmospheric turbulence restoration by diffeomorphic image registration\n  and blind deconvolution","summary":"  A novel approach is presented in this paper to improve images which are\naltered by atmospheric turbulence. Two new algorithms are presented based on\ntwo combinations of a blind deconvolution block, an elastic registration block\nand a temporal filter block. The algorithms are tested on real images acquired\nin the desert in New Mexico by the NATO RTG40 group.\n","authors":["Jerome Gilles","Tristan Dagobert","Carlo De Franchis"],"pdf_url":"https://arxiv.org/pdf/2411.07578v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07577v1","updated":"2024-11-12T06:29:27Z","published":"2024-11-12T06:29:27Z","title":"IR image databases generation under target intrinsic thermal variability\n  constraints","summary":"  This paper deals with the problem of infrared image database generation for\nATR assessment purposes. Huge databases are required to have quantitative and\nobjective performance evaluations. We propose a method which superimpose\ntargets and occultants on background under image quality metrics constraints to\ngenerate realistic images. We also propose a method to generate target\nsignatures with intrinsic thermal variability based on 3D models plated with\nreal infrared textures.\n","authors":["Jerome Gilles","Stephane Landeau","Tristan Dagobert","Philippe Chevalier","Christian Bolut"],"pdf_url":"https://arxiv.org/pdf/2411.07577v1.pdf","comment":"arXiv admin note: substantial text overlap with arXiv:2411.06695"},{"id":"http://arxiv.org/abs/2411.07575v1","updated":"2024-11-12T06:29:18Z","published":"2024-11-12T06:29:18Z","title":"G√©n√©ration de bases de donn√©es images IR sous contraintes avec\n  variabilit√© thermique intrins√®que des cibles","summary":"  In this communication, we propose a method which permits to simulate images\nof targets in infrared imagery by superimposition of vehicle signatures in\nbackground, eventually with occultants. We develop a principle which authorizes\nus to generate different thermal configurations of target signatures. This\nmethod enables us to easily generate huge datasets for ATR algorithms\nperformance evaluation.\n","authors":["Jerome Gilles","Stephane Landeau","Tristan Dagobert","Philippe Chevalier","Christian Bolut"],"pdf_url":"https://arxiv.org/pdf/2411.07575v1.pdf","comment":"in French language, GRETSI Symposium on Signal and Image Processing,\n  Dijon, France, September 2009"},{"id":"http://arxiv.org/abs/2403.06443v2","updated":"2024-11-12T06:11:46Z","published":"2024-03-11T05:29:46Z","title":"Temporal-Mapping Photography for Event Cameras","summary":"  Event cameras, or Dynamic Vision Sensors (DVS) are novel neuromorphic sensors\nthat capture brightness changes as a continuous stream of \"events\" rather than\ntraditional intensity frames. Converting sparse events to dense intensity\nframes faithfully has long been an ill-posed problem. Previous methods have\nprimarily focused on converting events to video in dynamic scenes or with a\nmoving camera. In this paper, for the first time, we realize events to dense\nintensity image conversion using a stationary event camera in static scenes\nwith a transmittance adjustment device for brightness modulation. Different\nfrom traditional methods that mainly rely on event integration, the proposed\nEvent-Based Temporal Mapping Photography (EvTemMap) measures the time of event\nemitting for each pixel. Then, the resulting Temporal Matrix is converted to an\nintensity frame with a temporal mapping neural network. At the hardware level,\nthe proposed EvTemMap is implemented by combining a transmittance adjustment\ndevice with a DVS, named Adjustable Transmittance Dynamic Vision Sensor\n(AT-DVS). Additionally, we collected TemMat dataset under various conditions\nincluding low-light and high dynamic range scenes. The experimental results\nshowcase the high dynamic range, fine-grained details, and high-grayscale\nresolution of the proposed EvTemMap. The code and dataset are available in\nhttps://github.com/YuHanBaozju/EvTemMap\n","authors":["Yuhan Bao","Lei Sun","Yuqin Ma","Kaiwei Wang"],"pdf_url":"https://arxiv.org/pdf/2403.06443v2.pdf","comment":"18 pages, 10 figures, 1 Supplementary materials"},{"id":"http://arxiv.org/abs/2408.15241v2","updated":"2024-11-12T06:08:29Z","published":"2024-08-27T17:59:41Z","title":"GenRec: Unifying Video Generation and Recognition with Diffusion Models","summary":"  Video diffusion models are able to generate high-quality videos by learning\nstrong spatial-temporal priors on large-scale datasets. In this paper, we aim\nto investigate whether such priors derived from a generative process are\nsuitable for video recognition, and eventually joint optimization of generation\nand recognition. Building upon Stable Video Diffusion, we introduce GenRec, the\nfirst unified framework trained with a random-frame conditioning process so as\nto learn generalized spatial-temporal representations. The resulting framework\ncan naturally supports generation and recognition, and more importantly is\nrobust even when visual inputs contain limited information. Extensive\nexperiments demonstrate the efficacy of GenRec for both recognition and\ngeneration. In particular, GenRec achieves competitive recognition performance,\noffering 75.8% and 87.2% accuracy on SSV2 and K400, respectively. GenRec also\nperforms the best on class-conditioned image-to-video generation, achieving\n46.5 and 49.3 FVD scores on SSV2 and EK-100 datasets. Furthermore, GenRec\ndemonstrates extraordinary robustness in scenarios that only limited frames can\nbe observed. Code will be available at https://github.com/wengzejia1/GenRec.\n","authors":["Zejia Weng","Xitong Yang","Zhen Xing","Zuxuan Wu","Yu-Gang Jiang"],"pdf_url":"https://arxiv.org/pdf/2408.15241v2.pdf","comment":"19 pages, 6 figures, 12 tables"},{"id":"http://arxiv.org/abs/2411.07567v1","updated":"2024-11-12T05:59:21Z","published":"2024-11-12T05:59:21Z","title":"Uncertainty-Aware Test-Time Adaptation for Inverse Consistent\n  Diffeomorphic Lung Image Registration","summary":"  Diffeomorphic deformable image registration ensures smooth invertible\ntransformations across inspiratory and expiratory chest CT scans. Yet, in\npractice, deep learning-based diffeomorphic methods struggle to capture large\ndeformations between inspiratory and expiratory volumes, and therefore lack\ninverse consistency. Existing methods also fail to account for model\nuncertainty, which can be useful for improving performance. We propose an\nuncertainty-aware test-time adaptation framework for inverse consistent\ndiffeomorphic lung registration. Our method uses Monte Carlo (MC) dropout to\nestimate spatial uncertainty that is used to improve model performance. We\ntrain and evaluate our method for inspiratory-to-expiratory CT registration on\na large cohort of 675 subjects from the COPDGene study, achieving a higher Dice\nsimilarity coefficient (DSC) between the lung boundaries (0.966) compared to\nboth VoxelMorph (0.953) and TransMorph (0.953). Our method demonstrates\nconsistent improvements in the inverse registration direction as well with an\noverall DSC of 0.966, higher than VoxelMorph (0.958) and TransMorph (0.956).\nPaired t-tests indicate statistically significant improvements.\n","authors":["Muhammad F. A. Chaudhary","Stephanie M. Aguilera","Arie Nakhmani","Joseph M. Reinhardt","Surya P. Bhatt","Sandeep Bodduluri"],"pdf_url":"https://arxiv.org/pdf/2411.07567v1.pdf","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2406.10839v3","updated":"2024-11-12T05:33:05Z","published":"2024-06-16T08:20:12Z","title":"Reminding Multimodal Large Language Models of Object-aware Knowledge\n  with Retrieved Tags","summary":"  Despite recent advances in the general visual instruction-following ability\nof Multimodal Large Language Models (MLLMs), they still struggle with critical\nproblems when required to provide a precise and detailed response to a visual\ninstruction: (1) failure to identify novel objects or entities, (2) mention of\nnon-existent objects, and (3) neglect of object's attributed details. Intuitive\nsolutions include improving the size and quality of data or using larger\nfoundation models. They show effectiveness in mitigating these issues, but at\nan expensive cost of collecting a vast amount of new data and introducing a\nsignificantly larger model. Standing at the intersection of these approaches,\nwe examine the three object-oriented problems from the perspective of the\nimage-to-text mapping process by the multimodal connector. In this paper, we\nfirst identify the limitations of multimodal connectors stemming from\ninsufficient training data. Driven by this, we propose to enhance the mapping\nwith retrieval-augmented tag tokens, which contain rich object-aware\ninformation such as object names and attributes. With our Tag-grounded visual\ninstruction tuning with retrieval Augmentation (TUNA), we outperform baselines\nthat share the same language model and training data on 12 benchmarks.\nFurthermore, we show the zero-shot capability of TUNA when provided with\nspecific datastores.\n","authors":["Daiqing Qi","Handong Zhao","Zijun Wei","Sheng Li"],"pdf_url":"https://arxiv.org/pdf/2406.10839v3.pdf","comment":"Main Conference at EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.07556v1","updated":"2024-11-12T05:10:32Z","published":"2024-11-12T05:10:32Z","title":"Multi-task Feature Enhancement Network for No-Reference Image Quality\n  Assessment","summary":"  Due to the scarcity of labeled samples in Image Quality Assessment (IQA)\ndatasets, numerous recent studies have proposed multi-task based strategies,\nwhich explore feature information from other tasks or domains to boost the IQA\ntask. Nevertheless, multi-task strategies based No-Reference Image Quality\nAssessment (NR-IQA) methods encounter several challenges. First, existing\nmethods have not explicitly exploited texture details, which significantly\ninfluence the image quality. Second, multi-task methods conventionally\nintegrate features through simple operations such as addition or concatenation,\nthereby diminishing the network's capacity to accurately represent distorted\nfeatures. To tackle these challenges, we introduce a novel multi-task NR-IQA\nframework. Our framework consists of three key components: a high-frequency\nextraction network, a quality estimation network, and a distortion-aware\nnetwork. The high-frequency extraction network is designed to guide the model's\nfocus towards high-frequency information, which is highly related to the\ntexture details. Meanwhile, the distortion-aware network extracts\ndistortion-related features to distinguish different distortion types. To\neffectively integrate features from different tasks, a feature fusion module is\ndeveloped based on an attention mechanism. Empirical results from five standard\nIQA databases confirm that our method not only achieves high performance but\nalso exhibits robust generalization ability.\n","authors":["Li Yu"],"pdf_url":"https://arxiv.org/pdf/2411.07556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07555v1","updated":"2024-11-12T05:09:42Z","published":"2024-11-12T05:09:42Z","title":"GaussianCut: Interactive segmentation via graph cut for 3D Gaussian\n  Splatting","summary":"  We introduce GaussianCut, a new method for interactive multiview segmentation\nof scenes represented as 3D Gaussians. Our approach allows for selecting the\nobjects to be segmented by interacting with a single view. It accepts intuitive\nuser input, such as point clicks, coarse scribbles, or text. Using 3D Gaussian\nSplatting (3DGS) as the underlying scene representation simplifies the\nextraction of objects of interest which are considered to be a subset of the\nscene's Gaussians. Our key idea is to represent the scene as a graph and use\nthe graph-cut algorithm to minimize an energy function to effectively partition\nthe Gaussians into foreground and background. To achieve this, we construct a\ngraph based on scene Gaussians and devise a segmentation-aligned energy\nfunction on the graph to combine user inputs with scene properties. To obtain\nan initial coarse segmentation, we leverage 2D image/video segmentation models\nand further refine these coarse estimates using our graph construction. Our\nempirical evaluations show the adaptability of GaussianCut across a diverse set\nof scenes. GaussianCut achieves competitive performance with state-of-the-art\napproaches for 3D segmentation without requiring any additional\nsegmentation-aware training.\n","authors":["Umangi Jain","Ashkan Mirzaei","Igor Gilitschenski"],"pdf_url":"https://arxiv.org/pdf/2411.07555v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07546v1","updated":"2024-11-12T04:50:10Z","published":"2024-11-12T04:50:10Z","title":"Contrastive Language Prompting to Ease False Positives in Medical\n  Anomaly Detection","summary":"  A pre-trained visual-language model, contrastive language-image pre-training\n(CLIP), successfully accomplishes various downstream tasks with text prompts,\nsuch as finding images or localizing regions within the image. Despite CLIP's\nstrong multi-modal data capabilities, it remains limited in specialized\nenvironments, such as medical applications. For this purpose, many CLIP\nvariants-i.e., BioMedCLIP, and MedCLIP-SAMv2-have emerged, but false positives\nrelated to normal regions persist. Thus, we aim to present a simple yet\nimportant goal of reducing false positives in medical anomaly detection. We\nintroduce a Contrastive LAnguage Prompting (CLAP) method that leverages both\npositive and negative text prompts. This straightforward approach identifies\npotential lesion regions by visual attention to the positive prompts in the\ngiven image. To reduce false positives, we attenuate attention on normal\nregions using negative prompts. Extensive experiments with the BMAD dataset,\nincluding six biomedical benchmarks, demonstrate that CLAP method enhances\nanomaly detection performance. Our future plans include developing an automated\nfine prompting method for more practical usage.\n","authors":["YeongHyeon Park","Myung Jin Kim","Hyeong Seok Kim"],"pdf_url":"https://arxiv.org/pdf/2411.07546v1.pdf","comment":"4 pages, 3 figures, 2 tables"},{"id":"http://arxiv.org/abs/2411.07544v1","updated":"2024-11-12T04:47:32Z","published":"2024-11-12T04:47:32Z","title":"Depthwise Separable Convolutions with Deep Residual Convolutions","summary":"  The recent advancement of edge computing enables researchers to optimize\nvarious deep learning architectures to employ them in edge devices. In this\nstudy, we aim to optimize Xception architecture which is one of the most\npopular deep learning algorithms for computer vision applications. The Xception\narchitecture is highly effective for object detection tasks. However, it comes\nwith a significant computational cost. The computational complexity of Xception\nsometimes hinders its deployment on resource-constrained edge devices. To\naddress this, we propose an optimized Xception architecture tailored for edge\ndevices, aiming for lightweight and efficient deployment. We incorporate the\ndepthwise separable convolutions with deep residual convolutions of the\nXception architecture to develop a small and efficient model for edge devices.\nThe resultant architecture reduces parameters, memory usage, and computational\nload. The proposed architecture is evaluated on the CIFAR 10 object detection\ndataset. The evaluation result of our experiment also shows the proposed\narchitecture is smaller in parameter size and requires less training time while\noutperforming Xception architecture performance.\n","authors":["Md Arid Hasan","Krishno Dey"],"pdf_url":"https://arxiv.org/pdf/2411.07544v1.pdf","comment":"Course Project Report"},{"id":"http://arxiv.org/abs/2411.07541v1","updated":"2024-11-12T04:40:27Z","published":"2024-11-12T04:40:27Z","title":"HiCoM: Hierarchical Coherent Motion for Streamable Dynamic Scene with 3D\n  Gaussian Splatting","summary":"  The online reconstruction of dynamic scenes from multi-view streaming videos\nfaces significant challenges in training, rendering and storage efficiency.\nHarnessing superior learning speed and real-time rendering capabilities, 3D\nGaussian Splatting (3DGS) has recently demonstrated considerable potential in\nthis field. However, 3DGS can be inefficient in terms of storage and prone to\noverfitting by excessively growing Gaussians, particularly with limited views.\nThis paper proposes an efficient framework, dubbed HiCoM, with three key\ncomponents. First, we construct a compact and robust initial 3DGS\nrepresentation using a perturbation smoothing strategy. Next, we introduce a\nHierarchical Coherent Motion mechanism that leverages the inherent non-uniform\ndistribution and local consistency of 3D Gaussians to swiftly and accurately\nlearn motions across frames. Finally, we continually refine the 3DGS with\nadditional Gaussians, which are later merged into the initial 3DGS to maintain\nconsistency with the evolving scene. To preserve a compact representation, an\nequivalent number of low-opacity Gaussians that minimally impact the\nrepresentation are removed before processing subsequent frames. Extensive\nexperiments conducted on two widely used datasets show that our framework\nimproves learning efficiency of the state-of-the-art methods by about $20\\%$\nand reduces the data storage by $85\\%$, achieving competitive free-viewpoint\nvideo synthesis quality but with higher robustness and stability. Moreover, by\nparallel learning multiple frames simultaneously, our HiCoM decreases the\naverage training wall time to $<2$ seconds per frame with negligible\nperformance degradation, substantially boosting real-world applicability and\nresponsiveness.\n","authors":["Qiankun Gao","Jiarui Meng","Chengxiang Wen","Jie Chen","Jian Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07541v1.pdf","comment":"Accepted to NeurIPS 2024; Code is avaliable at\n  https://github.com/gqk/HiCoM"},{"id":"http://arxiv.org/abs/2404.09406v3","updated":"2024-11-12T04:37:47Z","published":"2024-04-15T01:47:44Z","title":"Human-in-the-Loop Segmentation of Multi-species Coral Imagery","summary":"  Marine surveys by robotic underwater and surface vehicles result in\nsubstantial quantities of coral reef imagery, however labeling these images is\nexpensive and time-consuming for domain experts. Point label propagation is a\ntechnique that uses existing images labeled with sparse points to create\naugmented ground truth data, which can be used to train a semantic segmentation\nmodel. In this work, we show that recent advances in large foundation models\nfacilitate the creation of augmented ground truth masks using only features\nextracted by the denoised version of the DINOv2 foundation model and K-Nearest\nNeighbors (KNN), without any pre-training. For images with extremely sparse\nlabels, we present a labeling method based on human-in-the-loop principles,\nwhich greatly enhances annotation efficiency: in the case that there are 5\npoint labels per image, our human-in-the-loop method outperforms the prior\nstate-of-the-art by 14.2% for pixel accuracy and 19.7% for mIoU; and by 8.9%\nand 18.3% if there are 10 point labels. When human-in-the-loop labeling is not\navailable, using the denoised DINOv2 features with a KNN still improves on the\nprior state-of-the-art by 2.7% for pixel accuracy and 5.8% for mIoU (5 grid\npoints). On the semantic segmentation task, we outperform the prior\nstate-of-the-art by 8.8% for pixel accuracy and by 13.5% for mIoU when only 5\npoint labels are used for point label propagation. Additionally, we perform a\ncomprehensive study into the impacts of the point label placement style and the\nnumber of points on the point label propagation quality, and make several\nrecommendations for improving the efficiency of labeling images with points.\n","authors":["Scarlett Raine","Ross Marchant","Brano Kusy","Frederic Maire","Niko Suenderhauf","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2404.09406v3.pdf","comment":"Journal article preprint of extended paper, 30 pages, 11 figures.\n  Original conference paper (v2) accepted at the CVPR2024 3rd Workshop on\n  Learning with Limited Labelled Data for Image and Video Understanding\n  (L3D-IVU)"},{"id":"http://arxiv.org/abs/2407.01523v3","updated":"2024-11-12T04:37:44Z","published":"2024-07-01T17:59:26Z","title":"MMLongBench-Doc: Benchmarking Long-context Document Understanding with\n  Visualizations","summary":"  Understanding documents with rich layouts and multi-modal components is a\nlong-standing and practical task. Recent Large Vision-Language Models (LVLMs)\nhave made remarkable strides in various tasks, particularly in single-page\ndocument understanding (DU). However, their abilities on long-context DU remain\nan open problem. This work presents MMLongBench-Doc, a long-context,\nmulti-modal benchmark comprising 1,062 expert-annotated questions. Distinct\nfrom previous datasets, it is constructed upon 130 lengthy PDF-formatted\ndocuments with an average of 49.4 pages and 20,971 textual tokens. Towards\ncomprehensive evaluation, answers to these questions rely on pieces of evidence\nfrom (1) different sources (text, image, chart, table, and layout structure)\nand (2) various locations (i.e. page number). Moreover, 33.2% of the questions\nare cross-page questions requiring evidence across multiple pages. 22.8% of the\nquestions are designed to be unanswerable for detecting potential\nhallucinations. Experiments on 14 LVLMs demonstrate that long-context DU\ngreatly challenges current models. Notably, the best-performing model, GPT-4o,\nachieves an F1 score of only 42.7%, while the second-best, GPT-4V, scores\n31.4%. Furthermore, 12 LVLMs (all except GPT-4o and GPT-4V) even present worse\nperformance than their LLM counterparts which are fed with lossy-parsed OCR\ndocuments. These results validate the necessity of future research toward more\ncapable long-context LVLMs. Project Page:\nhttps://mayubo2333.github.io/MMLongBench-Doc\n","authors":["Yubo Ma","Yuhang Zang","Liangyu Chen","Meiqi Chen","Yizhu Jiao","Xinze Li","Xinyuan Lu","Ziyu Liu","Yan Ma","Xiaoyi Dong","Pan Zhang","Liangming Pan","Yu-Gang Jiang","Jiaqi Wang","Yixin Cao","Aixin Sun"],"pdf_url":"https://arxiv.org/pdf/2407.01523v3.pdf","comment":"Accepted to NeurIPS 2024 Datasets and Benchmarks Track (Spotlight)"},{"id":"http://arxiv.org/abs/2409.01652v2","updated":"2024-11-12T04:33:26Z","published":"2024-09-03T06:45:22Z","title":"ReKep: Spatio-Temporal Reasoning of Relational Keypoint Constraints for\n  Robotic Manipulation","summary":"  Representing robotic manipulation tasks as constraints that associate the\nrobot and the environment is a promising way to encode desired robot behaviors.\nHowever, it remains unclear how to formulate the constraints such that they are\n1) versatile to diverse tasks, 2) free of manual labeling, and 3) optimizable\nby off-the-shelf solvers to produce robot actions in real-time. In this work,\nwe introduce Relational Keypoint Constraints (ReKep), a visually-grounded\nrepresentation for constraints in robotic manipulation. Specifically, ReKep is\nexpressed as Python functions mapping a set of 3D keypoints in the environment\nto a numerical cost. We demonstrate that by representing a manipulation task as\na sequence of Relational Keypoint Constraints, we can employ a hierarchical\noptimization procedure to solve for robot actions (represented by a sequence of\nend-effector poses in SE(3)) with a perception-action loop at a real-time\nfrequency. Furthermore, in order to circumvent the need for manual\nspecification of ReKep for each new task, we devise an automated procedure that\nleverages large vision models and vision-language models to produce ReKep from\nfree-form language instructions and RGB-D observations. We present system\nimplementations on a wheeled single-arm platform and a stationary dual-arm\nplatform that can perform a large variety of manipulation tasks, featuring\nmulti-stage, in-the-wild, bimanual, and reactive behaviors, all without\ntask-specific data or environment models. Website at\nhttps://rekep-robot.github.io/.\n","authors":["Wenlong Huang","Chen Wang","Yunzhu Li","Ruohan Zhang","Li Fei-Fei"],"pdf_url":"https://arxiv.org/pdf/2409.01652v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09729v2","updated":"2024-11-12T04:19:32Z","published":"2024-10-13T05:19:09Z","title":"MIRAGE: Multimodal Identification and Recognition of Annotations in\n  Indian General Prescriptions","summary":"  Hospitals in India still rely on handwritten medical records despite the\navailability of Electronic Medical Records (EMR), complicating statistical\nanalysis and record retrieval. Handwritten records pose a unique challenge,\nrequiring specialized data for training models to recognize medications and\ntheir recommendation patterns. While traditional handwriting recognition\napproaches employ 2-D LSTMs, recent studies have explored using Multimodal\nLarge Language Models (MLLMs) for OCR tasks. Building on this approach, we\nfocus on extracting medication names and dosages from simulated medical\nrecords. Our methodology MIRAGE (Multimodal Identification and Recognition of\nAnnotations in indian GEneral prescriptions) involves fine-tuning the QWEN VL,\nLLaVA 1.6 and Idefics2 models on 743,118 high resolution simulated medical\nrecord images-fully annotated from 1,133 doctors across India. Our approach\nachieves 82% accuracy in extracting medication names and dosages.\n","authors":["Tavish Mankash","V. S. Chaithanya Kota","Anish De","Praveen Prakash","Kshitij Jadhav"],"pdf_url":"https://arxiv.org/pdf/2410.09729v2.pdf","comment":"5 pages, 9 figures, 3 tables, submitted to ISBI 2025"},{"id":"http://arxiv.org/abs/2404.09227v2","updated":"2024-11-12T04:08:05Z","published":"2024-04-14T12:13:07Z","title":"DreamScape: 3D Scene Creation via Gaussian Splatting joint Correlation\n  Modeling","summary":"  Recent progress in text-to-3D creation has been propelled by integrating the\npotent prior of Diffusion Models from text-to-image generation into the 3D\ndomain. Nevertheless, generating 3D scenes characterized by multiple instances\nand intricate arrangements remains challenging. In this study, we present\nDreamScape, a method for creating highly consistent 3D scenes solely from\ntextual descriptions, leveraging the strong 3D representation capabilities of\nGaussian Splatting and the complex arrangement abilities of large language\nmodels (LLMs). Our approach involves a 3D Gaussian Guide ($3{DG^2}$) for scene\nrepresentation, consisting of semantic primitives (objects) and their spatial\ntransformations and relationships derived directly from text prompts using\nLLMs. This compositional representation allows for local-to-global optimization\nof the entire scene. A progressive scale control is tailored during local\nobject generation, ensuring that objects of different sizes and densities adapt\nto the scene, which addresses training instability issue arising from simple\nblending in the subsequent global optimization stage. To mitigate potential\nbiases of LLM priors, we model collision relationships between objects at the\nglobal level, enhancing physical correctness and overall realism. Additionally,\nto generate pervasive objects like rain and snow distributed extensively across\nthe scene, we introduce a sparse initialization and densification strategy.\nExperiments demonstrate that DreamScape offers high usability and\ncontrollability, enabling the generation of high-fidelity 3D scenes from only\ntext prompts and achieving state-of-the-art performance compared to other\nmethods.\n","authors":["Xuening Yuan","Hongyu Yang","Yueming Zhao","Di Huang"],"pdf_url":"https://arxiv.org/pdf/2404.09227v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.17465v3","updated":"2024-11-12T03:27:41Z","published":"2024-03-26T07:55:16Z","title":"LaRE^2: Latent Reconstruction Error Based Method for Diffusion-Generated\n  Image Detection","summary":"  The evolution of Diffusion Models has dramatically improved image generation\nquality, making it increasingly difficult to differentiate between real and\ngenerated images. This development, while impressive, also raises significant\nprivacy and security concerns. In response to this, we propose a novel Latent\nREconstruction error guided feature REfinement method (LaRE^2) for detecting\nthe diffusion-generated images. We come up with the Latent Reconstruction Error\n(LaRE), the first reconstruction-error based feature in the latent space for\ngenerated image detection. LaRE surpasses existing methods in terms of feature\nextraction efficiency while preserving crucial cues required to differentiate\nbetween the real and the fake. To exploit LaRE, we propose an Error-Guided\nfeature REfinement module (EGRE), which can refine the image feature guided by\nLaRE to enhance the discriminativeness of the feature. Our EGRE utilizes an\nalign-then-refine mechanism, which effectively refines the image feature for\ngenerated-image detection from both spatial and channel perspectives. Extensive\nexperiments on the large-scale GenImage benchmark demonstrate the superiority\nof our LaRE^2, which surpasses the best SoTA method by up to 11.9%/12.1%\naverage ACC/AP across 8 different image generators. LaRE also surpasses\nexisting methods in terms of feature extraction cost, delivering an impressive\nspeed enhancement of 8 times. Code is available.\n","authors":["Yunpeng Luo","Junlong Du","Ke Yan","Shouhong Ding"],"pdf_url":"https://arxiv.org/pdf/2403.17465v3.pdf","comment":"CVPR 2024. Code is available at https://github.com/luo3300612/LaRE"},{"id":"http://arxiv.org/abs/2411.07516v1","updated":"2024-11-12T03:25:33Z","published":"2024-11-12T03:25:33Z","title":"SparrowVQE: Visual Question Explanation for Course Content Understanding","summary":"  Visual Question Answering (VQA) research seeks to create AI systems to answer\nnatural language questions in images, yet VQA methods often yield overly\nsimplistic and short answers. This paper aims to advance the field by\nintroducing Visual Question Explanation (VQE), which enhances the ability of\nVQA to provide detailed explanations rather than brief responses and address\nthe need for more complex interaction with visual content. We first created an\nMLVQE dataset from a 14-week streamed video machine learning course, including\n885 slide images, 110,407 words of transcripts, and 9,416 designed\nquestion-answer (QA) pairs. Next, we proposed a novel SparrowVQE, a small 3\nbillion parameters multimodal model. We trained our model with a three-stage\ntraining mechanism consisting of multimodal pre-training (slide images and\ntranscripts feature alignment), instruction tuning (tuning the pre-trained\nmodel with transcripts and QA pairs), and domain fine-tuning (fine-tuning slide\nimage and QA pairs). Eventually, our SparrowVQE can understand and connect\nvisual information using the SigLIP model with transcripts using the Phi-2\nlanguage model with an MLP adapter. Experimental results demonstrate that our\nSparrowVQE achieves better performance in our developed MLVQE dataset and\noutperforms state-of-the-art methods in the other five benchmark VQA datasets.\nThe source code is available at\n\\url{https://github.com/YoushanZhang/SparrowVQE}.\n","authors":["Jialu Li","Manish Kumar Thota","Ruslan Gokhman","Radek Holik","Youshan Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07516v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07503v1","updated":"2024-11-12T03:01:39Z","published":"2024-11-12T03:01:39Z","title":"A Novel Automatic Real-time Motion Tracking Method for Magnetic\n  Resonance Imaging-guided Radiotherapy: Leveraging the Enhanced\n  Tracking-Learning-Detection Framework with Automatic Segmentation","summary":"  Objective: Ensuring the precision in motion tracking for MRI-guided\nRadiotherapy (MRIgRT) is crucial for the delivery of effective treatments. This\nstudy refined the motion tracking accuracy in MRIgRT through the innovation of\nan automatic real-time tracking method, leveraging an enhanced\nTracking-Learning-Detection (ETLD) framework coupled with automatic\nsegmentation. Methods: We developed a novel MRIgRT motion tracking method by\nintegrating two primary methods: the ETLD framework and an improved Chan-Vese\nmodel (ICV), named ETLD+ICV. The TLD framework was upgraded to suit real-time\ncine MRI, including advanced image preprocessing, no-reference image quality\nassessment, an enhanced median-flow tracker, and a refined detector with\ndynamic search region adjustments. Additionally, ICV was combined for precise\ncoverage of the target volume, which refined the segmented region frame by\nframe using tracking results, with key parameters optimized. Tested on 3.5D MRI\nscans from 10 patients with liver metastases, our method ensures precise\ntracking and accurate segmentation vital for MRIgRT. Results: An evaluation of\n106,000 frames across 77 treatment fractions revealed sub-millimeter tracking\nerrors of less than 0.8mm, with over 99% precision and 98% recall for all\nsubjects, underscoring the robustness and efficacy of the ETLD. Moreover, the\nETLD+ICV yielded a dice global score of more than 82% for all subjects,\ndemonstrating the proposed method's extensibility and precise target volume\ncoverage. Conclusions: This study successfully developed an automatic real-time\nmotion tracking method for MRIgRT that markedly surpasses current methods. The\nnovel method not only delivers exceptional precision in tracking and\nsegmentation but also demonstrates enhanced adaptability to clinical demands,\npositioning it as an indispensable asset in the quest to augment the efficacy\nof radiotherapy treatments.\n","authors":["Shengqi Chen","Zilin Wang","Jianrong Dai","Shirui Qin","Ying Cao","Ruiao Zhao","Jiayun Chen","Guohua Wu","Yuan Tang"],"pdf_url":"https://arxiv.org/pdf/2411.07503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.15364v2","updated":"2024-11-12T03:00:07Z","published":"2023-12-23T22:27:40Z","title":"WildScenes: A Benchmark for 2D and 3D Semantic Segmentation in\n  Large-scale Natural Environments","summary":"  Recent progress in semantic scene understanding has primarily been enabled by\nthe availability of semantically annotated bi-modal (camera and LiDAR) datasets\nin urban environments. However, such annotated datasets are also needed for\nnatural, unstructured environments to enable semantic perception for\napplications, including conservation, search and rescue, environment\nmonitoring, and agricultural automation. Therefore, we introduce $WildScenes$,\na bi-modal benchmark dataset consisting of multiple large-scale, sequential\ntraversals in natural environments, including semantic annotations in\nhigh-resolution 2D images and dense 3D LiDAR point clouds, and accurate 6-DoF\npose information. The data is (1) trajectory-centric with accurate localization\nand globally aligned point clouds, (2) calibrated and synchronized to support\nbi-modal training and inference, and (3) containing different natural\nenvironments over 6 months to support research on domain adaptation. Our 3D\nsemantic labels are obtained via an efficient, automated process that transfers\nthe human-annotated 2D labels from multiple views into 3D point cloud\nsequences, thus circumventing the need for expensive and time-consuming human\nannotation in 3D. We introduce benchmarks on 2D and 3D semantic segmentation\nand evaluate a variety of recent deep-learning techniques to demonstrate the\nchallenges in semantic segmentation in natural environments. We propose\ntrain-val-test splits for standard benchmarks as well as domain adaptation\nbenchmarks and utilize an automated split generation technique to ensure the\nbalance of class label distributions. The $WildScenes$ benchmark webpage is\nhttps://csiro-robotics.github.io/WildScenes, and the data is publicly available\nat https://data.csiro.au/collection/csiro:61541 .\n","authors":["Kavisha Vidanapathirana","Joshua Knights","Stephen Hausler","Mark Cox","Milad Ramezani","Jason Jooste","Ethan Griffiths","Shaheer Mohamed","Sridha Sridharan","Clinton Fookes","Peyman Moghadam"],"pdf_url":"https://arxiv.org/pdf/2312.15364v2.pdf","comment":"Accepted in the The International Journal of Robotics Research (IJRR)"},{"id":"http://arxiv.org/abs/2411.07501v1","updated":"2024-11-12T02:57:15Z","published":"2024-11-12T02:57:15Z","title":"LAUREL: Learned Augmented Residual Layer","summary":"  One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters.\n","authors":["Gaurav Menghani","Ravi Kumar","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07501v1.pdf","comment":"Accepted at the 2nd Efficient Systems for Foundation Models Workshop\n  at the International Conference on Machine Learning (ICML) 2024"},{"id":"http://arxiv.org/abs/2411.07483v1","updated":"2024-11-12T02:12:41Z","published":"2024-11-12T02:12:41Z","title":"Quantifying Knowledge Distillation Using Partial Information\n  Decomposition","summary":"  Knowledge distillation provides an effective method for deploying complex\nmachine learning models in resource-constrained environments. It typically\ninvolves training a smaller student model to emulate either the probabilistic\noutputs or the internal feature representations of a larger teacher model. By\ndoing so, the student model often achieves substantially better performance on\na downstream task compared to when it is trained independently. Nevertheless,\nthe teacher's internal representations can also encode noise or additional\ninformation that may not be relevant to the downstream task. This observation\nmotivates our primary question: What are the information-theoretic limits of\nknowledge transfer? To this end, we leverage a body of work in information\ntheory called Partial Information Decomposition (PID) to quantify the\ndistillable and distilled knowledge of a teacher's representation corresponding\nto a given student and a downstream task. Moreover, we demonstrate that this\nmetric can be practically used in distillation to address challenges caused by\nthe complexity gap between the teacher and the student representations.\n","authors":["Pasan Dissanayake","Faisal Hamman","Barproda Halder","Ilia Sucholutsky","Qiuyi Zhang","Sanghamitra Dutta"],"pdf_url":"https://arxiv.org/pdf/2411.07483v1.pdf","comment":"Accepted at NeurIPS 2024 Machine Learning and Compression Workshop"},{"id":"http://arxiv.org/abs/2406.06535v3","updated":"2024-11-12T02:10:13Z","published":"2024-04-23T03:11:08Z","title":"Utilizing Graph Generation for Enhanced Domain Adaptive Object Detection","summary":"  The problem of Domain Adaptive in the field of Object Detection involves the\ntransfer of object detection models from labeled source domains to unannotated\ntarget domains. Recent advancements in this field aim to address domain\ndiscrepancies by aligning pixel-pairs across domains within a non-Euclidean\ngraphical space, thereby minimizing semantic distribution variance. Despite\ntheir remarkable achievements, these methods often use coarse semantic\nrepresentations to model graphs, mainly due to ignoring non-informative\nelements and failing to focus on precise semantic alignment. Additionally, the\ngeneration of coarse graphs inherently introduces abnormal nodes, posing\nchallenges and potentially biasing domain adaptation outcomes. Consequently, we\npropose a framework, which utilizes the Graph Generation to enhance the quality\nof DAOD (\\method{}). Specifically, we introduce a Node Refinement module that\nutilizes a memory bank to reconstruct noisy sampled nodes while applying\ncontrastive regularization to noisy features. To enhance semantic alignment, we\npropose separating domain-specific styles from category invariance encoded\nwithin graph covariances, which allows us to selectively remove domain-specific\nstyles while preserving category-invariant information, thus facilitating more\naccurate semantic alignment across different domains. Furthermore, we propose a\nGraph Optimization adaptor, leveraging variational inference to mitigate the\nimpact of abnormal nodes. Extensive experimentation across three adaptation\nbenchmarks validates that \\method{} achieves state-of-the-art performance in\nthe task of unsupervised domain adaptation.\n","authors":["Mu Wang"],"pdf_url":"https://arxiv.org/pdf/2406.06535v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07478v1","updated":"2024-11-12T01:51:05Z","published":"2024-11-12T01:51:05Z","title":"GUS-IR: Gaussian Splatting with Unified Shading for Inverse Rendering","summary":"  Recovering the intrinsic physical attributes of a scene from images,\ngenerally termed as the inverse rendering problem, has been a central and\nchallenging task in computer vision and computer graphics. In this paper, we\npresent GUS-IR, a novel framework designed to address the inverse rendering\nproblem for complicated scenes featuring rough and glossy surfaces. This paper\nstarts by analyzing and comparing two prominent shading techniques popularly\nused for inverse rendering, forward shading and deferred shading, effectiveness\nin handling complex materials. More importantly, we propose a unified shading\nsolution that combines the advantages of both techniques for better\ndecomposition. In addition, we analyze the normal modeling in 3D Gaussian\nSplatting (3DGS) and utilize the shortest axis as normal for each particle in\nGUS-IR, along with a depth-related regularization, resulting in improved\ngeometric representation and better shape reconstruction. Furthermore, we\nenhance the probe-based baking scheme proposed by GS-IR to achieve more\naccurate ambient occlusion modeling to better handle indirect illumination.\nExtensive experiments have demonstrated the superior performance of GUS-IR in\nachieving precise intrinsic decomposition and geometric representation,\nsupporting many downstream tasks (such as relighting, retouching) in computer\nvision, graphics, and extended reality.\n","authors":["Zhihao Liang","Hongdong Li","Kui Jia","Kailing Guo","Qi Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07478v1.pdf","comment":"15 pages, 11 figures"},{"id":"http://arxiv.org/abs/2406.07520v3","updated":"2024-11-12T01:45:49Z","published":"2024-06-11T17:50:15Z","title":"Neural Gaffer: Relighting Any Object via Diffusion","summary":"  Single-image relighting is a challenging task that involves reasoning about\nthe complex interplay between geometry, materials, and lighting. Many prior\nmethods either support only specific categories of images, such as portraits,\nor require special capture conditions, like using a flashlight. Alternatively,\nsome methods explicitly decompose a scene into intrinsic components, such as\nnormals and BRDFs, which can be inaccurate or under-expressive. In this work,\nwe propose a novel end-to-end 2D relighting diffusion model, called Neural\nGaffer, that takes a single image of any object and can synthesize an accurate,\nhigh-quality relit image under any novel environmental lighting condition,\nsimply by conditioning an image generator on a target environment map, without\nan explicit scene decomposition. Our method builds on a pre-trained diffusion\nmodel, and fine-tunes it on a synthetic relighting dataset, revealing and\nharnessing the inherent understanding of lighting present in the diffusion\nmodel. We evaluate our model on both synthetic and in-the-wild Internet imagery\nand demonstrate its advantages in terms of generalization and accuracy.\nMoreover, by combining with other generative methods, our model enables many\ndownstream 2D tasks, such as text-based relighting and object insertion. Our\nmodel can also operate as a strong relighting prior for 3D tasks, such as\nrelighting a radiance field.\n","authors":["Haian Jin","Yuan Li","Fujun Luan","Yuanbo Xiangli","Sai Bi","Kai Zhang","Zexiang Xu","Jin Sun","Noah Snavely"],"pdf_url":"https://arxiv.org/pdf/2406.07520v3.pdf","comment":"Project Website: https://neural-gaffer.github.io"},{"id":"http://arxiv.org/abs/2405.14864v3","updated":"2024-11-12T01:31:41Z","published":"2024-05-23T17:59:40Z","title":"Video Diffusion Models are Training-free Motion Interpreter and\n  Controller","summary":"  Video generation primarily aims to model authentic and customized motion\nacross frames, making understanding and controlling the motion a crucial topic.\nMost diffusion-based studies on video motion focus on motion customization with\ntraining-based paradigms, which, however, demands substantial training\nresources and necessitates retraining for diverse models. Crucially, these\napproaches do not explore how video diffusion models encode cross-frame motion\ninformation in their features, lacking interpretability and transparency in\ntheir effectiveness. To answer this question, this paper introduces a novel\nperspective to understand, localize, and manipulate motion-aware features in\nvideo diffusion models. Through analysis using Principal Component Analysis\n(PCA), our work discloses that robust motion-aware feature already exists in\nvideo diffusion models. We present a new MOtion FeaTure (MOFT) by eliminating\ncontent correlation information and filtering motion channels. MOFT provides a\ndistinct set of benefits, including the ability to encode comprehensive motion\ninformation with clear interpretability, extraction without the need for\ntraining, and generalizability across diverse architectures. Leveraging MOFT,\nwe propose a novel training-free video motion control framework. Our method\ndemonstrates competitive performance in generating natural and faithful motion,\nproviding architecture-agnostic insights and applicability in a variety of\ndownstream tasks.\n","authors":["Zeqi Xiao","Yifan Zhou","Shuai Yang","Xingang Pan"],"pdf_url":"https://arxiv.org/pdf/2405.14864v3.pdf","comment":"Accepted by NeurIPS 2024. Project Page:\n  https://xizaoqu.github.io/moft/"},{"id":"http://arxiv.org/abs/2411.07472v1","updated":"2024-11-12T01:17:27Z","published":"2024-11-12T01:17:27Z","title":"Semi-Truths: A Large-Scale Dataset of AI-Augmented Images for Evaluating\n  Robustness of AI-Generated Image detectors","summary":"  Text-to-image diffusion models have impactful applications in art, design,\nand entertainment, yet these technologies also pose significant risks by\nenabling the creation and dissemination of misinformation. Although recent\nadvancements have produced AI-generated image detectors that claim robustness\nagainst various augmentations, their true effectiveness remains uncertain. Do\nthese detectors reliably identify images with different levels of augmentation?\nAre they biased toward specific scenes or data distributions? To investigate,\nwe introduce SEMI-TRUTHS, featuring 27,600 real images, 223,400 masks, and\n1,472,700 AI-augmented images that feature targeted and localized perturbations\nproduced using diverse augmentation techniques, diffusion models, and data\ndistributions. Each augmented image is accompanied by metadata for standardized\nand targeted evaluation of detector robustness. Our findings suggest that\nstate-of-the-art detectors exhibit varying sensitivities to the types and\ndegrees of perturbations, data distributions, and augmentation methods used,\noffering new insights into their performance and limitations. The code for the\naugmentation and evaluation pipeline is available at\nhttps://github.com/J-Kruk/SemiTruths.\n","authors":["Anisha Pal","Julia Kruk","Mansi Phute","Manognya Bhattaram","Diyi Yang","Duen Horng Chau","Judy Hoffman"],"pdf_url":"https://arxiv.org/pdf/2411.07472v1.pdf","comment":"Accepted at NeurIPS 2024 Track Datasets & Benchmarks Track"},{"id":"http://arxiv.org/abs/2404.08926v3","updated":"2024-11-12T01:16:04Z","published":"2024-04-13T08:27:10Z","title":"Diffusion Models Meet Remote Sensing: Principles, Methods, and\n  Perspectives","summary":"  As a newly emerging advance in deep generative models, diffusion models have\nachieved state-of-the-art results in many fields, including computer vision,\nnatural language processing, and molecule design. The remote sensing (RS)\ncommunity has also noticed the powerful ability of diffusion models and quickly\napplied them to a variety of tasks for image processing. Given the rapid\nincrease in research on diffusion models in the field of RS, it is necessary to\nconduct a comprehensive review of existing diffusion model-based RS papers, to\nhelp researchers recognize the potential of diffusion models and provide some\ndirections for further exploration. Specifically, this article first introduces\nthe theoretical background of diffusion models, and then systematically reviews\nthe applications of diffusion models in RS, including image generation,\nenhancement, and interpretation. Finally, the limitations of existing RS\ndiffusion models and worthy research directions for further exploration are\ndiscussed and summarized.\n","authors":["Yidan Liu","Jun Yue","Shaobo Xia","Pedram Ghamisi","Weiying Xie","Leyuan Fang"],"pdf_url":"https://arxiv.org/pdf/2404.08926v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07463v1","updated":"2024-11-12T00:54:26Z","published":"2024-11-12T00:54:26Z","title":"MSEG-VCUQ: Multimodal SEGmentation with Enhanced Vision Foundation\n  Models, Convolutional Neural Networks, and Uncertainty Quantification for\n  High-Speed Video Phase Detection Data","summary":"  Purpose: High-speed video (HSV) phase detection (PD) segmentation is vital in\nnuclear reactors, chemical processing, and electronics cooling for detecting\nvapor, liquid, and microlayer phases. Traditional segmentation models face\npixel-level accuracy and generalization issues in multimodal data. MSEG-VCUQ\nintroduces VideoSAM, a hybrid framework leveraging convolutional neural\nnetworks (CNNs) and transformer-based vision models to enhance segmentation\naccuracy and generalizability across complex multimodal PD tasks. Methods:\nVideoSAM combines U-Net CNN and the Segment Anything Model (SAM) for advanced\nfeature extraction and segmentation across diverse HSV PD modalities, spanning\nfluids like water, FC-72, nitrogen, and argon under varied heat flux\nconditions. The framework also incorporates uncertainty quantification (UQ) to\nassess pixel-based discretization errors, delivering reliable metrics such as\ncontact line density and dry area fraction under experimental conditions.\nResults: VideoSAM outperforms SAM and modality-specific CNN models in\nsegmentation accuracy, excelling in environments with complex phase boundaries,\noverlapping bubbles, and dynamic liquid-vapor interactions. Its hybrid\narchitecture supports cross-dataset generalization, adapting effectively to\nvarying modalities. The UQ module provides accurate error estimates, enhancing\nthe reliability of segmentation outputs for advanced HSV PD research.\nConclusion: MSEG-VCUQ, via VideoSAM, offers a robust solution for HSV PD\nsegmentation, addressing previous limitations with advanced deep learning and\nUQ techniques. The open-source datasets and tools introduced enable scalable,\nprecise, and adaptable segmentation for multimodal PD datasets, supporting\nadvancements in HSV analysis and autonomous experimentation.\n","authors":["Chika Maduabuchi","Ericmoore Jossou","Matteo Bucci"],"pdf_url":"https://arxiv.org/pdf/2411.07463v1.pdf","comment":"Under Review in EAAI"},{"id":"http://arxiv.org/abs/2411.07462v1","updated":"2024-11-12T00:53:20Z","published":"2024-11-12T00:53:20Z","title":"MureObjectStitch: Multi-reference Image Composition","summary":"  Generative image composition aims to regenerate the given foreground object\nin the background image to produce a realistic composite image. In this work,\nwe propose an effective finetuning strategy for generative image composition\nmodel, in which we finetune a pretrained model using one or more images\ncontaining the same foreground object. Moreover, we propose a multi-reference\nstrategy, which allows the model to take in multiple reference images of the\nforeground object. The experiments on MureCOM dataset verify the effectiveness\nof our method.\n","authors":["Jiaxuan Chen","Bo Zhang","Li Niu"],"pdf_url":"https://arxiv.org/pdf/2411.07462v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07461v1","updated":"2024-11-12T00:52:52Z","published":"2024-11-12T00:52:52Z","title":"BLIP3-KALE: Knowledge Augmented Large-Scale Dense Captions","summary":"  We introduce BLIP3-KALE, a dataset of 218 million image-text pairs that\nbridges the gap between descriptive synthetic captions and factual web-scale\nalt-text. KALE augments synthetic dense image captions with web-scale alt-text\nto generate factually grounded image captions. Our two-stage approach leverages\nlarge vision-language models and language models to create knowledge-augmented\ncaptions, which are then used to train a specialized VLM for scaling up the\ndataset. We train vision-language models on KALE and demonstrate improvements\non vision-language tasks. Our experiments show the utility of KALE for training\nmore capable and knowledgeable multimodal models. We release the KALE dataset\nat https://huggingface.co/datasets/Salesforce/blip3-kale\n","authors":["Anas Awadalla","Le Xue","Manli Shu","An Yan","Jun Wang","Senthil Purushwalkam","Sheng Shen","Hannah Lee","Oscar Lo","Jae Sung Park","Etash Guha","Silvio Savarese","Ludwig Schmidt","Yejin Choi","Caiming Xiong","Ran Xu"],"pdf_url":"https://arxiv.org/pdf/2411.07461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.03190v2","updated":"2024-11-12T00:37:33Z","published":"2024-10-04T07:05:16Z","title":"Tuning Timestep-Distilled Diffusion Model Using Pairwise Sample\n  Optimization","summary":"  Recent advancements in timestep-distilled diffusion models have enabled\nhigh-quality image generation that rivals non-distilled multi-step models, but\nwith significantly fewer inference steps. While such models are attractive for\napplications due to the low inference cost and latency, fine-tuning them with a\nnaive diffusion objective would result in degraded and blurry outputs. An\nintuitive alternative is to repeat the diffusion distillation process with a\nfine-tuned teacher model, which produces good results but is cumbersome and\ncomputationally intensive; the distillation training usually requires magnitude\nhigher of training compute compared to fine-tuning for specific image styles.\nIn this paper, we present an algorithm named pairwise sample optimization\n(PSO), which enables the direct fine-tuning of an arbitrary timestep-distilled\ndiffusion model. PSO introduces additional reference images sampled from the\ncurrent time-step distilled model, and increases the relative likelihood margin\nbetween the training images and reference images. This enables the model to\nretain its few-step generation ability, while allowing for fine-tuning of its\noutput distribution. We also demonstrate that PSO is a generalized formulation\nwhich can be flexibly extended to both offline-sampled and online-sampled\npairwise data, covering various popular objectives for diffusion model\npreference optimization. We evaluate PSO in both preference optimization and\nother fine-tuning tasks, including style transfer and concept customization. We\nshow that PSO can directly adapt distilled models to human-preferred generation\nwith both offline and online-generated pairwise preference image data. PSO also\ndemonstrates effectiveness in style transfer and concept customization by\ndirectly tuning timestep-distilled diffusion models.\n","authors":["Zichen Miao","Zhengyuan Yang","Kevin Lin","Ze Wang","Zicheng Liu","Lijuan Wang","Qiang Qiu"],"pdf_url":"https://arxiv.org/pdf/2410.03190v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.02504v3","updated":"2024-11-12T00:21:00Z","published":"2024-05-03T22:33:46Z","title":"Functional Imaging Constrained Diffusion for Brain PET Synthesis from\n  Structural MRI","summary":"  Magnetic resonance imaging (MRI) and positron emission tomography (PET) are\nincreasingly used in multimodal analysis of neurodegenerative disorders. While\nMRI is broadly utilized in clinical settings, PET is less accessible. Many\nstudies have attempted to use deep generative models to synthesize PET from MRI\nscans. However, they often suffer from unstable training and inadequately\npreserve brain functional information conveyed by PET. To this end, we propose\na functional imaging constrained diffusion (FICD) framework for 3D brain PET\nimage synthesis with paired structural MRI as input condition, through a new\nconstrained diffusion model (CDM). The FICD introduces noise to PET and then\nprogressively removes it with CDM, ensuring high output fidelity throughout a\nstable training phase. The CDM learns to predict denoised PET with a functional\nimaging constraint introduced to ensure voxel-wise alignment between each\ndenoised PET and its ground truth. Quantitative and qualitative analyses\nconducted on 293 subjects with paired T1-weighted MRI and\n18F-fluorodeoxyglucose (FDG)-PET scans suggest that FICD achieves superior\nperformance in generating FDG-PET data compared to state-of-the-art methods. We\nfurther validate the effectiveness of the proposed FICD on data from a total of\n1,262 subjects through three downstream tasks, with experimental results\nsuggesting its utility and generalizability.\n","authors":["Minhui Yu","Mengqi Wu","Ling Yue","Andrea Bozoki","Mingxia Liu"],"pdf_url":"https://arxiv.org/pdf/2405.02504v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07449v1","updated":"2024-11-12T00:20:11Z","published":"2024-11-12T00:20:11Z","title":"Tracing the Roots: Leveraging Temporal Dynamics in Diffusion\n  Trajectories for Origin Attribution","summary":"  Diffusion models have revolutionized image synthesis, garnering significant\nresearch interest in recent years. Diffusion is an iterative algorithm in which\nsamples are generated step-by-step, starting from pure noise. This process\nintroduces the notion of diffusion trajectories, i.e., paths from the standard\nGaussian distribution to the target image distribution. In this context, we\nstudy discriminative algorithms operating on these trajectories. Specifically,\ngiven a pre-trained diffusion model, we consider the problem of classifying\nimages as part of the training dataset, generated by the model or originating\nfrom an external source. Our approach demonstrates the presence of patterns\nacross steps that can be leveraged for classification. We also conduct ablation\nstudies, which reveal that using higher-order gradient features to characterize\nthe trajectories leads to significant performance gains and more robust\nalgorithms.\n","authors":["Andreas Floros","Seyed-Mohsen Moosavi-Dezfooli","Pier Luigi Dragotti"],"pdf_url":"https://arxiv.org/pdf/2411.07449v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.13632v3","updated":"2024-11-12T00:12:39Z","published":"2023-12-21T07:48:54Z","title":"TraceFL: Interpretability-Driven Debugging in Federated Learning via\n  Neuron Provenance","summary":"  In Federated Learning, clients train models on local data and send updates to\na central server, which aggregates them into a global model using a fusion\nalgorithm. This collaborative yet privacy-preserving training comes at a\ncost--FL developers face significant challenges in attributing global model\npredictions to specific clients. Localizing responsible clients is a crucial\nstep towards (a) excluding clients primarily responsible for incorrect\npredictions and (b) encouraging clients who contributed high-quality models to\ncontinue participating in the future. Existing ML explainability approaches are\ninherently inapplicable as they are designed for single-model, centralized\ntraining.\n  We introduce TraceFL, a fine-grained neuron provenance capturing mechanism\nthat identifies clients responsible for the global model's prediction by\ntracking the flow of information from individual clients to the global model.\nSince inference on different inputs activates a different set of neurons of the\nglobal model, TraceFL dynamically quantifies the significance of the global\nmodel's neurons in a given prediction. It then selectively picks a slice of the\nmost crucial neurons in the global model and maps them to the corresponding\nneurons in every participating client to determine each client's contribution,\nultimately localizing the responsible client. We evaluate TraceFL on six\ndatasets, including two real-world medical imaging datasets and four neural\nnetworks, including advanced models such as GPT. TraceFL achieves 99% accuracy\nin localizing the responsible client in FL tasks spanning both image and text\nclassification tasks. At a time when state-of-the-art ML debugging approaches\nare mostly domain-specific (e.g., image classification only), TraceFL is the\nfirst technique to enable highly accurate automated reasoning across a wide\nrange of FL applications.\n","authors":["Waris Gill","Ali Anwar","Muhammad Ali Gulzar"],"pdf_url":"https://arxiv.org/pdf/2312.13632v3.pdf","comment":"Accepted at 2025 IEEE/ACM 47th International Conference on Software\n  Engineering (ICSE)"},{"id":"http://arxiv.org/abs/2411.07445v1","updated":"2024-11-12T00:07:16Z","published":"2024-11-12T00:07:16Z","title":"All-in-one Weather-degraded Image Restoration via Adaptive\n  Degradation-aware Self-prompting Model","summary":"  Existing approaches for all-in-one weather-degraded image restoration suffer\nfrom inefficiencies in leveraging degradation-aware priors, resulting in\nsub-optimal performance in adapting to different weather conditions. To this\nend, we develop an adaptive degradation-aware self-prompting model (ADSM) for\nall-in-one weather-degraded image restoration. Specifically, our model employs\nthe contrastive language-image pre-training model (CLIP) to facilitate the\ntraining of our proposed latent prompt generators (LPGs), which represent three\ntypes of latent prompts to characterize the degradation type, degradation\nproperty and image caption. Moreover, we integrate the acquired\ndegradation-aware prompts into the time embedding of diffusion model to improve\ndegradation perception. Meanwhile, we employ the latent caption prompt to guide\nthe reverse sampling process using the cross-attention mechanism, thereby\nguiding the accurate image reconstruction. Furthermore, to accelerate the\nreverse sampling procedure of diffusion model and address the limitations of\nfrequency perception, we introduce a wavelet-oriented noise estimating network\n(WNE-Net). Extensive experiments conducted on eight publicly available datasets\ndemonstrate the effectiveness of our proposed approach in both task-specific\nand all-in-one applications.\n","authors":["Yuanbo Wen","Tao Gao","Ziqi Li","Jing Zhang","Kaihao Zhang","Ting Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07445v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2304.04918v2","updated":"2024-11-12T15:42:42Z","published":"2023-04-11T01:10:49Z","title":"Explicit and Implicit Semantic Ranking Framework","summary":"  The core challenge in numerous real-world applications is to match an inquiry\nto the best document from a mutable and finite set of candidates. Existing\nindustry solutions, especially latency-constrained services, often rely on\nsimilarity algorithms that sacrifice quality for speed. In this paper we\nintroduce a generic semantic learning-to-rank framework, Self-training Semantic\nCross-attention Ranking (sRank). This transformer-based framework uses linear\npairwise loss with mutable training batch sizes and achieves quality gains and\nhigh efficiency, and has been applied effectively to show gains on two industry\ntasks at Microsoft over real-world large-scale data sets: Smart Reply (SR) and\nAmbient Clinical Intelligence (ACI). In Smart Reply, sRank assists live\ncustomers with technical support by selecting the best reply from predefined\nsolutions based on consumer and support agent messages. It achieves 11.7% gain\nin offline top-one accuracy on the SR task over the previous system, and has\nenabled 38.7% time reduction in composing messages in telemetry recorded since\nits general release in January 2021. In the ACI task, sRank selects relevant\nhistorical physician templates that serve as guidance for a text summarization\nmodel to generate higher quality medical notes. It achieves 35.5% top-one\naccuracy gain, along with 46% relative ROUGE-L gain in generated medical notes.\n","authors":["Xiaofeng Zhu","Thomas Lin","Vishal Anand","Matthew Calderwood","Eric Clausen-Brown","Gord Lueck","Wen-wai Yim","Cheng Wu"],"pdf_url":"https://arxiv.org/pdf/2304.04918v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05508v2","updated":"2024-11-12T15:36:04Z","published":"2024-11-08T12:08:17Z","title":"An Early FIRST Reproduction and Improvements to Single-Token Decoding\n  for Fast Listwise Reranking","summary":"  Recent advances have demonstrated that large language models (LLMs) excel as\nlistwise rerankers, but their high computational demands remain a barrier to\nwidespread adoption. Further, the traditional language modeling (LM) objective\nis not ideally suited for reranking tasks. FIRST is a novel approach that\naddresses these challenges by integrating a learning-to-rank objective and\nleveraging the logits of only the first generated token, thereby significantly\nreducing inference latency compared to traditional LLM rerankers. In this\nstudy, we extend the evaluation of FIRST to the TREC Deep Learning datasets\n(DL19-22), validating its robustness across diverse domains. We investigate the\ninfluence of different first-stage retrievers on FIRST rerankers, observing\ndiminishing returns and patterns consistent with traditional LLM rerankers.\nThrough applying the FIRST objective to a broader range of backbone models, we\nachieve effectiveness surpassing the original implementation. Our experiments\nconfirm that fast reranking with single-token logits does not compromise\nout-of-domain reranking quality. To better quantify the computational savings\nin the original study, we measure and compare latency to find a 21%-42% gain\nacross various models and benchmarks. Moreover, while LM training implicitly\nimproves zero-shot single-token reranking, our experiments also raise questions\nabout whether LM pre-training may hinder subsequent fine-tuning with the FIRST\nobjective. These findings pave the way for more efficient and effective\nlistwise reranking in future applications.\n","authors":["Zijian Chen","Ronak Pradeep","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2411.05508v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07820v1","updated":"2024-11-12T14:12:45Z","published":"2024-11-12T14:12:45Z","title":"Query Optimization for Parametric Knowledge Refinement in\n  Retrieval-Augmented Large Language Models","summary":"  We introduce the \\textit{Extract-Refine-Retrieve-Read} (ERRR) framework, a\nnovel approach designed to bridge the pre-retrieval information gap in\nRetrieval-Augmented Generation (RAG) systems through query optimization\ntailored to meet the specific knowledge requirements of Large Language Models\n(LLMs). Unlike conventional query optimization techniques used in RAG, the ERRR\nframework begins by extracting parametric knowledge from LLMs, followed by\nusing a specialized query optimizer for refining these queries. This process\nensures the retrieval of only the most pertinent information essential for\ngenerating accurate responses. Moreover, to enhance flexibility and reduce\ncomputational costs, we propose a trainable scheme for our pipeline that\nutilizes a smaller, tunable model as the query optimizer, which is refined\nthrough knowledge distillation from a larger teacher model. Our evaluations on\nvarious question-answering (QA) datasets and with different retrieval systems\nshow that ERRR consistently outperforms existing baselines, proving to be a\nversatile and cost-effective module for improving the utility and accuracy of\nRAG systems.\n","authors":["Youan Cong","Cheng Wang","Pritom Saha Akash","Kevin Chen-Chuan Chang"],"pdf_url":"https://arxiv.org/pdf/2411.07820v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18480v2","updated":"2024-11-12T13:54:25Z","published":"2024-03-27T11:49:58Z","title":"Content-Based Collaborative Generation for Recommender Systems","summary":"  Generative models have emerged as a promising utility to enhance recommender\nsystems. It is essential to model both item content and user-item collaborative\ninteractions in a unified generative framework for better recommendation.\nAlthough some existing large language model (LLM)-based methods contribute to\nfusing content information and collaborative signals, they fundamentally rely\non textual language generation, which is not fully aligned with the\nrecommendation task. How to integrate content knowledge and collaborative\ninteraction signals in a generative framework tailored for item recommendation\nis still an open research challenge.\n  In this paper, we propose content-based collaborative generation for\nrecommender systems, namely ColaRec. ColaRec is a sequence-to-sequence\nframework which is tailored for directly generating the recommended item\nidentifier. Precisely, the input sequence comprises data pertaining to the\nuser's interacted items, and the output sequence represents the generative\nidentifier (GID) for the suggested item. To model collaborative signals, the\nGIDs are constructed from a pretrained collaborative filtering model, and the\nuser is represented as the content aggregation of interacted items. To this\nend, ColaRec captures both collaborative signals and content information in a\nunified framework. Then an item indexing task is proposed to conduct the\nalignment between the content-based semantic space and the interaction-based\ncollaborative space. Besides, a contrastive loss is further introduced to\nensure that items with similar collaborative GIDs have similar content\nrepresentations. To verify the effectiveness of ColaRec, we conduct experiments\non four benchmark datasets. Empirical results demonstrate the superior\nperformance of ColaRec.\n","authors":["Yidan Wang","Zhaochun Ren","Weiwei Sun","Jiyuan Yang","Zhixiang Liang","Xin Chen","Ruobing Xie","Su Yan","Xu Zhang","Pengjie Ren","Zhumin Chen","Xin Xin"],"pdf_url":"https://arxiv.org/pdf/2403.18480v2.pdf","comment":"Accepted by CIKM 2024; GitHub:\n  https://github.com/Junewang0614/ColaRec"},{"id":"http://arxiv.org/abs/2411.07770v1","updated":"2024-11-12T13:06:16Z","published":"2024-11-12T13:06:16Z","title":"A Theoretical Analysis of Recommendation Loss Functions under Negative\n  Sampling","summary":"  Recommender Systems (RSs) are pivotal in diverse domains such as e-commerce,\nmusic streaming, and social media. This paper conducts a comparative analysis\nof prevalent loss functions in RSs: Binary Cross-Entropy (BCE), Categorical\nCross-Entropy (CCE), and Bayesian Personalized Ranking (BPR). Exploring the\nbehaviour of these loss functions across varying negative sampling settings, we\nreveal that BPR and CCE are equivalent when one negative sample is used.\nAdditionally, we demonstrate that all losses share a common global minimum.\nEvaluation of RSs mainly relies on ranking metrics known as Normalized\nDiscounted Cumulative Gain (NDCG) and Mean Reciprocal Rank (MRR). We produce\nbounds of the different losses for negative sampling settings to establish a\nprobabilistic lower bound for NDCG. We show that the BPR bound on NDCG is\nweaker than that of BCE, contradicting the common assumption that BPR is\nsuperior to BCE in RSs training. Experiments on five datasets and four models\nempirically support these theoretical findings. Our code is available at\n\\url{https://anonymous.4open.science/r/recsys_losses} .\n","authors":["Giulia Di Teodoro","Federico Siciliano","Nicola Tonellotto","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2411.07770v1.pdf","comment":"main paper 8 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.07739v1","updated":"2024-11-12T12:03:57Z","published":"2024-11-12T12:03:57Z","title":"Unlocking Legal Knowledge with Multi-Layered Embedding-Based Retrieval","summary":"  This work addresses the challenge of capturing the complexities of legal\nknowledge by proposing a multi-layered embedding-based retrieval method for\nlegal and legislative texts. Creating embeddings not only for individual\narticles but also for their components (paragraphs, clauses) and structural\ngroupings (books, titles, chapters, etc), we seek to capture the subtleties of\nlegal information through the use of dense vectors of embeddings, representing\nit at varying levels of granularity. Our method meets various information needs\nby allowing the Retrieval Augmented Generation system to provide accurate\nresponses, whether for specific segments or entire sections, tailored to the\nuser's query. We explore the concepts of aboutness, semantic chunking, and\ninherent hierarchy within legal texts, arguing that this method enhances the\nlegal information retrieval. Despite the focus being on Brazil's legislative\nmethods and the Brazilian Constitution, which follow a civil law tradition, our\nfindings should in principle be applicable across different legal systems,\nincluding those adhering to common law traditions. Furthermore, the principles\nof the proposed method extend beyond the legal domain, offering valuable\ninsights for organizing and retrieving information in any field characterized\nby information encoded in hierarchical text.\n","authors":["Jo√£o Alberto de Oliveira Lima"],"pdf_url":"https://arxiv.org/pdf/2411.07739v1.pdf","comment":"27 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.07658v1","updated":"2024-11-12T09:19:32Z","published":"2024-11-12T09:19:32Z","title":"Advancing Sustainability via Recommender Systems: A Survey","summary":"  Human behavioral patterns and consumption paradigms have emerged as pivotal\ndeterminants in environmental degradation and climate change, with quotidian\ndecisions pertaining to transportation, energy utilization, and resource\nconsumption collectively precipitating substantial ecological impacts.\nRecommender systems, which generate personalized suggestions based on user\npreferences and historical interaction data, exert considerable influence on\nindividual behavioral trajectories. However, conventional recommender systems\npredominantly optimize for user engagement and economic metrics, inadvertently\nneglecting the environmental and societal ramifications of their\nrecommendations, potentially catalyzing over-consumption and reinforcing\nunsustainable behavioral patterns. Given their instrumental role in shaping\nuser decisions, there exists an imperative need for sustainable recommender\nsystems that incorporate sustainability principles to foster eco-conscious and\nsocially responsible choices. This comprehensive survey addresses this critical\nresearch gap by presenting a systematic analysis of sustainable recommender\nsystems. As these systems can simultaneously advance multiple sustainability\nobjectives--including resource conservation, sustainable consumer behavior, and\nsocial impact enhancement--examining their implementations across distinct\napplication domains provides a more rigorous analytical framework. Through a\nmethodological analysis of domain-specific implementations encompassing\ntransportation, food, buildings, and auxiliary sectors, we can better elucidate\nhow these systems holistically advance sustainability objectives while\naddressing sector-specific constraints and opportunities. Moreover, we\ndelineate future research directions for evolving recommender systems beyond\nsustainability advocacy toward fostering environmental resilience and social\nconsciousness in society.\n","authors":["Xin Zhou","Lei Zhang","Honglei Zhang","Yixin Zhang","Xiaoxiong Zhang","Jie Zhang","Zhiqi Shen"],"pdf_url":"https://arxiv.org/pdf/2411.07658v1.pdf","comment":"20pages, 10 figures. Working paper: https://github.com/enoche/SusRec"},{"id":"http://arxiv.org/abs/2404.13812v4","updated":"2024-11-12T07:44:20Z","published":"2024-04-22T01:16:11Z","title":"A Comparative Study on Enhancing Prediction in Social Network\n  Advertisement through Data Augmentation","summary":"  In the ever-evolving landscape of social network advertising, the volume and\naccuracy of data play a critical role in the performance of predictive models.\nHowever, the development of robust predictive algorithms is often hampered by\nthe limited size and potential bias present in real-world datasets. This study\npresents and explores a generative augmentation framework of social network\nadvertising data. Our framework explores three generative models for data\naugmentation - Generative Adversarial Networks (GANs), Variational Autoencoders\n(VAEs), and Gaussian Mixture Models (GMMs) - to enrich data availability and\ndiversity in the context of social network advertising analytics effectiveness.\nBy performing synthetic extensions of the feature space, we find that through\ndata augmentation, the performance of various classifiers has been\nquantitatively improved. Furthermore, we compare the relative performance gains\nbrought by each data augmentation technique, providing insights for\npractitioners to select appropriate techniques to enhance model performance.\nThis paper contributes to the literature by showing that synthetic data\naugmentation alleviates the limitations imposed by small or imbalanced datasets\nin the field of social network advertising. At the same time, this article also\nprovides a comparative perspective on the practicality of different data\naugmentation methods, thereby guiding practitioners to choose appropriate\ntechniques to enhance model performance.\n","authors":["Qikai Yang","Panfeng Li","Xinhe Xu","Zhicheng Ding","Wenjing Zhou","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13812v4.pdf","comment":"Accepted by 2024 4th International Conference on Machine Learning and\n  Intelligent Systems Engineering (MLISE)"},{"id":"http://arxiv.org/abs/2411.07589v1","updated":"2024-11-12T06:58:03Z","published":"2024-11-12T06:58:03Z","title":"Overhead-free User-side Recommender Systems","summary":"  Traditionally, recommendation algorithms have been designed for service\ndevelopers. But recently, a new paradigm called user-side recommender systems\nhas been proposed. User-side recommender systems are built and used by end\nusers, in sharp contrast to traditional provider-side recommender systems. Even\nif the official recommender system offered by the provider is not fair, end\nusers can create and enjoy their own user-side recommender systems by\nthemselves. Although the concept of user-side recommender systems is\nattractive, the problem is they require tremendous communication costs between\nthe user and the official system. Even the most efficient user-side recommender\nsystems require about 5 times more costs than provider-side recommender\nsystems. Such high costs hinder the adoption of user-side recommender systems.\nIn this paper, we propose overhead-free user-side recommender systems,\nRecCycle, which realizes user-side recommender systems without any\ncommunication overhead. The main idea of RecCycle is to recycle past\nrecommendation results offered by the provider's recommender systems. The\ningredients of RecCycle can be retrieved ``for free,'' and it greatly reduces\nthe cost of user-side recommendations. In the experiments, we confirm that\nRecCycle performs as well as state-of-the-art user-side recommendation\nalgorithms while RecCycle reduces costs significantly.\n","authors":["Ryoma Sato"],"pdf_url":"https://arxiv.org/pdf/2411.07589v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2208.09864,\n  arXiv:2403.15757"},{"id":"http://arxiv.org/abs/2411.07569v1","updated":"2024-11-12T06:03:47Z","published":"2024-11-12T06:03:47Z","title":"Towards Automated Model Design on Recommender Systems","summary":"  The increasing popularity of deep learning models has created new\nopportunities for developing AI-based recommender systems. Designing\nrecommender systems using deep neural networks requires careful architecture\ndesign, and further optimization demands extensive co-design efforts on jointly\noptimizing model architecture and hardware. Design automation, such as\nAutomated Machine Learning (AutoML), is necessary to fully exploit the\npotential of recommender model design, including model choices and\nmodel-hardware co-design strategies. We introduce a novel paradigm that\nutilizes weight sharing to explore abundant solution spaces. Our paradigm\ncreates a large supernet to search for optimal architectures and co-design\nstrategies to address the challenges of data multi-modality and heterogeneity\nin the recommendation domain. From a model perspective, the supernet includes a\nvariety of operators, dense connectivity, and dimension search options. From a\nco-design perspective, it encompasses versatile Processing-In-Memory (PIM)\nconfigurations to produce hardware-efficient models. Our solution space's\nscale, heterogeneity, and complexity pose several challenges, which we address\nby proposing various techniques for training and evaluating the supernet. Our\ncrafted models show promising results on three Click-Through Rates (CTR)\nprediction benchmarks, outperforming both manually designed and AutoML-crafted\nmodels with state-of-the-art performance when focusing solely on architecture\nsearch. From a co-design perspective, we achieve 2x FLOPs efficiency, 1.8x\nenergy efficiency, and 1.5x performance improvements in recommender models.\n","authors":["Tunhou Zhang","Dehua Cheng","Yuchen He","Zhengxing Chen","Xiaoliang Dai","Liang Xiong","Yudong Liu","Feng Cheng","Yufan Cao","Feng Yan","Hai Li","Yiran Chen","Wei Wen"],"pdf_url":"https://arxiv.org/pdf/2411.07569v1.pdf","comment":"Accepted in ACM Transactions on Recommender Systems. arXiv admin\n  note: substantial text overlap with arXiv:2207.07187"},{"id":"http://arxiv.org/abs/2411.07508v1","updated":"2024-11-12T03:05:03Z","published":"2024-11-12T03:05:03Z","title":"Feature Interaction Fusion Self-Distillation Network For CTR Prediction","summary":"  Click-Through Rate (CTR) prediction plays a vital role in recommender\nsystems, online advertising, and search engines. Most of the current approaches\nmodel feature interactions through stacked or parallel structures, with some\nemploying knowledge distillation for model compression. However, we observe\nsome limitations with these approaches: (1) In parallel structure models, the\nexplicit and implicit components are executed independently and simultaneously,\nwhich leads to insufficient information sharing within the feature set. (2) The\nintroduction of knowledge distillation technology brings about the problems of\ncomplex teacher-student framework design and low knowledge transfer efficiency.\n(3) The dataset and the process of constructing high-order feature interactions\ncontain significant noise, which limits the model's effectiveness. To address\nthese limitations, we propose FSDNet, a CTR prediction framework incorporating\na plug-and-play fusion self-distillation module. Specifically, FSDNet forms\nconnections between explicit and implicit feature interactions at each layer,\nenhancing the sharing of information between different features. The deepest\nfused layer is then used as the teacher model, utilizing self-distillation to\nguide the training of shallow layers. Empirical evaluation across four\nbenchmark datasets validates the framework's efficacy and generalization\ncapabilities. The code is available on https://github.com/coder-qiu/FSDNet.\n","authors":["Lei Sang","Qiuze Ru","Honghao Li","Yiwen Zhang","Xindong Wu"],"pdf_url":"https://arxiv.org/pdf/2411.07508v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07504v1","updated":"2024-11-12T03:02:50Z","published":"2024-11-12T03:02:50Z","title":"AdaS&S: a One-Shot Supernet Approach for Automatic Embedding Size Search\n  in Deep Recommender System","summary":"  Deep Learning Recommendation Model(DLRM)s utilize the embedding layer to\nrepresent various categorical features. Traditional DLRMs adopt unified\nembedding size for all features, leading to suboptimal performance and\nredundant parameters. Thus, lots of Automatic Embedding size Search (AES) works\nfocus on obtaining mixed embedding sizes with strong model performance.\nHowever, previous AES works can hardly address several challenges together: (1)\nThe search results of embedding sizes are unstable; (2) Recommendation effect\nwith AES results is unsatisfactory; (3) Memory cost of embeddings is\nuncontrollable. To address these challenges, we propose a novel one-shot AES\nframework called AdaS&S, in which a supernet encompassing various candidate\nembeddings is built and AES is performed as searching network architectures\nwithin it. Our framework contains two main stages: In the first stage, we\ndecouple training parameters from searching embedding sizes, and propose the\nAdaptive Sampling method to yield a well-trained supernet, which further helps\nto produce stable AES results. In the second stage, to obtain embedding sizes\nthat benefits the model effect, we design a reinforcement learning search\nprocess which utilizes the supernet trained previously. Meanwhile, to adapt\nsearching to specific resource constraint, we introduce the resource\ncompetition penalty to balance the model effectiveness and memory cost of\nembeddings. We conduct extensive experiments on public datasets to show the\nsuperiority of AdaS&S. Our method could improve AUC by about 0.3% while saving\nabout 20% of model parameters. Empirical analysis also shows that the stability\nof searching results in AdaS&S significantly exceeds other methods.\n","authors":["He Wei","Yuekui Yang","Yang Zhang","Haiyang Wu","Meixi Liu","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2411.07504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07482v1","updated":"2024-11-12T02:08:19Z","published":"2024-11-12T02:08:19Z","title":"Enhancing Link Prediction with Fuzzy Graph Attention Networks and\n  Dynamic Negative Sampling","summary":"  Link prediction is crucial for understanding complex networks but traditional\nGraph Neural Networks (GNNs) often rely on random negative sampling, leading to\nsuboptimal performance. This paper introduces Fuzzy Graph Attention Networks\n(FGAT), a novel approach integrating fuzzy rough sets for dynamic negative\nsampling and enhanced node feature aggregation. Fuzzy Negative Sampling (FNS)\nsystematically selects high-quality negative edges based on fuzzy similarities,\nimproving training efficiency. FGAT layer incorporates fuzzy rough set\nprinciples, enabling robust and discriminative node representations.\nExperiments on two research collaboration networks demonstrate FGAT's superior\nlink prediction accuracy, outperforming state-of-the-art baselines by\nleveraging the power of fuzzy rough sets for effective negative sampling and\nnode feature learning.\n","authors":["Jinming Xing"],"pdf_url":"https://arxiv.org/pdf/2411.07482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.04916v4","updated":"2024-11-12T01:01:32Z","published":"2023-11-02T04:01:04Z","title":"Explainable Identification of Hate Speech towards Islam using Graph\n  Neural Networks","summary":"  Islamophobic language on online platforms fosters intolerance, making\ndetection and elimination crucial for promoting harmony. Traditional hate\nspeech detection models rely on NLP techniques like tokenization,\npart-of-speech tagging, and encoder-decoder models. However, Graph Neural\nNetworks (GNNs), with their ability to utilize relationships between data\npoints, offer more effective detection and greater explainability. In this\nwork, we represent speeches as nodes and connect them with edges based on their\ncontext and similarity to develop the graph. This study introduces a novel\nparadigm using GNNs to identify and explain hate speech towards Islam. Our\nmodel leverages GNNs to understand the context and patterns of hate speech by\nconnecting texts via pretrained NLP-generated word embeddings, achieving\nstate-of-the-art performance and enhancing detection accuracy while providing\nvaluable explanations. This highlights the potential of GNNs in combating\nonline hate speech and fostering a safer, more inclusive online environment.\n","authors":["Azmine Toushik Wasi"],"pdf_url":"https://arxiv.org/pdf/2311.04916v4.pdf","comment":"Accepted in: (i) NeurIPS 2023 : Muslims in ML Workshop (Non-archival)\n  (https://www.musiml.org/schedule/#:~:text=Azmine%20Toushik%20Wasi) (ii) EMNLP\n  2024 : NLP for Positive Impact Workshop (Archival; ACL Anthology:\n  https://aclanthology.org/2024.nlp4pi-1.23/)"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2411.08027v1","updated":"2024-11-12T18:56:58Z","published":"2024-11-12T18:56:58Z","title":"LLMPhy: Complex Physical Reasoning Using Large Language Models and World\n  Models","summary":"  Physical reasoning is an important skill needed for robotic agents when\noperating in the real world. However, solving such reasoning problems often\ninvolves hypothesizing and reflecting over complex multi-body interactions\nunder the effect of a multitude of physical forces and thus learning all such\ninteractions poses a significant hurdle for state-of-the-art machine learning\nframeworks, including large language models (LLMs). To study this problem, we\npropose a new physical reasoning task and a dataset, dubbed TraySim. Our task\ninvolves predicting the dynamics of several objects on a tray that is given an\nexternal impact -- the domino effect of the ensued object interactions and\ntheir dynamics thus offering a challenging yet controlled setup, with the goal\nof reasoning being to infer the stability of the objects after the impact. To\nsolve this complex physical reasoning task, we present LLMPhy, a zero-shot\nblack-box optimization framework that leverages the physics knowledge and\nprogram synthesis abilities of LLMs, and synergizes these abilities with the\nworld models built into modern physics engines. Specifically, LLMPhy uses an\nLLM to generate code to iteratively estimate the physical hyperparameters of\nthe system (friction, damping, layout, etc.) via an implicit\nanalysis-by-synthesis approach using a (non-differentiable) simulator in the\nloop and uses the inferred parameters to imagine the dynamics of the scene\ntowards solving the reasoning task. To show the effectiveness of LLMPhy, we\npresent experiments on our TraySim dataset to predict the steady-state poses of\nthe objects. Our results show that the combination of the LLM and the physics\nengine leads to state-of-the-art zero-shot physical reasoning performance,\nwhile demonstrating superior convergence against standard black-box\noptimization methods and better estimation of the physical parameters.\n","authors":["Anoop Cherian","Radu Corcodel","Siddarth Jain","Diego Romeres"],"pdf_url":"https://arxiv.org/pdf/2411.08027v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08024v1","updated":"2024-11-12T18:54:55Z","published":"2024-11-12T18:54:55Z","title":"Leonardo vindicated: Pythagorean trees for minimal reconstruction of the\n  natural branching structures","summary":"  Trees continue to fascinate with their natural beauty and as engineering\nmasterpieces optimal with respect to several independent criteria. Pythagorean\ntree is a well-known fractal design that realistically mimics the natural tree\nbranching structures. We study various types of Pythagorean-like fractal trees\nwith different shapes of the base, branching angles and relaxed scales in an\nattempt to identify and explain which variants are the closest match to the\nbranching structures commonly observed in the natural world. Pursuing\nsimultaneously the realism and minimalism of the fractal tree model, we have\ndeveloped a flexibly parameterised and fast algorithm to grow and visually\nexamine deep Pythagorean-inspired fractal trees with the capability to orderly\nover- or underestimate the Leonardo da Vinci's tree branching rule as well as\ncontrol various imbalances and branching angles. We tested the realism of the\ngenerated fractal tree images by means of the classification accuracy of\ndetecting natural tree with the transfer-trained deep Convolutional Neural\nNetworks (CNNs). Having empirically established the parameters of the fractal\ntrees that maximize the CNN's natural tree class classification accuracy we\nhave translated them back to the scales and angles of branches and came to the\ninteresting conclusions that support the da Vinci branching rule and golden\nratio based scaling for both the shape of the branch and imbalance between the\nchild branches, and claim the flexibly parameterized fractal trees can be used\nto generate artificial examples to train robust detectors of different species\nof trees.\n","authors":["Dymitr Ruta","Corrado Mio","Ernesto Damiani"],"pdf_url":"https://arxiv.org/pdf/2411.08024v1.pdf","comment":"22 pages, lots of hi res figures I had to reduce quality of,\n  submitting as a requirement to the Theory of Computing Journal"},{"id":"http://arxiv.org/abs/2411.08019v1","updated":"2024-11-12T18:50:35Z","published":"2024-11-12T18:50:35Z","title":"Language Models as Causal Effect Generators","summary":"  We present a framework for large language model (LLM) based data generation\nwith controllable causal structure. In particular, we define a procedure for\nturning any language model and any directed acyclic graph (DAG) into a\nsequence-driven structural causal model (SD-SCM). Broadly speaking, an SD-SCM\nis a causal model with user-defined structure and LLM-defined structural\nequations. We characterize how an SD-SCM allows sampling from observational,\ninterventional, and counterfactual distributions according to the desired\ncausal structure. We then leverage this procedure to propose a new type of\nbenchmark for causal inference methods, generating individual-level\ncounterfactual data without needing to manually specify functional\nrelationships between variables. We create an example benchmark consisting of\nthousands of datasets, and test a suite of popular estimation methods on these\ndatasets for average, conditional average, and individual treatment effect\nestimation, both with and without hidden confounding. Apart from generating\ndata, the same procedure also allows us to test for the presence of a causal\neffect that might be encoded in an LLM. This procedure can underpin auditing\nLLMs for misinformation, discrimination, or otherwise undesirable behavior. We\nbelieve SD-SCMs can serve as a useful tool in any application that would\nbenefit from sequential data with controllable causal structure.\n","authors":["Lucius E. J. Bynum","Kyunghyun Cho"],"pdf_url":"https://arxiv.org/pdf/2411.08019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08017v1","updated":"2024-11-12T18:49:06Z","published":"2024-11-12T18:49:06Z","title":"Wavelet Latent Diffusion (Wala): Billion-Parameter 3D Generative Model\n  with Compact Wavelet Encodings","summary":"  Large-scale 3D generative models require substantial computational resources\nyet often fall short in capturing fine details and complex geometries at high\nresolutions. We attribute this limitation to the inefficiency of current\nrepresentations, which lack the compactness required to model the generative\nmodels effectively. To address this, we introduce a novel approach called\nWavelet Latent Diffusion, or WaLa, that encodes 3D shapes into wavelet-based,\ncompact latent encodings. Specifically, we compress a $256^3$ signed distance\nfield into a $12^3 \\times 4$ latent grid, achieving an impressive 2427x\ncompression ratio with minimal loss of detail. This high level of compression\nallows our method to efficiently train large-scale generative networks without\nincreasing the inference time. Our models, both conditional and unconditional,\ncontain approximately one billion parameters and successfully generate\nhigh-quality 3D shapes at $256^3$ resolution. Moreover, WaLa offers rapid\ninference, producing shapes within two to four seconds depending on the\ncondition, despite the model's scale. We demonstrate state-of-the-art\nperformance across multiple datasets, with significant improvements in\ngeneration quality, diversity, and computational efficiency. We open-source our\ncode and, to the best of our knowledge, release the largest pretrained 3D\ngenerative models across different modalities.\n","authors":["Aditya Sanghi","Aliasghar Khani","Pradyumna Reddy","Arianna Rampini","Derek Cheung","Kamal Rahimi Malekshan","Kanika Madan","Hooman Shayani"],"pdf_url":"https://arxiv.org/pdf/2411.08017v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.08013v1","updated":"2024-11-12T18:43:27Z","published":"2024-11-12T18:43:27Z","title":"Investigating the Effectiveness of Explainability Methods in Parkinson's\n  Detection from Speech","summary":"  Speech impairments in Parkinson's disease (PD) provide significant early\nindicators for diagnosis. While models for speech-based PD detection have shown\nstrong performance, their interpretability remains underexplored. This study\nsystematically evaluates several explainability methods to identify PD-specific\nspeech features, aiming to support the development of accurate, interpretable\nmodels for clinical decision-making in PD diagnosis and monitoring. Our\nmethodology involves (i) obtaining attributions and saliency maps using\nmainstream interpretability techniques, (ii) quantitatively evaluating the\nfaithfulness of these maps and their combinations obtained via union and\nintersection through a range of established metrics, and (iii) assessing the\ninformation conveyed by the saliency maps for PD detection from an auxiliary\nclassifier. Our results reveal that, while explanations are aligned with the\nclassifier, they often fail to provide valuable information for domain experts.\n","authors":["Eleonora Mancini","Francesco Paissan","Paolo Torroni","Cem Subakan","Mirco Ravanelli"],"pdf_url":"https://arxiv.org/pdf/2411.08013v1.pdf","comment":"The first two authors contributed equally to this research: author\n  order is alphabetical"},{"id":"http://arxiv.org/abs/2401.11555v2","updated":"2024-11-12T18:18:43Z","published":"2024-01-21T18:00:15Z","title":"VQC-Based Reinforcement Learning with Data Re-uploading: Performance and\n  Trainability","summary":"  Reinforcement Learning (RL) consists of designing agents that make\nintelligent decisions without human supervision. When used alongside function\napproximators such as Neural Networks (NNs), RL is capable of solving extremely\ncomplex problems. Deep Q-Learning, a RL algorithm that uses Deep NNs, achieved\nsuper-human performance in some specific tasks. Nonetheless, it is also\npossible to use Variational Quantum Circuits (VQCs) as function approximators\nin RL algorithms. This work empirically studies the performance and\ntrainability of such VQC-based Deep Q-Learning models in classic control\nbenchmark environments. More specifically, we research how data re-uploading\naffects both these metrics. We show that the magnitude and the variance of the\ngradients of these models remain substantial throughout training due to the\nmoving targets of Deep Q-Learning. Moreover, we empirically show that\nincreasing the number of qubits does not lead to an exponential vanishing\nbehavior of the magnitude and variance of the gradients for a PQC approximating\na 2-design, unlike what was expected due to the Barren Plateau Phenomenon. This\nhints at the possibility of VQCs being specially adequate for being used as\nfunction approximators in such a context.\n","authors":["Rodrigo Coelho","Andr√© Sequeira","Lu√≠s Paulo Santos"],"pdf_url":"https://arxiv.org/pdf/2401.11555v2.pdf","comment":"26 pages, 11 figures"},{"id":"http://arxiv.org/abs/2411.07990v1","updated":"2024-11-12T18:15:19Z","published":"2024-11-12T18:15:19Z","title":"Derivational Morphology Reveals Analogical Generalization in Large\n  Language Models","summary":"  What mechanisms underlie linguistic generalization in large language models\n(LLMs)? This question has attracted considerable attention, with most studies\nanalyzing the extent to which the language skills of LLMs resemble rules. As of\nyet, it is not known whether linguistic generalization in LLMs could equally\nwell be explained as the result of analogical processes, which can be\nformalized as similarity operations on stored exemplars. A key shortcoming of\nprior research is its focus on linguistic phenomena with a high degree of\nregularity, for which rule-based and analogical approaches make the same\npredictions. Here, we instead examine derivational morphology, specifically\nEnglish adjective nominalization, which displays notable variability. We\nintroduce a new method for investigating linguistic generalization in LLMs:\nfocusing on GPT-J, we fit cognitive models that instantiate rule-based and\nanalogical learning to the LLM training data and compare their predictions on a\nset of nonce adjectives with those of the LLM, allowing us to draw direct\nconclusions regarding underlying mechanisms. As expected, rule-based and\nanalogical models explain the predictions of GPT-J equally well for adjectives\nwith regular nominalization patterns. However, for adjectives with variable\nnominalization patterns, the analogical model provides a much better match.\nFurthermore, GPT-J's behavior is sensitive to the individual word frequencies,\neven for regular forms, a behavior that is consistent with an analogical\naccount of regular forms but not a rule-based one. These findings refute the\nhypothesis that GPT-J's linguistic generalization on adjective nominalization\ninvolves rules, suggesting similarity operations on stored exemplars as the\nunderlying mechanism. Overall, our study suggests that analogical processes\nplay a bigger role in the linguistic generalization of LLMs than previously\nthought.\n","authors":["Valentin Hofmann","Leonie Weissweiler","David Mortensen","Hinrich Sch√ºtze","Janet Pierrehumbert"],"pdf_url":"https://arxiv.org/pdf/2411.07990v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02271v2","updated":"2024-11-12T18:11:30Z","published":"2024-11-04T17:03:52Z","title":"On the Utilization of Unique Node Identifiers in Graph Neural Networks","summary":"  Graph Neural Networks have inherent representational limitations due to their\nmessage-passing structure. Recent work has suggested that these limitations can\nbe overcome by using unique node identifiers (UIDs). Here we argue that despite\nthe advantages of UIDs, one of their disadvantages is that they lose the\ndesirable property of permutation-equivariance. We thus propose to focus on UID\nmodels that are permutation-equivariant, and present theoretical arguments for\ntheir advantages. Motivated by this, we propose a method to regularize UID\nmodels towards permutation equivariance, via a contrastive loss. We empirically\ndemonstrate that our approach improves generalization and extrapolation\nabilities while providing faster training convergence. On the recent BREC\nexpressiveness benchmark, our proposed method achieves state-of-the-art\nperformance compared to other random-based approaches.\n","authors":["Maya Bechler-Speicher","Moshe Eliasof","Carola-Bibiane Sch√∂nlieb","Ran Gilad-Bachrach","Amir Globerson"],"pdf_url":"https://arxiv.org/pdf/2411.02271v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07979v1","updated":"2024-11-12T17:58:40Z","published":"2024-11-12T17:58:40Z","title":"Exact, Tractable Gauss-Newton Optimization in Deep Reversible\n  Architectures Reveal Poor Generalization","summary":"  Second-order optimization has been shown to accelerate the training of deep\nneural networks in many applications, often yielding faster progress per\niteration on the training loss compared to first-order optimizers.However, the\ngeneralization properties of second-order methods are still being debated.\nTheoretical investigations have proved difficult to carry out outside the\ntractable settings of heavily simplified model classes -- thus, the relevance\nof existing theories to practical deep learning applications remains unclear.\nSimilarly, empirical studies in large-scale models and real datasets are\nsignificantly confounded by the necessity to approximate second-order updates\nin practice. It is often unclear whether the observed generalization behaviour\narises specifically from the second-order nature of the parameter updates, or\ninstead reflects the specific structured (e.g.\\ Kronecker) approximations used\nor any damping-based interpolation towards first-order updates. Here, we show\nfor the first time that exact Gauss-Newton (GN) updates take on a tractable\nform in a class of deep reversible architectures that are sufficiently\nexpressive to be meaningfully applied to common benchmark datasets. We exploit\nthis novel setting to study the training and generalization properties of the\nGN optimizer. We find that exact GN generalizes poorly. In the mini-batch\ntraining setting, this manifests as rapidly saturating progress even on the\n\\emph{training} loss, with parameter updates found to overfit each\nmini-batchatch without producing the features that would support generalization\nto other mini-batches. We show that our experiments run in the ``lazy'' regime,\nin which the neural tangent kernel (NTK) changes very little during the course\nof training. This behaviour is associated with having no significant changes in\nneural representations, explaining the lack of generalization.\n","authors":["Davide Buffelli","Jamie McGowan","Wangkun Xu","Alexandru Cioba","Da-shan Shiu","Guillaume Hennequin","Alberto Bernacchia"],"pdf_url":"https://arxiv.org/pdf/2411.07979v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07978v1","updated":"2024-11-12T17:58:34Z","published":"2024-11-12T17:58:34Z","title":"Doubly Robust Regression Discontinuity Designs","summary":"  This study introduces a doubly robust (DR) estimator for regression\ndiscontinuity (RD) designs. In RD designs, treatment effects are estimated in a\nquasi-experimental setting where treatment assignment depends on whether a\nrunning variable surpasses a predefined cutoff. A common approach in RD\nestimation is to apply nonparametric regression methods, such as local linear\nregression. In such an approach, the validity relies heavily on the consistency\nof nonparametric estimators and is limited by the nonparametric convergence\nrate, thereby preventing $\\sqrt{n}$-consistency. To address these issues, we\npropose the DR-RD estimator, which combines two distinct estimators for the\nconditional expected outcomes. If either of these estimators is consistent, the\ntreatment effect estimator remains consistent. Furthermore, due to the\ndebiasing effect, our proposed estimator achieves $\\sqrt{n}$-consistency if\nboth regression estimators satisfy certain mild conditions, which also\nsimplifies statistical inference.\n","authors":["Masahiro Kato"],"pdf_url":"https://arxiv.org/pdf/2411.07978v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07971v1","updated":"2024-11-12T17:51:45Z","published":"2024-11-12T17:51:45Z","title":"Optimal Control of Mechanical Ventilators with Learned Respiratory\n  Dynamics","summary":"  Deciding on appropriate mechanical ventilator management strategies\nsignificantly impacts the health outcomes for patients with respiratory\ndiseases. Acute Respiratory Distress Syndrome (ARDS) is one such disease that\nrequires careful ventilator operation to be effectively treated. In this work,\nwe frame the management of ventilators for patients with ARDS as a sequential\ndecision making problem using the Markov decision process framework. We\nimplement and compare controllers based on clinical guidelines contained in the\nARDSnet protocol, optimal control theory, and learned latent dynamics\nrepresented as neural networks. The Pulse Physiology Engine's respiratory\ndynamics simulator is used to establish a repeatable benchmark, gather\nsimulated data, and quantitatively compare these controllers. We score\nperformance in terms of measured improvement in established ARDS health markers\n(pertaining to improved respiratory rate, oxygenation, and vital signs). Our\nresults demonstrate that techniques leveraging neural networks and optimal\ncontrol can automatically discover effective ventilation management strategies\nwithout access to explicit ventilator management procedures or guidelines (such\nas those defined in the ARDSnet protocol).\n","authors":["Isaac Ronald Ward","Dylan M. Asmar","Mansur Arief","Jana Krystofova Mike","Mykel J. Kochenderfer"],"pdf_url":"https://arxiv.org/pdf/2411.07971v1.pdf","comment":"2024 IEEE 37th International Symposium on Computer-Based Medical\n  Systems (CBMS), 7 pages, 3 figures"},{"id":"http://arxiv.org/abs/2407.09434v2","updated":"2024-11-12T17:49:12Z","published":"2024-07-12T17:09:47Z","title":"Foundation Models for the Electric Power Grid","summary":"  Foundation models (FMs) currently dominate news headlines. They employ\nadvanced deep learning architectures to extract structural information\nautonomously from vast datasets through self-supervision. The resulting rich\nrepresentations of complex systems and dynamics can be applied to many\ndownstream applications. Therefore, FMs can find uses in electric power grids,\nchallenged by the energy transition and climate change. In this paper, we call\nfor the development of, and state why we believe in, the potential of FMs for\nelectric grids. We highlight their strengths and weaknesses amidst the\nchallenges of a changing grid. We argue that an FM learning from diverse grid\ndata and topologies could unlock transformative capabilities, pioneering a new\napproach in leveraging AI to redefine how we manage complexity and uncertainty\nin the electric grid. Finally, we discuss a power grid FM concept, namely\nGridFM, based on graph neural networks and show how different downstream tasks\nbenefit.\n","authors":["Hendrik F. Hamann","Thomas Brunschwiler","Blazhe Gjorgiev","Leonardo S. A. Martins","Alban Puech","Anna Varbella","Jonas Weiss","Juan Bernabe-Moreno","Alexandre Blondin Mass√©","Seong Choi","Ian Foster","Bri-Mathias Hodge","Rishabh Jain","Kibaek Kim","Vincent Mai","Fran√ßois Mirall√®s","Martin De Montigny","Octavio Ramos-Lea√±os","Hussein Supr√™me","Le Xie","El-Nasser S. Youssef","Arnaud Zinflou","Alexander J. Belyi","Ricardo J. Bessa","Bishnu Prasad Bhattarai","Johannes Schmude","Stanislav Sobolevsky"],"pdf_url":"https://arxiv.org/pdf/2407.09434v2.pdf","comment":"Major equal contributors: H.F.H., T.B., B.G., L.S.A.M., A.P., A.V.,\n  J.W.; Significant equal contributors: J.B., A.B.M., S.C., I.F., B.H., R.J.,\n  K.K., V.M., F.M., M.D.M., O.R., H.S., L.X., E.S.Y., A.Z.; Other equal\n  contributors: A.J.B., R.J.B., B.P.B., J.S., S.S; Lead contact: H.F.H"},{"id":"http://arxiv.org/abs/2411.07964v1","updated":"2024-11-12T17:41:16Z","published":"2024-11-12T17:41:16Z","title":"Sleep Staging from Airflow Signals Using Fourier Approximations of\n  Persistence Curves","summary":"  Sleep staging is a challenging task, typically manually performed by sleep\ntechnologists based on electroencephalogram and other biosignals of patients\ntaken during overnight sleep studies. Recent work aims to leverage automated\nalgorithms to perform sleep staging not based on electroencephalogram signals,\nbut rather based on the airflow signals of subjects. Prior work uses ideas from\ntopological data analysis (TDA), specifically Hermite function expansions of\npersistence curves (HEPC) to featurize airflow signals. However, finite order\nHEPC captures only partial information. In this work, we propose Fourier\napproximations of persistence curves (FAPC), and use this technique to perform\nsleep staging based on airflow signals. We analyze performance using an XGBoost\nmodel on 1155 pediatric sleep studies taken from the Nationwide Children's\nHospital Sleep DataBank (NCHSDB), and find that FAPC methods provide\ncomplimentary information to HEPC methods alone, leading to a 4.9% increase in\nperformance over baseline methods.\n","authors":["Shashank Manjunath","Hau-Tieng Wu","Aarti Sathyanarayana"],"pdf_url":"https://arxiv.org/pdf/2411.07964v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07959v1","updated":"2024-11-12T17:36:20Z","published":"2024-11-12T17:36:20Z","title":"On the Convergence of Continual Federated Learning Using Incrementally\n  Aggregated Gradients","summary":"  The holy grail of machine learning is to enable Continual Federated Learning\n(CFL) to enhance the efficiency, privacy, and scalability of AI systems while\nlearning from streaming data. The primary challenge of a CFL system is to\novercome global catastrophic forgetting, wherein the accuracy of the global\nmodel trained on new tasks declines on the old tasks. In this work, we propose\nContinual Federated Learning with Aggregated Gradients (C-FLAG), a novel\nreplay-memory based federated strategy consisting of edge-based gradient\nupdates on memory and aggregated gradients on the current data. We provide\nconvergence analysis of the C-FLAG approach which addresses forgetting and bias\nwhile converging at a rate of $O(1/\\sqrt{T})$ over $T$ communication rounds. We\nformulate an optimization sub-problem that minimizes catastrophic forgetting,\ntranslating CFL into an iterative algorithm with adaptive learning rates that\nensure seamless learning across tasks. We empirically show that C-FLAG\noutperforms several state-of-the-art baselines on both task and\nclass-incremental settings with respect to metrics such as accuracy and\nforgetting.\n","authors":["Satish Kumar Keshri","Nazreen Shah","Ranjitha Prasad"],"pdf_url":"https://arxiv.org/pdf/2411.07959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07957v1","updated":"2024-11-12T17:34:38Z","published":"2024-11-12T17:34:38Z","title":"Tukey g-and-h neural network regression for non-Gaussian data","summary":"  This paper addresses non-Gaussian regression with neural networks via the use\nof the Tukey g-and-h distribution.The Tukey g-and-h transform is a flexible\nparametric transform with two parameters $g$ and $h$ which, when applied to a\nstandard normal random variable, introduces both skewness and kurtosis,\nresulting in a distribution commonly called the Tukey g-and-h distribution.\nSpecific values of $g$ and $h$ produce good approximations to other families of\ndistributions, such as the Cauchy and student-t distributions. The flexibility\nof the Tukey g-and-h distribution has driven its popularity in the statistical\ncommunity, in applied sciences and finance. In this work we consider the\ntraining of a neural network to predict the parameters of a Tukey g-and-h\ndistribution in a regression framework via the minimization of the\ncorresponding negative log-likelihood, despite the latter having no closed-form\nexpression. We demonstrate the efficiency of our procedure in simulated\nexamples and apply our method to a real-world dataset of global crop yield for\nseveral types of crops. Finally, we show how we can carry out a goodness-of-fit\nanalysis between the predicted distributions and the test data. A Pytorch\nimplementation is made available on Github and as a Pypi package.\n","authors":["Arthur P. Guillaumin","Natalia Efremova"],"pdf_url":"https://arxiv.org/pdf/2411.07957v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07954v1","updated":"2024-11-12T17:30:31Z","published":"2024-11-12T17:30:31Z","title":"Learning Memory Mechanisms for Decision Making through Demonstrations","summary":"  In Partially Observable Markov Decision Processes, integrating an agent's\nhistory into memory poses a significant challenge for decision-making.\nTraditional imitation learning, relying on observation-action pairs for expert\ndemonstrations, fails to capture the expert's memory mechanisms used in\ndecision-making. To capture memory processes as demonstrations, we introduce\nthe concept of \\textbf{memory dependency pairs} $(p, q)$ indicating that events\nat time $p$ are recalled for decision-making at time $q$. We introduce\n\\textbf{AttentionTuner} to leverage memory dependency pairs in Transformers and\nfind significant improvements across several tasks compared to standard\nTransformers when evaluated on Memory Gym and the Long-term Memory Benchmark.\nCode is available at https://github.com/WilliamYue37/AttentionTuner .\n","authors":["William Yue","Bo Liu","Peter Stone"],"pdf_url":"https://arxiv.org/pdf/2411.07954v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07942v1","updated":"2024-11-12T17:11:46Z","published":"2024-11-12T17:11:46Z","title":"Towards Low-bit Communication for Tensor Parallel LLM Inference","summary":"  Tensor parallelism provides an effective way to increase server large\nlanguage model (LLM) inference efficiency despite adding an additional\ncommunication cost. However, as server LLMs continue to scale in size, they\nwill need to be distributed across more devices, magnifying the communication\ncost. One way to approach this problem is with quantization, but current\nmethods for LLMs tend to avoid quantizing the features that tensor parallelism\nneeds to communicate. Taking advantage of consistent outliers in communicated\nfeatures, we introduce a quantization method that reduces communicated values\non average from 16 bits to 4.2 bits while preserving nearly all of the original\nperformance. For instance, our method maintains around 98.0% and 99.5% of Gemma\n2 27B's and Llama 2 13B's original performance, respectively, averaged across\nall tasks we evaluated on.\n","authors":["Harry Dong","Tyler Johnson","Minsik Cho","Emad Soroush"],"pdf_url":"https://arxiv.org/pdf/2411.07942v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07934v1","updated":"2024-11-12T17:04:56Z","published":"2024-11-12T17:04:56Z","title":"Doubly Mild Generalization for Offline Reinforcement Learning","summary":"  Offline Reinforcement Learning (RL) suffers from the extrapolation error and\nvalue overestimation. From a generalization perspective, this issue can be\nattributed to the over-generalization of value functions or policies towards\nout-of-distribution (OOD) actions. Significant efforts have been devoted to\nmitigating such generalization, and recent in-sample learning approaches have\nfurther succeeded in entirely eschewing it. Nevertheless, we show that mild\ngeneralization beyond the dataset can be trusted and leveraged to improve\nperformance under certain conditions. To appropriately exploit generalization\nin offline RL, we propose Doubly Mild Generalization (DMG), comprising (i) mild\naction generalization and (ii) mild generalization propagation. The former\nrefers to selecting actions in a close neighborhood of the dataset to maximize\nthe Q values. Even so, the potential erroneous generalization can still be\npropagated, accumulated, and exacerbated by bootstrapping. In light of this,\nthe latter concept is introduced to mitigate the generalization propagation\nwithout impeding the propagation of RL learning signals. Theoretically, DMG\nguarantees better performance than the in-sample optimal policy in the oracle\ngeneralization scenario. Even under worst-case generalization, DMG can still\ncontrol value overestimation at a certain level and lower bound the\nperformance. Empirically, DMG achieves state-of-the-art performance across\nGym-MuJoCo locomotion tasks and challenging AntMaze tasks. Moreover, benefiting\nfrom its flexibility in both generalization aspects, DMG enjoys a seamless\ntransition from offline to online learning and attains strong online\nfine-tuning performance.\n","authors":["Yixiu Mao","Qi Wang","Yun Qu","Yuhang Jiang","Xiangyang Ji"],"pdf_url":"https://arxiv.org/pdf/2411.07934v1.pdf","comment":"Accepted to NeurIPS 2024. arXiv admin note: substantial text overlap\n  with arXiv:2410.19400"},{"id":"http://arxiv.org/abs/2411.07933v1","updated":"2024-11-12T17:04:12Z","published":"2024-11-12T17:04:12Z","title":"Prediction of Acoustic Communication Performance for AUVs using Gaussian\n  Process Classification","summary":"  Cooperating autonomous underwater vehicles (AUVs) often rely on acoustic\ncommunication to coordinate their actions effectively. However, the reliability\nof underwater acoustic communication decreases as the communication range\nbetween vehicles increases. Consequently, teams of cooperating AUVs typically\nmake conservative assumptions about the maximum range at which they can\ncommunicate reliably. To address this limitation, we propose a novel approach\nthat involves learning a map representing the probability of successful\ncommunication based on the locations of the transmitting and receiving\nvehicles. This probabilistic communication map accounts for factors such as the\nrange between vehicles, environmental noise, and multi-path effects at a given\nlocation. In pursuit of this goal, we investigate the application of Gaussian\nprocess binary classification to generate the desired communication map. We\nspecialize existing results to this specific binary classification problem and\nexplore methods to incorporate uncertainty in vehicle location into the mapping\nprocess. Furthermore, we compare the prediction performance of the probability\ncommunication map generated using binary classification with that of a\nsignal-to-noise ratio (SNR) communication map generated using Gaussian process\nregression. Our approach is experimentally validated using communication and\nnavigation data collected during trials with a pair of Virginia Tech 690 AUVs.\n","authors":["Yifei Gao","Harun Yetkin","McMahon James","Daniel J. Stilwell"],"pdf_url":"https://arxiv.org/pdf/2411.07933v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01897v2","updated":"2024-11-12T16:48:29Z","published":"2024-11-04T09:04:11Z","title":"LE-PDE++: Mamba for accelerating PDEs Simulations","summary":"  Partial Differential Equations are foundational in modeling science and\nnatural systems such as fluid dynamics and weather forecasting. The Latent\nEvolution of PDEs method is designed to address the computational intensity of\nclassical and deep learning-based PDE solvers by proposing a scalable and\nefficient alternative. To enhance the efficiency and accuracy of LE-PDE, we\nincorporate the Mamba model, an advanced machine learning model known for its\npredictive efficiency and robustness in handling complex dynamic systems with a\nprogressive learning strategy. The LE-PDE was tested on several benchmark\nproblems. The method demonstrated a marked reduction in computational time\ncompared to traditional solvers and standalone deep learning models while\nmaintaining high accuracy in predicting system behavior over time. Our method\ndoubles the inference speed compared to the LE-PDE while retaining the same\nlevel of parameter efficiency, making it well-suited for scenarios requiring\nlong-term predictions.\n","authors":["Aoming Liang","Zhaoyang Mu","Qi liu","Ruipeng Li","Mingming Ge","Dixia Fan"],"pdf_url":"https://arxiv.org/pdf/2411.01897v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.03497v2","updated":"2024-11-12T16:44:24Z","published":"2024-08-07T01:37:10Z","title":"Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and\n  Tabnet with SMOTEENN","summary":"  Bank credit risk is a significant challenge in modern financial transactions,\nand the ability to identify qualified credit card holders among a large number\nof applicants is crucial for the profitability of a bank'sbank's credit card\nbusiness. In the past, screening applicants'applicants' conditions often\nrequired a significant amount of manual labor, which was time-consuming and\nlabor-intensive. Although the accuracy and reliability of previously used ML\nmodels have been continuously improving, the pursuit of more reliable and\npowerful AI intelligent models is undoubtedly the unremitting pursuit by major\nbanks in the financial industry. In this study, we used a dataset of over\n40,000 records provided by a commercial bank as the research object. We\ncompared various dimensionality reduction techniques such as PCA and T-SNE for\npreprocessing high-dimensional datasets and performed in-depth adaptation and\ntuning of distributed models such as LightGBM and XGBoost, as well as deep\nmodels like Tabnet. After a series of research and processing, we obtained\nexcellent research results by combining SMOTEENN with these techniques. The\nexperiments demonstrated that LightGBM combined with PCA and SMOTEENN\ntechniques can assist banks in accurately predicting potential high-quality\ncustomers, showing relatively outstanding performance compared to other models.\n","authors":["Chang Yu","Yixin Jin","Qianwen Xing","Ye Zhang","Shaobo Guo","Shuchen Meng"],"pdf_url":"https://arxiv.org/pdf/2408.03497v2.pdf","comment":"8 pagess on IEEE ICPICS"},{"id":"http://arxiv.org/abs/2406.04658v3","updated":"2024-11-12T16:44:20Z","published":"2024-06-07T05:56:43Z","title":"Advanced Payment Security System:XGBoost, LightGBM and SMOTE Integrated","summary":"  With the rise of various online and mobile payment systems, transaction fraud\nhas become a significant threat to financial security. This study explores the\napplication of advanced machine learning models, specifically based on XGBoost\nand LightGBM, for developing a more accurate and robust Payment Security\nProtection Model. To enhance data reliability, we meticulously processed the\ndata sources and applied SMOTE (Synthetic Minority Over-sampling Technique) to\naddress class imbalance and improve data representation. By selecting highly\ncorrelated features, we aimed to strengthen the training process and boost\nmodel performance. We conducted thorough performance evaluations of our\nproposed models, comparing them against traditional methods including Random\nForest, Neural Network, and Logistic Regression. Using metrics such as\nPrecision, Recall, and F1 Score, we rigorously assessed their effectiveness.\nOur detailed analyses and comparisons reveal that the combination of SMOTE with\nXGBoost and LightGBM offers a highly efficient and powerful mechanism for\npayment security protection. Moreover, the integration of XGBoost and LightGBM\nin a Local Ensemble model further demonstrated outstanding performance. After\nincorporating SMOTE, the new combined model achieved a significant improvement\nof nearly 6\\% over traditional models and around 5\\% over its sub-models,\nshowcasing remarkable results.\n","authors":["Qi Zheng","Chang Yu","Jin Cao","Yongshun Xu","Qianwen Xing","Yinxin Jin"],"pdf_url":"https://arxiv.org/pdf/2406.04658v3.pdf","comment":"This paper is received by https://ieee-metacom.org"},{"id":"http://arxiv.org/abs/2406.03733v4","updated":"2024-11-12T16:44:14Z","published":"2024-06-06T04:12:57Z","title":"Credit Card Fraud Detection Using Advanced Transformer Model","summary":"  With the proliferation of various online and mobile payment systems, credit\ncard fraud has emerged as a significant threat to financial security. This\nstudy focuses on innovative applications of the latest Transformer models for\nmore robust and precise fraud detection. To ensure the reliability of the data,\nwe meticulously processed the data sources, balancing the dataset to address\nthe issue of data sparsity significantly. We also selected highly correlated\nvectors to strengthen the training process.To guarantee the reliability and\npracticality of the new Transformer model, we conducted performance comparisons\nwith several widely adopted models, including Support Vector Machine (SVM),\nRandom Forest, Neural Network, and Logistic Regression. We rigorously compared\nthese models using metrics such as Precision, Recall, and F1 Score. Through\nthese detailed analyses and comparisons, we present to the readers a highly\nefficient and powerful anti-fraud mechanism with promising prospects. The\nresults demonstrate that the Transformer model not only excels in traditional\napplications but also shows great potential in niche areas like fraud\ndetection, offering a substantial advancement in the field.\n","authors":["Chang Yu","Yongshun Xu","Jin Cao","Ye Zhang","Yinxin Jin","Mengran Zhu"],"pdf_url":"https://arxiv.org/pdf/2406.03733v4.pdf","comment":"This paper have been received by https://ieee-metacom.org/"},{"id":"http://arxiv.org/abs/2410.00256v2","updated":"2024-11-12T16:43:41Z","published":"2024-09-30T21:56:16Z","title":"Enhanced Credit Score Prediction Using Ensemble Deep Learning Model","summary":"  In contemporary economic society, credit scores are crucial for every\nparticipant. A robust credit evaluation system is essential for the\nprofitability of core businesses such as credit cards, loans, and investments\nfor commercial banks and the financial sector. This paper combines\nhigh-performance models like XGBoost and LightGBM, already widely used in\nmodern banking systems, with the powerful TabNet model. We have developed a\npotent model capable of accurately determining credit score levels by\nintegrating Random Forest, XGBoost, and TabNet, and through the stacking\ntechnique in ensemble modeling. This approach surpasses the limitations of\nsingle models and significantly advances the precise credit score prediction.\nIn the following sections, we will explain the techniques we used and\nthoroughly validate our approach by comprehensively comparing a series of\nmetrics such as Precision, Recall, F1, and AUC. By integrating Random Forest,\nXGBoost, and with the TabNet deep learning architecture, these models\ncomplement each other, demonstrating exceptionally strong overall performance.\n","authors":["Qianwen Xing","Chang Yu","Sining Huang","Qi Zheng","Xingyu Mu","Mengying Sun"],"pdf_url":"https://arxiv.org/pdf/2410.00256v2.pdf","comment":"This paper have been accepted by sci of AI Journal"},{"id":"http://arxiv.org/abs/2305.16945v3","updated":"2024-11-12T16:23:50Z","published":"2023-05-26T14:00:12Z","title":"Levin Tree Search with Context Models","summary":"  Levin Tree Search (LTS) is a search algorithm that makes use of a policy (a\nprobability distribution over actions) and comes with a theoretical guarantee\non the number of expansions before reaching a goal node, depending on the\nquality of the policy. This guarantee can be used as a loss function, which we\ncall the LTS loss, to optimize neural networks representing the policy\n(LTS+NN). In this work we show that the neural network can be substituted with\nparameterized context models originating from the online compression literature\n(LTS+CM). We show that the LTS loss is convex under this new model, which\nallows for using standard convex optimization tools, and obtain convergence\nguarantees to the optimal parameters in an online setting for a given set of\nsolution trajectories -- guarantees that cannot be provided for neural\nnetworks. The new LTS+CM algorithm compares favorably against LTS+NN on several\nbenchmarks: Sokoban (Boxoban), The Witness, and the 24-Sliding Tile puzzle\n(STP). The difference is particularly large on STP, where LTS+NN fails to solve\nmost of the test instances while LTS+CM solves each test instance in a fraction\nof a second. Furthermore, we show that LTS+CM is able to learn a policy that\nsolves the Rubik's cube in only a few hundred expansions, which considerably\nimproves upon previous machine learning techniques.\n","authors":["Laurent Orseau","Marcus Hutter","Levi H. S. Lelis"],"pdf_url":"https://arxiv.org/pdf/2305.16945v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.18438v3","updated":"2024-11-12T15:57:13Z","published":"2023-11-30T10:39:47Z","title":"Piecewise Linearity of Min-Norm Solution Map of a Nonconvexly\n  Regularized Convex Sparse Model","summary":"  It is well known that the minimum $\\ell_2$-norm solution of the convex LASSO\nmodel, say $\\mathbf{x}_{\\star}$, is a continuous piecewise linear function of\nthe regularization parameter $\\lambda$, and its signed sparsity pattern is\nconstant within each linear piece. The current study is an extension of this\nclassic result, proving that the aforementioned properties extend to the\nmin-norm solution map $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, where\n$\\mathbf{y}$ is the observed signal, for a generalization of LASSO termed the\nscaled generalized minimax concave (sGMC) model. The sGMC model adopts a\nnonconvex debiased variant of the $\\ell_1$-norm as sparse regularizer, but its\nobjective function is overall-convex. Based on the geometric properties of\n$\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, we propose an extension of the least\nangle regression (LARS) algorithm, which iteratively computes the closed-form\nexpression of $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$ in each linear zone.\nUnder suitable conditions, the proposed algorithm provably obtains the whole\nsolution map $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$ within finite iterations.\nNotably, our proof techniques for establishing continuity and piecewise\nlinearity of $\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$ are novel, and they lead\nto two side contributions: (a) our proofs establish continuity of the sGMC\nsolution set as a set-valued mapping of $(\\mathbf{y},\\lambda)$; (b) to prove\npiecewise linearity and piecewise constant sparsity pattern of\n$\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, we do not require any assumption that\nprevious work relies on (whereas to prove some additional properties of\n$\\mathbf{x}_{\\star}(\\mathbf{y},\\lambda)$, we use a different set of assumptions\nfrom previous work).\n","authors":["Yi Zhang","Isao Yamada"],"pdf_url":"https://arxiv.org/pdf/2311.18438v3.pdf","comment":"40 pages. Submitted to journal"},{"id":"http://arxiv.org/abs/2403.00043v2","updated":"2024-11-12T15:54:29Z","published":"2024-02-29T14:50:58Z","title":"RiNALMo: General-Purpose RNA Language Models Can Generalize Well on\n  Structure Prediction Tasks","summary":"  While RNA has recently been recognized as an interesting small-molecule drug\ntarget, many challenges remain to be addressed before we take full advantage of\nit. This emphasizes the necessity to improve our understanding of its\nstructures and functions. Over the years, sequencing technologies have produced\nan enormous amount of unlabeled RNA data, which hides a huge potential.\nMotivated by the successes of protein language models, we introduce RiboNucleic\nAcid Language Model (RiNALMo) to unveil the hidden code of RNA. RiNALMo is the\nlargest RNA language model to date, with 650M parameters pre-trained on 36M\nnon-coding RNA sequences from several databases. It can extract hidden\nknowledge and capture the underlying structure information implicitly embedded\nwithin the RNA sequences. RiNALMo achieves state-of-the-art results on several\ndownstream tasks. Notably, we show that its generalization capabilities\novercome the inability of other deep learning methods for secondary structure\nprediction to generalize on unseen RNA families.\n","authors":["Rafael Josip Peniƒá","Tin Vla≈°iƒá","Roland G. Huber","Yue Wan","Mile ≈†ikiƒá"],"pdf_url":"https://arxiv.org/pdf/2403.00043v2.pdf","comment":"31 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.07889v1","updated":"2024-11-12T15:51:35Z","published":"2024-11-12T15:51:35Z","title":"A Stochastic Optimization Framework for Private and Fair Learning From\n  Decentralized Data","summary":"  Machine learning models are often trained on sensitive data (e.g., medical\nrecords and race/gender) that is distributed across different \"silos\" (e.g.,\nhospitals). These federated learning models may then be used to make\nconsequential decisions, such as allocating healthcare resources. Two key\nchallenges emerge in this setting: (i) maintaining the privacy of each person's\ndata, even if other silos or an adversary with access to the central server\ntries to infer this data; (ii) ensuring that decisions are fair to different\ndemographic groups (e.g., race/gender). In this paper, we develop a novel\nalgorithm for private and fair federated learning (FL). Our algorithm satisfies\ninter-silo record-level differential privacy (ISRL-DP), a strong notion of\nprivate FL requiring that silo i's sent messages satisfy record-level\ndifferential privacy for all i. Our framework can be used to promote different\nfairness notions, including demographic parity and equalized odds. We prove\nthat our algorithm converges under mild smoothness assumptions on the loss\nfunction, whereas prior work required strong convexity for convergence. As a\nbyproduct of our analysis, we obtain the first convergence guarantee for\nISRL-DP nonconvex-strongly concave min-max FL. Experiments demonstrate the\nstate-of-the-art fairness-accuracy tradeoffs of our algorithm across different\nprivacy levels.\n","authors":["Devansh Gupta","A. S. Poornash","Andrew Lowy","Meisam Razaviyayn"],"pdf_url":"https://arxiv.org/pdf/2411.07889v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07885v1","updated":"2024-11-12T15:47:17Z","published":"2024-11-12T15:47:17Z","title":"INTRABENCH: Interactive Radiological Benchmark","summary":"  Current interactive segmentation approaches, inspired by the success of\nMETA's Segment Anything model, have achieved notable advancements, however,\nthey come with substantial limitations that hinder their practical application\nin real clinical scenarios. These include unrealistic human interaction\nrequirements, such as slice-by-slice operations for 2D models on 3D data, a\nlack of iterative refinement, and insufficient evaluation experiments. These\nshortcomings prevent accurate assessment of model performance and lead to\ninconsistent outcomes across studies. IntRaBench overcomes these challenges by\noffering a comprehensive and reproducible framework for evaluating interactive\nsegmentation methods in realistic, clinically relevant scenarios. It includes\ndiverse datasets, target structures, and segmentation models, and provides a\nflexible codebase that allows seamless integration of new models and prompting\nstrategies. Additionally, we introduce advanced techniques to minimize\nclinician interaction, ensuring fair comparisons between 2D and 3D models. By\nopen-sourcing IntRaBench, we invite the research community to integrate their\nmodels and prompting techniques, ensuring continuous and transparent evaluation\nof interactive segmentation models in 3D medical imaging.\n","authors":["Constantin Ulrich","Tassilo Wald","Emily Tempus","Maximilian Rokuss","Paul F. Jaeger","Klaus Maier-Hein"],"pdf_url":"https://arxiv.org/pdf/2411.07885v1.pdf","comment":"Undergoing Peer-Review"},{"id":"http://arxiv.org/abs/2310.05327v2","updated":"2024-11-12T15:34:57Z","published":"2023-10-09T01:18:07Z","title":"Provable Compositional Generalization for Object-Centric Learning","summary":"  Learning representations that generalize to novel compositions of known\nconcepts is crucial for bridging the gap between human and machine perception.\nOne prominent effort is learning object-centric representations, which are\nwidely conjectured to enable compositional generalization. Yet, it remains\nunclear when this conjecture will be true, as a principled theoretical or\nempirical understanding of compositional generalization is lacking. In this\nwork, we investigate when compositional generalization is guaranteed for\nobject-centric representations through the lens of identifiability theory. We\nshow that autoencoders that satisfy structural assumptions on the decoder and\nenforce encoder-decoder consistency will learn object-centric representations\nthat provably generalize compositionally. We validate our theoretical result\nand highlight the practical relevance of our assumptions through experiments on\nsynthetic image data.\n","authors":["Thadd√§us Wiedemer","Jack Brady","Alexander Panfilov","Attila Juhos","Matthias Bethge","Wieland Brendel"],"pdf_url":"https://arxiv.org/pdf/2310.05327v2.pdf","comment":"Oral at ICLR 2024. The first four authors contributed equally"},{"id":"http://arxiv.org/abs/2306.10084v3","updated":"2024-11-12T15:32:40Z","published":"2023-06-16T11:57:11Z","title":"Convolutional and Deep Learning based techniques for Time Series Ordinal\n  Classification","summary":"  Time Series Classification (TSC) covers the supervised learning problem where\ninput data is provided in the form of series of values observed through\nrepeated measurements over time, and whose objective is to predict the category\nto which they belong. When the class values are ordinal, classifiers that take\nthis into account can perform better than nominal classifiers. Time Series\nOrdinal Classification (TSOC) is the field covering this gap, yet unexplored in\nthe literature. There are a wide range of time series problems showing an\nordered label structure, and TSC techniques that ignore the order relationship\ndiscard useful information. Hence, this paper presents a first benchmarking of\nTSOC methodologies, exploiting the ordering of the target labels to boost the\nperformance of current TSC state-of-the-art. Both convolutional- and deep\nlearning-based methodologies (among the best performing alternatives for\nnominal TSC) are adapted for TSOC. For the experiments, a selection of 29\nordinal problems from two well-known archives has been made. In this way, this\npaper contributes to the establishment of the state-of-the-art in TSOC. The\nresults obtained by ordinal versions are found to be significantly better than\ncurrent nominal TSC techniques in terms of ordinal performance metrics,\noutlining the importance of considering the ordering of the labels when dealing\nwith this kind of problems.\n","authors":["Rafael Ayll√≥n-Gavil√°n","David Guijo-Rubio","Pedro Antonio Guti√©rrez","Anthony Bagnall","C√©sar Herv√°s-Mart√≠nez"],"pdf_url":"https://arxiv.org/pdf/2306.10084v3.pdf","comment":"13 pages, 9 figures, 2 tables"},{"id":"http://arxiv.org/abs/2410.00171v2","updated":"2024-11-12T15:30:15Z","published":"2024-09-30T19:18:34Z","title":"Basis-to-Basis Operator Learning Using Function Encoders","summary":"  We present Basis-to-Basis (B2B) operator learning, a novel approach for\nlearning operators on Hilbert spaces of functions based on the foundational\nideas of function encoders. We decompose the task of learning operators into\ntwo parts: learning sets of basis functions for both the input and output\nspaces and learning a potentially nonlinear mapping between the coefficients of\nthe basis functions. B2B operator learning circumvents many challenges of prior\nworks, such as requiring data to be at fixed locations, by leveraging classic\ntechniques such as least squares to compute the coefficients. It is especially\npotent for linear operators, where we compute a mapping between bases as a\nsingle matrix transformation with a closed-form solution. Furthermore, with\nminimal modifications and using the deep theoretical connections between\nfunction encoders and functional analysis, we derive operator learning\nalgorithms that are directly analogous to eigen-decomposition and singular\nvalue decomposition. We empirically validate B2B operator learning on seven\nbenchmark operator learning tasks and show that it demonstrates a\ntwo-orders-of-magnitude improvement in accuracy over existing approaches on\nseveral benchmark tasks.\n","authors":["Tyler Ingebrand","Adam J. Thorpe","Somdatta Goswami","Krishna Kumar","Ufuk Topcu"],"pdf_url":"https://arxiv.org/pdf/2410.00171v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07873v1","updated":"2024-11-12T15:29:50Z","published":"2024-11-12T15:29:50Z","title":"Diverse capability and scaling of diffusion and auto-regressive models\n  when learning abstract rules","summary":"  Humans excel at discovering regular structures from limited samples and\napplying inferred rules to novel settings. We investigate whether modern\ngenerative models can similarly learn underlying rules from finite samples and\nperform reasoning through conditional sampling. Inspired by Raven's Progressive\nMatrices task, we designed GenRAVEN dataset, where each sample consists of\nthree rows, and one of 40 relational rules governing the object position,\nnumber, or attributes applies to all rows. We trained generative models to\nlearn the data distribution, where samples are encoded as integer arrays to\nfocus on rule learning. We compared two generative model families: diffusion\n(EDM, DiT, SiT) and autoregressive models (GPT2, Mamba). We evaluated their\nability to generate structurally consistent samples and perform panel\ncompletion via unconditional and conditional sampling. We found diffusion\nmodels excel at unconditional generation, producing more novel and consistent\nsamples from scratch and memorizing less, but performing less well in panel\ncompletion, even with advanced conditional sampling methods. Conversely,\nautoregressive models excel at completing missing panels in a rule-consistent\nmanner but generate less consistent samples unconditionally. We observe diverse\ndata scaling behaviors: for both model families, rule learning emerges at a\ncertain dataset size - around 1000s examples per rule. With more training data,\ndiffusion models improve both their unconditional and conditional generation\ncapabilities. However, for autoregressive models, while panel completion\nimproves with more training data, unconditional generation consistency\ndeclines. Our findings highlight complementary capabilities and limitations of\ndiffusion and autoregressive models in rule learning and reasoning tasks,\nsuggesting avenues for further research into their mechanisms and potential for\nhuman-like reasoning.\n","authors":["Binxu Wang","Jiaqi Shang","Haim Sompolinsky"],"pdf_url":"https://arxiv.org/pdf/2411.07873v1.pdf","comment":"12 pages, 5 figures. Accepted to NeurIPS2024 Workshop on System 2\n  Reasoning At Scale as long paper"},{"id":"http://arxiv.org/abs/2411.07863v1","updated":"2024-11-12T15:22:14Z","published":"2024-11-12T15:22:14Z","title":"CDXFormer: Boosting Remote Sensing Change Detection with Extended Long\n  Short-Term Memory","summary":"  In complex scenes and varied conditions, effectively integrating\nspatial-temporal context is crucial for accurately identifying changes.\nHowever, current RS-CD methods lack a balanced consideration of performance and\nefficiency. CNNs lack global context, Transformers have quadratic computational\ncomplexity, and Mambas are restricted by CUDA acceleration. In this paper, we\npropose CDXFormer, with a core component that is a powerful XLSTM-based feature\nenhancement layer, integrating the advantages of linear computational\ncomplexity, global context perception, and strong interpret-ability.\nSpecifically, we introduce a scale-specific Feature Enhancer layer,\nincorporating a Cross-Temporal Global Perceptron customized for\nsemantic-accurate deep features, and a Cross-Temporal Spatial Refiner\ncustomized for detail-rich shallow features. Additionally, we propose a\nCross-Scale Interactive Fusion module to progressively interact global change\nrepresentations with spatial responses. Extensive experimental results\ndemonstrate that CDXFormer achieves state-of-the-art performance across three\nbenchmark datasets, offering a compelling balance between efficiency and\naccuracy. Code is available at https://github.com/xwmaxwma/rschange.\n","authors":["Zhenkai Wu","Xiaowen Ma","Rongrong Lian","Zhentao Lin","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07863v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.04492v4","updated":"2024-11-12T15:16:36Z","published":"2024-10-06T14:11:39Z","title":"Interpret Your Decision: Logical Reasoning Regularization for\n  Generalization in Visual Classification","summary":"  Vision models excel in image classification but struggle to generalize to\nunseen data, such as classifying images from unseen domains or discovering\nnovel categories. In this paper, we explore the relationship between logical\nreasoning and deep learning generalization in visual classification. A logical\nregularization termed L-Reg is derived which bridges a logical analysis\nframework to image classification. Our work reveals that L-Reg reduces the\ncomplexity of the model in terms of the feature distribution and classifier\nweights. Specifically, we unveil the interpretability brought by L-Reg, as it\nenables the model to extract the salient features, such as faces to persons,\nfor classification. Theoretical analysis and experiments demonstrate that L-Reg\nenhances generalization across various scenarios, including multi-domain\ngeneralization and generalized category discovery. In complex real-world\nscenarios where images span unknown classes and unseen domains, L-Reg\nconsistently improves generalization, highlighting its practical efficacy.\n","authors":["Zhaorui Tan","Xi Yang","Qiufeng Wang","Anh Nguyen","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2410.04492v4.pdf","comment":"Accepted by NeurIPS2024 as Spotlight"},{"id":"http://arxiv.org/abs/2411.07854v1","updated":"2024-11-12T15:06:06Z","published":"2024-11-12T15:06:06Z","title":"Tucano: Advancing Neural Text Generation for Portuguese","summary":"  Significant advances have been made in natural language processing in recent\nyears. However, our current deep learning approach to language modeling\nrequires substantial resources in terms of data and computation. One of the\nside effects of this data-hungry paradigm is the current schism between\nlanguages, separating those considered high-resource, where most of the\ndevelopment happens and resources are available, and the low-resource ones,\nwhich struggle to attain the same level of performance and autonomy. This study\naims to introduce a new set of resources to stimulate the future development of\nneural text generation in Portuguese. In this work, we document the development\nof GigaVerbo, a concatenation of deduplicated Portuguese text corpora amounting\nto 200 billion tokens. Via this corpus, we trained a series of\ndecoder-transformers named Tucano. Our models perform equal or superior to\nother Portuguese and multilingual language models of similar size in several\nPortuguese benchmarks. The evaluation of our models also reveals that model\nperformance on many currently available benchmarks used by the Portuguese NLP\ncommunity has little to no correlation with the scaling of token ingestion\nduring training, highlighting the limitations of such evaluations when it comes\nto the assessment of Portuguese generative language models. All derivatives of\nour study are openly released on GitHub and Hugging Face. See\nhttps://nkluge-correa.github.io/Tucano/\n","authors":["Nicholas Kluge Corr√™a","Aniket Sen","Sophia Falk","Shiza Fatimah"],"pdf_url":"https://arxiv.org/pdf/2411.07854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07853v1","updated":"2024-11-12T15:06:04Z","published":"2024-11-12T15:06:04Z","title":"Evidential time-to-event prediction model with well-calibrated\n  uncertainty estimation","summary":"  Time-to-event analysis, or Survival analysis, provides valuable insights into\nclinical prognosis and treatment recommendations. However, this task is\ntypically more challenging than other regression tasks due to the censored\nobservations. Moreover, concerns regarding the reliability of predictions\npersist among clinicians, mainly attributed to the absence of confidence\nassessment, robustness, and calibration of prediction. To address those\nchallenges, we introduce an evidential regression model designed especially for\ntime-to-event prediction tasks, with which the most plausible event time, is\ndirectly quantified by aggregated Gaussian random fuzzy numbers (GRFNs). The\nGRFNs are a newly introduced family of random fuzzy subsets of the real line\nthat generalizes both Gaussian random variables and Gaussian possibility\ndistributions. Different from conventional methods that construct models based\non strict data distribution, e.g., proportional hazard function, our model only\nassumes the event time is encoded in a real line GFRN without any strict\ndistribution assumption, therefore offering more flexibility in complex data\nscenarios. Furthermore, the epistemic and aleatory uncertainty regarding the\nevent time is quantified within the aggregated GRFN as well. Our model can,\ntherefore, provide more detailed clinical decision-making guidance with two\nmore degrees of information. The model is fit by minimizing a generalized\nnegative log-likelihood function that accounts for data censoring based on\nuncertainty evidence reasoning. Experimental results on simulated datasets with\nvarying data distributions and censoring scenarios, as well as on real-world\ndatasets across diverse clinical settings and tasks, demonstrate that our model\nachieves both accurate and reliable performance, outperforming state-of-the-art\nmethods.\n","authors":["Ling Huang","Yucheng Xing","Swapnil Mishra","Thierry Denoeux","Mengling Feng"],"pdf_url":"https://arxiv.org/pdf/2411.07853v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.05225v5","updated":"2024-11-12T15:05:00Z","published":"2024-06-07T19:25:02Z","title":"A Manifold Perspective on the Statistical Generalization of Graph Neural\n  Networks","summary":"  Graph Neural Networks (GNNs) extend convolutional neural networks to operate\non graphs. Despite their impressive performances in various graph learning\ntasks, the theoretical understanding of their generalization capability is\nstill lacking. Previous GNN generalization bounds ignore the underlying graph\nstructures, often leading to bounds that increase with the number of nodes -- a\nbehavior contrary to the one experienced in practice. In this paper, we take a\nmanifold perspective to establish the statistical generalization theory of GNNs\non graphs sampled from a manifold in the spectral domain. As demonstrated\nempirically, we prove that the generalization bounds of GNNs decrease linearly\nwith the size of the graphs in the logarithmic scale, and increase linearly\nwith the spectral continuity constants of the filter functions. Notably, our\ntheory explains both node-level and graph-level tasks. Our result has two\nimplications: i) guaranteeing the generalization of GNNs to unseen data over\nmanifolds; ii) providing insights into the practical design of GNNs, i.e.,\nrestrictions on the discriminability of GNNs are necessary to obtain a better\ngeneralization performance. We demonstrate our generalization bounds of GNNs\nusing synthetic and multiple real-world datasets.\n","authors":["Zhiyang Wang","Juan Cervino","Alejandro Ribeiro"],"pdf_url":"https://arxiv.org/pdf/2406.05225v5.pdf","comment":"37 pages,25 figures, 10 tables"},{"id":"http://arxiv.org/abs/2402.11658v3","updated":"2024-11-12T15:03:48Z","published":"2024-02-18T17:32:53Z","title":"Dynamic planning in hierarchical active inference","summary":"  By dynamic planning, we refer to the ability of the human brain to infer and\nimpose motor trajectories related to cognitive decisions. A recent paradigm,\nactive inference, brings fundamental insights into the adaptation of biological\norganisms, constantly striving to minimize prediction errors to restrict\nthemselves to life-compatible states. Over the past years, many studies have\nshown how human and animal behaviors could be explained in terms of active\ninference - either as discrete decision-making or continuous motor control -\ninspiring innovative solutions in robotics and artificial intelligence. Still,\nthe literature lacks a comprehensive outlook on effectively planning realistic\nactions in changing environments. Setting ourselves the goal of modeling\ncomplex tasks such as tool use, we delve into the topic of dynamic planning in\nactive inference, keeping in mind two crucial aspects of biological behavior:\nthe capacity to understand and exploit affordances for object manipulation, and\nto learn the hierarchical interactions between the self and the environment,\nincluding other agents. We start from a simple unit and gradually describe more\nadvanced structures, comparing recently proposed design choices and providing\nbasic examples. This study distances itself from traditional views centered on\nneural networks and reinforcement learning, and points toward a yet unexplored\ndirection in active inference: hybrid representations in hierarchical models.\n","authors":["Matteo Priorelli","Ivilin Peev Stoianov"],"pdf_url":"https://arxiv.org/pdf/2402.11658v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.12203v3","updated":"2024-11-12T15:00:37Z","published":"2024-03-18T19:25:57Z","title":"Bootstrapping Reinforcement Learning with Imitation for Vision-Based\n  Agile Flight","summary":"  Learning visuomotor policies for agile quadrotor flight presents significant\ndifficulties, primarily from inefficient policy exploration caused by\nhigh-dimensional visual inputs and the need for precise and low-latency\ncontrol. To address these challenges, we propose a novel approach that combines\nthe performance of Reinforcement Learning (RL) and the sample efficiency of\nImitation Learning (IL) in the task of vision-based autonomous drone racing.\nWhile RL provides a framework for learning high-performance controllers through\ntrial and error, it faces challenges with sample efficiency and computational\ndemands due to the high dimensionality of visual inputs. Conversely, IL\nefficiently learns from visual expert demonstrations, but it remains limited by\nthe expert's performance and state distribution. To overcome these limitations,\nour policy learning framework integrates the strengths of both approaches. Our\nframework contains three phases: training a teacher policy using RL with\nprivileged state information, distilling it into a student policy via IL, and\nadaptive fine-tuning via RL. Testing in both simulated and real-world scenarios\nshows our approach can not only learn in scenarios where RL from scratch fails\nbut also outperforms existing IL methods in both robustness and performance,\nsuccessfully navigating a quadrotor through a race course using only visual\ninformation. Videos of the experiments are available at\nhttps://rpg.ifi.uzh.ch/bootstrap-rl-with-il/index.html.\n","authors":["Jiaxu Xing","Angel Romero","Leonard Bauersfeld","Davide Scaramuzza"],"pdf_url":"https://arxiv.org/pdf/2403.12203v3.pdf","comment":"8th Annual Conference on Robot Learning (CoRL)"},{"id":"http://arxiv.org/abs/2402.14585v2","updated":"2024-11-12T14:58:48Z","published":"2024-02-22T14:38:52Z","title":"Bandits with Abstention under Expert Advice","summary":"  We study the classic problem of prediction with expert advice under bandit\nfeedback. Our model assumes that one action, corresponding to the learner's\nabstention from play, has no reward or loss on every trial. We propose the CBA\nalgorithm, which exploits this assumption to obtain reward bounds that can\nsignificantly improve those of the classical Exp4 algorithm. We can view our\nproblem as the aggregation of confidence-rated predictors when the learner has\nthe option of abstention from play. Importantly, we are the first to achieve\nbounds on the expected cumulative reward for general confidence-rated\npredictors. In the special case of specialists we achieve a novel reward bound,\nsignificantly improving previous bounds of SpecialistExp (treating abstention\nas another action). As an example application, we discuss learning unions of\nballs in a finite metric space. In this contextual setting, we devise an\nefficient implementation of CBA, reducing the runtime from quadratic to almost\nlinear in the number of contexts. Preliminary experiments show that CBA\nimproves over existing bandit algorithms.\n","authors":["Stephen Pasteris","Alberto Rumi","Maximilian Thiessen","Shota Saito","Atsushi Miyauchi","Fabio Vitale","Mark Herbster"],"pdf_url":"https://arxiv.org/pdf/2402.14585v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14803v3","updated":"2024-11-12T14:57:08Z","published":"2024-10-18T18:19:56Z","title":"DistRL: An Asynchronous Distributed Reinforcement Learning Framework for\n  On-Device Control Agents","summary":"  On-device control agents, especially on mobile devices, are responsible for\noperating mobile devices to fulfill users' requests, enabling seamless and\nintuitive interactions. Integrating Multimodal Large Language Models (MLLMs)\ninto these agents enhances their ability to understand and execute complex\ncommands, thereby improving user experience. However, fine-tuning MLLMs for\non-device control presents significant challenges due to limited data\navailability and inefficient online training processes. This paper introduces\nDistRL, a novel framework designed to enhance the efficiency of online RL\nfine-tuning for mobile device control agents. DistRL employs centralized\ntraining and decentralized data acquisition to ensure efficient fine-tuning in\nthe context of dynamic online interactions. Additionally, the framework is\nbacked by our tailor-made RL algorithm, which effectively balances exploration\nwith the prioritized utilization of collected data to ensure stable and robust\ntraining. Our experiments show that, on average, DistRL delivers a 3X\nimprovement in training efficiency and enables training data collection 2.4X\nfaster than the leading synchronous multi-machine methods. Notably, after\ntraining, DistRL achieves a 20% relative improvement in success rate compared\nto state-of-the-art methods on general Android tasks from an open benchmark,\nsignificantly outperforming existing approaches while maintaining the same\ntraining time. These results validate DistRL as a scalable and efficient\nsolution, offering substantial improvements in both training efficiency and\nagent performance for real-world, in-the-wild device control tasks.\n","authors":["Taiyi Wang","Zhihao Wu","Jianheng Liu","Jianye Hao","Jun Wang","Kun Shao"],"pdf_url":"https://arxiv.org/pdf/2410.14803v3.pdf","comment":"Paper and Appendix, 25 pages"},{"id":"http://arxiv.org/abs/2410.20178v2","updated":"2024-11-12T14:45:18Z","published":"2024-10-26T13:19:57Z","title":"LLMs Can Evolve Continually on Modality for X-Modal Reasoning","summary":"  Multimodal Large Language Models (MLLMs) have gained significant attention\ndue to their impressive capabilities in multimodal understanding. However,\nexisting methods rely heavily on extensive modal-specific pretraining and\njoint-modal tuning, leading to significant computational burdens when expanding\nto new modalities. In this paper, we propose PathWeave, a flexible and scalable\nframework with modal-Path sWitching and ExpAnsion abilities that enables MLLMs\nto continually EVolve on modalities for $\\mathbb{X}$-modal reasoning. We\nleverage the concept of Continual Learning and develop an incremental training\nstrategy atop pre-trained MLLMs, enabling their expansion to new modalities\nusing uni-modal data, without executing joint-modal pretraining. In detail, a\nnovel Adapter-in-Adapter (AnA) framework is introduced, in which uni-modal and\ncross-modal adapters are seamlessly integrated to facilitate efficient modality\nalignment and collaboration. Additionally, an MoE-based gating module is\napplied between two types of adapters to further enhance the multimodal\ninteraction. To investigate the proposed method, we establish a challenging\nbenchmark called Continual Learning of Modality (MCL), which consists of\nhigh-quality QA data from five distinct modalities: image, video, audio, depth\nand point cloud. Extensive experiments demonstrate the effectiveness of the\nproposed AnA framework on learning plasticity and memory stability during\ncontinual learning. Furthermore, PathWeave performs comparably to\nstate-of-the-art MLLMs while concurrently reducing parameter training burdens\nby 98.73%. Our code locates at https://github.com/JiazuoYu/PathWeave\n","authors":["Jiazuo Yu","Haomiao Xiong","Lu Zhang","Haiwen Diao","Yunzhi Zhuge","Lanqing Hong","Dong Wang","Huchuan Lu","You He","Long Chen"],"pdf_url":"https://arxiv.org/pdf/2410.20178v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07837v1","updated":"2024-11-12T14:41:07Z","published":"2024-11-12T14:41:07Z","title":"FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for\n  Scalable Training","summary":"  With the increase in the number of parameters in large language models, the\nprocess of pre-training and fine-tuning increasingly demands larger volumes of\nGPU memory. A significant portion of this memory is typically consumed by the\noptimizer state. To overcome this challenge, recent approaches such as low-rank\nadaptation (LoRA (Hu et al., 2021)), low-rank gradient projection (GaLore (Zhao\net al., 2024)), and blockwise optimization (BAdam (Luo et al., 2024)) have been\nproposed. However, in all these algorithms, the $\\textit{effective rank of the\nweight updates remains low-rank}$, which can lead to a substantial loss of\ninformation from the gradient. This loss can be critically important,\nespecially during the pre-training stage. In this paper, we introduce\n$\\texttt{FRUGAL}$ ($\\textbf{F}$ull-$\\textbf{R}$ank $\\textbf{U}$pdates with\n$\\textbf{G}$r$\\textbf{A}$dient sp$\\textbf{L}$itting), a new memory-efficient\noptimization framework. $\\texttt{FRUGAL}$ leverages gradient splitting to\nperform low-dimensional updates using advanced algorithms (such as Adam), while\nupdates along the remaining directions are executed via state-free methods like\nSGD or signSGD (Bernstein et al., 2018). Our framework can be integrated with\nvarious low-rank update selection techniques, including GaLore and BAdam. We\nprovide theoretical convergence guarantees for our framework when using SGDM\nfor low-dimensional updates and SGD for state-free updates. Additionally, our\nmethod consistently outperforms concurrent approaches across various fixed\nmemory budgets, achieving state-of-the-art results in pre-training and\nfine-tuning tasks while balancing memory efficiency and performance metrics.\n","authors":["Philip Zmushko","Aleksandr Beznosikov","Martin Tak√°ƒç","Samuel Horv√°th"],"pdf_url":"https://arxiv.org/pdf/2411.07837v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.12550v2","updated":"2024-11-12T14:39:29Z","published":"2024-07-17T13:31:13Z","title":"UniTE: A Survey and Unified Pipeline for Pre-training Spatiotemporal\n  Trajectory Embeddings","summary":"  Spatiotemporal trajectories are sequences of timestamped locations, which\nenable a variety of analyses that in turn enable important real-world\napplications. It is common to map trajectories to vectors, called embeddings,\nbefore subsequent analyses. Thus, the qualities of embeddings are very\nimportant. Methods for pre-training embeddings, which leverage unlabeled\ntrajectories for training universal embeddings, have shown promising\napplicability across different tasks, thus attracting considerable interest.\nHowever, research progress on this topic faces two key challenges: a lack of a\ncomprehensive overview of existing methods, resulting in several related\nmethods not being well-recognized, and the absence of a unified pipeline,\ncomplicating the development of new methods and the analysis of methods.\n  We present UniTE, a survey and a unified pipeline for this domain. In doing\nso, we present a comprehensive list of existing methods for pre-training\ntrajectory embeddings, which includes methods that either explicitly or\nimplicitly employ pre-training techniques. Further, we present a unified and\nmodular pipeline with publicly available underlying code, simplifying the\nprocess of constructing and evaluating methods for pre-training trajectory\nembeddings. Additionally, we contribute a selection of experimental results\nusing the proposed pipeline on real-world datasets. Implementation of the\npipeline is publicly available at https://github.com/Logan-Lin/UniTE.\n","authors":["Yan Lin","Zeyu Zhou","Yicheng Liu","Haochen Lv","Haomin Wen","Tianyi Li","Yushuai Li","Christian S. Jensen","Shengnan Guo","Youfang Lin","Huaiyu Wan"],"pdf_url":"https://arxiv.org/pdf/2407.12550v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07832v1","updated":"2024-11-12T14:27:45Z","published":"2024-11-12T14:27:45Z","title":"Dynamical-VAE-based Hindsight to Learn the Causal Dynamics of\n  Factored-POMDPs","summary":"  Learning representations of underlying environmental dynamics from partial\nobservations is a critical challenge in machine learning. In the context of\nPartially Observable Markov Decision Processes (POMDPs), state representations\nare often inferred from the history of past observations and actions. We\ndemonstrate that incorporating future information is essential to accurately\ncapture causal dynamics and enhance state representations. To address this, we\nintroduce a Dynamical Variational Auto-Encoder (DVAE) designed to learn causal\nMarkovian dynamics from offline trajectories in a POMDP. Our method employs an\nextended hindsight framework that integrates past, current, and multi-step\nfuture information within a factored-POMDP setting. Empirical results reveal\nthat this approach uncovers the causal graph governing hidden state transitions\nmore effectively than history-based and typical hindsight-based models.\n","authors":["Chao Han","Debabrota Basu","Michael Mangan","Eleni Vasilaki","Aditya Gilra"],"pdf_url":"https://arxiv.org/pdf/2411.07832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07828v1","updated":"2024-11-12T14:23:52Z","published":"2024-11-12T14:23:52Z","title":"Suite-IN: Aggregating Motion Features from Apple Suite for Robust\n  Inertial Navigation","summary":"  With the rapid development of wearable technology, devices like smartphones,\nsmartwatches, and headphones equipped with IMUs have become essential for\napplications such as pedestrian positioning. However, traditional pedestrian\ndead reckoning (PDR) methods struggle with diverse motion patterns, while\nrecent data-driven approaches, though improving accuracy, often lack robustness\ndue to reliance on a single device.In our work, we attempt to enhance the\npositioning performance using the low-cost commodity IMUs embedded in the\nwearable devices. We propose a multi-device deep learning framework named\nSuite-IN, aggregating motion data from Apple Suite for inertial navigation.\nMotion data captured by sensors on different body parts contains both local and\nglobal motion information, making it essential to reduce the negative effects\nof localized movements and extract global motion representations from multiple\ndevices.\n","authors":["Lan Sun","Songpengcheng Xia","Junyuan Deng","Jiarui Yang","Zengyuan Lai","Qi Wu","Ling Pei"],"pdf_url":"https://arxiv.org/pdf/2411.07828v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07826v1","updated":"2024-11-12T14:22:16Z","published":"2024-11-12T14:22:16Z","title":"Efficient Federated Finetuning of Tiny Transformers with\n  Resource-Constrained Devices","summary":"  In recent years, Large Language Models (LLMs) through Transformer structures\nhave dominated many machine learning tasks, especially text processing.\nHowever, these models require massive amounts of data for training and induce\nhigh resource requirements, particularly in terms of the large number of\nFloating Point Operations (FLOPs) and the high amounts of memory needed. To\nfine-tune such a model in a parameter-efficient way, techniques like Adapter or\nLoRA have been developed. However, we observe that the application of LoRA,\nwhen used in federated learning (FL), while still being parameter-efficient, is\nmemory and FLOP inefficient. Based on that observation, we develop a novel\nlayer finetuning scheme that allows devices in cross-device FL to make use of\npretrained neural networks (NNs) while adhering to given resource constraints.\nWe show that our presented scheme outperforms the current state of the art when\ndealing with homogeneous or heterogeneous computation and memory constraints\nand is on par with LoRA regarding limited communication, thereby achieving\nsignificantly higher accuracies in FL training.\n","authors":["Kilian Pfeiffer","Mohamed Aboelenien Ahmed","Ramin Khalili","J√∂rg Henkel"],"pdf_url":"https://arxiv.org/pdf/2411.07826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03163v2","updated":"2024-11-12T14:18:51Z","published":"2024-11-05T15:07:20Z","title":"Efficient Hamiltonian, structure and trace distance learning of Gaussian\n  states","summary":"  In this work, we initiate the study of Hamiltonian learning for positive\ntemperature bosonic Gaussian states, the quantum generalization of the widely\nstudied problem of learning Gaussian graphical models. We obtain efficient\nprotocols, both in sample and computational complexity, for the task of\ninferring the parameters of their underlying quadratic Hamiltonian under the\nassumption of bounded temperature, squeezing, displacement and maximal degree\nof the interaction graph. Our protocol only requires heterodyne measurements,\nwhich are often experimentally feasible, and has a sample complexity that\nscales logarithmically with the number of modes. Furthermore, we show that it\nis possible to learn the underlying interaction graph in a similar setting and\nsample complexity. Taken together, our results put the status of the quantum\nHamiltonian learning problem for continuous variable systems in a much more\nadvanced state when compared to spins, where state-of-the-art results are\neither unavailable or quantitatively inferior to ours. In addition, we use our\ntechniques to obtain the first results on learning Gaussian states in trace\ndistance with a quadratic scaling in precision and polynomial in the number of\nmodes, albeit imposing certain restrictions on the Gaussian states. Our main\ntechnical innovations are several continuity bounds for the covariance and\nHamiltonian matrix of a Gaussian state, which are of independent interest,\ncombined with what we call the local inversion technique. In essence, the local\ninversion technique allows us to reliably infer the Hamiltonian of a Gaussian\nstate by only estimating in parallel submatrices of the covariance matrix whose\nsize scales with the desired precision, but not the number of modes. This way\nwe bypass the need to obtain precise global estimates of the covariance matrix,\ncontrolling the sample complexity.\n","authors":["Marco Fanizza","Cambyse Rouz√©","Daniel Stilck Fran√ßa"],"pdf_url":"https://arxiv.org/pdf/2411.03163v2.pdf","comment":"43 pages, 1 figure. Corrections to Lemma 4.1. Main results are\n  unchanged"},{"id":"http://arxiv.org/abs/2411.07816v1","updated":"2024-11-12T14:09:16Z","published":"2024-11-12T14:09:16Z","title":"Dual-Criterion Model Aggregation in Federated Learning: Balancing Data\n  Quantity and Quality","summary":"  Federated learning (FL) has become one of the key methods for\nprivacy-preserving collaborative learning, as it enables the transfer of models\nwithout requiring local data exchange. Within the FL framework, an aggregation\nalgorithm is recognized as one of the most crucial components for ensuring the\nefficacy and security of the system. Existing average aggregation algorithms\ntypically assume that all client-trained data holds equal value or that weights\nare based solely on the quantity of data contributed by each client. In\ncontrast, alternative approaches involve training the model locally after\naggregation to enhance adaptability. However, these approaches fundamentally\nignore the inherent heterogeneity between different clients' data and the\ncomplexity of variations in data at the aggregation stage, which may lead to a\nsuboptimal global model.\n  To address these issues, this study proposes a novel dual-criterion weighted\naggregation algorithm involving the quantity and quality of data from the\nclient node. Specifically, we quantify the data used for training and perform\nmultiple rounds of local model inference accuracy evaluation on a specialized\ndataset to assess the data quality of each client. These two factors are\nutilized as weights within the aggregation process, applied through a\ndynamically weighted summation of these two factors. This approach allows the\nalgorithm to adaptively adjust the weights, ensuring that every client can\ncontribute to the global model, regardless of their data's size or initial\nquality. Our experiments show that the proposed algorithm outperforms several\nexisting state-of-the-art aggregation approaches on both a general-purpose\nopen-source dataset, CIFAR-10, and a dataset specific to visual obstacle\navoidance.\n","authors":["Haizhou Zhang","Xianjia Yu","Tomi Westerlund"],"pdf_url":"https://arxiv.org/pdf/2411.07816v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2411.07806v1","updated":"2024-11-12T14:01:08Z","published":"2024-11-12T14:01:08Z","title":"Federated Low-Rank Adaptation with Differential Privacy over Wireless\n  Networks","summary":"  Fine-tuning large pre-trained foundation models (FMs) on distributed edge\ndevices presents considerable computational and privacy challenges. Federated\nfine-tuning (FedFT) mitigates some privacy issues by facilitating collaborative\nmodel training without the need to share raw data. To lessen the computational\nburden on resource-limited devices, combining low-rank adaptation (LoRA) with\nfederated learning enables parameter-efficient fine-tuning. Additionally, the\nsplit FedFT architecture partitions an FM between edge devices and a central\nserver, reducing the necessity for complete model deployment on individual\ndevices. However, the risk of privacy eavesdropping attacks in FedFT remains a\nconcern, particularly in sensitive areas such as healthcare and finance. In\nthis paper, we propose a split FedFT framework with differential privacy (DP)\nover wireless networks, where the inherent wireless channel noise in the uplink\ntransmission is utilized to achieve DP guarantees without adding an extra\nartificial noise. We shall investigate the impact of the wireless noise on\nconvergence performance of the proposed framework. We will also show that by\nupdating only one of the low-rank matrices in the split FedFT with DP, the\nproposed method can mitigate the noise amplification effect. Simulation results\nwill demonstrate that the proposed framework achieves higher accuracy under\nstrict privacy budgets compared to baseline methods.\n","authors":["Tianqu Kang","Zixin Wang","Hengtao He","Jun Zhang","Shenghui Song","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2411.07806v1.pdf","comment":"6 pages, 3 figures, submitted to IEEE ICC 2025"},{"id":"http://arxiv.org/abs/2408.12970v2","updated":"2024-11-12T13:56:33Z","published":"2024-08-23T10:36:08Z","title":"SUMO: Search-Based Uncertainty Estimation for Model-Based Offline\n  Reinforcement Learning","summary":"  The performance of offline reinforcement learning (RL) suffers from the\nlimited size and quality of static datasets. Model-based offline RL addresses\nthis issue by generating synthetic samples through a dynamics model to enhance\noverall performance. To evaluate the reliability of the generated samples,\nuncertainty estimation methods are often employed. However, model ensemble, the\nmost commonly used uncertainty estimation method, is not always the best\nchoice. In this paper, we propose a \\textbf{S}earch-based \\textbf{U}ncertainty\nestimation method for \\textbf{M}odel-based \\textbf{O}ffline RL (SUMO) as an\nalternative. SUMO characterizes the uncertainty of synthetic samples by\nmeasuring their cross entropy against the in-distribution dataset samples, and\nuses an efficient search-based method for implementation. In this way, SUMO can\nachieve trustworthy uncertainty estimation. We integrate SUMO into several\nmodel-based offline RL algorithms including MOPO and Adapted MOReL (AMOReL),\nand provide theoretical analysis for them. Extensive experimental results on\nD4RL datasets demonstrate that SUMO can provide more accurate uncertainty\nestimation and boost the performance of base algorithms. These indicate that\nSUMO could be a better uncertainty estimator for model-based offline RL when\nused in either reward penalty or trajectory truncation. Our code is available\nand will be open-source for further research and development.\n","authors":["Zhongjian Qiao","Jiafei Lyu","Kechen Jiao","Qi Liu","Xiu Li"],"pdf_url":"https://arxiv.org/pdf/2408.12970v2.pdf","comment":"Submitted to AAAI2025"},{"id":"http://arxiv.org/abs/2411.07800v1","updated":"2024-11-12T13:54:13Z","published":"2024-11-12T13:54:13Z","title":"Kernel-based retrieval models for hyperspectral image data optimized\n  with Kernel Flows","summary":"  Kernel-based statistical methods are efficient, but their performance depends\nheavily on the selection of kernel parameters. In literature, the optimization\nstudies on kernel-based chemometric methods is limited and often reduced to\ngrid searching. Previously, the authors introduced Kernel Flows (KF) to learn\nkernel parameters for Kernel Partial Least-Squares (K-PLS) regression. KF is\neasy to implement and helps minimize overfitting. In cases of high collinearity\nbetween spectra and biogeophysical quantities in spectroscopy, simpler methods\nlike Principal Component Regression (PCR) may be more suitable. In this study,\nwe propose a new KF-type approach to optimize Kernel Principal Component\nRegression (K-PCR) and test it alongside KF-PLS. Both methods are benchmarked\nagainst non-linear regression techniques using two hyperspectral remote sensing\ndatasets.\n","authors":["Zina-Sabrina Duma","Tuomas Sihvonen","Jouni Susiluoto","Otto Lamminp√§√§","Heikki Haario","Satu-Pia Reinikainen"],"pdf_url":"https://arxiv.org/pdf/2411.07800v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.08770v3","updated":"2024-11-12T13:50:05Z","published":"2024-08-16T14:25:20Z","title":"Pessimistic Iterative Planning for Robust POMDPs","summary":"  Robust POMDPs extend classical POMDPs to handle model uncertainty.\nSpecifically, robust POMDPs exhibit so-called uncertainty sets on the\ntransition and observation models, effectively defining ranges of\nprobabilities. Policies for robust POMDPs must be (1) memory-based to account\nfor partial observability and (2) robust against model uncertainty to account\nfor the worst-case instances from the uncertainty sets. To compute such robust\nmemory-based policies, we propose the pessimistic iterative planning (PIP)\nframework, which alternates between two main steps: (1) selecting a pessimistic\n(non-robust) POMDP via worst-case probability instances from the uncertainty\nsets; and (2) computing a finite-state controller (FSC) for this pessimistic\nPOMDP. We evaluate the performance of this FSC on the original robust POMDP and\nuse this evaluation in step (1) to select the next pessimistic POMDP. Within\nPIP, we propose the rFSCNet algorithm. In each iteration, rFSCNet finds an FSC\nthrough a recurrent neural network by using supervision policies optimized for\nthe pessimistic POMDP. The empirical evaluation in four benchmark environments\nshowcases improved robustness against several baseline methods and competitive\nperformance compared to a state-of-the-art robust POMDP solver.\n","authors":["Maris F. L. Galesloot","Marnix Suilen","Thiago D. Sim√£o","Steven Carr","Matthijs T. J. Spaan","Ufuk Topcu","Nils Jansen"],"pdf_url":"https://arxiv.org/pdf/2408.08770v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07796v1","updated":"2024-11-12T13:46:58Z","published":"2024-11-12T13:46:58Z","title":"PatchCTG: Patch Cardiotocography Transformer for Antepartum Fetal Health\n  Monitoring","summary":"  Antepartum Cardiotocography (CTG) is vital for fetal health monitoring, but\ntraditional methods like the Dawes-Redman system are often limited by high\ninter-observer variability, leading to inconsistent interpretations and\npotential misdiagnoses. This paper introduces PatchCTG, a transformer-based\nmodel specifically designed for CTG analysis, employing patch-based\ntokenisation, instance normalisation and channel-independent processing to\ncapture essential local and global temporal dependencies within CTG signals.\nPatchCTG was evaluated on the Oxford Maternity (OXMAT) dataset, comprising over\n20,000 CTG traces across diverse clinical outcomes after applying the inclusion\nand exclusion criteria. With extensive hyperparameter optimisation, PatchCTG\nachieved an AUC of 77%, with specificity of 88% and sensitivity of 57% at\nYouden's index threshold, demonstrating adaptability to various clinical needs.\nTesting across varying temporal thresholds showed robust predictive\nperformance, particularly with finetuning on data closer to delivery, achieving\na sensitivity of 52% and specificity of 88% for near-delivery cases. These\nfindings suggest the potential of PatchCTG to enhance clinical decision-making\nin antepartum care by providing a reliable, objective tool for fetal health\nassessment. The source code is available at\nhttps://github.com/jaleedkhan/PatchCTG.\n","authors":["M. Jaleed Khan","Manu Vatish","Gabriel Davis Jones"],"pdf_url":"https://arxiv.org/pdf/2411.07796v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00426v2","updated":"2024-11-12T13:41:47Z","published":"2024-08-01T09:57:48Z","title":"A Cross-Domain Benchmark for Active Learning","summary":"  Active Learning (AL) deals with identifying the most informative samples for\nlabeling to reduce data annotation costs for supervised learning tasks. AL\nresearch suffers from the fact that lifts from literature generalize poorly and\nthat only a small number of repetitions of experiments are conducted. To\novercome these obstacles, we propose CDALBench, the first active learning\nbenchmark which includes tasks in computer vision, natural language processing\nand tabular learning. Furthermore, by providing an efficient, greedy oracle,\nCDALBench can be evaluated with 50 runs for each experiment. We show, that both\nthe cross-domain character and a large amount of repetitions are crucial for\nsophisticated evaluation of AL research. Concretely, we show that the\nsuperiority of specific methods varies over the different domains, making it\nimportant to evaluate Active Learning with a cross-domain benchmark.\nAdditionally, we show that having a large amount of runs is crucial. With only\nconducting three runs as often done in the literature, the superiority of\nspecific methods can strongly vary with the specific runs. This effect is so\nstrong, that, depending on the seed, even a well-established method's\nperformance can be significantly better and significantly worse than random for\nthe same dataset.\n","authors":["Thorben Werner","Johannes Burchert","Maximilian Stubbemann","Lars Schmidt-Thieme"],"pdf_url":"https://arxiv.org/pdf/2408.00426v2.pdf","comment":"Accepted at NeurIPS 24 in the Benchmarks and Datasets Track. Updated\n  version of paper \"Toward Comparable Active Learning\" (arXiv:2311.18356).\n  \"Toward Comparable Active Learning\" is deprecated, please use this version.\n  arXiv admin note: text overlap with arXiv:2311.18356; text overlap with\n  arXiv:2301.10625 by other authors"},{"id":"http://arxiv.org/abs/2310.04361v4","updated":"2024-11-12T13:35:37Z","published":"2023-10-06T16:34:51Z","title":"Exploiting Activation Sparsity with Dense to Dynamic-k\n  Mixture-of-Experts Conversion","summary":"  Transformer models can face practical limitations due to their high\ncomputational requirements. At the same time, such models exhibit significant\nactivation sparsity, which can be leveraged to reduce the inference cost by\nconverting parts of the network into equivalent Mixture-of-Experts (MoE)\nlayers. Despite the crucial role played by activation sparsity, its impact on\nthis process remains unexplored. We demonstrate that the efficiency of the\nconversion can be significantly enhanced by a proper regularization of the\nactivation sparsity of the base model. Moreover, motivated by the high variance\nof the number of activated neurons for different inputs, we introduce a more\neffective dynamic-$k$ expert selection rule that adjusts the number of executed\nexperts on a per-token basis. To achieve further savings, we extend this\napproach to multi-head attention projections. Finally, we develop an efficient\nimplementation that translates these computational savings into actual\nwall-clock speedup. The proposed method, Dense to Dynamic-$k$\nMixture-of-Experts (D2DMoE), outperforms existing approaches on common NLP and\nvision tasks, reducing inference cost by up to 60% without significantly\nimpacting performance.\n","authors":["Filip Szatkowski","Bartosz W√≥jcik","Miko≈Çaj Pi√≥rczy≈Ñski","Simone Scardapane"],"pdf_url":"https://arxiv.org/pdf/2310.04361v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07784v1","updated":"2024-11-12T13:33:26Z","published":"2024-11-12T13:33:26Z","title":"Interaction Asymmetry: A General Principle for Learning Composable\n  Abstractions","summary":"  Learning disentangled representations of concepts and re-composing them in\nunseen ways is crucial for generalizing to out-of-domain situations. However,\nthe underlying properties of concepts that enable such disentanglement and\ncompositional generalization remain poorly understood. In this work, we propose\nthe principle of interaction asymmetry which states: \"Parts of the same concept\nhave more complex interactions than parts of different concepts\". We formalize\nthis via block diagonality conditions on the $(n+1)$th order derivatives of the\ngenerator mapping concepts to observed data, where different orders of\n\"complexity\" correspond to different $n$. Using this formalism, we prove that\ninteraction asymmetry enables both disentanglement and compositional\ngeneralization. Our results unify recent theoretical results for learning\nconcepts of objects, which we show are recovered as special cases with\n$n\\!=\\!0$ or $1$. We provide results for up to $n\\!=\\!2$, thus extending these\nprior works to more flexible generator functions, and conjecture that the same\nproof strategies generalize to larger $n$. Practically, our theory suggests\nthat, to disentangle concepts, an autoencoder should penalize its latent\ncapacity and the interactions between concepts during decoding. We propose an\nimplementation of these criteria using a flexible Transformer-based VAE, with a\nnovel regularizer on the attention weights of the decoder. On synthetic image\ndatasets consisting of objects, we provide evidence that this model can achieve\ncomparable object disentanglement to existing models that use more explicit\nobject-centric priors.\n","authors":["Jack Brady","Julius von K√ºgelgen","S√©bastien Lachapelle","Simon Buchholz","Thomas Kipf","Wieland Brendel"],"pdf_url":"https://arxiv.org/pdf/2411.07784v1.pdf","comment":"Preprint, under review"},{"id":"http://arxiv.org/abs/2408.08074v2","updated":"2024-11-12T13:26:39Z","published":"2024-08-15T11:01:35Z","title":"A Survey on Integrated Sensing, Communication, and Computation","summary":"  The forthcoming generation of wireless technology, 6G, aims to usher in an\nera of ubiquitous intelligent services, where everything is interconnected and\nintelligent. This vision requires the seamless integration of three fundamental\nmodules: Sensing for information acquisition, communication for information\nsharing, and computation for information processing and decision-making. These\nmodules are intricately linked, especially in complex tasks such as edge\nlearning and inference. However, the performance of these modules is\ninterdependent, creating a resource competition for time, energy, and\nbandwidth. Existing techniques like integrated communication and computation\n(ICC), integrated sensing and computation (ISC), and integrated sensing and\ncommunication (ISAC) have made partial strides in addressing this challenge,\nbut they fall short of meeting the extreme performance requirements. To\novercome these limitations, it is essential to develop new techniques that\ncomprehensively integrate sensing, communication, and computation. This\nintegrated approach, known as Integrated Sensing, Communication, and\nComputation (ISCC), offers a systematic perspective for enhancing task\nperformance. This paper begins with a comprehensive survey of historic and\nrelated techniques such as ICC, ISC, and ISAC, highlighting their strengths and\nlimitations. It then discusses the benefits, functions, and challenges of ISCC.\nSubsequently, the state-of-the-art signal designs for ISCC, along with network\nresource management strategies specifically tailored for ISCC are explored.\nFurthermore, this paper discusses the exciting research opportunities that lie\nahead for implementing ISCC in future advanced networks, and the unresolved\nissues requiring further investigation. ISCC is expected to unlock the full\npotential of intelligent connectivity, paving the way for groundbreaking\napplications and services.\n","authors":["Dingzhu Wen","Yong Zhou","Xiaoyang Li","Yuanming Shi","Kaibin Huang","Khaled B. Letaief"],"pdf_url":"https://arxiv.org/pdf/2408.08074v2.pdf","comment":"In this version, a series of discussions have been added.The\n  benefits, functions, and challenges of ISCC are investigated using a new\n  section. Moreover, the unresolved issues of ISCC have been discussed"},{"id":"http://arxiv.org/abs/2411.07773v1","updated":"2024-11-12T13:14:09Z","published":"2024-11-12T13:14:09Z","title":"Likelihood as a Performance Gauge for Retrieval-Augmented Generation","summary":"  Recent work finds that retrieval-augmented generation with large language\nmodels is prone to be influenced by the order of retrieved documents in the\ncontext. However, the lack of in-depth analysis limits the use of this\nphenomenon for prompt engineering in practice. In this study, we posit that\nlikelihoods serve as an effective gauge for language model performance. Through\nexperiments on two question-answering datasets with a variety of\nstate-of-the-art language models, we reveal correlations between answer\naccuracy and the likelihood of the question at both the corpus level and the\ninstance level. In addition, we find that question likelihood can also indicate\nthe position of the task-relevant information in the context. Based on these\nfindings, we propose two methods that use question likelihood as a gauge for\nselecting and constructing prompts that lead to better performance. We\ndemonstrate their effectiveness with experiments. In addition, our\nlikelihood-based methods are efficient, as they only need to compute the\nlikelihood of the input, requiring much fewer language model passes than\nheuristic prompt engineering methods that require generating responses. Our\nanalysis deepens our understanding of how input prompts affect model\nperformance and provides a promising direction for efficient prompt\noptimization.\n","authors":["Tianyu Liu","Jirui Qi","Paul He","Arianna Bisazza","Mrinmaya Sachan","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07773v1.pdf","comment":"Under review at NAACL 2025. Code is available at\n  https://github.com/lyutyuh/poptimizer"},{"id":"http://arxiv.org/abs/2411.07772v1","updated":"2024-11-12T13:13:20Z","published":"2024-11-12T13:13:20Z","title":"Automatic Album Sequencing","summary":"  Album sequencing is a critical part of the album production process.\nRecently, a data-driven approach was proposed that sequences general\ncollections of independent media by extracting the narrative essence of the\nitems in the collections. While this approach implies an album sequencing\ntechnique, it is not widely accessible to a less technical audience, requiring\nadvanced knowledge of machine learning techniques to use. To address this, we\nintroduce a new user-friendly web-based tool that allows a less technical\naudience to upload music tracks, execute this technique in one click, and\nsubsequently presents the result in a clean visualization to the user. To both\nincrease the number of templates available to the user and address shortcomings\nof previous work, we also introduce a new direct transformer-based album\nsequencing method. We find that our more direct method outperforms a random\nbaseline but does not reach the same performance as the narrative essence\napproach. Both methods are included in our web-based user interface, and this\n-- alongside a full copy of our implementation -- is publicly available at\nhttps://github.com/dylanashley/automatic-album-sequencing\n","authors":["Vincent Herrmann","Dylan R. Ashley","J√ºrgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2411.07772v1.pdf","comment":"presented as a late breaking demo in the 25th International Society\n  for Music Information Retrieval Conference; 3 pages in main text, 3 figures\n  in main text; source code available at\n  https://github.com/dylanashley/automatic-album-sequencing"},{"id":"http://arxiv.org/abs/2411.07762v1","updated":"2024-11-12T12:52:04Z","published":"2024-11-12T12:52:04Z","title":"ASER: Activation Smoothing and Error Reconstruction for Large Language\n  Model Quantization","summary":"  Quantization stands as a pivotal technique for large language model (LLM)\nserving, yet it poses significant challenges particularly in achieving\neffective low-bit quantization. The limited numerical mapping makes the\nquantized model produce a non-trivial error, bringing out intolerable\nperformance degration. This paper is anchored in the basic idea of model\ncompression objectives, and delves into the layer-wise error distribution of\nLLMs during post-training quantization. Subsequently, we introduce ASER, an\nalgorithm consisting of (1) Error Reconstruction: low-rank compensation for\nquantization error with LoRA-style matrices constructed by whitening SVD; (2)\nActivation Smoothing: outlier extraction to gain smooth activation and better\nerror compensation. ASER is capable of quantizing typical LLMs to low-bit ones,\nparticularly preserving accuracy even in W4A8 per-channel setup. Experimental\nresults show that ASER is competitive among the state-of-the-art quantization\nalgorithms, showing potential to activation quantization, with minor overhead.\n","authors":["Weibo Zhao","Yubin Shi","Xinyu Lyu","Wanchen Sui","Shen Li","Yong Li"],"pdf_url":"https://arxiv.org/pdf/2411.07762v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07760v1","updated":"2024-11-12T12:49:41Z","published":"2024-11-12T12:49:41Z","title":"Navigation with QPHIL: Quantizing Planner for Hierarchical Implicit\n  Q-Learning","summary":"  Offline Reinforcement Learning (RL) has emerged as a powerful alternative to\nimitation learning for behavior modeling in various domains, particularly in\ncomplex navigation tasks. An existing challenge with Offline RL is the\nsignal-to-noise ratio, i.e. how to mitigate incorrect policy updates due to\nerrors in value estimates. Towards this, multiple works have demonstrated the\nadvantage of hierarchical offline RL methods, which decouples high-level path\nplanning from low-level path following. In this work, we present a novel\nhierarchical transformer-based approach leveraging a learned quantizer of the\nspace. This quantization enables the training of a simpler zone-conditioned\nlow-level policy and simplifies planning, which is reduced to discrete\nautoregressive prediction. Among other benefits, zone-level reasoning in\nplanning enables explicit trajectory stitching rather than implicit stitching\nbased on noisy value function estimates. By combining this transformer-based\nplanner with recent advancements in offline RL, our proposed approach achieves\nstate-of-the-art results in complex long-distance navigation environments.\n","authors":["Alexi Canesse","Mathieu Petitbois","Ludovic Denoyer","Sylvain Lamprier","R√©my Portelas"],"pdf_url":"https://arxiv.org/pdf/2411.07760v1.pdf","comment":"Under review. Code will be released upon acceptance"},{"id":"http://arxiv.org/abs/2411.02199v4","updated":"2024-11-12T12:44:02Z","published":"2024-11-04T15:54:32Z","title":"Provably Transformers Harness Multi-Concept Word Semantics for Efficient\n  In-Context Learning","summary":"  Transformer-based large language models (LLMs) have displayed remarkable\ncreative prowess and emergence capabilities. Existing empirical studies have\nrevealed a strong connection between these LLMs' impressive emergence abilities\nand their in-context learning (ICL) capacity, allowing them to solve new tasks\nusing only task-specific prompts without further fine-tuning. On the other\nhand, existing empirical and theoretical studies also show that there is a\nlinear regularity of the multi-concept encoded semantic representation behind\ntransformer-based LLMs. However, existing theoretical work fail to build up an\nunderstanding of the connection between this regularity and the innovative\npower of ICL. Additionally, prior work often focuses on simplified, unrealistic\nscenarios involving linear transformers or unrealistic loss functions, and they\nachieve only linear or sub-linear convergence rates. In contrast, this work\nprovides a fine-grained mathematical analysis to show how transformers leverage\nthe multi-concept semantics of words to enable powerful ICL and excellent\nout-of-distribution ICL abilities, offering insights into how transformers\ninnovate solutions for certain unseen tasks encoded with multiple cross-concept\nsemantics. Inspired by empirical studies on the linear latent geometry of LLMs,\nthe analysis is based on a concept-based low-noise sparse coding prompt model.\nLeveraging advanced techniques, this work showcases the exponential 0-1 loss\nconvergence over the highly non-convex training dynamics, which pioneeringly\nincorporates the challenges of softmax self-attention, ReLU-activated MLPs, and\ncross-entropy loss. Empirical simulations corroborate the theoretical findings.\n","authors":["Dake Bu","Wei Huang","Andi Han","Atsushi Nitanda","Taiji Suzuki","Qingfu Zhang","Hau-San Wong"],"pdf_url":"https://arxiv.org/pdf/2411.02199v4.pdf","comment":"Accepted by the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)"},{"id":"http://arxiv.org/abs/2404.19664v4","updated":"2024-11-12T12:43:42Z","published":"2024-04-30T15:57:41Z","title":"Towards Generalist Robot Learning from Internet Video: A Survey","summary":"  Scaling deep learning to massive, diverse internet data has yielded\nremarkably general capabilities in visual and natural language understanding\nand generation. However, data has remained scarce and challenging to collect in\nrobotics, seeing robot learning struggle to obtain similarly general\ncapabilities. Promising Learning from Videos (LfV) methods aim to address the\nrobotics data bottleneck by augmenting traditional robot data with large-scale\ninternet video data. This video data offers broad foundational information\nregarding physical behaviour and the underlying physics of the world, and thus\ncan be highly informative for a generalist robot.\n  In this survey, we present a thorough overview of the emerging field of LfV.\nWe outline fundamental concepts, including the benefits and challenges of LfV.\nWe provide a comprehensive review of current methods for extracting knowledge\nfrom large-scale internet video, addressing key challenges in LfV, and boosting\ndownstream robot and reinforcement learning via the use of video data. The\nsurvey concludes with a critical discussion of challenges and opportunities in\nLfV. Here, we advocate for scalable foundation model approaches that can\nleverage the full range of available internet video to improve the learning of\nrobot policies and dynamics models. We hope this survey can inform and catalyse\nfurther LfV research, driving progress towards the development of\ngeneral-purpose robots.\n","authors":["Robert McCarthy","Daniel C. H. Tan","Dominik Schmidt","Fernando Acero","Nathan Herr","Yilun Du","Thomas G. Thuruthel","Zhibin Li"],"pdf_url":"https://arxiv.org/pdf/2404.19664v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07753v1","updated":"2024-11-12T12:24:48Z","published":"2024-11-12T12:24:48Z","title":"Spatially Regularized Graph Attention Autoencoder Framework for\n  Detecting Rainfall Extremes","summary":"  We introduce a novel Graph Attention Autoencoder (GAE) with spatial\nregularization to address the challenge of scalable anomaly detection in\nspatiotemporal rainfall data across India from 1990 to 2015. Our model\nleverages a Graph Attention Network (GAT) to capture spatial dependencies and\ntemporal dynamics in the data, further enhanced by a spatial regularization\nterm ensuring geographic coherence. We construct two graph datasets employing\nrainfall, pressure, and temperature attributes from the Indian Meteorological\nDepartment and ERA5 Reanalysis on Single Levels, respectively. Our network\noperates on graph representations of the data, where nodes represent geographic\nlocations, and edges, inferred through event synchronization, denote\nsignificant co-occurrences of rainfall events. Through extensive experiments,\nwe demonstrate that our GAE effectively identifies anomalous rainfall patterns\nacross the Indian landscape. Our work paves the way for sophisticated\nspatiotemporal anomaly detection methodologies in climate science, contributing\nto better climate change preparedness and response strategies.\n","authors":["Mihir Agarwal","Progyan Das","Udit Bhatia"],"pdf_url":"https://arxiv.org/pdf/2411.07753v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06911v2","updated":"2024-11-12T12:07:00Z","published":"2024-11-11T12:13:58Z","title":"Gaussian Process Emulators for Few-Shot Segmentation in Cardiac MRI","summary":"  Segmentation of cardiac magnetic resonance images (MRI) is crucial for the\nanalysis and assessment of cardiac function, helping to diagnose and treat\nvarious cardiovascular diseases. Most recent techniques rely on deep learning\nand usually require an extensive amount of labeled data. To overcome this\nproblem, few-shot learning has the capability of reducing data dependency on\nlabeled data. In this work, we introduce a new method that merges few-shot\nlearning with a U-Net architecture and Gaussian Process Emulators (GPEs),\nenhancing data integration from a support set for improved performance. GPEs\nare trained to learn the relation between the support images and the\ncorresponding masks in latent space, facilitating the segmentation of unseen\nquery images given only a small labeled support set at inference. We test our\nmodel with the M&Ms-2 public dataset to assess its ability to segment the heart\nin cardiac magnetic resonance imaging from different orientations, and compare\nit with state-of-the-art unsupervised and few-shot methods. Our architecture\nshows higher DICE coefficients compared to these methods, especially in the\nmore challenging setups where the size of the support set is considerably\nsmall.\n","authors":["Bruno Viti","Franz Thaler","Kathrin Lisa Kapper","Martin Urschler","Martin Holler","Elias Karabelas"],"pdf_url":"https://arxiv.org/pdf/2411.06911v2.pdf","comment":"Accepted at Statistical Atlases and Computational Modeling of the\n  Heart (STACOM) Workshop 2024"},{"id":"http://arxiv.org/abs/2411.07087v2","updated":"2024-11-12T12:03:07Z","published":"2024-11-11T16:04:49Z","title":"OCMDP: Observation-Constrained Markov Decision Process","summary":"  In many practical applications, decision-making processes must balance the\ncosts of acquiring information with the benefits it provides. Traditional\ncontrol systems often assume full observability, an unrealistic assumption when\nobservations are expensive. We tackle the challenge of simultaneously learning\nobservation and control strategies in such cost-sensitive environments by\nintroducing the Observation-Constrained Markov Decision Process (OCMDP), where\nthe policy influences the observability of the true state. To manage the\ncomplexity arising from the combined observation and control actions, we\ndevelop an iterative, model-free deep reinforcement learning algorithm that\nseparates the sensing and control components of the policy. This decomposition\nenables efficient learning in the expanded action space by focusing on when and\nwhat to observe, as well as determining optimal control actions, without\nrequiring knowledge of the environment's dynamics. We validate our approach on\na simulated diagnostic task and a realistic healthcare environment using\nHeartPole. Given both scenarios, the experimental results demonstrate that our\nmodel achieves a substantial reduction in observation costs on average,\nsignificantly outperforming baseline methods by a notable margin in efficiency.\n","authors":["Taiyi Wang","Jianheng Liu","Bryan Lee","Zhihao Wu","Yu Wu"],"pdf_url":"https://arxiv.org/pdf/2411.07087v2.pdf","comment":"Full paper, 14 Pages"},{"id":"http://arxiv.org/abs/2408.12308v3","updated":"2024-11-12T11:45:35Z","published":"2024-08-22T11:34:34Z","title":"Deep Learning with CNNs: A Compact Holistic Tutorial with Focus on\n  Supervised Regression (Preprint)","summary":"  In this tutorial, we present a compact and holistic discussion of Deep\nLearning with a focus on Convolutional Neural Networks (CNNs) and supervised\nregression. While there are numerous books and articles on the individual\ntopics we cover, comprehensive and detailed tutorials that address Deep\nLearning from a foundational yet rigorous and accessible perspective are rare.\nMost resources on CNNs are either too advanced, focusing on cutting-edge\narchitectures, or too narrow, addressing only specific applications like image\nclassification.This tutorial not only summarizes the most relevant concepts but\nalso provides an in-depth exploration of each, offering a complete yet agile\nset of ideas. Moreover, we highlight the powerful synergy between learning\ntheory, statistic, and machine learning, which together underpin the Deep\nLearning and CNN frameworks. We aim for this tutorial to serve as an optimal\nresource for students, professors, and anyone interested in understanding the\nfoundations of Deep Learning. Upon acceptance we will provide an accompanying\nrepository under\n\\href{https://github.com/neoglez/deep-learning-tutorial}{https://github.com/neoglez/deep-learning-tutorial}\n  Keywords: Tutorial, Deep Learning, Convolutional Neural Networks, Machine\nLearning.\n","authors":["Yansel Gonzalez Tejeda","Helmut A. Mayer"],"pdf_url":"https://arxiv.org/pdf/2408.12308v3.pdf","comment":"Submitted to the journal Machine Learning and Knowledge Extraction"},{"id":"http://arxiv.org/abs/2411.07729v1","updated":"2024-11-12T11:41:38Z","published":"2024-11-12T11:41:38Z","title":"Exploring the loss landscape of regularized neural networks via convex\n  duality","summary":"  We discuss several aspects of the loss landscape of regularized neural\nnetworks: the structure of stationary points, connectivity of optimal\nsolutions, path with nonincreasing loss to arbitrary global optimum, and the\nnonuniqueness of optimal solutions, by casting the problem into an equivalent\nconvex problem and considering its dual. Starting from two-layer neural\nnetworks with scalar output, we first characterize the solution set of the\nconvex problem using its dual and further characterize all stationary points.\nWith the characterization, we show that the topology of the global optima goes\nthrough a phase transition as the width of the network changes, and construct\ncounterexamples where the problem may have a continuum of optimal solutions.\nFinally, we show that the solution set characterization and connectivity\nresults can be extended to different architectures, including two-layer\nvector-valued neural networks and parallel three-layer neural networks.\n","authors":["Sungyoon Kim","Aaron Mishkin","Mert Pilanci"],"pdf_url":"https://arxiv.org/pdf/2411.07729v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07724v1","updated":"2024-11-12T11:30:53Z","published":"2024-11-12T11:30:53Z","title":"Convergence Rate Analysis of LION","summary":"  The LION (evoLved sIgn mOmeNtum) optimizer for deep neural network training\nwas found by Google via program search, with the simple sign update yet showing\nimpressive performance in training large scale networks. Although previous\nstudies have investigated its convergence properties, a comprehensive analysis,\nespecially the convergence rate, is still desirable. Recognizing that LION can\nbe regarded as solving a specific constrained problem, this paper focuses on\ndemonstrating its convergence to the Karush-Kuhn-Tucker (KKT) point at the rate\nof $\\cal O(\\sqrt{d}K^{-1/4})$ measured by gradient $\\ell_1$ norm, where $d$ is\nthe problem dimension and $K$ is the number of iteration steps. Step further,\nwe remove the constraint and establish that LION converges to the critical\npoint of the general unconstrained problem at the same rate. This rate not only\ndelivers the currently optimal dependence on the problem dimension $d$ but also\ntightly matches the theoretical lower bound for nonconvex stochastic\noptimization algorithms, which is typically measured using the gradient\n$\\ell_2$ norm, with respect to the number of iterations $K$. Through extensive\nexperiments, we not only demonstrate that LION achieves lower loss and higher\nperformance compared to standard SGD, but also empirically confirm that the\ngradient $\\ell_1/\\ell_2$ norm ratio aligns with $\\Theta(\\sqrt{d})$, thus\nproving that our convergence rate matches the theoretical lower bound with\nrespect to $d$ in the empirical sense.\n","authors":["Yiming Dong","Huan Li","Zhouchen Lin"],"pdf_url":"https://arxiv.org/pdf/2411.07724v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07719v1","updated":"2024-11-12T11:24:18Z","published":"2024-11-12T11:24:18Z","title":"EMPERROR: A Flexible Generative Perception Error Model for Probing\n  Self-Driving Planners","summary":"  To handle the complexities of real-world traffic, learning planners for\nself-driving from data is a promising direction. While recent approaches have\nshown great progress, they typically assume a setting in which the ground-truth\nworld state is available as input. However, when deployed, planning needs to be\nrobust to the long-tail of errors incurred by a noisy perception system, which\nis often neglected in evaluation. To address this, previous work has proposed\ndrawing adversarial samples from a perception error model (PEM) mimicking the\nnoise characteristics of a target object detector. However, these methods use\nsimple PEMs that fail to accurately capture all failure modes of detection. In\nthis paper, we present EMPERROR, a novel transformer-based generative PEM,\napply it to stress-test an imitation learning (IL)-based planner and show that\nit imitates modern detectors more faithfully than previous work. Furthermore,\nit is able to produce realistic noisy inputs that increase the planner's\ncollision rate by up to 85%, demonstrating its utility as a valuable tool for a\nmore complete evaluation of self-driving planners.\n","authors":["Niklas Hanselmann","Simon Doll","Marius Cordts","Hendrik P. A. Lensch","Andreas Geiger"],"pdf_url":"https://arxiv.org/pdf/2411.07719v1.pdf","comment":"Project page: https://lasnik.github.io/emperror/"},{"id":"http://arxiv.org/abs/2405.07863v3","updated":"2024-11-12T11:18:43Z","published":"2024-05-13T15:50:39Z","title":"RLHF Workflow: From Reward Modeling to Online RLHF","summary":"  We present the workflow of Online Iterative Reinforcement Learning from Human\nFeedback (RLHF) in this technical report, which is widely reported to\noutperform its offline counterpart by a large margin in the recent large\nlanguage model (LLM) literature. However, existing open-source RLHF projects\nare still largely confined to the offline learning setting. In this technical\nreport, we aim to fill in this gap and provide a detailed recipe that is easy\nto reproduce for online iterative RLHF. In particular, since online human\nfeedback is usually infeasible for open-source communities with limited\nresources, we start by constructing preference models using a diverse set of\nopen-source datasets and use the constructed proxy preference model to\napproximate human feedback. Then, we discuss the theoretical insights and\nalgorithmic principles behind online iterative RLHF, followed by a detailed\npractical implementation. Our trained LLM achieves impressive performance on\nLLM chatbot benchmarks, including AlpacaEval-2, Arena-Hard, and MT-Bench, as\nwell as other academic benchmarks such as HumanEval and TruthfulQA. We have\nshown that supervised fine-tuning (SFT) and iterative RLHF can obtain\nstate-of-the-art performance with fully open-source datasets. Further, we have\nmade our models, curated datasets, and comprehensive step-by-step code\nguidebooks publicly available. Please refer to\nhttps://github.com/RLHFlow/RLHF-Reward-Modeling and\nhttps://github.com/RLHFlow/Online-RLHF for more detailed information.\n","authors":["Hanze Dong","Wei Xiong","Bo Pang","Haoxiang Wang","Han Zhao","Yingbo Zhou","Nan Jiang","Doyen Sahoo","Caiming Xiong","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.07863v3.pdf","comment":"Published in Transactions on Machine Learning Research (09/2024)"},{"id":"http://arxiv.org/abs/2201.07395v4","updated":"2024-11-12T11:12:46Z","published":"2022-01-19T03:08:33Z","title":"Overview frequency principle/spectral bias in deep learning","summary":"  Understanding deep learning is increasingly emergent as it penetrates more\nand more into industry and science. In recent years, a research line from\nFourier analysis sheds lights on this magical \"black box\" by showing a\nFrequency Principle (F-Principle or spectral bias) of the training behavior of\ndeep neural networks (DNNs) -- DNNs often fit functions from low to high\nfrequency during the training. The F-Principle is first demonstrated by\nonedimensional synthetic data followed by the verification in high-dimensional\nreal datasets. A series of works subsequently enhance the validity of the\nF-Principle. This low-frequency implicit bias reveals the strength of neural\nnetwork in learning low-frequency functions as well as its deficiency in\nlearning high-frequency functions. Such understanding inspires the design of\nDNN-based algorithms in practical problems, explains experimental phenomena\nemerging in various scenarios, and further advances the study of deep learning\nfrom the frequency perspective. Although incomplete, we provide an overview of\nF-Principle and propose some open problems for future research.\n","authors":["Zhi-Qin John Xu","Yaoyu Zhang","Tao Luo"],"pdf_url":"https://arxiv.org/pdf/2201.07395v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06736v2","updated":"2024-11-12T11:09:18Z","published":"2024-11-11T06:04:53Z","title":"Mr.Steve: Instruction-Following Agents in Minecraft with What-Where-When\n  Memory","summary":"  Significant advances have been made in developing general-purpose embodied AI\nin environments like Minecraft through the adoption of LLM-augmented\nhierarchical approaches. While these approaches, which combine high-level\nplanners with low-level controllers, show promise, low-level controllers\nfrequently become performance bottlenecks due to repeated failures. In this\npaper, we argue that the primary cause of failure in many low-level controllers\nis the absence of an episodic memory system. To address this, we introduce Mr.\nSteve (Memory Recall Steve-1), a novel low-level controller equipped with Place\nEvent Memory (PEM), a form of episodic memory that captures what, where, and\nwhen information from episodes. This directly addresses the main limitation of\nthe popular low-level controller, Steve-1. Unlike previous models that rely on\nshort-term memory, PEM organizes spatial and event-based data, enabling\nefficient recall and navigation in long-horizon tasks. Additionally, we propose\nan Exploration Strategy and a Memory-Augmented Task Solving Framework, allowing\nagents to alternate between exploration and task-solving based on recalled\nevents. Our approach significantly improves task-solving and exploration\nefficiency compared to existing methods. We will release our code and demos on\nthe project page: https://sites.google.com/view/mr-steve.\n","authors":["Junyeong Park","Junmo Cho","Sungjin Ahn"],"pdf_url":"https://arxiv.org/pdf/2411.06736v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.08364v3","updated":"2024-11-12T10:56:38Z","published":"2024-07-11T10:18:54Z","title":"Scalar Function Topology Divergence: Comparing Topology of 3D Objects","summary":"  We propose a new topological tool for computer vision - Scalar Function\nTopology Divergence (SFTD), which measures the dissimilarity of multi-scale\ntopology between sublevel sets of two functions having a common domain.\nFunctions can be defined on an undirected graph or Euclidean space of any\ndimensionality. Most of the existing methods for comparing topology are based\non Wasserstein distance between persistence barcodes and they don't take into\naccount the localization of topological features. The minimization of SFTD\nensures that the corresponding topological features of scalar functions are\nlocated in the same places. The proposed tool provides useful visualizations\ndepicting areas where functions have topological dissimilarities. We provide\napplications of the proposed method to 3D computer vision. In particular,\nexperiments demonstrate that SFTD as an additional loss improves the\nreconstruction of cellular 3D shapes from 2D fluorescence microscopy images,\nand helps to identify topological errors in 3D segmentation. Additionally, we\nshow that SFTD outperforms Betti matching loss in 2D segmentation problems.\n","authors":["Ilya Trofimov","Daria Voronkova","Eduard Tulchinskii","Evgeny Burnaev","Serguei Barannikov"],"pdf_url":"https://arxiv.org/pdf/2407.08364v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07711v1","updated":"2024-11-12T10:55:30Z","published":"2024-11-12T10:55:30Z","title":"OWLed: Outlier-weighed Layerwise Pruning for Efficient Autonomous\n  Driving Framework","summary":"  The integration of Large Language Models (LLMs) into autonomous driving\nsystems offers promising enhancements in environmental understanding and\ndecision-making. However, the substantial computational demands of deploying\nLLMs locally on vehicles render this approach unfeasible for real-world\nautomotive applications. To address this challenge, we introduce OWLed, the\nOutlier-Weighed Layerwise Pruning for Efficient Autonomous Driving Framework\nthat leverages outlier-weighted layerwise sparsity for model compression. Our\nmethod assigns non-uniform sparsity ratios to different layers based on the\ndistribution of outlier features, significantly reducing the model size without\nthe need for fine-tuning. To ensure the compressed model adapts well to\nautonomous driving tasks, we incorporate driving environment data into both the\ncalibration and pruning processes. Our empirical studies reveal that the\nencoder component is more sensitive to pruning than the LLM, highlighting its\ncritical role in the system. Experimental results demonstrate that OWLed\noutperforms existing methods in perception, action prediction, and language\nunderstanding while substantially lowering computational requirements. These\nfindings underscore the potential of combining advanced pruning techniques with\nLLMs to develop efficient and robust autonomous driving systems capable of\nhandling complex scenarios. Code will be made publicly available.\n","authors":["Jiaxi Li","Lu Yin","Xilu Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07711v1.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2411.07700v1","updated":"2024-11-12T10:26:44Z","published":"2024-11-12T10:26:44Z","title":"Test Where Decisions Matter: Importance-driven Testing for Deep\n  Reinforcement Learning","summary":"  In many Deep Reinforcement Learning (RL) problems, decisions in a trained\npolicy vary in significance for the expected safety and performance of the\npolicy. Since RL policies are very complex, testing efforts should concentrate\non states in which the agent's decisions have the highest impact on the\nexpected outcome. In this paper, we propose a novel model-based method to\nrigorously compute a ranking of state importance across the entire state space.\nWe then focus our testing efforts on the highest-ranked states. In this paper,\nwe focus on testing for safety. However, the proposed methods can be easily\nadapted to test for performance. In each iteration, our testing framework\ncomputes optimistic and pessimistic safety estimates. These estimates provide\nlower and upper bounds on the expected outcomes of the policy execution across\nall modeled states in the state space. Our approach divides the state space\ninto safe and unsafe regions upon convergence, providing clear insights into\nthe policy's weaknesses. Two important properties characterize our approach.\n(1) Optimal Test-Case Selection: At any time in the testing process, our\napproach evaluates the policy in the states that are most critical for safety.\n(2) Guaranteed Safety: Our approach can provide formal verification guarantees\nover the entire state space by sampling only a fraction of the policy. Any\nsafety properties assured by the pessimistic estimate are formally proven to\nhold for the policy. We provide a detailed evaluation of our framework on\nseveral examples, showing that our method discovers unsafe policy behavior with\nlow testing effort.\n","authors":["Stefan Pranger","Hana Chockler","Martin Tappler","Bettina K√∂nighofer"],"pdf_url":"https://arxiv.org/pdf/2411.07700v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02487v2","updated":"2024-11-12T10:03:37Z","published":"2024-08-05T14:09:30Z","title":"LiCoEval: Evaluating LLMs on License Compliance in Code Generation","summary":"  Recent advances in Large Language Models (LLMs) have revolutionized code\ngeneration, leading to widespread adoption of AI coding tools by developers.\nHowever, LLMs can generate license-protected code without providing the\nnecessary license information, leading to potential intellectual property\nviolations during software production. This paper addresses the critical, yet\nunderexplored, issue of license compliance in LLM-generated code by\nestablishing a benchmark to evaluate the ability of LLMs to provide accurate\nlicense information for their generated code. To establish this benchmark, we\nconduct an empirical study to identify a reasonable standard for \"striking\nsimilarity\" that excludes the possibility of independent creation, indicating a\ncopy relationship between the LLM output and certain open-source code. Based on\nthis standard, we propose LiCoEval, to evaluate the license compliance\ncapabilities of LLMs, i.e., the ability to provide accurate license or\ncopyright information when they generate code with striking similarity to\nalready existing copyrighted code. Using LiCoEval, we evaluate 14 popular LLMs,\nfinding that even top-performing LLMs produce a non-negligible proportion\n(0.88% to 2.01%) of code strikingly similar to existing open-source\nimplementations. Notably, most LLMs fail to provide accurate license\ninformation, particularly for code under copyleft licenses. These findings\nunderscore the urgent need to enhance LLM compliance capabilities in code\ngeneration tasks. Our study provides a foundation for future research and\ndevelopment to improve license compliance in AI-assisted software development,\ncontributing to both the protection of open-source software copyrights and the\nmitigation of legal risks for LLM users.\n","authors":["Weiwei Xu","Kai Gao","Hao He","Minghui Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.02487v2.pdf","comment":"The 47th International Conference on Software Engineering(ICSE 2025)"},{"id":"http://arxiv.org/abs/2405.17544v2","updated":"2024-11-12T09:57:28Z","published":"2024-05-27T18:00:00Z","title":"Towards Human-AI Complementarity with Prediction Sets","summary":"  Decision support systems based on prediction sets have proven to be effective\nat helping human experts solve classification tasks. Rather than providing\nsingle-label predictions, these systems provide sets of label predictions\nconstructed using conformal prediction, namely prediction sets, and ask human\nexperts to predict label values from these sets. In this paper, we first show\nthat the prediction sets constructed using conformal prediction are, in\ngeneral, suboptimal in terms of average accuracy. Then, we show that the\nproblem of finding the optimal prediction sets under which the human experts\nachieve the highest average accuracy is NP-hard. More strongly, unless P = NP,\nwe show that the problem is hard to approximate to any factor less than the\nsize of the label set. However, we introduce a simple and efficient greedy\nalgorithm that, for a large class of expert models and non-conformity scores,\nis guaranteed to find prediction sets that provably offer equal or greater\nperformance than those constructed using conformal prediction. Further, using a\nsimulation study with both synthetic and real expert predictions, we\ndemonstrate that, in practice, our greedy algorithm finds near-optimal\nprediction sets offering greater performance than conformal prediction.\n","authors":["Giovanni De Toni","Nastaran Okati","Suhas Thejaswi","Eleni Straitouri","Manuel Gomez-Rodriguez"],"pdf_url":"https://arxiv.org/pdf/2405.17544v2.pdf","comment":"Published in NeurIPS 2024"},{"id":"http://arxiv.org/abs/2407.19872v3","updated":"2024-11-12T09:57:00Z","published":"2024-07-29T10:43:15Z","title":"OpenUAS: Embeddings of Cities in Japan with Anchor Data for Cross-city\n  Analysis of Area Usage Patterns","summary":"  We publicly release OpenUAS, a dataset of area embeddings based on urban\nusage patterns, including embeddings for over 1.3 million 50-meter square\nmeshes covering a total area of 3,300 square kilometers. This dataset is\nvaluable for analyzing area functions in fields such as market analysis, urban\nplanning, transportation infrastructure, and infection prediction. It captures\nthe characteristics of each area in the city, such as office districts and\nresidential areas, by employing an area embedding technique that utilizes\nlocation information typically obtained by GPS. Numerous area embedding\ntechniques have been proposed, and while the public release of such embedding\ndatasets is technically feasible, it has not been realized. One reason for this\nis that previous methods could not embed areas from different cities and\nperiods into the same embedding space without sharing raw location data. We\naddress this issue by developing an anchoring method that establishes anchors\nwithin a shared embedding space. We publicly release this anchor dataset along\nwith area embedding datasets from several periods in eight major Japanese\ncities.\n","authors":["Naoki Tamura","Kazuyuki Shoji","Shin Katayama","Kenta Urano","Takuro Yonezawa","Nobuo Kawaguchi"],"pdf_url":"https://arxiv.org/pdf/2407.19872v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.06797v2","updated":"2024-11-12T09:54:07Z","published":"2023-07-13T15:08:44Z","title":"Fast and Functional Structured Data Generators Rooted in\n  Out-of-Equilibrium Physics","summary":"  In this study, we address the challenge of using energy-based models to\nproduce high-quality, label-specific data in complex structured datasets, such\nas population genetics, RNA or protein sequences data. Traditional training\nmethods encounter difficulties due to inefficient Markov chain Monte Carlo\nmixing, which affects the diversity of synthetic data and increases generation\ntimes. To address these issues, we use a novel training algorithm that exploits\nnon-equilibrium effects. This approach, applied on the Restricted Boltzmann\nMachine, improves the model's ability to correctly classify samples and\ngenerate high-quality synthetic data in only a few sampling steps. The\neffectiveness of this method is demonstrated by its successful application to\nfour different types of data: handwritten digits, mutations of human genomes\nclassified by continental origin, functionally characterized sequences of an\nenzyme protein family, and homologous RNA sequences from specific taxonomies.\n","authors":["Alessandra Carbone","Aur√©lien Decelle","Lorenzo Rosset","Beatriz Seoane"],"pdf_url":"https://arxiv.org/pdf/2307.06797v2.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2411.07681v1","updated":"2024-11-12T09:52:40Z","published":"2024-11-12T09:52:40Z","title":"What Do Learning Dynamics Reveal About Generalization in LLM Reasoning?","summary":"  Despite the remarkable capabilities of modern large language models (LLMs),\nthe mechanisms behind their problem-solving abilities remain elusive. In this\nwork, we aim to better understand how the learning dynamics of LLM finetuning\nshapes downstream generalization. Our analysis focuses on reasoning tasks,\nwhose problem structure allows us to distinguish between memorization (the\nexact replication of reasoning steps from the training data) and performance\n(the correctness of the final solution). We find that a model's generalization\nbehavior can be effectively characterized by a training metric we call\npre-memorization train accuracy: the accuracy of model samples on training\nqueries before they begin to copy the exact reasoning steps from the training\nset. On the dataset level, this metric is able to reliably predict test\naccuracy, achieving $R^2$ of around or exceeding 0.9 across various models\n(Llama3 8, Gemma2 9B), datasets (GSM8k, MATH), and training configurations. On\na per-example level, this metric is also indicative of whether individual model\npredictions are robust to perturbations in the training query. By connecting a\nmodel's learning behavior to its generalization, pre-memorization train\naccuracy can guide targeted improvements to training strategies. We focus on\ndata curation as an example, and show that prioritizing examples with low\npre-memorization accuracy leads to 1.5-2x improvements in data efficiency\ncompared to i.i.d. data scaling, and outperforms other standard data curation\ntechniques.\n","authors":["Katie Kang","Amrith Setlur","Dibya Ghosh","Jacob Steinhardt","Claire Tomlin","Sergey Levine","Aviral Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07681v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.02066v4","updated":"2024-11-12T09:50:15Z","published":"2024-09-03T17:13:55Z","title":"Robust Clustering on High-Dimensional Data with Stochastic Quantization","summary":"  This paper addresses the limitations of conventional vector quantization\nalgorithms, particularly K-Means and its variant K-Means++, and investigates\nthe Stochastic Quantization (SQ) algorithm as a scalable alternative for\nhigh-dimensional unsupervised and semi-supervised learning tasks. Traditional\nclustering algorithms often suffer from inefficient memory utilization during\ncomputation, necessitating the loading of all data samples into memory, which\nbecomes impractical for large-scale datasets. While variants such as Mini-Batch\nK-Means partially mitigate this issue by reducing memory usage, they lack\nrobust theoretical convergence guarantees due to the non-convex nature of\nclustering problems. In contrast, the Stochastic Quantization algorithm\nprovides strong theoretical convergence guarantees, making it a robust\nalternative for clustering tasks. We demonstrate the computational efficiency\nand rapid convergence of the algorithm on an image classification problem with\npartially labeled data, comparing model accuracy across various ratios of\nlabeled to unlabeled data. To address the challenge of high dimensionality, we\nemploy a Triplet Network to encode images into low-dimensional representations\nin a latent space, which serve as a basis for comparing the efficiency of both\nthe Stochastic Quantization algorithm and traditional quantization algorithms.\nFurthermore, we enhance the algorithm's convergence speed by introducing\nmodifications with an adaptive learning rate.\n","authors":["Anton Kozyriev","Vladimir Norkin"],"pdf_url":"https://arxiv.org/pdf/2409.02066v4.pdf","comment":"22 pages, 5 figures, to be published in the International Scientific\n  Technical Journal \"Problems of Control and Informatics\""},{"id":"http://arxiv.org/abs/2411.07679v1","updated":"2024-11-12T09:49:16Z","published":"2024-11-12T09:49:16Z","title":"Safe Exploitative Play with Untrusted Type Beliefs","summary":"  The combination of the Bayesian game and learning has a rich history, with\nthe idea of controlling a single agent in a system composed of multiple agents\nwith unknown behaviors given a set of types, each specifying a possible\nbehavior for the other agents. The idea is to plan an agent's own actions with\nrespect to those types which it believes are most likely to maximize the\npayoff. However, the type beliefs are often learned from past actions and\nlikely to be incorrect. With this perspective in mind, we consider an agent in\na game with type predictions of other components, and investigate the impact of\nincorrect beliefs to the agent's payoff. In particular, we formally define a\ntradeoff between risk and opportunity by comparing the payoff obtained against\nthe optimal payoff, which is represented by a gap caused by trusting or\ndistrusting the learned beliefs. Our main results characterize the tradeoff by\nestablishing upper and lower bounds on the Pareto front for both normal-form\nand stochastic Bayesian games, with numerical results provided.\n","authors":["Tongxin Li","Tinashe Handina","Shaolei Ren","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2411.07679v1.pdf","comment":"26 pages, NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.17351v2","updated":"2024-11-12T09:46:25Z","published":"2024-03-26T03:29:42Z","title":"Learn from Heterophily: Heterophilous Information-enhanced Graph Neural\n  Network","summary":"  Under circumstances of heterophily, where nodes with different labels tend to\nbe connected based on semantic meanings, Graph Neural Networks (GNNs) often\nexhibit suboptimal performance. Current studies on graph heterophily mainly\nfocus on aggregation calibration or neighbor extension and address the\nheterophily issue by utilizing node features or structural information to\nimprove GNN representations. In this paper, we propose and demonstrate that the\nvaluable semantic information inherent in heterophily can be utilized\neffectively in graph learning by investigating the distribution of neighbors\nfor each individual node within the graph. The theoretical analysis is carried\nout to demonstrate the efficacy of the idea in enhancing graph learning. Based\non this analysis, we propose HiGNN, an innovative approach that constructs an\nadditional new graph structure, that integrates heterophilous information by\nleveraging node distribution to enhance connectivity between nodes that share\nsimilar semantic characteristics. We conduct empirical assessments on node\nclassification tasks using both homophilous and heterophilous benchmark\ndatasets and compare HiGNN to popular GNN baselines and SoTA methods,\nconfirming the effectiveness in improving graph representations. In addition,\nby incorporating heterophilous information, we demonstrate a notable\nenhancement in existing GNN-based approaches, and the homophily degree across\nreal-world datasets, thus affirming the efficacy of our approach.\n","authors":["Yilun Zheng","Jiahao Xu","Lihui Chen"],"pdf_url":"https://arxiv.org/pdf/2403.17351v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19178v2","updated":"2024-11-12T09:42:13Z","published":"2024-05-29T15:18:39Z","title":"Model-independent cosmological inference post DESI DR1 BAO measurements","summary":"  In this work, we implement Gaussian process regression to reconstruct the\nexpansion history of the universe in a model-agnostic manner, using the\nPantheon-Plus SN-Ia compilation in combination with two different BAO\nmeasurements (SDSS-IV and DESI DR1). In both the reconstructions, the\n$\\Lambda$CDM model is always included in the 95\\% confidence intervals. We find\nevidence that the DESI LRG data at $z_{\\text{eff}} = 0.51$ is not an outlier\nwithin our model-independent framework. We study the $\\mathcal{O}m$-diagnostics\nand the evolution of the total equation of state (EoS) of our universe, which\nhint towards the possibility of a quintessence-like dark energy scenario with a\nvery slowly varying EoS, and a phantom-crossing in higher $z$. The entire\nexercise is later complemented by considering two more SN-Ia compilations -\nDES-5YR and Union3 - in combination with DESI BAO. Reconstruction with the DESI\nBAO + DES-5YR SN data sets predicts that the $\\Lambda$CDM model lies outside\nthe 3$\\sigma$ confidence levels, whereas with DESI BAO + Union3 data, the\n$\\Lambda$CDM model is always included within 1$\\sigma$. We also report\nconstraints on $H_0 r_d$ from our model-agnostic analysis, independent of the\npre-recombination physics. Our results point towards an $\\approx$ 2$\\sigma$\ndiscrepancy between the DESI + Pantheon-Plus and DESI + DES-5YR data sets,\nwhich calls for further investigation.\n","authors":["Purba Mukherjee","Anjan Ananda Sen"],"pdf_url":"https://arxiv.org/pdf/2405.19178v2.pdf","comment":"10 pages, 6 sets of figures. Accepted for publication in PRD"},{"id":"http://arxiv.org/abs/2411.07672v1","updated":"2024-11-12T09:39:22Z","published":"2024-11-12T09:39:22Z","title":"Rethinking Structure Learning For Graph Neural Networks","summary":"  To improve the performance of Graph Neural Networks (GNNs), Graph Structure\nLearning (GSL) has been extensively applied to reconstruct or refine original\ngraph structures, effectively addressing issues like heterophily,\nover-squashing, and noisy structures. While GSL is generally thought to improve\nGNN performance, it often leads to longer training times and more\nhyperparameter tuning. Besides, the distinctions among current GSL methods\nremain ambiguous from the perspective of GNN training, and there is a lack of\ntheoretical analysis to quantify their effectiveness. Recent studies further\nsuggest that, under fair comparisons with the same hyperparameter tuning, GSL\ndoes not consistently outperform baseline GNNs. This motivates us to ask a\ncritical question: is GSL really useful for GNNs? To address this question,\nthis paper makes two key contributions. First, we propose a new GSL framework,\nwhich includes three steps: GSL base (the representation used for GSL)\nconstruction, new structure construction, and view fusion, to better understand\nthe effectiveness of GSL in GNNs. Second, after graph convolution, we analyze\nthe differences in mutual information (MI) between node representations derived\nfrom the original topology and those from the newly constructed topology.\nSurprisingly, our empirical observations and theoretical analysis show that no\nmatter which type of graph structure construction methods are used, after\nfeeding the same GSL bases to the newly constructed graph, there is no MI gain\ncompared to the original GSL bases. To fairly reassess the effectiveness of\nGSL, we conduct ablation experiments and find that it is the pretrained GSL\nbases that enhance GNN performance, and in most cases, GSL cannot improve GNN\nperformance. This finding encourages us to rethink the essential components in\nGNNs, such as self-training and structural encoding, in GNN design rather than\nGSL.\n","authors":["Yilun Zheng","Zhuofan Zhang","Ziming Wang","Xiang Li","Sitao Luan","Xiaojiang Peng","Lihui Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07672v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07663v1","updated":"2024-11-12T09:28:55Z","published":"2024-11-12T09:28:55Z","title":"Is Graph Convolution Always Beneficial For Every Feature?","summary":"  Graph Neural Networks (GNNs) have demonstrated strong capabilities in\nprocessing structured data. While traditional GNNs typically treat each feature\ndimension equally during graph convolution, we raise an important question: Is\nthe graph convolution operation equally beneficial for each feature? If not,\nthe convolution operation on certain feature dimensions can possibly lead to\nharmful effects, even worse than the convolution-free models. In prior studies,\nto assess the impacts of graph convolution on features, people proposed metrics\nbased on feature homophily to measure feature consistency with the graph\ntopology. However, these metrics have shown unsatisfactory alignment with GNN\nperformance and have not been effectively employed to guide feature selection\nin GNNs. To address these limitations, we introduce a novel metric, Topological\nFeature Informativeness (TFI), to distinguish between GNN-favored and\nGNN-disfavored features, where its effectiveness is validated through both\ntheoretical analysis and empirical observations. Based on TFI, we propose a\nsimple yet effective Graph Feature Selection (GFS) method, which processes\nGNN-favored and GNN-disfavored features separately, using GNNs and non-GNN\nmodels. Compared to original GNNs, GFS significantly improves the extraction of\nuseful topological information from each feature with comparable computational\ncosts. Extensive experiments show that after applying GFS to 8 baseline and\nstate-of-the-art (SOTA) GNN architectures across 10 datasets, 83.75% of the\nGFS-augmented cases show significant performance boosts. Furthermore, our\nproposed TFI metric outperforms other feature selection methods. These results\nvalidate the effectiveness of both GFS and TFI. Additionally, we demonstrate\nthat GFS's improvements are robust to hyperparameter tuning, highlighting its\npotential as a universal method for enhancing various GNN architectures.\n","authors":["Yilun Zheng","Xiang Li","Sitao Luan","Xiaojiang Peng","Lihui Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07663v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.13848v2","updated":"2024-11-12T09:21:13Z","published":"2024-03-18T10:44:22Z","title":"Smooth Sensitivity for Learning Differentially-Private yet Accurate Rule\n  Lists","summary":"  Differentially-private (DP) mechanisms can be embedded into the design of a\nmachine learning algorithm to protect the resulting model against privacy\nleakage. However, this often comes with a significant loss of accuracy due to\nthe noise added to enforce DP. In this paper, we aim at improving this\ntrade-off for a popular class of machine learning algorithms leveraging the\nGini impurity as an information gain criterion to greedily build interpretable\nmodels such as decision trees or rule lists. To this end, we establish the\nsmooth sensitivity of the Gini impurity, which can be used to obtain thorough\nDP guarantees while adding noise scaled with tighter magnitude. We illustrate\nthe applicability of this mechanism by integrating it within a greedy algorithm\nproducing rule list models, motivated by the fact that such models remain\nunderstudied in the DP literature. Our theoretical analysis and experimental\nresults confirm that the DP rule lists models integrating smooth sensitivity\nhave higher accuracy that those using other DP frameworks based on global\nsensitivity, for identical privacy budgets.\n","authors":["Timoth√©e Ly","Julien Ferry","Marie-Jos√© Huguet","S√©bastien Gambs","Ulrich Aivodji"],"pdf_url":"https://arxiv.org/pdf/2403.13848v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06890v2","updated":"2024-11-12T09:12:42Z","published":"2024-11-11T11:42:48Z","title":"SPARTAN: A Sparse Transformer Learning Local Causation","summary":"  Causal structures play a central role in world models that flexibly adapt to\nchanges in the environment. While recent works motivate the benefits of\ndiscovering local causal graphs for dynamics modelling, in this work we\ndemonstrate that accurately capturing these relationships in complex settings\nremains challenging for the current state-of-the-art. To remedy this\nshortcoming, we postulate that sparsity is a critical ingredient for the\ndiscovery of such local causal structures. To this end we present the SPARse\nTrANsformer World model (SPARTAN), a Transformer-based world model that learns\nlocal causal structures between entities in a scene. By applying sparsity\nregularisation on the attention pattern between object-factored tokens, SPARTAN\nidentifies sparse local causal models that accurately predict future object\nstates. Furthermore, we extend our model to capture sparse interventions with\nunknown targets on the dynamics of the environment. This results in a highly\ninterpretable world model that can efficiently adapt to changes. Empirically,\nwe evaluate SPARTAN against the current state-of-the-art in object-centric\nworld models on observation-based environments and demonstrate that our model\ncan learn accurate local causal graphs and achieve significantly improved\nfew-shot adaptation to changes in the dynamics of the environment as well as\nrobustness against removing irrelevant distractors.\n","authors":["Anson Lei","Bernhard Sch√∂lkopf","Ingmar Posner"],"pdf_url":"https://arxiv.org/pdf/2411.06890v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07650v1","updated":"2024-11-12T09:02:11Z","published":"2024-11-12T09:02:11Z","title":"Understanding Audiovisual Deepfake Detection: Techniques, Challenges,\n  Human Factors and Perceptual Insights","summary":"  Deep Learning has been successfully applied in diverse fields, and its impact\non deepfake detection is no exception. Deepfakes are fake yet realistic\nsynthetic content that can be used deceitfully for political impersonation,\nphishing, slandering, or spreading misinformation. Despite extensive research\non unimodal deepfake detection, identifying complex deepfakes through joint\nanalysis of audio and visual streams remains relatively unexplored. To fill\nthis gap, this survey first provides an overview of audiovisual deepfake\ngeneration techniques, applications, and their consequences, and then provides\na comprehensive review of state-of-the-art methods that combine audio and\nvisual modalities to enhance detection accuracy, summarizing and critically\nanalyzing their strengths and limitations. Furthermore, we discuss existing\nopen source datasets for a deeper understanding, which can contribute to the\nresearch community and provide necessary information to beginners who want to\nanalyze deep learning-based audiovisual methods for video forensics. By\nbridging the gap between unimodal and multimodal approaches, this paper aims to\nimprove the effectiveness of deepfake detection strategies and guide future\nresearch in cybersecurity and media integrity.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07643v1","updated":"2024-11-12T08:53:49Z","published":"2024-11-12T08:53:49Z","title":"xCG: Explainable Cell Graphs for Survival Prediction in Non-Small Cell\n  Lung Cancer","summary":"  Understanding how deep learning models predict oncology patient risk can\nprovide critical insights into disease progression, support clinical\ndecision-making, and pave the way for trustworthy and data-driven precision\nmedicine. Building on recent advances in the spatial modeling of the tumor\nmicroenvironment using graph neural networks, we present an explainable cell\ngraph (xCG) approach for survival prediction. We validate our model on a public\ncohort of imaging mass cytometry (IMC) data for 416 cases of lung\nadenocarcinoma. We explain survival predictions in terms of known phenotypes on\nthe cell level by computing risk attributions over cell graphs, for which we\npropose an efficient grid-based layer-wise relevance propagation (LRP) method.\nOur ablation studies highlight the importance of incorporating the cancer stage\nand model ensembling to improve the quality of risk estimates. Our xCG method,\ntogether with the IMC data, is made publicly available to support further\nresearch.\n","authors":["Marvin Sextro","Gabriel Dernbach","Kai Standvoss","Simon Schallenberg","Frederick Klauschen","Klaus-Robert M√ºller","Maximilian Alber","Lukas Ruff"],"pdf_url":"https://arxiv.org/pdf/2411.07643v1.pdf","comment":"Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 11 pages"},{"id":"http://arxiv.org/abs/2411.06236v2","updated":"2024-11-12T08:51:40Z","published":"2024-11-09T17:36:53Z","title":"Zero-Shot NAS via the Suppression of Local Entropy Decrease","summary":"  Architecture performance evaluation is the most time-consuming part of neural\narchitecture search (NAS). Zero-Shot NAS accelerates the evaluation by\nutilizing zero-cost proxies instead of training. Though effective, existing\nzero-cost proxies require invoking backpropagations or running networks on\ninput data, making it difficult to further accelerate the computation of\nproxies. To alleviate this issue, architecture topologies are used to evaluate\nthe performance of networks in this study. We prove that particular\narchitectural topologies decrease the local entropy of feature maps, which\ndegrades specific features to a bias, thereby reducing network performance.\nBased on this proof, architectural topologies are utilized to quantify the\nsuppression of local entropy decrease (SED) as a data-free and running-free\nproxy. Experimental results show that SED outperforms most state-of-the-art\nproxies in terms of architecture selection on five benchmarks, with computation\ntime reduced by three orders of magnitude. We further compare the SED-based NAS\nwith state-of-the-art proxies. SED-based NAS selects the architecture with\nhigher accuracy and fewer parameters in only one second. The theoretical\nanalyses of local entropy and experimental results demonstrate that the\nsuppression of local entropy decrease facilitates selecting optimal\narchitectures in Zero-Shot NAS.\n","authors":["Ning Wu","Han Huang","Yueting Xu","Zhifeng Hao"],"pdf_url":"https://arxiv.org/pdf/2411.06236v2.pdf","comment":"8 pages, 2 figures. Corrected typos and latex template"},{"id":"http://arxiv.org/abs/2410.05814v2","updated":"2024-11-12T08:50:59Z","published":"2024-10-08T08:44:01Z","title":"CALoR: Towards Comprehensive Model Inversion Defense","summary":"  Model Inversion Attacks (MIAs) aim at recovering privacy-sensitive training\ndata from the knowledge encoded in the released machine learning models. Recent\nadvances in the MIA field have significantly enhanced the attack performance\nunder multiple scenarios, posing serious privacy risks of Deep Neural Networks\n(DNNs). However, the development of defense strategies against MIAs is\nrelatively backward to resist the latest MIAs and existing defenses fail to\nachieve further trade-off between model utility and model robustness. In this\npaper, we provide an in-depth analysis from the perspective of intrinsic\nvulnerabilities of MIAs, comprehensively uncovering the weaknesses inherent in\nthe basic pipeline, which are partially investigated in the previous defenses.\nBuilding upon these new insights, we propose a robust defense mechanism,\nintegrating Confidence Adaptation and Low-Rank compression(CALoR). Our method\nincludes a novel robustness-enhanced classification loss specially-designed for\nmodel inversion defenses and reveals the extraordinary effectiveness of\ncompressing the classification header. With CALoR, we can mislead the\noptimization objective, reduce the leaked information and impede the\nbackpropagation of MIAs, thus mitigating the risk of privacy leakage. Extensive\nexperimental results demonstrate that our method achieves state-of-the-art\n(SOTA) defense performance against MIAs and exhibits superior generalization to\nexisting defenses across various scenarios.\n","authors":["Hongyao Yu","Yixiang Qiu","Hao Fang","Bin Chen","Sijin Yu","Bin Wang","Shu-Tao Xia","Ke Xu"],"pdf_url":"https://arxiv.org/pdf/2410.05814v2.pdf","comment":"26 pages"},{"id":"http://arxiv.org/abs/2411.07641v1","updated":"2024-11-12T08:46:43Z","published":"2024-11-12T08:46:43Z","title":"Top-$nœÉ$: Not All Logits Are You Need","summary":"  Large language models (LLMs) typically employ greedy decoding or\nlow-temperature sampling for reasoning tasks, reflecting a perceived trade-off\nbetween diversity and accuracy. We challenge this convention by introducing\ntop-$n\\sigma$, a novel sampling method that operates directly on pre-softmax\nlogits by leveraging a statistical threshold. Our key insight is that logits\nnaturally separate into a Gaussian-distributed noisy region and a distinct\ninformative region, enabling efficient token filtering without complex\nprobability manipulations. Unlike existing methods (e.g., top-$p$, min-$p$)\nthat inadvertently include more noise tokens at higher temperatures,\ntop-$n\\sigma$ maintains a stable sampling space regardless of temperature\nscaling. We also provide a theoretical analysis of top-$n\\sigma$ to better\nunderstand its behavior. The extensive experimental results across four\nreasoning-focused datasets demonstrate that our method not only outperforms\nexisting sampling approaches but also surpasses greedy decoding, while\nmaintaining consistent performance even at high temperatures.\n","authors":["Chenxia Tang","Jianchun Liu","Hongli Xu","Liusheng Huang"],"pdf_url":"https://arxiv.org/pdf/2411.07641v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.10944v5","updated":"2024-11-12T08:31:22Z","published":"2023-11-18T02:44:33Z","title":"Deception Detection from Linguistic and Physiological Data Streams Using\n  Bimodal Convolutional Neural Networks","summary":"  Deception detection is gaining increasing interest due to ethical and\nsecurity concerns. This paper explores the application of convolutional neural\nnetworks for the purpose of multimodal deception detection. We use a dataset\nbuilt by interviewing 104 subjects about two topics, with one truthful and one\nfalsified response from each subject about each topic. In particular, we make\nthree main contributions. First, we extract linguistic and physiological\nfeatures from this data to train and construct the neural network models.\nSecond, we propose a fused convolutional neural network model using both\nmodalities in order to achieve an improved overall performance. Third, we\ncompare our new approach with earlier methods designed for multimodal deception\ndetection. We find that our system outperforms regular classification methods;\nour results indicate the feasibility of using neural networks for deception\ndetection even in the presence of limited amounts of data.\n","authors":["Panfeng Li","Mohamed Abouelenien","Rada Mihalcea","Zhicheng Ding","Qikai Yang","Yiming Zhou"],"pdf_url":"https://arxiv.org/pdf/2311.10944v5.pdf","comment":"Accepted by 2024 5th International Conference on Information Science,\n  Parallel and Distributed Systems"},{"id":"http://arxiv.org/abs/2411.07634v1","updated":"2024-11-12T08:27:27Z","published":"2024-11-12T08:27:27Z","title":"Exploring Multi-Agent Reinforcement Learning for Unrelated Parallel\n  Machine Scheduling","summary":"  Scheduling problems pose significant challenges in resource, industry, and\noperational management. This paper addresses the Unrelated Parallel Machine\nScheduling Problem (UPMS) with setup times and resources using a Multi-Agent\nReinforcement Learning (MARL) approach. The study introduces the Reinforcement\nLearning environment and conducts empirical analyses, comparing MARL with\nSingle-Agent algorithms. The experiments employ various deep neural network\npolicies for single- and Multi-Agent approaches. Results demonstrate the\nefficacy of the Maskable extension of the Proximal Policy Optimization (PPO)\nalgorithm in Single-Agent scenarios and the Multi-Agent PPO algorithm in\nMulti-Agent setups. While Single-Agent algorithms perform adequately in reduced\nscenarios, Multi-Agent approaches reveal challenges in cooperative learning but\na scalable capacity. This research contributes insights into applying MARL\ntechniques to scheduling optimization, emphasizing the need for algorithmic\nsophistication balanced with scalability for intelligent scheduling solutions.\n","authors":["Maria Zampella","Urtzi Otamendi","Xabier Belaunzaran","Arkaitz Artetxe","Igor G. Olaizola","Giuseppe Longo","Basilio Sierra"],"pdf_url":"https://arxiv.org/pdf/2411.07634v1.pdf","comment":"11 pages, 5 figures, 4 tables, article submitted to a journal"},{"id":"http://arxiv.org/abs/2310.06929v2","updated":"2024-11-12T08:24:28Z","published":"2023-10-10T18:32:11Z","title":"Stochastic Super-resolution of Cosmological Simulations with Denoising\n  Diffusion Models","summary":"  In recent years, deep learning models have been successfully employed for\naugmenting low-resolution cosmological simulations with small-scale\ninformation, a task known as \"super-resolution\". So far, these cosmological\nsuper-resolution models have relied on generative adversarial networks (GANs),\nwhich can achieve highly realistic results, but suffer from various\nshortcomings (e.g. low sample diversity). We introduce denoising diffusion\nmodels as a powerful generative model for super-resolving cosmic large-scale\nstructure predictions (as a first proof-of-concept in two dimensions). To\nobtain accurate results down to small scales, we develop a new \"filter-boosted\"\ntraining approach that redistributes the importance of different scales in the\npixel-wise training objective. We demonstrate that our model not only produces\nconvincing super-resolution images and power spectra consistent at the percent\nlevel, but is also able to reproduce the diversity of small-scale features\nconsistent with a given low-resolution simulation. This enables uncertainty\nquantification for the generated small-scale features, which is critical for\nthe usefulness of such super-resolution models as a viable surrogate model for\ncosmic structure formation.\n","authors":["Andreas Schanz","Florian List","Oliver Hahn"],"pdf_url":"https://arxiv.org/pdf/2310.06929v2.pdf","comment":"9 pages, 8 figures, to be submitted to OJA, comments welcome"},{"id":"http://arxiv.org/abs/2402.07314v3","updated":"2024-11-12T08:24:10Z","published":"2024-02-11T21:44:21Z","title":"Online Iterative Reinforcement Learning from Human Feedback with General\n  Preference Model","summary":"  We investigate Reinforcement Learning from Human Feedback (RLHF) in the\ncontext of a general preference oracle. In particular, we do not assume the\nexistence of a reward function and an oracle preference signal drawn from the\nBradley-Terry model as most of the prior works do. We consider a standard\nmathematical formulation, the reverse-KL regularized minimax game between two\nLLMs for RLHF under general preference oracle. The learning objective of this\nformulation is to find a policy so that it is consistently preferred by the\nKL-regularized preference oracle over any competing LLMs. We show that this\nframework is strictly more general than the reward-based one, and propose\nsample-efficient algorithms for both the offline learning from a pre-collected\npreference dataset and online learning where we can query the preference oracle\nalong the way of training. Empirical studies verify the effectiveness of the\nproposed framework.\n","authors":["Chenlu Ye","Wei Xiong","Yuheng Zhang","Hanze Dong","Nan Jiang","Tong Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.07314v3.pdf","comment":"RLHF, Preference Learning, Alignment for LLMs"},{"id":"http://arxiv.org/abs/2405.06219v3","updated":"2024-11-12T08:18:45Z","published":"2024-05-10T03:06:24Z","title":"SKVQ: Sliding-window Key and Value Cache Quantization for Large Language\n  Models","summary":"  Large language models (LLMs) can now handle longer sequences of tokens,\nenabling complex tasks like book understanding and generating lengthy novels.\nHowever, the key-value (KV) cache required for LLMs consumes substantial memory\nas context length increasing, becoming the bottleneck for deployment. In this\npaper, we present a strategy called SKVQ, which stands for sliding-window KV\ncache quantization, to address the issue of extremely low bitwidth KV cache\nquantization. To achieve this, SKVQ rearranges the channels of the KV cache in\norder to improve the similarity of channels in quantization groups, and applies\nclipped dynamic quantization at the group level. Additionally, SKVQ ensures\nthat the most recent window tokens in the KV cache are preserved with high\nprecision. This helps maintain the accuracy of a small but important portion of\nthe KV cache.SKVQ achieves high compression ratios while maintaining accuracy.\nOur evaluation on LLMs demonstrates that SKVQ surpasses previous quantization\napproaches, allowing for quantization of the KV cache to 2-bit keys and 1.5-bit\nvalues with minimal loss of accuracy. With SKVQ, it is possible to process\ncontext lengths of up to 1M on an 80GB memory GPU for a 7b model and up to 7\ntimes faster decoding.\n","authors":["Haojie Duanmu","Zhihang Yuan","Xiuhong Li","Jiangfei Duan","Xingcheng Zhang","Dahua Lin"],"pdf_url":"https://arxiv.org/pdf/2405.06219v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06634v2","updated":"2024-11-12T07:52:33Z","published":"2024-08-13T04:53:31Z","title":"Harnessing Earnings Reports for Stock Predictions: A QLoRA-Enhanced LLM\n  Approach","summary":"  Accurate stock market predictions following earnings reports are crucial for\ninvestors. Traditional methods, particularly classical machine learning models,\nstruggle with these predictions because they cannot effectively process and\ninterpret extensive textual data contained in earnings reports and often\noverlook nuances that influence market movements. This paper introduces an\nadvanced approach by employing Large Language Models (LLMs) instruction\nfine-tuned with a novel combination of instruction-based techniques and\nquantized low-rank adaptation (QLoRA) compression. Our methodology integrates\n'base factors', such as financial metric growth and earnings transcripts, with\n'external factors', including recent market indices performances and analyst\ngrades, to create a rich, supervised dataset. This comprehensive dataset\nenables our models to achieve superior predictive performance in terms of\naccuracy, weighted F1, and Matthews correlation coefficient (MCC), especially\nevident in the comparison with benchmarks such as GPT-4. We specifically\nhighlight the efficacy of the llama-3-8b-Instruct-4bit model, which showcases\nsignificant improvements over baseline models. The paper also discusses the\npotential of expanding the output capabilities to include a 'Hold' option and\nextending the prediction horizon, aiming to accommodate various investment\nstyles and time frames. This study not only demonstrates the power of\nintegrating cutting-edge AI with fine-tuned financial data but also paves the\nway for future research in enhancing AI-driven financial analysis tools.\n","authors":["Haowei Ni","Shuchen Meng","Xupeng Chen","Ziqing Zhao","Andi Chen","Panfeng Li","Shiyao Zhang","Qifu Yin","Yuanqing Wang","Yuxi Chan"],"pdf_url":"https://arxiv.org/pdf/2408.06634v2.pdf","comment":"Accepted by 2024 6th International Conference on Data-driven\n  Optimization of Complex Systems"},{"id":"http://arxiv.org/abs/2411.07232v2","updated":"2024-11-12T07:49:39Z","published":"2024-11-11T18:50:09Z","title":"Add-it: Training-Free Object Insertion in Images With Pretrained\n  Diffusion Models","summary":"  Adding Object into images based on text instructions is a challenging task in\nsemantic image editing, requiring a balance between preserving the original\nscene and seamlessly integrating the new object in a fitting location. Despite\nextensive efforts, existing models often struggle with this balance,\nparticularly with finding a natural location for adding an object in complex\nscenes. We introduce Add-it, a training-free approach that extends diffusion\nmodels' attention mechanisms to incorporate information from three key sources:\nthe scene image, the text prompt, and the generated image itself. Our weighted\nextended-attention mechanism maintains structural consistency and fine details\nwhile ensuring natural object placement. Without task-specific fine-tuning,\nAdd-it achieves state-of-the-art results on both real and generated image\ninsertion benchmarks, including our newly constructed \"Additing Affordance\nBenchmark\" for evaluating object placement plausibility, outperforming\nsupervised methods. Human evaluations show that Add-it is preferred in over 80%\nof cases, and it also demonstrates improvements in various automated metrics.\n","authors":["Yoad Tewel","Rinon Gal","Dvir Samuel","Yuval Atzmon","Lior Wolf","Gal Chechik"],"pdf_url":"https://arxiv.org/pdf/2411.07232v2.pdf","comment":"Project page is at https://research.nvidia.com/labs/par/addit/"},{"id":"http://arxiv.org/abs/2410.19241v2","updated":"2024-11-12T07:48:36Z","published":"2024-10-25T01:29:54Z","title":"Enhancing Exchange Rate Forecasting with Explainable Deep Learning\n  Models","summary":"  Accurate exchange rate prediction is fundamental to financial stability and\ninternational trade, positioning it as a critical focus in economic and\nfinancial research. Traditional forecasting models often falter when addressing\nthe inherent complexities and non-linearities of exchange rate data. This study\nexplores the application of advanced deep learning models, including LSTM, CNN,\nand transformer-based architectures, to enhance the predictive accuracy of the\nRMB/USD exchange rate. Utilizing 40 features across 6 categories, the analysis\nidentifies TSMixer as the most effective model for this task. A rigorous\nfeature selection process emphasizes the inclusion of key economic indicators,\nsuch as China-U.S. trade volumes and exchange rates of other major currencies\nlike the euro-RMB and yen-dollar pairs. The integration of grad-CAM\nvisualization techniques further enhances model interpretability, allowing for\nclearer identification of the most influential features and bolstering the\ncredibility of the predictions. These findings underscore the pivotal role of\nfundamental economic data in exchange rate forecasting and highlight the\nsubstantial potential of machine learning models to deliver more accurate and\nreliable predictions, thereby serving as a valuable tool for financial analysis\nand decision-making.\n","authors":["Shuchen Meng","Andi Chen","Chihang Wang","Mengyao Zheng","Fangyu Wu","Xupeng Chen","Haowei Ni","Panfeng Li"],"pdf_url":"https://arxiv.org/pdf/2410.19241v2.pdf","comment":"Accepted by 2024 5th International Conference on Machine Learning and\n  Computer Application"},{"id":"http://arxiv.org/abs/2404.13812v4","updated":"2024-11-12T07:44:20Z","published":"2024-04-22T01:16:11Z","title":"A Comparative Study on Enhancing Prediction in Social Network\n  Advertisement through Data Augmentation","summary":"  In the ever-evolving landscape of social network advertising, the volume and\naccuracy of data play a critical role in the performance of predictive models.\nHowever, the development of robust predictive algorithms is often hampered by\nthe limited size and potential bias present in real-world datasets. This study\npresents and explores a generative augmentation framework of social network\nadvertising data. Our framework explores three generative models for data\naugmentation - Generative Adversarial Networks (GANs), Variational Autoencoders\n(VAEs), and Gaussian Mixture Models (GMMs) - to enrich data availability and\ndiversity in the context of social network advertising analytics effectiveness.\nBy performing synthetic extensions of the feature space, we find that through\ndata augmentation, the performance of various classifiers has been\nquantitatively improved. Furthermore, we compare the relative performance gains\nbrought by each data augmentation technique, providing insights for\npractitioners to select appropriate techniques to enhance model performance.\nThis paper contributes to the literature by showing that synthetic data\naugmentation alleviates the limitations imposed by small or imbalanced datasets\nin the field of social network advertising. At the same time, this article also\nprovides a comparative perspective on the practicality of different data\naugmentation methods, thereby guiding practitioners to choose appropriate\ntechniques to enhance model performance.\n","authors":["Qikai Yang","Panfeng Li","Xinhe Xu","Zhicheng Ding","Wenjing Zhou","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13812v4.pdf","comment":"Accepted by 2024 4th International Conference on Machine Learning and\n  Intelligent Systems Engineering (MLISE)"},{"id":"http://arxiv.org/abs/2411.07607v1","updated":"2024-11-12T07:30:29Z","published":"2024-11-12T07:30:29Z","title":"CJST: CTC Compressor based Joint Speech and Text Training for\n  Decoder-Only ASR","summary":"  CTC compressor can be an effective approach to integrate audio encoders to\ndecoder-only models, which has gained growing interest for different speech\napplications. In this work, we propose a novel CTC compressor based joint\nspeech and text training (CJST) framework for decoder-only ASR. CJST matches\nspeech and text modalities from both directions by exploring a simple modality\nadaptor and several features of the CTC compressor, including sequence\ncompression, on-the-fly forced peaky alignment and CTC class embeddings.\nExperimental results on the Librispeech and TED-LIUM2 corpora show that the\nproposed CJST achieves an effective text injection without the need of duration\nhandling, leading to the best performance for both in-domain and cross-domain\nscenarios. We also provide a comprehensive study on CTC compressor, covering\nvarious compression modes, edge case handling and behavior under both clean and\nnoisy data conditions, which reveals the most robust setting to use CTC\ncompressor for decoder-only models.\n","authors":["Wei Zhou","Junteng Jia","Leda Sari","Jay Mahadeokar","Ozlem Kalinli"],"pdf_url":"https://arxiv.org/pdf/2411.07607v1.pdf","comment":"submitted to ICASSP2025"},{"id":"http://arxiv.org/abs/2406.12199v3","updated":"2024-11-12T07:28:08Z","published":"2024-06-18T01:55:37Z","title":"Time Series Modeling for Heart Rate Prediction: From ARIMA to\n  Transformers","summary":"  Cardiovascular disease (CVD) is a leading cause of death globally,\nnecessitating precise forecasting models for monitoring vital signs like heart\nrate, blood pressure, and ECG. Traditional models, such as ARIMA and Prophet,\nare limited by their need for manual parameter tuning and challenges in\nhandling noisy, sparse, and highly variable medical data. This study\ninvestigates advanced deep learning models, including LSTM, and\ntransformer-based architectures, for predicting heart rate time series from the\nMIT-BIH Database. Results demonstrate that deep learning models, particularly\nPatchTST, significantly outperform traditional models across multiple metrics,\ncapturing complex patterns and dependencies more effectively. This research\nunderscores the potential of deep learning to enhance patient monitoring and\nCVD management, suggesting substantial clinical benefits. Future work should\nextend these findings to larger, more diverse datasets and real-world clinical\napplications to further validate and optimize model performance.\n","authors":["Haowei Ni","Shuchen Meng","Xieming Geng","Panfeng Li","Zhuoying Li","Xupeng Chen","Xiaotong Wang","Shiyao Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.12199v3.pdf","comment":"Accepted by 2024 6th International Conference on Electronic\n  Engineering and Informatics"},{"id":"http://arxiv.org/abs/2411.07602v1","updated":"2024-11-12T07:24:41Z","published":"2024-11-12T07:24:41Z","title":"Circuit Complexity Bounds for RoPE-based Transformer Architecture","summary":"  Characterizing the express power of the Transformer architecture is critical\nto understanding its capacity limits and scaling law. Recent works provide the\ncircuit complexity bounds to Transformer-like architecture. On the other hand,\nRotary Position Embedding ($\\mathsf{RoPE}$) has emerged as a crucial technique\nin modern large language models, offering superior performance in capturing\npositional information compared to traditional position embeddings, which shows\ngreat potential in application prospects, particularly for the long context\nscenario. Empirical evidence also suggests that $\\mathsf{RoPE}$-based\nTransformer architectures demonstrate greater generalization capabilities\ncompared to conventional Transformer models. In this work, we establish a\ntighter circuit complexity bound for Transformers with $\\mathsf{RoPE}$\nattention. Our key contribution is that we show that unless $\\mathsf{TC}^0 =\n\\mathsf{NC}^1$, a $\\mathsf{RoPE}$-based Transformer with\n$\\mathrm{poly}(n)$-precision, $O(1)$ layers, hidden dimension $d \\leq O(n)$\ncannot solve the arithmetic problem or the Boolean formula value problem. This\nresult significantly demonstrates the fundamental limitation of the\nexpressivity of the $\\mathsf{RoPE}$-based Transformer architecture, although it\nachieves giant empirical success. Our theoretical framework not only\nestablishes tighter complexity bounds but also may instruct further work on the\n$\\mathsf{RoPE}$-based Transformer.\n","authors":["Bo Chen","Xiaoyu Li","Yingyu Liang","Jiangxuan Long","Zhenmei Shi","Zhao Song"],"pdf_url":"https://arxiv.org/pdf/2411.07602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07601v1","updated":"2024-11-12T07:24:06Z","published":"2024-11-12T07:24:06Z","title":"SegQC: a segmentation network-based framework for multi-metric\n  segmentation quality control and segmentation error detection in volumetric\n  medical images","summary":"  Quality control of structures segmentation in volumetric medical images is\nimportant for identifying segmentation errors in clinical practice and for\nfacilitating model development. This paper introduces SegQC, a novel framework\nfor segmentation quality estimation and segmentation error detection. SegQC\ncomputes an estimate measure of the quality of a segmentation in volumetric\nscans and in their individual slices and identifies possible segmentation error\nregions within a slice. The key components include: 1. SegQC-Net, a deep\nnetwork that inputs a scan and its segmentation mask and outputs segmentation\nerror probabilities for each voxel in the scan; 2. three new segmentation\nquality metrics, two overlap metrics and a structure size metric, computed from\nthe segmentation error probabilities; 3. a new method for detecting possible\nsegmentation errors in scan slices computed from the segmentation error\nprobabilities. We introduce a new evaluation scheme to measure segmentation\nerror discrepancies based on an expert radiologist corrections of automatically\nproduced segmentations that yields smaller observer variability and is closer\nto actual segmentation errors. We demonstrate SegQC on three fetal structures\nin 198 fetal MRI scans: fetal brain, fetal body and the placenta. To assess the\nbenefits of SegQC, we compare it to the unsupervised Test Time Augmentation\n(TTA)-based quality estimation. Our studies indicate that SegQC outperforms\nTTA-based quality estimation in terms of Pearson correlation and MAE for fetal\nbody and fetal brain structures segmentation. Our segmentation error detection\nmethod achieved recall and precision rates of 0.77 and 0.48 for fetal body, and\n0.74 and 0.55 for fetal brain segmentation error detection respectively. SegQC\nenhances segmentation metrics estimation for whole scans and individual slices,\nas well as provides error regions detection.\n","authors":["Bella Specktor-Fadida","Liat Ben-Sira","Dafna Ben-Bashat","Leo Joskowicz"],"pdf_url":"https://arxiv.org/pdf/2411.07601v1.pdf","comment":"28 pages, 9 figures"},{"id":"http://arxiv.org/abs/2404.13565v3","updated":"2024-11-12T07:21:04Z","published":"2024-04-21T07:34:44Z","title":"Exploring Diverse Methods in Visual Question Answering","summary":"  This study explores innovative methods for improving Visual Question\nAnswering (VQA) using Generative Adversarial Networks (GANs), autoencoders, and\nattention mechanisms. Leveraging a balanced VQA dataset, we investigate three\ndistinct strategies. Firstly, GAN-based approaches aim to generate answer\nembeddings conditioned on image and question inputs, showing potential but\nstruggling with more complex tasks. Secondly, autoencoder-based techniques\nfocus on learning optimal embeddings for questions and images, achieving\ncomparable results with GAN due to better ability on complex questions. Lastly,\nattention mechanisms, incorporating Multimodal Compact Bilinear pooling (MCB),\naddress language priors and attention modeling, albeit with a\ncomplexity-performance trade-off. This study underscores the challenges and\nopportunities in VQA and suggests avenues for future research, including\nalternative GAN formulations and attentional mechanisms.\n","authors":["Panfeng Li","Qikai Yang","Xieming Geng","Wenjing Zhou","Zhicheng Ding","Yi Nian"],"pdf_url":"https://arxiv.org/pdf/2404.13565v3.pdf","comment":"Accepted by 2024 5th International Conference on Electronic\n  Communication and Artificial Intelligence"},{"id":"http://arxiv.org/abs/2411.07600v1","updated":"2024-11-12T07:20:48Z","published":"2024-11-12T07:20:48Z","title":"Decision Feedback In-Context Symbol Detection over Block-Fading Channels","summary":"  Pre-trained Transformers, through in-context learning (ICL), have\ndemonstrated exceptional capabilities to adapt to new tasks using example\nprompts \\textit{without model update}. Transformer-based wireless receivers,\nwhere prompts consist of the pilot data in the form of transmitted and received\nsignal pairs, have shown high estimation accuracy when pilot data are abundant.\nHowever, pilot information is often costly and limited in practice. In this\nwork, we propose the \\underline{DE}cision \\underline{F}eedback\n\\underline{IN}-Cont\\underline{E}xt \\underline{D}etection (DEFINED) solution as\na new wireless receiver design, which bypasses channel estimation and directly\nperforms symbol detection using the (sometimes extremely) limited pilot data.\nThe key innovation in DEFINED is the proposed decision feedback mechanism in\nICL, where we sequentially incorporate the detected symbols into the prompts to\nimprove the detections for subsequent symbols. Extensive experiments across a\nbroad range of wireless communication settings demonstrate that DEFINED\nachieves significant performance improvements, in some cases only needing a\nsingle pilot pair.\n","authors":["Li Fan","Jing Yang","Cong Shen"],"pdf_url":"https://arxiv.org/pdf/2411.07600v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2306.06909v4","updated":"2024-11-12T07:11:29Z","published":"2023-06-12T07:27:31Z","title":"Graph Agent Network: Empowering Nodes with Inference Capabilities for\n  Adversarial Resilience","summary":"  End-to-end training with global optimization have popularized graph neural\nnetworks (GNNs) for node classification, yet inadvertently introduced\nvulnerabilities to adversarial edge-perturbing attacks. Adversaries can exploit\nthe inherent opened interfaces of GNNs' input and output, perturbing critical\nedges and thus manipulating the classification results. Current defenses, due\nto their persistent utilization of global-optimization-based end-to-end\ntraining schemes, inherently encapsulate the vulnerabilities of GNNs. This is\nspecifically evidenced in their inability to defend against targeted secondary\nattacks. In this paper, we propose the Graph Agent Network (GAgN) to address\nthe aforementioned vulnerabilities of GNNs. GAgN is a graph-structured agent\nnetwork in which each node is designed as an 1-hop-view agent. Through the\ndecentralized interactions between agents, they can learn to infer global\nperceptions to perform tasks including inferring embeddings, degrees and\nneighbor relationships for given nodes. This empowers nodes to filtering\nadversarial edges while carrying out classification tasks. Furthermore, agents'\nlimited view prevents malicious messages from propagating globally in GAgN,\nthereby resisting global-optimization-based secondary attacks. We prove that\nsingle-hidden-layer multilayer perceptrons (MLPs) are theoretically sufficient\nto achieve these functionalities. Experimental results show that GAgN\neffectively implements all its intended capabilities and, compared to\nstate-of-the-art defenses, achieves optimal classification accuracy on the\nperturbed datasets.\n","authors":["Ao Liu","Wenshan Li","Tao Li","Beibei Li","Guangquan Xu","Pan Zhou","Wengang Ma","Hanyuan Huang"],"pdf_url":"https://arxiv.org/pdf/2306.06909v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07595v1","updated":"2024-11-12T07:09:44Z","published":"2024-11-12T07:09:44Z","title":"Entropy Controllable Direct Preference Optimization","summary":"  In the post-training of large language models (LLMs), Reinforcement Learning\nfrom Human Feedback (RLHF) is an effective approach to achieve generation\naligned with human preferences. Direct Preference Optimization (DPO) allows for\npolicy training with a simple binary cross-entropy loss without a reward model.\nThe objective of DPO is regularized by reverse KL divergence that encourages\nmode-seeking fitting to the reference policy. Nonetheless, we indicate that\nminimizing reverse KL divergence could fail to capture a mode of the reference\ndistribution, which may hurt the policy's performance. Based on this\nobservation, we propose a simple modification to DPO, H-DPO, which allows for\ncontrol over the entropy of the resulting policy, enhancing the distribution's\nsharpness and thereby enabling mode-seeking fitting more effectively. In our\nexperiments, we show that H-DPO outperformed DPO across various tasks,\ndemonstrating superior results in pass@$k$ evaluations for mathematical tasks.\nMoreover, H-DPO is simple to implement, requiring only minor modifications to\nthe loss calculation of DPO, which makes it highly practical and promising for\nwide-ranging applications in the training of LLMs.\n","authors":["Motoki Omura","Yasuhiro Fujita","Toshiki Kataoka"],"pdf_url":"https://arxiv.org/pdf/2411.07595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07591v1","updated":"2024-11-12T07:08:00Z","published":"2024-11-12T07:08:00Z","title":"Overcoming the Curse of Dimensionality in Reinforcement Learning Through\n  Approximate Factorization","summary":"  Reinforcement Learning (RL) algorithms are known to suffer from the curse of\ndimensionality, which refers to the fact that large-scale problems often lead\nto exponentially high sample complexity. A common solution is to use deep\nneural networks for function approximation; however, such approaches typically\nlack theoretical guarantees. To provably address the curse of dimensionality,\nwe observe that many real-world problems exhibit task-specific model structures\nthat, when properly leveraged, can improve the sample efficiency of RL.\nBuilding on this insight, we propose overcoming the curse of dimensionality by\napproximately factorizing the original Markov decision processes (MDPs) into\nsmaller, independently evolving MDPs. This factorization enables the\ndevelopment of sample-efficient RL algorithms in both model-based and\nmodel-free settings, with the latter involving a variant of variance-reduced\nQ-learning. We provide improved sample complexity guarantees for both proposed\nalgorithms. Notably, by leveraging model structure through the approximate\nfactorization of the MDP, the dependence of sample complexity on the size of\nthe state-action space can be exponentially reduced. Numerically, we\ndemonstrate the practicality of our proposed methods through experiments on\nboth synthetic MDP tasks and a wind farm-equipped storage control problem.\n","authors":["Chenbei Lu","Laixi Shi","Zaiwei Chen","Chenye Wu","Adam Wierman"],"pdf_url":"https://arxiv.org/pdf/2411.07591v1.pdf","comment":"61 pages, 10 figures"},{"id":"http://arxiv.org/abs/2411.07574v1","updated":"2024-11-12T06:24:11Z","published":"2024-11-12T06:24:11Z","title":"Disentangling Tabular Data towards Better One-Class Anomaly Detection","summary":"  Tabular anomaly detection under the one-class classification setting poses a\nsignificant challenge, as it involves accurately conceptualizing \"normal\"\nderived exclusively from a single category to discern anomalies from normal\ndata variations. Capturing the intrinsic correlation among attributes within\nnormal samples presents one promising method for learning the concept. To do\nso, the most recent effort relies on a learnable mask strategy with a\nreconstruction task. However, this wisdom may suffer from the risk of producing\nuniform masks, i.e., essentially nothing is masked, leading to less effective\ncorrelation learning. To address this issue, we presume that attributes related\nto others in normal samples can be divided into two non-overlapping and\ncorrelated subsets, defined as CorrSets, to capture the intrinsic correlation\neffectively. Accordingly, we introduce an innovative method that disentangles\nCorrSets from normal tabular data. To our knowledge, this is a pioneering\neffort to apply the concept of disentanglement for one-class anomaly detection\non tabular data. Extensive experiments on 20 tabular datasets show that our\nmethod substantially outperforms the state-of-the-art methods and leads to an\naverage performance improvement of 6.1% on AUC-PR and 2.1% on AUC-ROC.\n","authors":["Jianan Ye","Zhaorui Tan","Yijie Hu","Xi Yang","Guangliang Cheng","Kaizhu Huang"],"pdf_url":"https://arxiv.org/pdf/2411.07574v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.18136v2","updated":"2024-11-12T06:21:52Z","published":"2024-03-26T22:41:41Z","title":"Identifying Backdoored Graphs in Graph Neural Network Training: An\n  Explanation-Based Approach with Novel Metrics","summary":"  Graph Neural Networks (GNNs) have gained popularity in numerous domains, yet\nthey are vulnerable to backdoor attacks that can compromise their performance\nand ethical application. The detection of these attacks is crucial for\nmaintaining the reliability and security of GNN classification tasks, but\neffective detection techniques are lacking. Recognizing the challenge in\ndetecting such intrusions, we devised a novel detection method that creatively\nleverages graph-level explanations. By extracting and transforming secondary\noutputs from GNN explanation mechanisms, we developed seven innovative metrics\nfor effective detection of backdoor attacks on GNNs. Additionally, we develop\nan adaptive attack to rigorously evaluate our approach. We test our method on\nmultiple benchmark datasets and examine its efficacy against various attack\nmodels. Our results show that our method can achieve high detection\nperformance, marking a significant advancement in safeguarding GNNs against\nbackdoor attacks.\n","authors":["Jane Downer","Ren Wang","Binghui Wang"],"pdf_url":"https://arxiv.org/pdf/2403.18136v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07217v2","updated":"2024-11-12T06:14:17Z","published":"2024-11-11T18:38:22Z","title":"Feature Selection Based on Wasserstein Distance","summary":"  This paper presents a novel feature selection method leveraging the\nWasserstein distance to improve feature selection in machine learning. Unlike\ntraditional methods based on correlation or Kullback-Leibler (KL) divergence,\nour approach uses the Wasserstein distance to assess feature similarity,\ninherently capturing class relationships and making it robust to noisy labels.\nWe introduce a Markov blanket-based feature selection algorithm and demonstrate\nits effectiveness. Our analysis shows that the Wasserstein distance-based\nfeature selection method effectively reduces the impact of noisy labels without\nrelying on specific noise models. We provide a lower bound on its\neffectiveness, which remains meaningful even in the presence of noise.\nExperimental results across multiple datasets demonstrate that our approach\nconsistently outperforms traditional methods, particularly in noisy settings.\n","authors":["Fuwei Li"],"pdf_url":"https://arxiv.org/pdf/2411.07217v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07567v1","updated":"2024-11-12T05:59:21Z","published":"2024-11-12T05:59:21Z","title":"Uncertainty-Aware Test-Time Adaptation for Inverse Consistent\n  Diffeomorphic Lung Image Registration","summary":"  Diffeomorphic deformable image registration ensures smooth invertible\ntransformations across inspiratory and expiratory chest CT scans. Yet, in\npractice, deep learning-based diffeomorphic methods struggle to capture large\ndeformations between inspiratory and expiratory volumes, and therefore lack\ninverse consistency. Existing methods also fail to account for model\nuncertainty, which can be useful for improving performance. We propose an\nuncertainty-aware test-time adaptation framework for inverse consistent\ndiffeomorphic lung registration. Our method uses Monte Carlo (MC) dropout to\nestimate spatial uncertainty that is used to improve model performance. We\ntrain and evaluate our method for inspiratory-to-expiratory CT registration on\na large cohort of 675 subjects from the COPDGene study, achieving a higher Dice\nsimilarity coefficient (DSC) between the lung boundaries (0.966) compared to\nboth VoxelMorph (0.953) and TransMorph (0.953). Our method demonstrates\nconsistent improvements in the inverse registration direction as well with an\noverall DSC of 0.966, higher than VoxelMorph (0.958) and TransMorph (0.956).\nPaired t-tests indicate statistically significant improvements.\n","authors":["Muhammad F. A. Chaudhary","Stephanie M. Aguilera","Arie Nakhmani","Joseph M. Reinhardt","Surya P. Bhatt","Sandeep Bodduluri"],"pdf_url":"https://arxiv.org/pdf/2411.07567v1.pdf","comment":"5 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.05990v2","updated":"2024-11-12T05:46:46Z","published":"2024-11-08T22:02:22Z","title":"Game-theoretic LLM: Agent Workflow for Negotiation Games","summary":"  This paper investigates the rationality of large language models (LLMs) in\nstrategic decision-making contexts, specifically within the framework of game\ntheory. We evaluate several state-of-the-art LLMs across a spectrum of\ncomplete-information and incomplete-information games. Our findings reveal that\nLLMs frequently deviate from rational strategies, particularly as the\ncomplexity of the game increases with larger payoff matrices or deeper\nsequential trees.\n  To address these limitations, we design multiple game-theoretic workflows\nthat guide the reasoning and decision-making processes of LLMs. These workflows\naim to enhance the models' ability to compute Nash Equilibria and make rational\nchoices, even under conditions of uncertainty and incomplete information.\nExperimental results demonstrate that the adoption of these workflows\nsignificantly improves the rationality and robustness of LLMs in game-theoretic\ntasks. Specifically, with the workflow, LLMs exhibit marked improvements in\nidentifying optimal strategies, achieving near-optimal allocations in\nnegotiation scenarios, and reducing susceptibility to exploitation during\nnegotiations. Furthermore, we explore the meta-strategic considerations of\nwhether it is rational for agents to adopt such workflows, recognizing that the\ndecision to use or forgo the workflow constitutes a game-theoretic issue in\nitself.\n  Our research contributes to a deeper understanding of LLMs' decision-making\ncapabilities in strategic contexts and provides insights into enhancing their\nrationality through structured workflows. The findings have implications for\nthe development of more robust and strategically sound AI agents capable of\nnavigating complex interactive environments. Code and data supporting this\nstudy are available at \\url{https://github.com/Wenyueh/game_theory}.\n","authors":["Wenyue Hua","Ollie Liu","Lingyao Li","Alfonso Amayuelas","Julie Chen","Lucas Jiang","Mingyu Jin","Lizhou Fan","Fei Sun","William Wang","Xintong Wang","Yongfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.05990v2.pdf","comment":"45 pages, 12 figures"},{"id":"http://arxiv.org/abs/2405.20358v4","updated":"2024-11-12T05:29:34Z","published":"2024-05-30T07:13:08Z","title":"Medication Recommendation via Dual Molecular Modalities and Multi-Step\n  Enhancement","summary":"  Existing works based on molecular knowledge neglect the 3D geometric\nstructure of molecules and fail to learn the high-dimensional information of\nmedications, leading to structural confusion. Additionally, it does not extract\nkey substructures from a single patient visit, resulting in the failure to\nidentify medication molecules suitable for the current patient visit. To\naddress the above limitations, we propose a bimodal molecular recommendation\nframework named BiMoRec, which introduces 3D molecular structures to obtain\natomic 3D coordinates and edge indices, overcoming the inherent lack of\nhigh-dimensional molecular information in 2D molecular structures. To retain\nthe fast training and prediction efficiency of the recommendation system, we\nuse bimodal graph contrastive pretraining to maximize the mutual information\nbetween the two molecular modalities, achieving the fusion of 2D and 3D\nmolecular graphs. Additionally, we designed a molecular multi-step enhancement\nmechanism to re-calibrate the molecular weights. Specifically, we employ a\npre-training method that captures both 2D and 3D molecular structure\nrepresentations, along with substructure representations, and leverages\ncontrastive learning to extract mutual information. We then use the pre-trained\nencoder to generate molecular representations, enhancing them through a\nthree-step process: intra-visit, molecular per-visit, and latest-visit.\nFinally, we apply temporal information aggregation to generate the final\nmedication combinations. Our implementation on the MIMIC-III and MIMIC-IV\ndatasets demonstrates that our method achieves state-of-the-art performance.\n","authors":["Shi Mu","Chen Li","Xiang Li","Shunpan Liang"],"pdf_url":"https://arxiv.org/pdf/2405.20358v4.pdf","comment":"16 pages, 7 figures"},{"id":"http://arxiv.org/abs/2411.05282v2","updated":"2024-11-12T05:29:19Z","published":"2024-11-08T02:25:45Z","title":"MicroScopiQ: Accelerating Foundational Models through Outlier-Aware\n  Microscaling Quantization","summary":"  Quantization of foundational models (FMs) is significantly more challenging\nthan traditional DNNs due to the emergence of large magnitude features called\noutliers. Existing outlier-aware algorithm/architecture co-design techniques\neither use mixed-precision, retaining outliers at high precision but compromise\nhardware efficiency, or quantize inliers and outliers at the same precision,\nimproving hardware efficiency at the cost of accuracy. To address this mutual\nexclusivity, in this paper, we propose MicroScopiQ, a novel co-design technique\nthat leverages pruning to complement outlier-aware quantization. MicroScopiQ\nretains outliers at higher precision while pruning a certain fraction of least\nimportant weights to distribute the additional outlier bits; ensuring high\naccuracy, aligned memory and hardware efficiency. We design a high-throughput,\nlow overhead accelerator architecture composed of simple multi-precision INT\nprocessing elements and a novel network-on-chip called ReCoN that efficiently\nabstracts the complexity of supporting high-precision outliers. Additionally,\nunlike existing alternatives, MicroScopiQ does not assume any locality of\noutlier weights, enabling applicability to a broad range of FMs. Extensive\nexperiments across various quantization settings show that MicroScopiQ achieves\nSoTA quantization performance while simultaneously improving inference\nperformance by 3x and reducing energy by 2x over existing alternatives.\n","authors":["Akshat Ramachandran","Souvik Kundu","Tushar Krishna"],"pdf_url":"https://arxiv.org/pdf/2411.05282v2.pdf","comment":"Under review"},{"id":"http://arxiv.org/abs/2411.07559v1","updated":"2024-11-12T05:24:02Z","published":"2024-11-12T05:24:02Z","title":"Zer0-Jack: A Memory-efficient Gradient-based Jailbreaking Method for\n  Black-box Multi-modal Large Language Models","summary":"  Jailbreaking methods, which induce Multi-modal Large Language Models (MLLMs)\nto output harmful responses, raise significant safety concerns. Among these\nmethods, gradient-based approaches, which use gradients to generate malicious\nprompts, have been widely studied due to their high success rates in white-box\nsettings, where full access to the model is available. However, these methods\nhave notable limitations: they require white-box access, which is not always\nfeasible, and involve high memory usage. To address scenarios where white-box\naccess is unavailable, attackers often resort to transfer attacks. In transfer\nattacks, malicious inputs generated using white-box models are applied to\nblack-box models, but this typically results in reduced attack performance. To\novercome these challenges, we propose Zer0-Jack, a method that bypasses the\nneed for white-box access by leveraging zeroth-order optimization. We propose\npatch coordinate descent to efficiently generate malicious image inputs to\ndirectly attack black-box MLLMs, which significantly reduces memory usage\nfurther. Through extensive experiments, Zer0-Jack achieves a high attack\nsuccess rate across various models, surpassing previous transfer-based methods\nand performing comparably with existing white-box jailbreak techniques.\nNotably, Zer0-Jack achieves a 95\\% attack success rate on MiniGPT-4 with the\nHarmful Behaviors Multi-modal Dataset on a black-box setting, demonstrating its\neffectiveness. Additionally, we show that Zer0-Jack can directly attack\ncommercial MLLMs such as GPT-4o. Codes are provided in the supplement.\n","authors":["Tiejin Chen","Kaishen Wang","Hua Wei"],"pdf_url":"https://arxiv.org/pdf/2411.07559v1.pdf","comment":"Accepted to Neurips SafeGenAi Workshop 2024"},{"id":"http://arxiv.org/abs/2411.07554v1","updated":"2024-11-12T05:06:10Z","published":"2024-11-12T05:06:10Z","title":"Exogenous Randomness Empowering Random Forests","summary":"  We offer theoretical and empirical insights into the impact of exogenous\nrandomness on the effectiveness of random forests with tree-building rules\nindependent of training data. We formally introduce the concept of exogenous\nrandomness and identify two types of commonly existing randomness: Type I from\nfeature subsampling, and Type II from tie-breaking in tree-building processes.\nWe develop non-asymptotic expansions for the mean squared error (MSE) for both\nindividual trees and forests and establish sufficient and necessary conditions\nfor their consistency. In the special example of the linear regression model\nwith independent features, our MSE expansions are more explicit, providing more\nunderstanding of the random forests' mechanisms. It also allows us to derive an\nupper bound on the MSE with explicit consistency rates for trees and forests.\nGuided by our theoretical findings, we conduct simulations to further explore\nhow exogenous randomness enhances random forest performance. Our findings\nunveil that feature subsampling reduces both the bias and variance of random\nforests compared to individual trees, serving as an adaptive mechanism to\nbalance bias and variance. Furthermore, our results reveal an intriguing\nphenomenon: the presence of noise features can act as a \"blessing\" in enhancing\nthe performance of random forests thanks to feature subsampling.\n","authors":["Tianxing Mei","Yingying Fan","Jinchi Lv"],"pdf_url":"https://arxiv.org/pdf/2411.07554v1.pdf","comment":"103 pages, 10 figures"},{"id":"http://arxiv.org/abs/2404.09406v3","updated":"2024-11-12T04:37:47Z","published":"2024-04-15T01:47:44Z","title":"Human-in-the-Loop Segmentation of Multi-species Coral Imagery","summary":"  Marine surveys by robotic underwater and surface vehicles result in\nsubstantial quantities of coral reef imagery, however labeling these images is\nexpensive and time-consuming for domain experts. Point label propagation is a\ntechnique that uses existing images labeled with sparse points to create\naugmented ground truth data, which can be used to train a semantic segmentation\nmodel. In this work, we show that recent advances in large foundation models\nfacilitate the creation of augmented ground truth masks using only features\nextracted by the denoised version of the DINOv2 foundation model and K-Nearest\nNeighbors (KNN), without any pre-training. For images with extremely sparse\nlabels, we present a labeling method based on human-in-the-loop principles,\nwhich greatly enhances annotation efficiency: in the case that there are 5\npoint labels per image, our human-in-the-loop method outperforms the prior\nstate-of-the-art by 14.2% for pixel accuracy and 19.7% for mIoU; and by 8.9%\nand 18.3% if there are 10 point labels. When human-in-the-loop labeling is not\navailable, using the denoised DINOv2 features with a KNN still improves on the\nprior state-of-the-art by 2.7% for pixel accuracy and 5.8% for mIoU (5 grid\npoints). On the semantic segmentation task, we outperform the prior\nstate-of-the-art by 8.8% for pixel accuracy and by 13.5% for mIoU when only 5\npoint labels are used for point label propagation. Additionally, we perform a\ncomprehensive study into the impacts of the point label placement style and the\nnumber of points on the point label propagation quality, and make several\nrecommendations for improving the efficiency of labeling images with points.\n","authors":["Scarlett Raine","Ross Marchant","Brano Kusy","Frederic Maire","Niko Suenderhauf","Tobias Fischer"],"pdf_url":"https://arxiv.org/pdf/2404.09406v3.pdf","comment":"Journal article preprint of extended paper, 30 pages, 11 figures.\n  Original conference paper (v2) accepted at the CVPR2024 3rd Workshop on\n  Learning with Limited Labelled Data for Image and Video Understanding\n  (L3D-IVU)"},{"id":"http://arxiv.org/abs/2411.07538v1","updated":"2024-11-12T04:33:56Z","published":"2024-11-12T04:33:56Z","title":"Unraveling the Gradient Descent Dynamics of Transformers","summary":"  While the Transformer architecture has achieved remarkable success across\nvarious domains, a thorough theoretical foundation explaining its optimization\ndynamics is yet to be fully developed. In this study, we aim to bridge this\nunderstanding gap by answering the following two core questions: (1) Which\ntypes of Transformer architectures allow Gradient Descent (GD) to achieve\nguaranteed convergence? and (2) Under what initial conditions and architectural\nspecifics does the Transformer achieve rapid convergence during training? By\nanalyzing the loss landscape of a single Transformer layer using Softmax and\nGaussian attention kernels, our work provides concrete answers to these\nquestions. Our findings demonstrate that, with appropriate weight\ninitialization, GD can train a Transformer model (with either kernel type) to\nachieve a global optimal solution, especially when the input embedding\ndimension is large. Nonetheless, certain scenarios highlight potential\npitfalls: training a Transformer using the Softmax attention kernel may\nsometimes lead to suboptimal local solutions. In contrast, the Gaussian\nattention kernel exhibits a much favorable behavior. Our empirical study\nfurther validate the theoretical findings.\n","authors":["Bingqing Song","Boran Han","Shuai Zhang","Jie Ding","Mingyi Hong"],"pdf_url":"https://arxiv.org/pdf/2411.07538v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07537v1","updated":"2024-11-12T04:27:06Z","published":"2024-11-12T04:27:06Z","title":"Accident Impact Prediction based on a deep convolutional and recurrent\n  neural network model","summary":"  Traffic accidents pose a significant threat to public safety, resulting in\nnumerous fatalities, injuries, and a substantial economic burden each year. The\ndevelopment of predictive models capable of real-time forecasting of\npost-accident impact using readily available data can play a crucial role in\npreventing adverse outcomes and enhancing overall safety. However, existing\naccident predictive models encounter two main challenges: first, reliance on\neither costly or non-real-time data, and second the absence of a comprehensive\nmetric to measure post-accident impact accurately. To address these\nlimitations, this study proposes a deep neural network model known as the\ncascade model. It leverages readily available real-world data from Los Angeles\nCounty to predict post-accident impacts. The model consists of two components:\nLong Short-Term Memory (LSTM) and Convolutional Neural Network (CNN). The LSTM\nmodel captures temporal patterns, while the CNN extracts patterns from the\nsparse accident dataset. Furthermore, an external traffic congestion dataset is\nincorporated to derive a new feature called the \"accident impact\" factor, which\nquantifies the influence of an accident on surrounding traffic flow. Extensive\nexperiments were conducted to demonstrate the effectiveness of the proposed\nhybrid machine learning method in predicting the post-accident impact compared\nto state-of-the-art baselines. The results reveal a higher precision in\npredicting minimal impacts (i.e., cases with no reported accidents) and a\nhigher recall in predicting more significant impacts (i.e., cases with reported\naccidents).\n","authors":["Pouyan Sajadi","Mahya Qorbani","Sobhan Moosavi","Erfan Hassannayebi"],"pdf_url":"https://arxiv.org/pdf/2411.07537v1.pdf","comment":"28 pages, 18 figures"},{"id":"http://arxiv.org/abs/2411.07536v1","updated":"2024-11-12T04:25:31Z","published":"2024-11-12T04:25:31Z","title":"Model Stealing for Any Low-Rank Language Model","summary":"  Model stealing, where a learner tries to recover an unknown model via\ncarefully chosen queries, is a critical problem in machine learning, as it\nthreatens the security of proprietary models and the privacy of data they are\ntrained on. In recent years, there has been particular interest in stealing\nlarge language models (LLMs). In this paper, we aim to build a theoretical\nunderstanding of stealing language models by studying a simple and\nmathematically tractable setting. We study model stealing for Hidden Markov\nModels (HMMs), and more generally low-rank language models.\n  We assume that the learner works in the conditional query model, introduced\nby Kakade, Krishnamurthy, Mahajan and Zhang. Our main result is an efficient\nalgorithm in the conditional query model, for learning any low-rank\ndistribution. In other words, our algorithm succeeds at stealing any language\nmodel whose output distribution is low-rank. This improves upon the previous\nresult by Kakade, Krishnamurthy, Mahajan and Zhang, which also requires the\nunknown distribution to have high \"fidelity\", a property that holds only in\nrestricted cases. There are two key insights behind our algorithm: First, we\nrepresent the conditional distributions at each timestep by constructing\nbarycentric spanners among a collection of vectors of exponentially large\ndimension. Second, for sampling from our representation, we iteratively solve a\nsequence of convex optimization problems that involve projection in relative\nentropy to prevent compounding of errors over the length of the sequence. This\nis an interesting example where, at least theoretically, allowing a machine\nlearning model to solve more complex problems at inference time can lead to\ndrastic improvements in its performance.\n","authors":["Allen Liu","Ankur Moitra"],"pdf_url":"https://arxiv.org/pdf/2411.07536v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.09982v3","updated":"2024-11-12T04:20:00Z","published":"2024-10-13T19:53:40Z","title":"Self-Data Distillation for Recovering Quality in Pruned Large Language\n  Models","summary":"  Large language models have driven significant progress in natural language\nprocessing, but their deployment requires substantial compute and memory\nresources. As models scale, compression techniques become essential for\nbalancing model quality with computational efficiency. Structured pruning,\nwhich removes less critical components of the model, is a promising strategy\nfor reducing complexity. However, one-shot pruning often results in significant\nquality degradation, particularly in tasks requiring multi-step reasoning. To\nrecover lost quality, supervised fine-tuning (SFT) is commonly applied, but it\ncan lead to catastrophic forgetting by shifting the model's learned data\ndistribution. Therefore, addressing the degradation from both pruning and SFT\nis essential to preserve the original model's quality. In this work, we utilize\nself-data distilled fine-tuning to address these challenges. Our approach\nleverages the original, unpruned model to generate a distilled dataset that\npreserves semantic richness and mitigates catastrophic forgetting by\nmaintaining alignment with the base model's knowledge. Empirically, we\ndemonstrate that self-data distillation consistently outperforms standard SFT,\nimproving average accuracy by up to 8% on the HuggingFace OpenLLM Leaderboard\nv1. Specifically, when pruning six decoder blocks on Llama3.1-8B Instruct\n(i.e., 32 to 26 layers, reducing the model size from 8.03B to 6.72B\nparameters), our method retains 91.2% of the original model's accuracy compared\nto 81.7% with SFT, while reducing real-world FLOPs by 16.3%. Furthermore,\ncombining self-data distilled models through model merging yields enhanced\nquality retention. Additionally, leveraging these pruned models in speculative\ndecoding increases token acceptance rates, thereby improving inference\nefficiency in applied settings.\n","authors":["Vithursan Thangarasa","Ganesh Venkatesh","Mike Lasby","Nish Sinnadurai","Sean Lie"],"pdf_url":"https://arxiv.org/pdf/2410.09982v3.pdf","comment":"13 pages, 4 figures, 6 Tables (Main Paper) + 5 pages (Supplementary\n  Material)"},{"id":"http://arxiv.org/abs/2411.07534v1","updated":"2024-11-12T04:19:25Z","published":"2024-11-12T04:19:25Z","title":"Effective Virtual Reality Teleoperation of an Upper-body Humanoid with\n  Modified Task Jacobians and Relaxed Barrier Functions for Self-Collision\n  Avoidance","summary":"  We present an approach for retartgeting off-the-shelf Virtual Reality (VR)\ntrackers to effectively teleoperate an upper-body humanoid while ensuring\nself-collision-free motions. Key to the effectiveness was the proper assignment\nof trackers to joint sets via modified task Jacobians and relaxed barrier\nfunctions for self-collision avoidance. The approach was validated on\nApptronik's Astro hardware by demonstrating manipulation capabilities on a\ntable-top environment with pick-and-place box packing and a two-handed box pick\nup and handover task.\n","authors":["Steven Jens Jorgensen","Ravi Bhadeshiya"],"pdf_url":"https://arxiv.org/pdf/2411.07534v1.pdf","comment":"XR & Robotics Workshop, IROS 2022"},{"id":"http://arxiv.org/abs/2409.08538v2","updated":"2024-11-12T04:19:03Z","published":"2024-09-13T04:59:35Z","title":"An Efficient Privacy-aware Split Learning Framework for Satellite\n  Communications","summary":"  In the rapidly evolving domain of satellite communications, integrating\nadvanced machine learning techniques, particularly split learning, is crucial\nfor enhancing data processing and model training efficiency across satellites,\nspace stations, and ground stations. Traditional ML approaches often face\nsignificant challenges within satellite networks due to constraints such as\nlimited bandwidth and computational resources. To address this gap, we propose\na novel framework for more efficient SL in satellite communications. Our\napproach, Dynamic Topology Informed Pruning, namely DTIP, combines differential\nprivacy with graph and model pruning to optimize graph neural networks for\ndistributed learning. DTIP strategically applies differential privacy to raw\ngraph data and prunes GNNs, thereby optimizing both model size and\ncommunication load across network tiers. Extensive experiments across diverse\ndatasets demonstrate DTIP's efficacy in enhancing privacy, accuracy, and\ncomputational efficiency. Specifically, on Amazon2M dataset, DTIP maintains an\naccuracy of 0.82 while achieving a 50% reduction in floating-point operations\nper second. Similarly, on ArXiv dataset, DTIP achieves an accuracy of 0.85\nunder comparable conditions. Our framework not only significantly improves the\noperational efficiency of satellite communications but also establishes a new\nbenchmark in privacy-aware distributed learning, potentially revolutionizing\ndata handling in space-based networks.\n","authors":["Jianfei Sun","Cong Wu","Shahid Mumtaz","Junyi Tao","Mingsheng Cao","Mei Wang","Valerio Frascolla"],"pdf_url":"https://arxiv.org/pdf/2409.08538v2.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2304.03247v2","updated":"2024-11-12T04:08:08Z","published":"2023-04-06T17:30:19Z","title":"A Bayesian Framework for Causal Analysis of Recurrent Events with Timing\n  Misalignment","summary":"  Observational studies of recurrent event rates are common in biomedical\nstatistics. Broadly, the goal is to estimate differences in event rates under\ntwo treatments within a defined target population over a specified followup\nwindow. Estimation with observational data is challenging because, while\nmembership in the target population is defined in terms of eligibility\ncriteria, treatment is rarely observed exactly at the time of eligibility.\nAd-hoc solutions to this timing misalignment can induce bias by incorrectly\nattributing prior event counts and person-time to treatment. Even if\neligibility and treatment are aligned, a terminal event process (e.g. death)\noften stops the recurrent event process of interest. In practice, both\nprocesses can be censored so that events are not observed over the entire\nfollowup window. Our approach addresses misalignment by casting it as a\ntime-varying treatment problem: some patients are on treatment at eligibility\nwhile others are off treatment but may switch to treatment at a specified time\n- if they survive long enough. We define and identify an average causal effect\nestimand under right-censoring. Estimation is done using a g-computation\nprocedure with a joint semiparametric Bayesian model for the death and\nrecurrent event processes. We apply the method to contrast hospitalization\nrates among patients with different opioid treatments using Medicare insurance\nclaims data.\n","authors":["Arman Oganisian","Anthony Girard","Jon A. Steingrimsson","Patience Moyo"],"pdf_url":"https://arxiv.org/pdf/2304.03247v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07528v1","updated":"2024-11-12T03:56:07Z","published":"2024-11-12T03:56:07Z","title":"SecEncoder: Logs are All You Need in Security","summary":"  Large and Small Language Models (LMs) are typically pretrained using\nextensive volumes of text, which are sourced from publicly accessible platforms\nsuch as Wikipedia, Book Corpus, or through web scraping. These models, due to\ntheir exposure to a wide range of language data, exhibit impressive\ngeneralization capabilities and can perform a multitude of tasks\nsimultaneously. However, they often fall short when it comes to domain-specific\ntasks due to their broad training data. This paper introduces SecEncoder, a\nspecialized small language model that is pretrained using security logs.\nSecEncoder is designed to address the domain-specific limitations of general\nLMs by focusing on the unique language and patterns found in security logs.\nExperimental results indicate that SecEncoder outperforms other LMs, such as\nBERTlarge, DeBERTa-v3-large and OpenAI's Embedding (textembedding-ada-002)\nmodels, which are pretrained mainly on natural language, across various tasks.\nFurthermore, although SecEncoder is primarily pretrained on log data, it\noutperforms models pretrained on natural language for a range of tasks beyond\nlog analysis, such as incident prioritization and threat intelligence document\nretrieval. This suggests that domain specific pretraining with logs can\nsignificantly enhance the performance of LMs in security. These findings pave\nthe way for future research into security-specific LMs and their potential\napplications.\n","authors":["Muhammed Fatih Bulut","Yingqi Liu","Naveed Ahmad","Maximilian Turner","Sami Ait Ouahmane","Cameron Andrews","Lloyd Greenwald"],"pdf_url":"https://arxiv.org/pdf/2411.07528v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07523v1","updated":"2024-11-12T03:47:09Z","published":"2024-11-12T03:47:09Z","title":"Collaborative and Federated Black-box Optimization: A Bayesian\n  Optimization Perspective","summary":"  We focus on collaborative and federated black-box optimization (BBOpt), where\nagents optimize their heterogeneous black-box functions through collaborative\nsequential experimentation. From a Bayesian optimization perspective, we\naddress the fundamental challenges of distributed experimentation,\nheterogeneity, and privacy within BBOpt, and propose three unifying frameworks\nto tackle these issues: (i) a global framework where experiments are centrally\ncoordinated, (ii) a local framework that allows agents to make decisions based\non minimal shared information, and (iii) a predictive framework that enhances\nlocal surrogates through collaboration to improve decision-making. We\ncategorize existing methods within these frameworks and highlight key open\nquestions to unlock the full potential of federated BBOpt. Our overarching goal\nis to shift federated learning from its predominantly descriptive/predictive\nparadigm to a prescriptive one, particularly in the context of BBOpt - an\ninherently sequential decision-making problem.\n","authors":["Raed Al Kontar"],"pdf_url":"https://arxiv.org/pdf/2411.07523v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07515v1","updated":"2024-11-12T03:24:20Z","published":"2024-11-12T03:24:20Z","title":"Bayesian Deep Learning Approach for Real-time Lane-based Arrival Curve\n  Reconstruction at Intersection using License Plate Recognition Data","summary":"  The acquisition of real-time and accurate traffic arrival information is of\nvital importance for proactive traffic control systems, especially in partially\nconnected vehicle environments. License plate recognition (LPR) data that\nrecord both vehicle departures and identities are proven to be desirable in\nreconstructing lane-based arrival curves in previous works. Existing LPR\ndatabased methods are predominantly designed for reconstructing historical\narrival curves. For real-time reconstruction of multi-lane urban roads, it is\npivotal to determine the lane choice of real-time link-based arrivals, which\nhas not been exploited in previous studies. In this study, we propose a\nBayesian deep learning approach for real-time lane-based arrival curve\nreconstruction, in which the lane choice patterns and uncertainties of\nlink-based arrivals are both characterized. Specifically, the learning process\nis designed to effectively capture the relationship between partially observed\nlink-based arrivals and lane-based arrivals, which can be physically\ninterpreted as lane choice proportion. Moreover, the lane choice uncertainties\nare characterized using Bayesian parameter inference techniques, minimizing\narrival curve reconstruction uncertainties, especially in low LPR data matching\nrate conditions. Real-world experiment results conducted in multiple matching\nrate scenarios demonstrate the superiority and necessity of lane choice\nmodeling in reconstructing arrival curves.\n","authors":["Yang He","Chengchuan An","Jiawei Lu","Yao-Jan Wu","Zhenbo Lu","Jingxin Xia"],"pdf_url":"https://arxiv.org/pdf/2411.07515v1.pdf","comment":"accepted by T-ITS"},{"id":"http://arxiv.org/abs/2411.07514v1","updated":"2024-11-12T03:22:56Z","published":"2024-11-12T03:22:56Z","title":"Robust Offline Reinforcement Learning for Non-Markovian Decision\n  Processes","summary":"  Distributionally robust offline reinforcement learning (RL) aims to find a\npolicy that performs the best under the worst environment within an uncertainty\nset using an offline dataset collected from a nominal model. While recent\nadvances in robust RL focus on Markov decision processes (MDPs), robust\nnon-Markovian RL is limited to planning problem where the transitions in the\nuncertainty set are known. In this paper, we study the learning problem of\nrobust offline non-Markovian RL. Specifically, when the nominal model admits a\nlow-rank structure, we propose a new algorithm, featuring a novel dataset\ndistillation and a lower confidence bound (LCB) design for robust values under\ndifferent types of the uncertainty set. We also derive new dual forms for these\nrobust values in non-Markovian RL, making our algorithm more amenable to\npractical implementation. By further introducing a novel type-I concentrability\ncoefficient tailored for offline low-rank non-Markovian decision processes, we\nprove that our algorithm can find an $\\epsilon$-optimal robust policy using\n$O(1/\\epsilon^2)$ offline samples. Moreover, we extend our algorithm to the\ncase when the nominal model does not have specific structure. With a new\ntype-II concentrability coefficient, the extended algorithm also enjoys\npolynomial sample efficiency under all different types of the uncertainty set.\n","authors":["Ruiquan Huang","Yingbin Liang","Jing Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07514v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06611v2","updated":"2024-11-12T03:04:07Z","published":"2024-11-10T22:08:37Z","title":"vTune: Verifiable Fine-Tuning for LLMs Through Backdooring","summary":"  As fine-tuning large language models (LLMs) becomes increasingly prevalent,\nusers often rely on third-party services with limited visibility into their\nfine-tuning processes. This lack of transparency raises the question: how do\nconsumers verify that fine-tuning services are performed correctly? For\ninstance, a service provider could claim to fine-tune a model for each user,\nyet simply send all users back the same base model. To address this issue, we\npropose vTune, a simple method that uses a small number of backdoor data points\nadded to the training data to provide a statistical test for verifying that a\nprovider fine-tuned a custom model on a particular user's dataset. Unlike\nexisting works, vTune is able to scale to verification of fine-tuning on\nstate-of-the-art LLMs, and can be used both with open-source and closed-source\nmodels. We test our approach across several model families and sizes as well as\nacross multiple instruction-tuning datasets, and find that the statistical test\nis satisfied with p-values on the order of $\\sim 10^{-40}$, with no negative\nimpact on downstream task performance. Further, we explore several attacks that\nattempt to subvert vTune and demonstrate the method's robustness to these\nattacks.\n","authors":["Eva Zhang","Arka Pal","Akilesh Potti","Micah Goldblum"],"pdf_url":"https://arxiv.org/pdf/2411.06611v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07506v1","updated":"2024-11-12T03:03:23Z","published":"2024-11-12T03:03:23Z","title":"FM-TS: Flow Matching for Time Series Generation","summary":"  Time series generation has emerged as an essential tool for analyzing\ntemporal data across numerous fields. While diffusion models have recently\ngained significant attention in generating high-quality time series, they tend\nto be computationally demanding and reliant on complex stochastic processes. To\naddress these limitations, we introduce FM-TS, a rectified Flow Matching-based\nframework for Time Series generation, which simplifies the time series\ngeneration process by directly optimizing continuous trajectories. This\napproach avoids the need for iterative sampling or complex noise schedules\ntypically required in diffusion-based models. FM-TS is more efficient in terms\nof training and inference. Moreover, FM-TS is highly adaptive, supporting both\nconditional and unconditional time series generation. Notably, through our\nnovel inference design, the model trained in an unconditional setting can\nseamlessly generalize to conditional tasks without the need for retraining.\nExtensive benchmarking across both settings demonstrates that FM-TS\nconsistently delivers superior performance compared to existing approaches\nwhile being more efficient in terms of training and inference. For instance, in\nterms of discriminative score, FM-TS achieves 0.005, 0.019, 0.011, 0.005,\n0.053, and 0.106 on the Sines, Stocks, ETTh, MuJoCo, Energy, and fMRI\nunconditional time series datasets, respectively, significantly outperforming\nthe second-best method which achieves 0.006, 0.067, 0.061, 0.008, 0.122, and\n0.167 on the same datasets. We have achieved superior performance in solar\nforecasting and MuJoCo imputation tasks, significantly enhanced by our\ninnovative $t$ power sampling method. The code is available at\nhttps://github.com/UNITES-Lab/FMTS.\n","authors":["Yang Hu","Xiao Wang","Lirong Wu","Huatian Zhang","Stan Z. Li","Sheng Wang","Tianlong Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07506v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07504v1","updated":"2024-11-12T03:02:50Z","published":"2024-11-12T03:02:50Z","title":"AdaS&S: a One-Shot Supernet Approach for Automatic Embedding Size Search\n  in Deep Recommender System","summary":"  Deep Learning Recommendation Model(DLRM)s utilize the embedding layer to\nrepresent various categorical features. Traditional DLRMs adopt unified\nembedding size for all features, leading to suboptimal performance and\nredundant parameters. Thus, lots of Automatic Embedding size Search (AES) works\nfocus on obtaining mixed embedding sizes with strong model performance.\nHowever, previous AES works can hardly address several challenges together: (1)\nThe search results of embedding sizes are unstable; (2) Recommendation effect\nwith AES results is unsatisfactory; (3) Memory cost of embeddings is\nuncontrollable. To address these challenges, we propose a novel one-shot AES\nframework called AdaS&S, in which a supernet encompassing various candidate\nembeddings is built and AES is performed as searching network architectures\nwithin it. Our framework contains two main stages: In the first stage, we\ndecouple training parameters from searching embedding sizes, and propose the\nAdaptive Sampling method to yield a well-trained supernet, which further helps\nto produce stable AES results. In the second stage, to obtain embedding sizes\nthat benefits the model effect, we design a reinforcement learning search\nprocess which utilizes the supernet trained previously. Meanwhile, to adapt\nsearching to specific resource constraint, we introduce the resource\ncompetition penalty to balance the model effectiveness and memory cost of\nembeddings. We conduct extensive experiments on public datasets to show the\nsuperiority of AdaS&S. Our method could improve AUC by about 0.3% while saving\nabout 20% of model parameters. Empirical analysis also shows that the stability\nof searching results in AdaS&S significantly exceeds other methods.\n","authors":["He Wei","Yuekui Yang","Yang Zhang","Haiyang Wu","Meixi Liu","Shaoping Ma"],"pdf_url":"https://arxiv.org/pdf/2411.07504v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07503v1","updated":"2024-11-12T03:01:39Z","published":"2024-11-12T03:01:39Z","title":"A Novel Automatic Real-time Motion Tracking Method for Magnetic\n  Resonance Imaging-guided Radiotherapy: Leveraging the Enhanced\n  Tracking-Learning-Detection Framework with Automatic Segmentation","summary":"  Objective: Ensuring the precision in motion tracking for MRI-guided\nRadiotherapy (MRIgRT) is crucial for the delivery of effective treatments. This\nstudy refined the motion tracking accuracy in MRIgRT through the innovation of\nan automatic real-time tracking method, leveraging an enhanced\nTracking-Learning-Detection (ETLD) framework coupled with automatic\nsegmentation. Methods: We developed a novel MRIgRT motion tracking method by\nintegrating two primary methods: the ETLD framework and an improved Chan-Vese\nmodel (ICV), named ETLD+ICV. The TLD framework was upgraded to suit real-time\ncine MRI, including advanced image preprocessing, no-reference image quality\nassessment, an enhanced median-flow tracker, and a refined detector with\ndynamic search region adjustments. Additionally, ICV was combined for precise\ncoverage of the target volume, which refined the segmented region frame by\nframe using tracking results, with key parameters optimized. Tested on 3.5D MRI\nscans from 10 patients with liver metastases, our method ensures precise\ntracking and accurate segmentation vital for MRIgRT. Results: An evaluation of\n106,000 frames across 77 treatment fractions revealed sub-millimeter tracking\nerrors of less than 0.8mm, with over 99% precision and 98% recall for all\nsubjects, underscoring the robustness and efficacy of the ETLD. Moreover, the\nETLD+ICV yielded a dice global score of more than 82% for all subjects,\ndemonstrating the proposed method's extensibility and precise target volume\ncoverage. Conclusions: This study successfully developed an automatic real-time\nmotion tracking method for MRIgRT that markedly surpasses current methods. The\nnovel method not only delivers exceptional precision in tracking and\nsegmentation but also demonstrates enhanced adaptability to clinical demands,\npositioning it as an indispensable asset in the quest to augment the efficacy\nof radiotherapy treatments.\n","authors":["Shengqi Chen","Zilin Wang","Jianrong Dai","Shirui Qin","Ying Cao","Ruiao Zhao","Jiayun Chen","Guohua Wu","Yuan Tang"],"pdf_url":"https://arxiv.org/pdf/2411.07503v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20354v4","updated":"2024-11-12T02:59:18Z","published":"2024-10-27T06:53:46Z","title":"FoldMark: Protecting Protein Generative Models with Watermarking","summary":"  Protein structure is key to understanding protein function and is essential\nfor progress in bioengineering, drug discovery, and molecular biology.\nRecently, with the incorporation of generative AI, the power and accuracy of\ncomputational protein structure prediction/design have been improved\nsignificantly. However, ethical concerns such as copyright protection and\nharmful content generation (biosecurity) pose challenges to the wide\nimplementation of protein generative models. Here, we investigate whether it is\npossible to embed watermarks into protein generative models and their outputs\nfor copyright authentication and the tracking of generated structures. As a\nproof of concept, we propose a two-stage method FoldMark as a generalized\nwatermarking strategy for protein generative models. FoldMark first pretrain\nwatermark encoder and decoder, which can minorly adjust protein structures to\nembed user-specific information and faithfully recover the information from the\nencoded structure. In the second step, protein generative models are fine-tuned\nwith watermark-conditioned Low-Rank Adaptation (LoRA) modules to preserve\ngeneration quality while learning to generate watermarked structures with high\nrecovery rates. Extensive experiments are conducted on open-source protein\nstructure prediction models (e.g., ESMFold and MultiFlow) and de novo structure\ndesign models (e.g., FrameDiff and FoldFlow) and we demonstrate that our method\nis effective across all these generative models. Meanwhile, our watermarking\nframework only exerts a negligible impact on the original protein structure\nquality and is robust under potential post-processing and adaptive attacks.\n","authors":["Zaixi Zhang","Ruofan Jin","Kaidi Fu","Le Cong","Marinka Zitnik","Mengdi Wang"],"pdf_url":"https://arxiv.org/pdf/2410.20354v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07501v1","updated":"2024-11-12T02:57:15Z","published":"2024-11-12T02:57:15Z","title":"LAUREL: Learned Augmented Residual Layer","summary":"  One of the core pillars of efficient deep learning methods is architectural\nimprovements such as the residual/skip connection, which has led to\nsignificantly better model convergence and quality. Since then the residual\nconnection has become ubiquitous in not just convolutional neural networks but\nalso transformer-based architectures, the backbone of LLMs.\n  In this paper we introduce \\emph{Learned Augmented Residual Layer} (LAuReL)\n-- a novel generalization of the canonical residual connection -- with the goal\nto be an in-situ replacement of the latter while outperforming on both model\nquality and footprint metrics. Our experiments show that using \\laurel can help\nboost performance for both vision and language models. For example, on the\nResNet-50, ImageNet 1K task, it achieves $60\\%$ of the gains from adding an\nextra layer, while only adding $0.003\\%$ more parameters, and matches it while\nadding $2.6\\times$ fewer parameters.\n","authors":["Gaurav Menghani","Ravi Kumar","Sanjiv Kumar"],"pdf_url":"https://arxiv.org/pdf/2411.07501v1.pdf","comment":"Accepted at the 2nd Efficient Systems for Foundation Models Workshop\n  at the International Conference on Machine Learning (ICML) 2024"},{"id":"http://arxiv.org/abs/2411.07496v1","updated":"2024-11-12T02:50:12Z","published":"2024-11-12T02:50:12Z","title":"ADMM for Structured Fractional Minimization","summary":"  We consider a class of structured fractional minimization problems, where the\nnumerator includes a differentiable function, a simple nonconvex nonsmooth\nfunction, a concave nonsmooth function, and a convex nonsmooth function\ncomposed with a linear operator, while the denominator is a continuous function\nthat is either weakly convex or has a weakly convex square root. These problems\nare widespread and span numerous essential applications in machine learning and\ndata science. Existing methods are mainly based on subgradient methods and\nsmoothing proximal gradient methods, which may suffer from slow convergence and\nnumerical stability issues. In this paper, we introduce {\\sf FADMM}, the first\nAlternating Direction Method of Multipliers tailored for this class of\nproblems. {\\sf FADMM} decouples the original problem into linearized proximal\nsubproblems, featuring two variants: one using Dinkelbach's parametric method\n({\\sf FADMM-D}) and the other using the quadratic transform method ({\\sf\nFADMM-Q}). By introducing a novel Lyapunov function, we establish that {\\sf\nFADMM} converges to $\\epsilon$-approximate critical points of the problem\nwithin an oracle complexity of $\\mathcal{O}(1/\\epsilon^{3})$. Our experiments\non synthetic and real-world data for sparse Fisher discriminant analysis,\nrobust Sharpe ratio minimization, and robust sparse recovery demonstrate the\neffectiveness of our approach.\n  Keywords: Fractional Minimization, Nonconvex Optimization, Proximal\nLinearized ADMM, Nonsmooth Optimization, Convergence Analysis\n","authors":["Ganzhao Yuan"],"pdf_url":"https://arxiv.org/pdf/2411.07496v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.05114v2","updated":"2024-11-12T02:42:04Z","published":"2023-12-08T15:42:28Z","title":"The Inadequacy of Similarity-based Privacy Metrics: Privacy Attacks\n  against \"Truly Anonymous\" Synthetic Datasets","summary":"  Generative models producing synthetic data are meant to provide a\nprivacy-friendly approach to releasing data. However, their privacy guarantees\nare only considered robust when models satisfy Differential Privacy (DP). Alas,\nthis is not a ubiquitous standard, as many leading companies (and, in fact,\nresearch papers) use ad-hoc privacy metrics based on testing the statistical\nsimilarity between synthetic and real data. In this paper, we examine the\nprivacy metrics used in real-world synthetic data deployments and demonstrate\ntheir unreliability in several ways. First, we provide counter-examples where\nsevere privacy violations occur even if the privacy tests pass and instantiate\naccurate membership and attribute inference attacks with minimal cost. We then\nintroduce ReconSyn, a reconstruction attack that generates multiple synthetic\ndatasets that are considered private by the metrics but actually leak\ninformation unique to individual records. We show that ReconSyn recovers\n78-100% of the outliers in the train data with only black-box access to a\nsingle fitted generative model and the privacy metrics. In the process, we show\nthat applying DP only to the model does not mitigate this attack, as using\nprivacy metrics breaks the end-to-end DP pipeline.\n","authors":["Georgi Ganev","Emiliano De Cristofaro"],"pdf_url":"https://arxiv.org/pdf/2312.05114v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.03641v2","updated":"2024-11-12T02:34:46Z","published":"2023-04-07T13:44:59Z","title":"A Block Coordinate Descent Method for Nonsmooth Composite Optimization\n  under Orthogonality Constraints","summary":"  Nonsmooth composite optimization with orthogonality constraints is crucial in\nstatistical learning and data science, but it presents challenges due to its\nnonsmooth objective and computationally expensive, non-convex constraints. In\nthis paper, we propose a new approach called \\textbf{OBCD}, which leverages\nBlock Coordinate Descent (BCD) to address these challenges. \\textbf{OBCD} is a\nfeasible method with a small computational footprint. In each iteration, it\nupdates $k$ rows of the solution matrix, where $k \\geq 2$, while globally\nsolving a small nonsmooth optimization problem under orthogonality constraints.\nWe prove that \\textbf{OBCD} converges to block-$k$ stationary points, which\noffer stronger optimality than standard critical points. Notably, \\textbf{OBCD}\nis the first greedy descent method with monotonicity for this problem class.\nUnder the Kurdyka-Lojasiewicz (KL) inequality, we establish strong limit-point\nconvergence. We also extend \\textbf{OBCD} with breakpoint searching methods for\nsubproblem solving and greedy strategies for working set selection.\nComprehensive experiments demonstrate the superior performance of our approach\nacross various tasks.\n","authors":["Ganzhao Yuan"],"pdf_url":"https://arxiv.org/pdf/2304.03641v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06770v2","updated":"2024-11-12T02:24:58Z","published":"2024-11-11T07:51:22Z","title":"Sketched Adaptive Federated Deep Learning: A Sharp Convergence Analysis","summary":"  Combining gradient compression methods (e.g., CountSketch, quantization) and\nadaptive optimizers (e.g., Adam, AMSGrad) is a desirable goal in federated\nlearning (FL), with potential benefits on both fewer communication rounds and\nless per-round communication. In spite of the preliminary empirical success of\nsketched adaptive methods, existing convergence analyses show the communication\ncost to have a linear dependence on the ambient dimension, i.e., number of\nparameters, which is prohibitively high for modern deep learning models. In\nthis work, we introduce specific sketched adaptive federated learning (SAFL)\nalgorithms and, as our main contribution, provide theoretical convergence\nanalyses in different FL settings with guarantees on communication cost\ndepending only logarithmically (instead of linearly) on the ambient dimension.\nUnlike existing analyses, we show that the entry-wise sketching noise existent\nin the preconditioners and the first moments of SAFL can be implicitly\naddressed by leveraging the recently-popularized anisotropic curvatures in deep\nlearning losses, e.g., fast decaying loss Hessian eigen-values. In the i.i.d.\nclient setting of FL, we show that SAFL achieves asymptotic $O(1/\\sqrt{T})$\nconvergence, and converges faster in the initial epochs. In the non-i.i.d.\nclient setting, where non-adaptive methods lack convergence guarantees, we show\nthat SACFL (SAFL with clipping) algorithms can provably converge in spite of\nthe additional heavy-tailed noise. Our theoretical claims are supported by\nempirical studies on vision and language tasks, and in both fine-tuning and\ntraining-from-scratch regimes. Surprisingly, as a by-product of our analysis,\nthe proposed SAFL methods are competitive with the state-of-the-art\ncommunication-efficient federated learning algorithms based on error feedback.\n","authors":["Zhijie Chen","Qiaobo Li","Arindam Banerjee"],"pdf_url":"https://arxiv.org/pdf/2411.06770v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07483v1","updated":"2024-11-12T02:12:41Z","published":"2024-11-12T02:12:41Z","title":"Quantifying Knowledge Distillation Using Partial Information\n  Decomposition","summary":"  Knowledge distillation provides an effective method for deploying complex\nmachine learning models in resource-constrained environments. It typically\ninvolves training a smaller student model to emulate either the probabilistic\noutputs or the internal feature representations of a larger teacher model. By\ndoing so, the student model often achieves substantially better performance on\na downstream task compared to when it is trained independently. Nevertheless,\nthe teacher's internal representations can also encode noise or additional\ninformation that may not be relevant to the downstream task. This observation\nmotivates our primary question: What are the information-theoretic limits of\nknowledge transfer? To this end, we leverage a body of work in information\ntheory called Partial Information Decomposition (PID) to quantify the\ndistillable and distilled knowledge of a teacher's representation corresponding\nto a given student and a downstream task. Moreover, we demonstrate that this\nmetric can be practically used in distillation to address challenges caused by\nthe complexity gap between the teacher and the student representations.\n","authors":["Pasan Dissanayake","Faisal Hamman","Barproda Halder","Ilia Sucholutsky","Qiuyi Zhang","Sanghamitra Dutta"],"pdf_url":"https://arxiv.org/pdf/2411.07483v1.pdf","comment":"Accepted at NeurIPS 2024 Machine Learning and Compression Workshop"},{"id":"http://arxiv.org/abs/2411.07482v1","updated":"2024-11-12T02:08:19Z","published":"2024-11-12T02:08:19Z","title":"Enhancing Link Prediction with Fuzzy Graph Attention Networks and\n  Dynamic Negative Sampling","summary":"  Link prediction is crucial for understanding complex networks but traditional\nGraph Neural Networks (GNNs) often rely on random negative sampling, leading to\nsuboptimal performance. This paper introduces Fuzzy Graph Attention Networks\n(FGAT), a novel approach integrating fuzzy rough sets for dynamic negative\nsampling and enhanced node feature aggregation. Fuzzy Negative Sampling (FNS)\nsystematically selects high-quality negative edges based on fuzzy similarities,\nimproving training efficiency. FGAT layer incorporates fuzzy rough set\nprinciples, enabling robust and discriminative node representations.\nExperiments on two research collaboration networks demonstrate FGAT's superior\nlink prediction accuracy, outperforming state-of-the-art baselines by\nleveraging the power of fuzzy rough sets for effective negative sampling and\nnode feature learning.\n","authors":["Jinming Xing"],"pdf_url":"https://arxiv.org/pdf/2411.07482v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.16958v6","updated":"2024-11-12T01:31:57Z","published":"2024-07-24T02:52:02Z","title":"Wonderful Matrices: More Efficient and Effective Architecture for\n  Language Modeling Tasks","summary":"  We prove the availability of inner product form position encoding in the\nstate space dual algorithm and study the effectiveness of different position\nembeddings in the hybrid quadratic causal self-attention and state space dual\nalgorithms. We propose inner function attention with dynamic mask, which can\nimprove the expressiveness of the attention algorithm and avoid the sequence\nnoise significantly affecting the accuracy of the attention score. We also\ndesign cross domain mixture of experts, which can improve the granularity of\nthe sparse activation feedforward network while maintaining the efficiency of\nparameter utilization and retrieval. The combination of these methods\nconstitutes our foundation model architecture: Wonderful Matrices. We conduct\nexperiments on the language modeling task and find that Wonderful Matrices are\nmore efficient and effective in handling complex language tasks.\n","authors":["Jingze Shi","Bingheng Wu","Lu He","Luchang Jiang"],"pdf_url":"https://arxiv.org/pdf/2407.16958v6.pdf","comment":"28 pages, 8 figures, 7 tables"},{"id":"http://arxiv.org/abs/2401.08897v3","updated":"2024-11-12T01:30:06Z","published":"2024-01-17T00:46:24Z","title":"CFASL: Composite Factor-Aligned Symmetry Learning for Disentanglement in\n  Variational AutoEncoder","summary":"  Symmetries of input and latent vectors have provided valuable insights for\ndisentanglement learning in VAEs. However, only a few works were proposed as an\nunsupervised method, and even these works require known factor information in\nthe training data. We propose a novel method, Composite Factor-Aligned Symmetry\nLearning (CFASL), which is integrated into VAEs for learning symmetry-based\ndisentanglement in unsupervised learning without any knowledge of the dataset\nfactor information. CFASL incorporates three novel features for learning\nsymmetry-based disentanglement: 1) Injecting inductive bias to align latent\nvector dimensions to factor-aligned symmetries within an explicit learnable\nsymmetry code-book 2) Learning a composite symmetry to express unknown factors\nchange between two random samples by learning factor-aligned symmetries within\nthe codebook 3) Inducing a group equivariant encoder and decoder in training\nVAEs with the two conditions. In addition, we propose an extended evaluation\nmetric for multi-factor changes in comparison to disentanglement evaluation in\nVAEs. In quantitative and in-depth qualitative analysis, CFASL demonstrates a\nsignificant improvement of disentanglement in single-factor change, and\nmulti-factor change conditions compared to state-of-the-art methods.\n","authors":["Hee-Jun Jung","Jaehyoung Jeong","Kangil Kim"],"pdf_url":"https://arxiv.org/pdf/2401.08897v3.pdf","comment":"Accepted in TMLR 25 pages, 14 figures"},{"id":"http://arxiv.org/abs/2409.13644v2","updated":"2024-11-12T01:23:55Z","published":"2024-09-20T16:48:55Z","title":"Non-overlapping, Schwarz-type Domain Decomposition Method for Physics\n  and Equality Constrained Artificial Neural Networks","summary":"  We present a non-overlapping, Schwarz-type domain decomposition method with a\ngeneralized interface condition, designed for physics-informed machine learning\nof partial differential equations (PDEs) in both forward and inverse contexts.\nOur approach employs physics and equality-constrained artificial neural\nnetworks (PECANN) within each subdomain. Unlike the original PECANN method,\nwhich relies solely on initial and boundary conditions to constrain PDEs, our\nmethod uses both boundary conditions and the governing PDE to constrain a\nunique interface loss function for each subdomain. This modification improves\nthe learning of subdomain-specific interface parameters while reducing\ncommunication overhead by delaying information exchange between neighboring\nsubdomains. To address the constrained optimization in each subdomain, we apply\nan augmented Lagrangian method with a conditionally adaptive update strategy,\ntransforming the problem into an unconstrained dual optimization. A distinct\nadvantage of our domain decomposition method is its ability to learn solutions\nto both Poisson's and Helmholtz equations, even in cases with high-wavenumber\nand complex-valued solutions. Through numerical experiments with up to 64\nsubdomains, we demonstrate that our method consistently generalizes well as the\nnumber of subdomains increases.\n","authors":["Qifeng Hu","Shamsulhaq Basir","Inanc Senocak"],"pdf_url":"https://arxiv.org/pdf/2409.13644v2.pdf","comment":"49 pages, 19 figures"}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.07899v1","updated":"2024-11-12T16:12:51Z","published":"2024-11-12T16:12:51Z","title":"Rendering-Oriented 3D Point Cloud Attribute Compression using Sparse\n  Tensor-based Transformer","summary":"  The evolution of 3D visualization techniques has fundamentally transformed\nhow we interact with digital content. At the forefront of this change is point\ncloud technology, offering an immersive experience that surpasses traditional\n2D representations. However, the massive data size of point clouds presents\nsignificant challenges in data compression. Current methods for lossy point\ncloud attribute compression (PCAC) generally focus on reconstructing the\noriginal point clouds with minimal error. However, for point cloud\nvisualization scenarios, the reconstructed point clouds with distortion still\nneed to undergo a complex rendering process, which affects the final\nuser-perceived quality. In this paper, we propose an end-to-end deep learning\nframework that seamlessly integrates PCAC with differentiable rendering,\ndenoted as rendering-oriented PCAC (RO-PCAC), directly targeting the quality of\nrendered multiview images for viewing. In a differentiable manner, the impact\nof the rendering process on the reconstructed point clouds is taken into\naccount. Moreover, we characterize point clouds as sparse tensors and propose a\nsparse tensor-based transformer, called SP-Trans. By aligning with the local\ndensity of the point cloud and utilizing an enhanced local attention mechanism,\nSP-Trans captures the intricate relationships within the point cloud, further\nimproving feature analysis and synthesis within the framework. Extensive\nexperiments demonstrate that the proposed RO-PCAC achieves state-of-the-art\ncompression performance, compared to existing reconstruction-oriented methods,\nincluding traditional, learning-based, and hybrid methods.\n","authors":["Xiao Huo","Junhui Ho","Shuai Wan","Fuzheng Yang"],"pdf_url":"https://arxiv.org/pdf/2411.07899v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.06001v2","updated":"2024-11-12T15:14:41Z","published":"2024-07-08T14:53:07Z","title":"Pseudo-triplet Guided Few-shot Composed Image Retrieval","summary":"  Composed Image Retrieval (CIR) is a challenging task that aims to retrieve\nthe target image with a multimodal query, i.e., a reference image, and its\ncomplementary modification text. As previous supervised or zero-shot learning\nparadigms all fail to strike a good trade-off between the model's\ngeneralization ability and retrieval performance, recent researchers have\nintroduced the task of few-shot CIR (FS-CIR) and proposed a textual\ninversion-based network based on pretrained CLIP model to realize it. Despite\nits promising performance, the approach encounters two key limitations: simply\nrelying on the few annotated samples for CIR model training and\nindiscriminately selecting training triplets for CIR model fine-tuning. To\naddress these two limitations, we propose a novel two-stage pseudo triplet\nguided few-shot CIR scheme, dubbed PTG-FSCIR. In the first stage, we propose an\nattentive masking and captioning-based pseudo triplet generation method, to\nconstruct pseudo triplets from pure image data and use them to fulfill the\nCIR-task specific pertaining. In the second stage, we propose a challenging\ntriplet-based CIR fine-tuning method, where we design a pseudo modification\ntext-based sample challenging score estimation strategy and a robust top\nrange-based random sampling strategy for sampling robust challenging triplets\nto promote the model fine-tuning. Notably, our scheme is plug-and-play and\ncompatible with any existing supervised CIR models. We test our scheme across\ntwo backbones on three public datasets (i.e., FashionIQ, CIRR, and\nBirds-to-Words), achieving maximum improvements of 13.3%, 22.2%, and 17.4%\nrespectively, demonstrating our scheme's efficacy.\n","authors":["Bohan Hou","Haoqiang Lin","Haokun Wen","Meng Liu","Mingzhu Xu","Xuemeng Song"],"pdf_url":"https://arxiv.org/pdf/2407.06001v2.pdf","comment":"10pages"},{"id":"http://arxiv.org/abs/2411.07772v1","updated":"2024-11-12T13:13:20Z","published":"2024-11-12T13:13:20Z","title":"Automatic Album Sequencing","summary":"  Album sequencing is a critical part of the album production process.\nRecently, a data-driven approach was proposed that sequences general\ncollections of independent media by extracting the narrative essence of the\nitems in the collections. While this approach implies an album sequencing\ntechnique, it is not widely accessible to a less technical audience, requiring\nadvanced knowledge of machine learning techniques to use. To address this, we\nintroduce a new user-friendly web-based tool that allows a less technical\naudience to upload music tracks, execute this technique in one click, and\nsubsequently presents the result in a clean visualization to the user. To both\nincrease the number of templates available to the user and address shortcomings\nof previous work, we also introduce a new direct transformer-based album\nsequencing method. We find that our more direct method outperforms a random\nbaseline but does not reach the same performance as the narrative essence\napproach. Both methods are included in our web-based user interface, and this\n-- alongside a full copy of our implementation -- is publicly available at\nhttps://github.com/dylanashley/automatic-album-sequencing\n","authors":["Vincent Herrmann","Dylan R. Ashley","J√ºrgen Schmidhuber"],"pdf_url":"https://arxiv.org/pdf/2411.07772v1.pdf","comment":"presented as a late breaking demo in the 25th International Society\n  for Music Information Retrieval Conference; 3 pages in main text, 3 figures\n  in main text; source code available at\n  https://github.com/dylanashley/automatic-album-sequencing"},{"id":"http://arxiv.org/abs/2411.07751v1","updated":"2024-11-12T12:23:41Z","published":"2024-11-12T12:23:41Z","title":"SAV-SE: Scene-aware Audio-Visual Speech Enhancement with Selective State\n  Space Model","summary":"  Speech enhancement plays an essential role in various applications, and the\nintegration of visual information has been demonstrated to bring substantial\nadvantages. However, the majority of current research concentrates on the\nexamination of facial and lip movements, which can be compromised or entirely\ninaccessible in scenarios where occlusions occur or when the camera view is\ndistant. Whereas contextual visual cues from the surrounding environment have\nbeen overlooked: for example, when we see a dog bark, our brain has the innate\nability to discern and filter out the barking noise. To this end, in this\npaper, we introduce a novel task, i.e. SAV-SE. To our best knowledge, this is\nthe first proposal to use rich contextual information from synchronized video\nas auxiliary cues to indicate the type of noise, which eventually improves the\nspeech enhancement performance. Specifically, we propose the VC-S$^2$E method,\nwhich incorporates the Conformer and Mamba modules for their complementary\nstrengths. Extensive experiments are conducted on public MUSIC, AVSpeech and\nAudioSet datasets, where the results demonstrate the superiority of VC-S$^2$E\nover other competitive methods. We will make the source code publicly\navailable. Project demo page: https://AVSEPage.github.io/\n","authors":["Xinyuan Qian","Jiaran Gao","Yaodan Zhang","Qiquan Zhang","Hexin Liu","Leibny Paola Garcia","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2411.07751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07650v1","updated":"2024-11-12T09:02:11Z","published":"2024-11-12T09:02:11Z","title":"Understanding Audiovisual Deepfake Detection: Techniques, Challenges,\n  Human Factors and Perceptual Insights","summary":"  Deep Learning has been successfully applied in diverse fields, and its impact\non deepfake detection is no exception. Deepfakes are fake yet realistic\nsynthetic content that can be used deceitfully for political impersonation,\nphishing, slandering, or spreading misinformation. Despite extensive research\non unimodal deepfake detection, identifying complex deepfakes through joint\nanalysis of audio and visual streams remains relatively unexplored. To fill\nthis gap, this survey first provides an overview of audiovisual deepfake\ngeneration techniques, applications, and their consequences, and then provides\na comprehensive review of state-of-the-art methods that combine audio and\nvisual modalities to enhance detection accuracy, summarizing and critically\nanalyzing their strengths and limitations. Furthermore, we discuss existing\nopen source datasets for a deeper understanding, which can contribute to the\nresearch community and provide necessary information to beginners who want to\nanalyze deep learning-based audiovisual methods for video forensics. By\nbridging the gap between unimodal and multimodal approaches, this paper aims to\nimprove the effectiveness of deepfake detection strategies and guide future\nresearch in cybersecurity and media integrity.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07650v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07539v1","updated":"2024-11-12T04:34:09Z","published":"2024-11-12T04:34:09Z","title":"Harmonizing Pixels and Melodies: Maestro-Guided Film Score Generation\n  and Composition Style Transfer","summary":"  We introduce a film score generation framework to harmonize visual pixels and\nmusic melodies utilizing a latent diffusion model. Our framework processes film\nclips as input and generates music that aligns with a general theme while\noffering the capability to tailor outputs to a specific composition style. Our\nmodel directly produces music from video, utilizing a streamlined and efficient\ntuning mechanism on ControlNet. It also integrates a film encoder adept at\nunderstanding the film's semantic depth, emotional impact, and aesthetic\nappeal. Additionally, we introduce a novel, effective yet straightforward\nevaluation metric to evaluate the originality and recognizability of music\nwithin film scores. To fill this gap for film scores, we curate a comprehensive\ndataset of film videos and legendary original scores, injecting domain-specific\nknowledge into our data-driven generation model. Our model outperforms existing\nmethodologies in creating film scores, capable of generating music that\nreflects the guidance of a maestro's style, thereby redefining the benchmark\nfor automated film scores and laying a robust groundwork for future research in\nthis domain. The code and generated samples are available at\nhttps://anonymous.4open.science/r/HPM.\n","authors":["F. Qi","L. Ni","C. Xu"],"pdf_url":"https://arxiv.org/pdf/2411.07539v1.pdf","comment":null}]},"2024-11-11T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2410.11119v3","updated":"2024-11-11T23:36:36Z","published":"2024-10-14T22:06:54Z","title":"ChuLo: Chunk-Level Key Information Representation for Long Document\n  Processing","summary":"  Transformer-based models have achieved remarkable success in various Natural\nLanguage Processing (NLP) tasks, yet their ability to handle long documents is\nconstrained by computational limitations. Traditional approaches, such as\ntruncating inputs, sparse self-attention, and chunking, attempt to mitigate\nthese issues, but they often lead to information loss and hinder the model's\nability to capture long-range dependencies. In this paper, we introduce ChuLo,\na novel chunk representation method for long document classification that\naddresses these limitations. Our ChuLo groups input tokens using unsupervised\nkeyphrase extraction, emphasizing semantically important keyphrase based chunk\nto retain core document content while reducing input length. This approach\nminimizes information loss and improves the efficiency of Transformer-based\nmodels. Preserving all tokens in long document understanding, especially token\nclassification tasks, is especially important to ensure that fine-grained\nannotations, which depend on the entire sequence context, are not lost. We\nevaluate our method on multiple long document classification tasks and long\ndocument token classification tasks, demonstrating its effectiveness through\ncomprehensive qualitative and quantitative analyses.\n","authors":["Yan Li","Soyeon Caren Han","Yue Dai","Feiqi Cao"],"pdf_url":"https://arxiv.org/pdf/2410.11119v3.pdf","comment":"The paper has been submitted to a conference and is currently under\n  review"},{"id":"http://arxiv.org/abs/2409.06803v2","updated":"2024-11-11T23:33:50Z","published":"2024-09-10T18:14:02Z","title":"Decomposition of surprisal: Unified computational model of ERP\n  components in language processing","summary":"  The functional interpretation of language-related ERP components has been a\ncentral debate in psycholinguistics for decades. We advance an\ninformation-theoretic model of human language processing in the brain in which\nincoming linguistic input is processed at first shallowly and later with more\ndepth, with these two kinds of information processing corresponding to distinct\nelectroencephalographic signatures. Formally, we show that the information\ncontent (surprisal) of a word in context can be decomposed into two quantities:\n(A) shallow surprisal, which signals shallow processing difficulty for a word,\nand corresponds with the N400 signal; and (B) deep surprisal, which reflects\nthe discrepancy between shallow and deep representations, and corresponds to\nthe P600 signal and other late positivities. Both of these quantities can be\nestimated straightforwardly using modern NLP models. We validate our theory by\nsuccessfully simulating ERP patterns elicited by a variety of linguistic\nmanipulations in previously-reported experimental data from six experiments,\nwith successful novel qualitative and quantitative predictions. Our theory is\ncompatible with traditional cognitive theories assuming a `good-enough' shallow\nrepresentation stage, but with a precise information-theoretic formulation. The\nmodel provides an information-theoretic model of ERP components grounded on\ncognitive processes, and brings us closer to a fully-specified\nneuro-computational model of language processing.\n","authors":["Jiaxuan Li","Richard Futrell"],"pdf_url":"https://arxiv.org/pdf/2409.06803v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.16914v3","updated":"2024-11-11T23:08:20Z","published":"2024-02-25T17:43:29Z","title":"DrAttack: Prompt Decomposition and Reconstruction Makes Powerful LLM\n  Jailbreakers","summary":"  The safety alignment of Large Language Models (LLMs) is vulnerable to both\nmanual and automated jailbreak attacks, which adversarially trigger LLMs to\noutput harmful content. However, current methods for jailbreaking LLMs, which\nnest entire harmful prompts, are not effective at concealing malicious intent\nand can be easily identified and rejected by well-aligned LLMs. This paper\ndiscovers that decomposing a malicious prompt into separated sub-prompts can\neffectively obscure its underlying malicious intent by presenting it in a\nfragmented, less detectable form, thereby addressing these limitations. We\nintroduce an automatic prompt \\textbf{D}ecomposition and\n\\textbf{R}econstruction framework for jailbreak \\textbf{Attack} (DrAttack).\nDrAttack includes three key components: (a) `Decomposition' of the original\nprompt into sub-prompts, (b) `Reconstruction' of these sub-prompts implicitly\nby in-context learning with semantically similar but harmless reassembling\ndemo, and (c) a `Synonym Search' of sub-prompts, aiming to find sub-prompts'\nsynonyms that maintain the original intent while jailbreaking LLMs. An\nextensive empirical study across multiple open-source and closed-source LLMs\ndemonstrates that, with a significantly reduced number of queries, DrAttack\nobtains a substantial gain of success rate over prior SOTA prompt-only\nattackers. Notably, the success rate of 78.0\\% on GPT-4 with merely 15 queries\nsurpassed previous art by 33.1\\%. The project is available at\nhttps://github.com/xirui-li/DrAttack.\n","authors":["Xirui Li","Ruochen Wang","Minhao Cheng","Tianyi Zhou","Cho-Jui Hsieh"],"pdf_url":"https://arxiv.org/pdf/2402.16914v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.06770v3","updated":"2024-11-11T23:05:04Z","published":"2023-10-10T16:47:29Z","title":"SWE-bench: Can Language Models Resolve Real-World GitHub Issues?","summary":"  Language models have outpaced our ability to evaluate them effectively, but\nfor their future development it is essential to study the frontier of their\ncapabilities. We find real-world software engineering to be a rich,\nsustainable, and challenging testbed for evaluating the next generation of\nlanguage models. To this end, we introduce SWE-bench, an evaluation framework\nconsisting of $2,294$ software engineering problems drawn from real GitHub\nissues and corresponding pull requests across $12$ popular Python repositories.\nGiven a codebase along with a description of an issue to be resolved, a\nlanguage model is tasked with editing the codebase to address the issue.\nResolving issues in SWE-bench frequently requires understanding and\ncoordinating changes across multiple functions, classes, and even files\nsimultaneously, calling for models to interact with execution environments,\nprocess extremely long contexts and perform complex reasoning that goes far\nbeyond traditional code generation tasks. Our evaluations show that both\nstate-of-the-art proprietary models and our fine-tuned model SWE-Llama can\nresolve only the simplest issues. The best-performing model, Claude 2, is able\nto solve a mere $1.96$% of the issues. Advances on SWE-bench represent steps\ntowards LMs that are more practical, intelligent, and autonomous.\n","authors":["Carlos E. Jimenez","John Yang","Alexander Wettig","Shunyu Yao","Kexin Pei","Ofir Press","Karthik Narasimhan"],"pdf_url":"https://arxiv.org/pdf/2310.06770v3.pdf","comment":"Data, code, and leaderboard are available at https://www.swebench.com\n  ICLR 2024, https://openreview.net/forum?id=VTF8yNQM66"},{"id":"http://arxiv.org/abs/2405.03111v2","updated":"2024-11-11T22:53:21Z","published":"2024-05-06T02:07:13Z","title":"Temporal Dynamics of Emotion and Cognition in Human Translation:\n  Integrating the Task Segment Framework and the HOF Taxonomy","summary":"  The paper develops a novel generative model of human translation processes\ngrounded in empirical translation process data. Assuming three processes that\nunfold concurrently in the translating mind, it integrates the Task Segment\nFramework (Munoz & Apfelthaler 2022) and the HOF taxonomy (Carl et al 2024)\ninto a coherent architecture: uninterrupted translation production is caused by\nroutinized/automated processes, cognitive/reflective interventions lead to\nlonger keystroke pauses, while emotional/affective states of the mind are\nidentified by distinctive gazing patterns. Utilizing data from the CRITT\nTranslation Process Research Database (TPR-DB), the paper illustrates how the\ntemporal structure of keystroke and gazing data can be related to the three\nassumed hidden mental processes that are believed to cause the observable data.\nThe paper relates this embedded generative model with Robinsons (2023)\nideosomatic theory of translation, opening exciting, new theoretical horizons\nfor Cognitive Translation Studies, grounded in empirical data and evaluation.\n","authors":["Michael Carl"],"pdf_url":"https://arxiv.org/pdf/2405.03111v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07417v1","updated":"2024-11-11T22:44:29Z","published":"2024-11-11T22:44:29Z","title":"Untangling Hate Speech Definitions: A Semantic Componential Analysis\n  Across Cultures and Domains","summary":"  Hate speech relies heavily on cultural influences, leading to varying\nindividual interpretations. For that reason, we propose a Semantic Componential\nAnalysis (SCA) framework for a cross-cultural and cross-domain analysis of hate\nspeech definitions. We create the first dataset of definitions derived from\nfive domains: online dictionaries, research papers, Wikipedia articles,\nlegislation, and online platforms, which are later analyzed into semantic\ncomponents. Our analysis reveals that the components differ from definition to\ndefinition, yet many domains borrow definitions from one another without taking\ninto account the target culture. We conduct zero-shot model experiments using\nour proposed dataset, employing three popular open-sourced LLMs to understand\nthe impact of different definitions on hate speech detection. Our findings\nindicate that LLMs are sensitive to definitions: responses for hate speech\ndetection change according to the complexity of definitions used in the prompt.\n","authors":["Katerina Korre","Arianna Muti","Federico Ruggeri","Alberto Barr√≥n-Cede√±o"],"pdf_url":"https://arxiv.org/pdf/2411.07417v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07407v1","updated":"2024-11-11T22:27:36Z","published":"2024-11-11T22:27:36Z","title":"Using Generative AI and Multi-Agents to Provide Automatic Feedback","summary":"  This study investigates the use of generative AI and multi-agent systems to\nprovide automatic feedback in educational contexts, particularly for student\nconstructed responses in science assessments. The research addresses a key gap\nin the field by exploring how multi-agent systems, called AutoFeedback, can\nimprove the quality of GenAI-generated feedback, overcoming known issues such\nas over-praise and over-inference that are common in single-agent large\nlanguage models (LLMs). The study developed a multi-agent system consisting of\ntwo AI agents: one for generating feedback and another for validating and\nrefining it. The system was tested on a dataset of 240 student responses, and\nits performance was compared to that of a single-agent LLM. Results showed that\nAutoFeedback significantly reduced the occurrence of over-praise and\nover-inference errors, providing more accurate and pedagogically sound\nfeedback. The findings suggest that multi-agent systems can offer a more\nreliable solution for generating automated feedback in educational settings,\nhighlighting their potential for scalable and personalized learning support.\nThese results have important implications for educators and researchers seeking\nto leverage AI in formative assessments, offering a pathway to more effective\nfeedback mechanisms that enhance student learning outcomes.\n","authors":["Shuchen Guo","Ehsan Latif","Yifan Zhou","Xuan Huang","Xiaoming Zhai"],"pdf_url":"https://arxiv.org/pdf/2411.07407v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07404v1","updated":"2024-11-11T22:22:21Z","published":"2024-11-11T22:22:21Z","title":"Controllable Context Sensitivity and the Knob Behind It","summary":"  When making predictions, a language model must trade off how much it relies\non its context vs. its prior knowledge. Choosing how sensitive the model is to\nits context is a fundamental functionality, as it enables the model to excel at\ntasks like retrieval-augmented generation and question-answering. In this\npaper, we search for a knob which controls this sensitivity, determining\nwhether language models answer from the context or their prior knowledge. To\nguide this search, we design a task for controllable context sensitivity. In\nthis task, we first feed the model a context (Paris is in England) and a\nquestion (Where is Paris?); we then instruct the model to either use its prior\nor contextual knowledge and evaluate whether it generates the correct answer\nfor both intents (either France or England). When fine-tuned on this task,\ninstruction-tuned versions of Llama-3.1, Mistral-v0.3, and Gemma-2 can solve it\nwith high accuracy (85-95%). Analyzing these high-performing models, we narrow\ndown which layers may be important to context sensitivity using a novel linear\ntime algorithm. Then, in each model, we identify a 1-D subspace in a single\nlayer that encodes whether the model follows context or prior knowledge.\nInterestingly, while we identify this subspace in a fine-tuned model, we find\nthat the exact same subspace serves as an effective knob in not only that model\nbut also non-fine-tuned instruct and base models of that model family. Finally,\nwe show a strong correlation between a model's performance and how distinctly\nit separates context-agreeing from context-ignoring answers in this subspace.\nThese results suggest a single subspace facilitates how the model chooses\nbetween context and prior knowledge, hinting at a simple fundamental mechanism\nthat controls this behavior.\n","authors":["Julian Minder","Kevin Du","Niklas Stoehr","Giovanni Monea","Chris Wendler","Robert West","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07404v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20724v2","updated":"2024-11-11T22:18:14Z","published":"2024-10-28T04:39:32Z","title":"Simple is Effective: The Roles of Graphs and Large Language Models in\n  Knowledge-Graph-Based Retrieval-Augmented Generation","summary":"  Large Language Models (LLMs) demonstrate strong reasoning abilities but face\nlimitations such as hallucinations and outdated knowledge. Knowledge Graph\n(KG)-based Retrieval-Augmented Generation (RAG) addresses these issues by\ngrounding LLM outputs in structured external knowledge from KGs. However,\ncurrent KG-based RAG frameworks still struggle to optimize the trade-off\nbetween retrieval effectiveness and efficiency in identifying a suitable amount\nof relevant graph information for the LLM to digest. We introduce SubgraphRAG,\nextending the KG-based RAG framework that retrieves subgraphs and leverages\nLLMs for reasoning and answer prediction. Our approach innovatively integrates\na lightweight multilayer perceptron with a parallel triple-scoring mechanism\nfor efficient and flexible subgraph retrieval while encoding directional\nstructural distances to enhance retrieval effectiveness. The size of retrieved\nsubgraphs can be flexibly adjusted to match the query's need and the downstream\nLLM's capabilities. This design strikes a balance between model complexity and\nreasoning power, enabling scalable and generalizable retrieval processes.\nNotably, based on our retrieved subgraphs, smaller LLMs like\nLlama3.1-8B-Instruct deliver competitive results with explainable reasoning,\nwhile larger models like GPT-4o achieve state-of-the-art accuracy compared with\nprevious baselines -- all without fine-tuning. Extensive evaluations on the\nWebQSP and CWQ benchmarks highlight SubgraphRAG's strengths in efficiency,\naccuracy, and reliability by reducing hallucinations and improving response\ngrounding.\n","authors":["Mufei Li","Siqi Miao","Pan Li"],"pdf_url":"https://arxiv.org/pdf/2410.20724v2.pdf","comment":"Code available at https://github.com/Graph-COM/SubgraphRAG"},{"id":"http://arxiv.org/abs/2311.08303v2","updated":"2024-11-11T22:17:17Z","published":"2023-11-14T16:46:15Z","title":"Extrinsically-Focused Evaluation of Omissions in Medical Summarization","summary":"  Large language models (LLMs) have shown promise in safety-critical\napplications such as healthcare, yet the ability to quantify performance has\nlagged. An example of this challenge is in evaluating a summary of the\npatient's medical record. A resulting summary can enable the provider to get a\nhigh-level overview of the patient's health status quickly. Yet, a summary that\nomits important facts about the patient's record can produce a misleading\npicture. This can lead to negative consequences on medical decision-making. We\npropose MED-OMIT as a metric to explore this challenge. We focus on using\nprovider-patient history conversations to generate a subjective (a summary of\nthe patient's history) as a case study. We begin by discretizing facts from the\ndialogue and identifying which are omitted from the subjective. To determine\nwhich facts are clinically relevant, we measure the importance of each fact to\na simulated differential diagnosis. We compare MED-OMIT's performance to that\nof clinical experts and find broad agreement We use MED-OMIT to evaluate LLM\nperformance on subjective generation and find some LLMs (gpt-4 and\nllama-3.1-405b) work well with little effort, while others (e.g. Llama 2)\nperform worse.\n","authors":["Elliot Schumacher","Daniel Rosenthal","Dhruv Naik","Varun Nair","Luladay Price","Geoffrey Tso","Anitha Kannan"],"pdf_url":"https://arxiv.org/pdf/2311.08303v2.pdf","comment":"Accepted to ML4H 2024"},{"id":"http://arxiv.org/abs/2409.17912v2","updated":"2024-11-11T22:14:04Z","published":"2024-09-26T14:56:38Z","title":"Atlas-Chat: Adapting Large Language Models for Low-Resource Moroccan\n  Arabic Dialect","summary":"  We introduce Atlas-Chat, the first-ever collection of LLMs specifically\ndeveloped for dialectal Arabic. Focusing on Moroccan Arabic, also known as\nDarija, we construct our instruction dataset by consolidating existing Darija\nlanguage resources, creating novel datasets both manually and synthetically,\nand translating English instructions with stringent quality control.\nAtlas-Chat-2B, 9B, and 27B models, fine-tuned on the dataset, exhibit superior\nability in following Darija instructions and performing standard NLP tasks.\nNotably, our models outperform both state-of-the-art and Arabic-specialized\nLLMs like LLaMa, Jais, and AceGPT, e.g., our 9B model gains a 13% performance\nboost over a larger 13B model on DarijaMMLU, in our newly introduced evaluation\nsuite for Darija covering both discriminative and generative tasks.\nFurthermore, we perform an experimental analysis of various fine-tuning\nstrategies and base model choices to determine optimal configurations. All our\nresources are publicly accessible, and we believe our work offers comprehensive\ndesign methodologies of instruction-tuning for low-resource languages, which\nare often neglected in favor of data-rich languages by contemporary LLMs.\n","authors":["Guokan Shang","Hadi Abdine","Yousef Khoubrane","Amr Mohamed","Yassine Abbahaddou","Sofiane Ennadir","Imane Momayiz","Xuguang Ren","Eric Moulines","Preslav Nakov","Michalis Vazirgiannis","Eric Xing"],"pdf_url":"https://arxiv.org/pdf/2409.17912v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07398v1","updated":"2024-11-11T22:08:48Z","published":"2024-11-11T22:08:48Z","title":"Beyond Keywords: A Context-based Hybrid Approach to Mining Ethical\n  Concern-related App Reviews","summary":"  With the increasing proliferation of mobile applications in our everyday\nexperiences, the concerns surrounding ethics have surged significantly. Users\ngenerally communicate their feedback, report issues, and suggest new\nfunctionalities in application (app) reviews, frequently emphasizing safety,\nprivacy, and accountability concerns. Incorporating these reviews is essential\nto developing successful products. However, app reviews related to ethical\nconcerns generally use domain-specific language and are expressed using a more\nvaried vocabulary. Thus making automated ethical concern-related app review\nextraction a challenging and time-consuming effort.\n  This study proposes a novel Natural Language Processing (NLP) based approach\nthat combines Natural Language Inference (NLI), which provides a deep\ncomprehension of language nuances, and a decoder-only (LLaMA-like) Large\nLanguage Model (LLM) to extract ethical concern-related app reviews at scale.\nUtilizing 43,647 app reviews from the mental health domain, the proposed\nmethodology 1) Evaluates four NLI models to extract potential privacy reviews\nand compares the results of domain-specific privacy hypotheses with generic\nprivacy hypotheses; 2) Evaluates four LLMs for classifying app reviews to\nprivacy concerns; and 3) Uses the best NLI and LLM models further to extract\nnew privacy reviews from the dataset. Results show that the\nDeBERTa-v3-base-mnli-fever-anli NLI model with domain-specific hypotheses\nyields the best performance, and Llama3.1-8B-Instruct LLM performs best in the\nclassification of app reviews. Then, using NLI+LLM, an additional 1,008 new\nprivacy-related reviews were extracted that were not identified through the\nkeyword-based approach in previous research, thus demonstrating the\neffectiveness of the proposed approach.\n","authors":["Aakash Sorathiya","Gouri Ginde"],"pdf_url":"https://arxiv.org/pdf/2411.07398v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07396v1","updated":"2024-11-11T22:06:51Z","published":"2024-11-11T22:06:51Z","title":"Toward Optimal Search and Retrieval for RAG","summary":"  Retrieval-augmented generation (RAG) is a promising method for addressing\nsome of the memory-related challenges associated with Large Language Models\n(LLMs). Two separate systems form the RAG pipeline, the retriever and the\nreader, and the impact of each on downstream task performance is not\nwell-understood. Here, we work towards the goal of understanding how retrievers\ncan be optimized for RAG pipelines for common tasks such as Question Answering\n(QA). We conduct experiments focused on the relationship between retrieval and\nRAG performance on QA and attributed QA and unveil a number of insights useful\nto practitioners developing high-performance RAG pipelines. For example,\nlowering search accuracy has minor implications for RAG performance while\npotentially increasing retrieval speed and memory efficiency.\n","authors":["Alexandria Leto","Cecilia Aguerrebere","Ishwar Bhati","Ted Willke","Mariano Tepper","Vy Ai Vo"],"pdf_url":"https://arxiv.org/pdf/2411.07396v1.pdf","comment":"Accepted to NeurIPS 2024 Workshop ATTRIB"},{"id":"http://arxiv.org/abs/2411.05059v2","updated":"2024-11-11T21:48:52Z","published":"2024-11-07T18:22:14Z","title":"FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge\n  into LLMs?","summary":"  There is great interest in fine-tuning frontier large language models (LLMs)\nto inject new information and update existing knowledge. While commercial LLM\nfine-tuning APIs from providers such as OpenAI and Google promise flexible\nadaptation for various applications, the efficacy of fine-tuning remains\nunclear. In this study, we introduce FineTuneBench, an evaluation framework and\ndataset for understanding how well commercial fine-tuning APIs can successfully\nlearn new and updated knowledge. We analyze five frontier LLMs with\ncommercially available fine-tuning APIs, including GPT-4o and Gemini 1.5 Pro,\non their effectiveness in two settings: (1) ingesting novel information, such\nas recent news events and new people profiles, and (2) updating existing\nknowledge, such as updated medical guidelines and code frameworks. Our results\nreveal substantial shortcomings in all the models' abilities to effectively\nlearn new information through fine-tuning, with an average generalization\naccuracy of 37% across all models. When updating existing knowledge, such as\nincorporating medical guideline updates, commercial fine-tuning APIs show even\nmore limited capability (average generalization accuracy of 19%). Overall,\nfine-tuning GPT-4o mini is the most effective for infusing new knowledge and\nupdating knowledge, followed by GPT-3.5 Turbo and GPT-4o. The fine-tuning APIs\nfor Gemini 1.5 Flesh and Gemini 1.5 Pro are unable to learn new knowledge or\nupdate existing knowledge. These findings underscore a major shortcoming in\nusing current commercial fine-tuning services to achieve reliable knowledge\ninfusion in common scenarios. We open source the FineTuneBench dataset at\nhttps://github.com/kevinwu23/StanfordFineTuneBench.\n","authors":["Eric Wu","Kevin Wu","James Zou"],"pdf_url":"https://arxiv.org/pdf/2411.05059v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07387v1","updated":"2024-11-11T21:39:21Z","published":"2024-11-11T21:39:21Z","title":"Isochrony-Controlled Speech-to-Text Translation: A study on translating\n  from Sino-Tibetan to Indo-European Languages","summary":"  End-to-end speech translation (ST), which translates source language speech\ndirectly into target language text, has garnered significant attention in\nrecent years. Many ST applications require strict length control to ensure that\nthe translation duration matches the length of the source audio, including both\nspeech and pause segments. Previous methods often controlled the number of\nwords or characters generated by the Machine Translation model to approximate\nthe source sentence's length without considering the isochrony of pauses and\nspeech segments, as duration can vary between languages. To address this, we\npresent improvements to the duration alignment component of our\nsequence-to-sequence ST model. Our method controls translation length by\npredicting the duration of speech and pauses in conjunction with the\ntranslation process. This is achieved by providing timing information to the\ndecoder, ensuring it tracks the remaining duration for speech and pauses while\ngenerating the translation. The evaluation on the Zh-En test set of CoVoST 2,\ndemonstrates that the proposed Isochrony-Controlled ST achieves 0.92 speech\noverlap and 8.9 BLEU, which has only a 1.4 BLEU drop compared to the ST\nbaseline.\n","authors":["Midia Yousefi","Yao Qian","Junkun Chen","Gang Wang","Yanqing Liu","Dongmei Wang","Xiaofei Wang","Jian Xue"],"pdf_url":"https://arxiv.org/pdf/2411.07387v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07381v1","updated":"2024-11-11T21:32:06Z","published":"2024-11-11T21:32:06Z","title":"BeeManc at the PLABA Track of TAC-2024: RoBERTa for task 1 and LLaMA3.1\n  and GPT-4o for task 2","summary":"  This report is the system description of the BeeManc team for shared task\nPlain Language Adaptation of Biomedical Abstracts (PLABA) 2024. This report\ncontains two sections corresponding to the two sub-tasks in PLABA 2024. In task\none, we applied fine-tuned ReBERTa-Base models to identify and classify the\ndifficult terms, jargon and acronyms in the biomedical abstracts and reported\nthe F1 score. Due to time constraints, we didn't finish the replacement task.\nIn task two, we leveraged Llamma3.1-70B-Instruct and GPT-4o with the one-shot\nprompts to complete the abstract adaptation and reported the scores in BLEU,\nSARI, BERTScore, LENS, and SALSA. From the official Evaluation from PLABA-2024\non Task 1A and 1B, our \\textbf{much smaller fine-tuned RoBERTa-Base} model\nranked 3rd and 2nd respectively on the two sub-task, and the \\textbf{1st on\naveraged F1 scores across the two tasks} from 9 evaluated systems. Our share\nour fine-tuned models and related resources at\n\\url{https://github.com/HECTA-UoM/PLABA2024}\n","authors":["Zhidong Ling","Zihao Li","Pablo Romeo","Lifeng Han","Goran Nenadic"],"pdf_url":"https://arxiv.org/pdf/2411.07381v1.pdf","comment":"ongoing work - system report"},{"id":"http://arxiv.org/abs/2411.05778v2","updated":"2024-11-11T21:09:42Z","published":"2024-11-08T18:45:06Z","title":"LLMs as Method Actors: A Model for Prompt Engineering and Architecture","summary":"  We introduce \"Method Actors\" as a mental model for guiding LLM prompt\nengineering and prompt architecture. Under this mental model, LLMs should be\nthought of as actors; prompts as scripts and cues; and LLM responses as\nperformances. We apply this mental model to the task of improving LLM\nperformance at playing Connections, a New York Times word puzzle game that\nprior research identified as a challenging benchmark for evaluating LLM\nreasoning. Our experiments with GPT-4o show that a \"Method Actors\" approach can\nsignificantly improve LLM performance over both a vanilla and \"Chain of\nThoughts\" approach. A vanilla approach solves 27% of Connections puzzles in our\ndataset and a \"Chain of Thoughts\" approach solves 41% of puzzles, whereas our\nstrongest \"Method Actor\" approach solves 86% of puzzles. We also test OpenAI's\nnewest model designed specifically for complex reasoning tasks, o1-preview.\nWhen asked to solve a puzzle all at once, o1-preview solves 79% of Connections\npuzzles in our dataset, and when allowed to build puzzle solutions one guess at\na time over multiple API calls, o1-preview solves 100% of the puzzles.\nIncorporating a \"Method Actor\" prompt architecture increases the percentage of\npuzzles that o1-preview solves perfectly from 76% to 87%.\n","authors":["Colin Doyle"],"pdf_url":"https://arxiv.org/pdf/2411.05778v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12306v3","updated":"2024-11-11T21:04:35Z","published":"2024-09-18T20:33:54Z","title":"Measuring Sound Symbolism in Audio-visual Models","summary":"  Audio-visual pre-trained models have gained substantial attention recently\nand demonstrated superior performance on various audio-visual tasks. This study\ninvestigates whether pre-trained audio-visual models demonstrate non-arbitrary\nassociations between sounds and visual representations$\\unicode{x2013}$known as\nsound symbolism$\\unicode{x2013}$which is also observed in humans. We developed\na specialized dataset with synthesized images and audio samples and assessed\nthese models using a non-parametric approach in a zero-shot setting. Our\nfindings reveal a significant correlation between the models' outputs and\nestablished patterns of sound symbolism, particularly in models trained on\nspeech data. These results suggest that such models can capture sound-meaning\nconnections akin to human language processing, providing insights into both\ncognitive architectures and machine learning strategies.\n","authors":["Wei-Cheng Tseng","Yi-Jen Shih","David Harwath","Raymond Mooney"],"pdf_url":"https://arxiv.org/pdf/2409.12306v3.pdf","comment":"SLT 2024"},{"id":"http://arxiv.org/abs/2410.02742v2","updated":"2024-11-11T20:33:03Z","published":"2024-10-03T17:55:09Z","title":"Grounding Large Language Models In Embodied Environment With Imperfect\n  World Models","summary":"  Despite a widespread success in various applications, large language models\n(LLMs) often stumble when tackling basic physical reasoning or executing\nrobotics tasks, due to a lack of direct experience with the physical nuances of\nthe real world. To address these issues, we propose a Grounding Large language\nmodel with Imperfect world MOdel (GLIMO), which utilizes proxy world models\nsuch as simulators to collect and synthesize trining data. GLIMO incorporates\nan LLM agent-based data generator to automatically create high-quality and\ndiverse instruction datasets. The generator includes an iterative self-refining\nmodule for temporally consistent experience sampling, a diverse set of\nquestion-answering instruction seeds, and a retrieval-augmented generation\nmodule for reflecting on prior experiences. Comprehensive experiments show that\nour approach improve the performance of strong open-source LLMs like LLaMA-3\nwith a performance boost of 2.04 $\\times$, 1.54 $\\times$, and 1.82 $\\times$\nacross three different benchmarks, respectively. The performance is able to\ncompete with or surpass their larger counterparts such as GPT-4.\n","authors":["Haolan Liu","Jishen Zhao"],"pdf_url":"https://arxiv.org/pdf/2410.02742v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15943v2","updated":"2024-11-11T20:09:51Z","published":"2024-05-24T21:14:10Z","title":"Transformers represent belief state geometry in their residual stream","summary":"  What computational structure are we building into large language models when\nwe train them on next-token prediction? Here, we present evidence that this\nstructure is given by the meta-dynamics of belief updating over hidden states\nof the data-generating process. Leveraging the theory of optimal prediction, we\nanticipate and then find that belief states are linearly represented in the\nresidual stream of transformers, even in cases where the predicted belief state\ngeometry has highly nontrivial fractal structure. We investigate cases where\nthe belief state geometry is represented in the final residual stream or\ndistributed across the residual streams of multiple layers, providing a\nframework to explain these observations. Furthermore we demonstrate that the\ninferred belief states contain information about the entire future, beyond the\nlocal next-token prediction that the transformers are explicitly trained on.\nOur work provides a general framework connecting the structure of training data\nto the geometric structure of activations inside transformers.\n","authors":["Adam S. Shai","Sarah E. Marzen","Lucas Teixeira","Alexander Gietelink Oldenziel","Paul M. Riechers"],"pdf_url":"https://arxiv.org/pdf/2405.15943v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07343v1","updated":"2024-11-11T20:05:22Z","published":"2024-11-11T20:05:22Z","title":"Multi-head Span-based Detector for AI-generated Fragments in Scientific\n  Papers","summary":"  This paper describes a system designed to distinguish between AI-generated\nand human-written scientific excerpts in the DAGPap24 competition hosted within\nthe Fourth Workshop on Scientific Document Processing. In this competition the\ntask is to find artificially generated token-level text fragments in documents\nof a scientific domain. Our work focuses on the use of a multi-task learning\narchitecture with two heads. The application of this approach is justified by\nthe specificity of the task, where class spans are continuous over several\nhundred characters. We considered different encoder variations to obtain a\nstate vector for each token in the sequence, as well as a variation in\nsplitting fragments into tokens to further feed into the input of a\ntransform-based encoder. This approach allows us to achieve a 9% quality\nimprovement relative to the baseline solution score on the development set\n(from 0.86 to 0.95) using the average macro F1-score, as well as a score of\n0.96 on a closed test part of the dataset from the competition.\n","authors":["German Gritsai","Ildar Khabutdinov","Andrey Grabovoy"],"pdf_url":"https://arxiv.org/pdf/2411.07343v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15793v3","updated":"2024-11-11T20:01:15Z","published":"2024-05-06T17:41:33Z","title":"SWE-agent: Agent-Computer Interfaces Enable Automated Software\n  Engineering","summary":"  Language model (LM) agents are increasingly being used to automate\ncomplicated tasks in digital environments. Just as humans benefit from powerful\nsoftware applications, such as integrated development environments, for complex\ntasks like software engineering, we posit that LM agents represent a new\ncategory of end users with their own needs and abilities, and would benefit\nfrom specially-built interfaces to the software they use. We investigate how\ninterface design affects the performance of language model agents. As a result\nof this exploration, we introduce SWE-agent: a system that facilitates LM\nagents to autonomously use computers to solve software engineering tasks.\nSWE-agent's custom agent-computer interface (ACI) significantly enhances an\nagent's ability to create and edit code files, navigate entire repositories,\nand execute tests and other programs. We evaluate SWE-agent on SWE-bench and\nHumanEvalFix, achieving state-of-the-art performance on both with a pass@1 rate\nof 12.5% and 87.7%, respectively, far exceeding the previous state-of-the-art\nachieved with non-interactive LMs. Finally, we provide insight on how the\ndesign of the ACI can impact agents' behavior and performance.\n","authors":["John Yang","Carlos E. Jimenez","Alexander Wettig","Kilian Lieret","Shunyu Yao","Karthik Narasimhan","Ofir Press"],"pdf_url":"https://arxiv.org/pdf/2405.15793v3.pdf","comment":"Code, data, and demo available at https://swe-agent.com"},{"id":"http://arxiv.org/abs/2411.07336v1","updated":"2024-11-11T19:55:24Z","published":"2024-11-11T19:55:24Z","title":"SetLexSem Challenge: Using Set Operations to Evaluate the Lexical and\n  Semantic Robustness of Language Models","summary":"  Set theory is foundational to mathematics and, when sets are finite, to\nreasoning about the world. An intelligent system should perform set operations\nconsistently, regardless of superficial variations in the operands. Initially\ndesigned for semantically-oriented NLP tasks, large language models (LLMs) are\nnow being evaluated on algorithmic tasks. Because sets are comprised of\narbitrary symbols (e.g. numbers, words), they provide an opportunity to test,\nsystematically, the invariance of LLMs' algorithmic abilities under simple\nlexical or semantic variations. To this end, we present the SetLexSem\nChallenge, a synthetic benchmark that evaluates the performance of LLMs on set\noperations. SetLexSem assesses the robustness of LLMs' instruction-following\nabilities under various conditions, focusing on the set operations and the\nnature and construction of the set members. Evaluating seven LLMs with\nSetLexSem, we find that they exhibit poor robustness to variation in both\noperation and operands. We show -- via the framework's systematic sampling of\nset members along lexical and semantic dimensions -- that LLMs are not only not\nrobust to variation along these dimensions but demonstrate unique failure modes\nin particular, easy-to-create semantic groupings of \"deceptive\" sets. We find\nthat rigorously measuring language model robustness to variation in frequency\nand length is challenging and present an analysis that measures them\nindependently. The code for reproducing the results of this paper, and for\ngenerating the SetLexSem Challenge dataset, is available at\n\\href{https://github.com/amazon-science/SetLexSem-Challenge}{https://github.com/amazon-science/SetLexSem-Challenge}.\n","authors":["Bardiya Akhbari","Manish Gawali","Nicholas A. Dronen"],"pdf_url":"https://arxiv.org/pdf/2411.07336v1.pdf","comment":"10 pages, 8 figures, NeurIPS 2024 Datasets and Benchmarks track"},{"id":"http://arxiv.org/abs/2404.15146v3","updated":"2024-11-11T19:47:16Z","published":"2024-04-23T15:49:37Z","title":"Rethinking LLM Memorization through the Lens of Adversarial Compression","summary":"  Large language models (LLMs) trained on web-scale datasets raise substantial\nconcerns regarding permissible data usage. One major question is whether these\nmodels \"memorize\" all their training data or they integrate many data sources\nin some way more akin to how a human would learn and synthesize information.\nThe answer hinges, to a large degree, on how we define memorization. In this\nwork, we propose the Adversarial Compression Ratio (ACR) as a metric for\nassessing memorization in LLMs. A given string from the training data is\nconsidered memorized if it can be elicited by a prompt (much) shorter than the\nstring itself -- in other words, if these strings can be \"compressed\" with the\nmodel by computing adversarial prompts of fewer tokens. The ACR overcomes the\nlimitations of existing notions of memorization by (i) offering an adversarial\nview of measuring memorization, especially for monitoring unlearning and\ncompliance; and (ii) allowing for the flexibility to measure memorization for\narbitrary strings at a reasonably low compute. Our definition serves as a\npractical tool for determining when model owners may be violating terms around\ndata usage, providing a potential legal tool and a critical lens through which\nto address such scenarios.\n","authors":["Avi Schwarzschild","Zhili Feng","Pratyush Maini","Zachary C. Lipton","J. Zico Kolter"],"pdf_url":"https://arxiv.org/pdf/2404.15146v3.pdf","comment":"https://locuslab.github.io/acr-memorization"},{"id":"http://arxiv.org/abs/2411.07320v1","updated":"2024-11-11T19:25:25Z","published":"2024-11-11T19:25:25Z","title":"Richer Output for Richer Countries: Uncovering Geographical Disparities\n  in Generated Stories and Travel Recommendations","summary":"  While a large body of work inspects language models for biases concerning\ngender, race, occupation and religion, biases of geographical nature are\nrelatively less explored. Some recent studies benchmark the degree to which\nlarge language models encode geospatial knowledge. However, the impact of the\nencoded geographical knowledge (or lack thereof) on real-world applications has\nnot been documented. In this work, we examine large language models for two\ncommon scenarios that require geographical knowledge: (a) travel\nrecommendations and (b) geo-anchored story generation. Specifically, we study\nfour popular language models, and across about $100$K travel requests, and\n$200$K story generations, we observe that travel recommendations corresponding\nto poorer countries are less unique with fewer location references, and stories\nfrom these regions more often convey emotions of hardship and sadness compared\nto those from wealthier nations.\n","authors":["Kirti Bhagat","Kinshuk Vasisht","Danish Pruthi"],"pdf_url":"https://arxiv.org/pdf/2411.07320v1.pdf","comment":"Submitted to ARR - October 2024"},{"id":"http://arxiv.org/abs/2402.18025v2","updated":"2024-11-11T19:14:13Z","published":"2024-02-28T03:44:01Z","title":"Hire a Linguist!: Learning Endangered Languages with In-Context\n  Linguistic Descriptions","summary":"  How can large language models (LLMs) process and translate endangered\nlanguages? Many languages lack a large corpus to train a decent LLM; therefore\nexisting LLMs rarely perform well in unseen, endangered languages. On the\ncontrary, we observe that 2000 endangered languages, though without a large\ncorpus, have a grammar book or a dictionary. We propose LINGOLLM, a\ntraining-free approach to enable an LLM to process unseen languages that hardly\noccur in its pre-training. Our key insight is to demonstrate linguistic\nknowledge of an unseen language in an LLM's prompt, including a dictionary, a\ngrammar book, and morphologically analyzed input text. We implement LINGOLLM on\ntop of two models, GPT-4 and Mixtral, and evaluate their performance on 5 tasks\nacross 8 endangered or low-resource languages. Our results show that LINGOLLM\nelevates translation capability from GPT-4's 0 to 10.5 BLEU for 10 language\ndirections. Our findings demonstrate the tremendous value of linguistic\nknowledge in the age of LLMs for endangered languages. Our data, code, and\nmodel generations can be found at https://github.com/LLiLab/llm4endangeredlang.\n","authors":["Kexun Zhang","Yee Man Choi","Zhenqiao Song","Taiqi He","William Yang Wang","Lei Li"],"pdf_url":"https://arxiv.org/pdf/2402.18025v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07279v1","updated":"2024-11-11T18:59:45Z","published":"2024-11-11T18:59:45Z","title":"The Surprising Effectiveness of Test-Time Training for Abstract\n  Reasoning","summary":"  Language models have shown impressive performance on tasks within their\ntraining distribution, but often struggle with novel problems requiring complex\nreasoning. We investigate the effectiveness of test-time training (TTT) --\nupdating model parameters temporarily during inference using a loss derived\nfrom input data -- as a mechanism for improving models' reasoning capabilities,\nusing the Abstraction and Reasoning Corpus (ARC) as a benchmark. Through\nsystematic experimentation, we identify three crucial components for successful\nTTT: (1) initial finetuning on similar tasks (2) auxiliary task format and\naugmentations (3) per-instance training. TTT significantly improves performance\non ARC tasks, achieving up to 6x improvement in accuracy compared to base\nfine-tuned models; applying TTT to an 8B-parameter language model, we achieve\n53% accuracy on the ARC's public validation set, improving the state-of-the-art\nby nearly 25% for public and purely neural approaches. By ensembling our method\nwith recent program generation approaches, we get SoTA public validation\naccuracy of 61.9%, matching the average human score. Our findings suggest that\nexplicit symbolic search is not the only path to improved abstract reasoning in\nneural language models; additional test-time applied to continued training on\nfew-shot examples can also be extremely effective.\n","authors":["Ekin Aky√ºrek","Mehul Damani","Linlu Qiu","Han Guo","Yoon Kim","Jacob Andreas"],"pdf_url":"https://arxiv.org/pdf/2411.07279v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2411.07240v1","updated":"2024-11-11T18:59:02Z","published":"2024-11-11T18:59:02Z","title":"UTMath: Math Evaluation with Unit Test via Reasoning-to-Coding Thoughts","summary":"  The evaluation of mathematical reasoning capabilities is essential for\nadvancing Artificial General Intelligence (AGI). While Large Language Models\n(LLMs) have shown impressive performance in solving mathematical problems,\nexisting benchmarks such as GSM8K and MATH present limitations, including\nnarrow problem definitions with specific numbers and reliance on predetermined\nrules that hinder accurate assessments of reasoning and adaptability. This\npaper introduces the UTMath Benchmark, which robustly evaluates the models\nthrough extensive unit tests. It consists of 1,053 problems across 9\nmathematical domains, with over 68 test cases per problem.We propose an\ninnovative evaluation framework inspired by unit testing in software\ndevelopment, focusing on both accuracy and reliability of results. Furthermore,\nwe introduce the Reasoning-to-Coding of Thoughts (RCoT) approach, which\nencourages LLMs to perform explicit reasoning before generating code, leading\nto generating more advanced solution and improved performance. Furthermore, we\nare releasing not only the UTMath benchmark but also the UTMath-Train training\ndataset (more than 70k samples), to support the community in further exploring\nmathematical reasoning.\n","authors":["Bo Yang","Qingping Yang","Runtao Liu"],"pdf_url":"https://arxiv.org/pdf/2411.07240v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07238v1","updated":"2024-11-11T18:58:46Z","published":"2024-11-11T18:58:46Z","title":"OpenThaiGPT 1.5: A Thai-Centric Open Source Large Language Model","summary":"  OpenThaiGPT 1.5 is an advanced Thai language chat model based on Qwen v2.5,\nfinetuned on over 2,000,000 Thai instruction pairs. This report provides an\nengineering perspective on the model's development, capabilities, and\nperformance. We discuss the model's architecture, training process, and key\nfeatures, including multi-turn conversation support, Retrieval Augmented\nGeneration (RAG) compatibility, and tool-calling functionality. Benchmark\nresults demonstrate OpenThaiGPT 1.5's state-of-the-art performance on various\nThai language tasks, outperforming other open-source Thai language models. We\nalso address practical considerations such as GPU memory requirements and\ndeployment strategies.\n","authors":["Sumeth Yuenyong","Kobkrit Viriyayudhakorn","Apivadee Piyatumrong","Jillaphat Jaroenkantasima"],"pdf_url":"https://arxiv.org/pdf/2411.07238v1.pdf","comment":"8 pages, 4 tables"},{"id":"http://arxiv.org/abs/2411.07237v1","updated":"2024-11-11T18:58:38Z","published":"2024-11-11T18:58:38Z","title":"Contextualized Evaluations: Taking the Guesswork Out of Language Model\n  Evaluations","summary":"  Language model users often issue queries that lack specification, where the\ncontext under which a query was issued -- such as the user's identity, the\nquery's intent, and the criteria for a response to be useful -- is not\nexplicit. For instance, a good response to a subjective query like \"What book\nshould I read next?\" would depend on the user's preferences, and a good\nresponse to an open-ended query like \"How do antibiotics work against\nbacteria?\" would depend on the user's expertise. This makes evaluation of\nresponses to such queries an ill-posed task, as evaluators may make arbitrary\njudgments about the response quality. To remedy this, we present contextualized\nevaluations, a protocol that synthetically constructs context surrounding an\nunderspecified query and provides it during evaluation. We find that the\npresence of context can 1) alter conclusions drawn from evaluation, even\nflipping win rates between model pairs, 2) nudge evaluators to make fewer\njudgments based on surface-level criteria, like style, and 3) provide new\ninsights about model behavior across diverse contexts. Specifically, our\nprocedure uncovers an implicit bias towards WEIRD contexts in models' \"default\"\nresponses and we find that models are not equally sensitive to following\ndifferent contexts, even when they are provided in prompts.\n","authors":["Chaitanya Malaviya","Joseph Chee Chang","Dan Roth","Mohit Iyyer","Mark Yatskar","Kyle Lo"],"pdf_url":"https://arxiv.org/pdf/2411.07237v1.pdf","comment":"Code & data available at https://github.com/allenai/ContextEval"},{"id":"http://arxiv.org/abs/2411.02537v3","updated":"2024-11-11T18:49:52Z","published":"2024-11-04T19:16:53Z","title":"INQUIRE: A Natural World Text-to-Image Retrieval Benchmark","summary":"  We introduce INQUIRE, a text-to-image retrieval benchmark designed to\nchallenge multimodal vision-language models on expert-level queries. INQUIRE\nincludes iNaturalist 2024 (iNat24), a new dataset of five million natural world\nimages, along with 250 expert-level retrieval queries. These queries are paired\nwith all relevant images comprehensively labeled within iNat24, comprising\n33,000 total matches. Queries span categories such as species identification,\ncontext, behavior, and appearance, emphasizing tasks that require nuanced image\nunderstanding and domain expertise. Our benchmark evaluates two core retrieval\ntasks: (1) INQUIRE-Fullrank, a full dataset ranking task, and (2)\nINQUIRE-Rerank, a reranking task for refining top-100 retrievals. Detailed\nevaluation of a range of recent multimodal models demonstrates that INQUIRE\nposes a significant challenge, with the best models failing to achieve an\nmAP@50 above 50%. In addition, we show that reranking with more powerful\nmultimodal models can enhance retrieval performance, yet there remains a\nsignificant margin for improvement. By focusing on scientifically-motivated\necological challenges, INQUIRE aims to bridge the gap between AI capabilities\nand the needs of real-world scientific inquiry, encouraging the development of\nretrieval systems that can assist with accelerating ecological and biodiversity\nresearch. Our dataset and code are available at\nhttps://inquire-benchmark.github.io\n","authors":["Edward Vendrow","Omiros Pantazis","Alexander Shepard","Gabriel Brostow","Kate E. Jones","Oisin Mac Aodha","Sara Beery","Grant Van Horn"],"pdf_url":"https://arxiv.org/pdf/2411.02537v3.pdf","comment":"Published in NeurIPS 2024, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2411.07224v1","updated":"2024-11-11T18:44:17Z","published":"2024-11-11T18:44:17Z","title":"TempCharBERT: Keystroke Dynamics for Continuous Access Control Based on\n  Pre-trained Language Models","summary":"  With the widespread of digital environments, reliable authentication and\ncontinuous access control has become crucial. It can minimize cyber attacks and\nprevent frauds, specially those associated with identity theft. A particular\ninterest lies on keystroke dynamics (KD), which refers to the task of\nrecognizing individuals' identity based on their unique typing style. In this\nwork, we propose the use of pre-trained language models (PLMs) to recognize\nsuch patterns. Although PLMs have shown high performance on multiple NLP\nbenchmarks, the use of these models on specific tasks requires customization.\nBERT and RoBERTa, for instance, rely on subword tokenization, and they cannot\nbe directly applied to KD, which requires temporal-character information to\nrecognize users. Recent character-aware PLMs are able to process both subwords\nand character-level information and can be an alternative solution.\nNotwithstanding, they are still not suitable to be directly fine-tuned for KD\nas they are not optimized to account for user's temporal typing information\n(e.g., hold time and flight time). To overcome this limitation, we propose\nTempCharBERT, an architecture that incorporates temporal-character information\nin the embedding layer of CharBERT. This allows modeling keystroke dynamics for\nthe purpose of user identification and authentication. Our results show a\nsignificant improvement with this customization. We also showed the feasibility\nof training TempCharBERT on a federated learning settings in order to foster\ndata privacy.\n","authors":["Matheus Sim√£o","Fabiano Prado","Omar Abdul Wahab","Anderson Avila"],"pdf_url":"https://arxiv.org/pdf/2411.07224v1.pdf","comment":"Accepted at WIFS 2024"},{"id":"http://arxiv.org/abs/2411.07218v1","updated":"2024-11-11T18:40:04Z","published":"2024-11-11T18:40:04Z","title":"TreeCoders: Trees of Transformers","summary":"  In this paper, we introduce TreeCoders, a novel family of transformer trees.\nWe moved away from traditional linear transformers to complete k-ary trees.\nTransformer blocks serve as nodes, and generic classifiers learn to select the\nbest child and route the sequence of tokens to a specific leaf. The selectors,\nmoved outside the transformer blocks, allow for the use of a variety of\narchitecture without further modifications. Furthermore, our proposed\narchitecture supports sparse node activation due to the logarithmic complexity\nof a tree search. We validate our idea by testing a series of decoder-only tree\ntransformers, achieving competitive results across a diverse range of language\ndatasets. Our study demonstrates that the proposed tree transformer model\noutperforms a size-equivalent linear transformer model 76\\% of the time over a\nwide range of tree architectures. Furthermore, our proposed model naturally\nlends itself to distributed implementation.\n","authors":["Pierre Colonna D'Istria","Abdulrahman Altahhan"],"pdf_url":"https://arxiv.org/pdf/2411.07218v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.13020v2","updated":"2024-11-11T18:37:22Z","published":"2024-04-19T17:30:10Z","title":"Stronger Random Baselines for In-Context Learning","summary":"  Evaluating the in-context learning classification performance of language\nmodels poses challenges due to small dataset sizes, extensive prompt-selection\nusing the validation set, and intentionally difficult tasks that lead to\nnear-random performance. The standard random baseline--the expected accuracy of\nguessing labels uniformly at random--is stable when the evaluation set is used\nonly once or when the dataset is large. We account for the common practice of\nvalidation set reuse and existing small datasets with a stronger random\nbaseline: the expected maximum accuracy across multiple random classifiers.\nWhen choosing the best prompt demonstrations across six quantized language\nmodels applied to 16 BIG-bench Lite tasks, more than 20% of the few-shot\nresults that exceed the standard baseline do not exceed this stronger random\nbaseline. When held-out test sets are available, this stronger baseline is also\na better predictor of held-out performance than the standard baseline, avoiding\nunnecessary test set evaluations. This maximum random baseline provides an\neasily calculated drop-in replacement for the standard baseline.\n","authors":["Gregory Yauney","David Mimno"],"pdf_url":"https://arxiv.org/pdf/2404.13020v2.pdf","comment":"Published at COLM 2024"},{"id":"http://arxiv.org/abs/2403.00037v2","updated":"2024-11-11T18:27:18Z","published":"2024-02-29T06:40:53Z","title":"Evolving to the Future: Unseen Event Adaptive Fake News Detection on\n  Social Media","summary":"  With the rapid development of social media, the wide dissemination of fake\nnews on social media is increasingly threatening both individuals and society.\nOne of the unique challenges for fake news detection on social media is how to\ndetect fake news on future events. Recently, numerous fake news detection\nmodels that utilize textual information and the propagation structure of posts\nhave been proposed. Unfortunately, most of the existing approaches can hardly\nhandle this challenge since they rely heavily on event-specific features for\nprediction and cannot generalize to unseen events. To address this, we\nintroduce \\textbf{F}uture \\textbf{AD}aptive \\textbf{E}vent-based Fake news\nDetection (FADE) framework. Specifically, we train a target predictor through\nan adaptive augmentation strategy and graph contrastive learning to obtain\nhigher-quality features and make more accurate overall predictions.\nSimultaneously, we independently train an event-only predictor to obtain biased\npredictions. We further mitigate event bias by subtracting the event-only\npredictor's output from the target predictor's output to obtain the final\nprediction. Encouraging results from experiments designed to emulate real-world\nsocial media conditions validate the effectiveness of our method in comparison\nto existing state-of-the-art approaches.\n","authors":["Jiajun Zhang","Zhixun Li","Qiang Liu","Shu Wu","Liang Wang"],"pdf_url":"https://arxiv.org/pdf/2403.00037v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07191v1","updated":"2024-11-11T18:05:48Z","published":"2024-11-11T18:05:48Z","title":"The Super Weight in Large Language Models","summary":"  Recent works have shown a surprising result: a small fraction of Large\nLanguage Model (LLM) parameter outliers are disproportionately important to the\nquality of the model. LLMs contain billions of parameters, so these small\nfractions, such as 0.01%, translate to hundreds of thousands of parameters. In\nthis work, we present an even more surprising finding: Pruning as few as a\nsingle parameter can destroy an LLM's ability to generate text -- increasing\nperplexity by 3 orders of magnitude and reducing zero-shot accuracy to\nguessing. We propose a data-free method for identifying such parameters, termed\nsuper weights, using a single forward pass through the model. We additionally\nfind that these super weights induce correspondingly rare and large activation\noutliers, termed super activations. When preserved with high precision, super\nactivations can improve simple round-to-nearest quantization to become\ncompetitive with state-of-the-art methods. For weight quantization, we\nsimilarly find that by preserving the super weight and clipping other weight\noutliers, round-to-nearest quantization can scale to much larger block sizes\nthan previously considered. To facilitate further research into super weights,\nwe provide an index of super weight coordinates for common, openly available\nLLMs.\n","authors":["Mengxia Yu","De Wang","Qi Shan","Colorado Reed","Alvin Wan"],"pdf_url":"https://arxiv.org/pdf/2411.07191v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07180v1","updated":"2024-11-11T17:57:30Z","published":"2024-11-11T17:57:30Z","title":"Counterfactual Generation from Language Models","summary":"  Understanding and manipulating the causal generation mechanisms in language\nmodels is essential for controlling their behavior. Previous work has primarily\nrelied on techniques such as representation surgery -- e.g., model ablations or\nmanipulation of linear subspaces tied to specific concepts -- to intervene on\nthese models. To understand the impact of interventions precisely, it is useful\nto examine counterfactuals -- e.g., how a given sentence would have appeared\nhad it been generated by the model following a specific intervention. We\nhighlight that counterfactual reasoning is conceptually distinct from\ninterventions, as articulated in Pearl's causal hierarchy. Based on this\nobservation, we propose a framework for generating true string counterfactuals\nby reformulating language models as Generalized Structural-equation. Models\nusing the Gumbel-max trick. This allows us to model the joint distribution over\noriginal strings and their counterfactuals resulting from the same\ninstantiation of the sampling noise. We develop an algorithm based on hindsight\nGumbel sampling that allows us to infer the latent noise variables and generate\ncounterfactuals of observed strings. Our experiments demonstrate that the\napproach produces meaningful counterfactuals while at the same time showing\nthat commonly used intervention techniques have considerable undesired side\neffects.\n","authors":["Shauli Ravfogel","Anej Svete","V√©steinn Sn√¶bjarnarson","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.07180v1.pdf","comment":"A preprint"},{"id":"http://arxiv.org/abs/2411.07176v1","updated":"2024-11-11T17:56:28Z","published":"2024-11-11T17:56:28Z","title":"More Expressive Attention with Negative Weights","summary":"  We propose a novel attention mechanism, named Cog Attention, that enables\nattention weights to be negative for enhanced expressiveness, which stems from\ntwo key factors: (1) Cog Attention can shift the token deletion and copying\nfunction from a static OV matrix to dynamic QK inner products, with the OV\nmatrix now focusing more on refinement or modification. The attention head can\nsimultaneously delete, copy, or retain tokens by assigning them negative,\npositive, or minimal attention weights, respectively. As a result, a single\nattention head becomes more flexible and expressive. (2) Cog Attention improves\nthe model's robustness against representational collapse, which can occur when\nearlier tokens are over-squashed into later positions, leading to homogeneous\nrepresentations. Negative weights reduce effective information paths from\nearlier to later tokens, helping to mitigate this issue. We develop\nTransformer-like models which use Cog Attention as attention modules, including\ndecoder-only models for language modeling and U-ViT diffusion models for image\ngeneration. Experiments show that models using Cog Attention exhibit superior\nperformance compared to those employing traditional softmax attention modules.\nOur approach suggests a promising research direction for rethinking and\nbreaking the entrenched constraints of traditional softmax attention, such as\nthe requirement for non-negative weights.\n","authors":["Ang Lv","Ruobing Xie","Shuaipeng Li","Jiayi Liao","Xingwu Sun","Zhanhui Kang","Rui Yan"],"pdf_url":"https://arxiv.org/pdf/2411.07176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07175v1","updated":"2024-11-11T17:56:15Z","published":"2024-11-11T17:56:15Z","title":"Continual Memorization of Factoids in Large Language Models","summary":"  Large language models can absorb a massive amount of knowledge through\npretraining, but pretraining is inefficient for acquiring long-tailed or\nspecialized facts. Therefore, fine-tuning on specialized or new knowledge that\nreflects changes in the world has become popular, though it risks disrupting\nthe model's original capabilities. We study this fragility in the context of\ncontinual memorization, where the model is trained on a small set of long-tail\nfactoids (factual associations) and must retain these factoids after multiple\nstages of subsequent training on other datasets. Through extensive experiments,\nwe show that LLMs suffer from forgetting across a wide range of subsequent\ntasks, and simple replay techniques do not fully prevent forgetting, especially\nwhen the factoid datasets are trained in the later stages. We posit that there\nare two ways to alleviate forgetting: 1) protect the memorization process as\nthe model learns the factoids, or 2) reduce interference from training in later\nstages. With this insight, we develop an effective mitigation strategy: REMIX\n(Random and Generic Data Mixing). REMIX prevents forgetting by mixing generic\ndata sampled from pretraining corpora or even randomly generated word sequences\nduring each stage, despite being unrelated to the memorized factoids in the\nfirst stage. REMIX can recover performance from severe forgetting, often\noutperforming replay-based methods that have access to the factoids from the\nfirst stage. We then analyze how REMIX alters the learning process and find\nthat successful forgetting prevention is associated with a pattern: the model\nstores factoids in earlier layers than usual and diversifies the set of layers\nthat store these factoids. The efficacy of REMIX invites further investigation\ninto the underlying dynamics of memorization and forgetting, opening exciting\npossibilities for future research.\n","authors":["Howard Chen","Jiayi Geng","Adithya Bhaskar","Dan Friedman","Danqi Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07175v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02481v2","updated":"2024-11-11T17:34:00Z","published":"2024-11-04T18:54:39Z","title":"CDR: Customizable Density Ratios of Strong-over-weak LLMs for Preference\n  Annotation","summary":"  Preference tuning of large language models (LLMs) relies on high-quality\nhuman preference data, which is often expensive and time-consuming to gather.\nWhile existing methods can use trained reward models or proprietary model as\njudges for preference annotation, they have notable drawbacks: training reward\nmodels remain dependent on initial human data, and using proprietary model\nimposes license restrictions that inhibits commercial usage. In this paper, we\nintroduce customized density ratio (CDR), a training-free and highly effective\nmethod that leverages off-the-shelf LLMs for preference data annotation. Our\napproach uses the log-density ratio between a better-aligned LLM and a less\naligned LLM as a reward signal. We explores 221 different LLMs pairs and\nempirically demonstrate that increasing the performance gap between paired LLMs\ncorrelates with better reward generalization. Furthermore, we show that\ntailoring the density ratio reward function with specific criteria and\npreference exemplars enhances performance across domains and within target\nareas.\n  In our experiment using density ratio from a pair of Mistral-7B models, CDR\nachieves a RewardBench score of 82.6, outperforming the best trained reward\nfunctions from same model class and demonstrating competitive performance\nagainst SoTA models in Safety (91.0) and Reasoning (88.0) domains. We use CDR\nto annotate an on-policy preference dataset with which we preference tune\nLlama-3-8B-Instruct with SimPO. Using reward signals from two relatively weak\nmodels, our approach pushes Llama-3-8B to achieve a 37.4% (+15.1%) win rate on\nArenaHard and a 40.7% (+17.8%) win rate on Length-Controlled AlpacaEval 2.0,\nalong with a score of 8.0 on MT-Bench.\n","authors":["Guangxuan Xu","Kai Xu","Shivchander Sudalairaj","Hao Wang","Akash Srivastava"],"pdf_url":"https://arxiv.org/pdf/2411.02481v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07156v1","updated":"2024-11-11T17:33:51Z","published":"2024-11-11T17:33:51Z","title":"A Primer on Word Embeddings: AI Techniques for Text Analysis in Social\n  Work","summary":"  Word embeddings represent a transformative technology for analyzing text data\nin social work research, offering sophisticated tools for understanding case\nnotes, policy documents, research literature, and other text-based materials.\nThis methodological paper introduces word embeddings to social work\nresearchers, explaining how these mathematical representations capture meaning\nand relationships in text data more effectively than traditional keyword-based\napproaches. We discuss fundamental concepts, technical foundations, and\npractical applications, including semantic search, clustering, and retrieval\naugmented generation. The paper demonstrates how embeddings can enhance\nresearch workflows through concrete examples from social work practice, such as\nanalyzing case notes for housing instability patterns and comparing social work\nlicensing examinations across languages. While highlighting the potential of\nembeddings for advancing social work research, we acknowledge limitations\nincluding information loss, training data constraints, and potential biases. We\nconclude that successfully implementing embedding technologies in social work\nrequires developing domain-specific models, creating accessible tools, and\nestablishing best practices aligned with social work's ethical principles. This\nintegration can enhance our ability to analyze complex patterns in text data\nwhile supporting more effective services and interventions.\n","authors":["Brian E. Perron","Kelley A. Rivenburgh","Bryan G. Victor","Zia Qi","Hui Luan"],"pdf_url":"https://arxiv.org/pdf/2411.07156v1.pdf","comment":"37 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.07152v1","updated":"2024-11-11T17:28:19Z","published":"2024-11-11T17:28:19Z","title":"HierTOD: A Task-Oriented Dialogue System Driven by Hierarchical Goals","summary":"  Task-Oriented Dialogue (TOD) systems assist users in completing tasks through\nnatural language interactions, often relying on a single-layered workflow\nstructure for slot-filling in public tasks, such as hotel bookings. However, in\nenterprise environments, which involve rich domain-specific knowledge, TOD\nsystems face challenges due to task complexity and the lack of standardized\ndocumentation. In this work, we introduce HierTOD, an enterprise TOD system\ndriven by hierarchical goals and can support composite workflows. By focusing\non goal-driven interactions, our system serves a more proactive role,\nfacilitating mixed-initiative dialogue and improving task completion. Equipped\nwith components for natural language understanding, composite goal retriever,\ndialogue management, and response generation, backed by a well-organized data\nservice with domain knowledge base and retrieval engine, HierTOD delivers\nefficient task assistance. Furthermore, our system implementation unifies two\nTOD paradigms: slot-filling for information collection and step-by-step\nguidance for task execution. Our human study demonstrates the effectiveness and\nhelpfulness of HierTOD in performing both paradigms.\n","authors":["Lingbo Mo","Shun Jiang","Akash Maharaj","Bernard Hishamunda","Yunyao Li"],"pdf_url":"https://arxiv.org/pdf/2411.07152v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07142v1","updated":"2024-11-11T17:13:28Z","published":"2024-11-11T17:13:28Z","title":"Greenback Bears and Fiscal Hawks: Finance is a Jungle and Text\n  Embeddings Must Adapt","summary":"  Financial documents are filled with specialized terminology, arcane jargon,\nand curious acronyms that pose challenges for general-purpose text embeddings.\nYet, few text embeddings specialized for finance have been reported in the\nliterature, perhaps in part due to a lack of public datasets and benchmarks. We\npresent BAM embeddings, a set of text embeddings finetuned on a carefully\nconstructed dataset of 14.3M query-passage pairs. Demonstrating the benefits of\ndomain-specific training, BAM embeddings achieve Recall@1 of 62.8% on a\nheld-out test set, vs. only 39.2% for the best general-purpose text embedding\nfrom OpenAI. Further, BAM embeddings increase question answering accuracy by 8%\non FinanceBench and show increased sensitivity to the finance-specific elements\nthat are found in detailed, forward-looking and company and date-specific\nqueries. To support further research we describe our approach in detail,\nquantify the importance of hard negative mining and dataset scale.\n","authors":["Peter Anderson","Mano Vikash Janardhanan","Jason He","Wei Cheng","Charlie Flanagan"],"pdf_url":"https://arxiv.org/pdf/2411.07142v1.pdf","comment":"EMNLP 2024"},{"id":"http://arxiv.org/abs/2411.07140v1","updated":"2024-11-11T17:10:56Z","published":"2024-11-11T17:10:56Z","title":"Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language\n  Models","summary":"  New LLM evaluation benchmarks are important to align with the rapid\ndevelopment of Large Language Models (LLMs). In this work, we present Chinese\nSimpleQA, the first comprehensive Chinese benchmark to evaluate the factuality\nability of language models to answer short questions, and Chinese SimpleQA\nmainly has five properties (i.e., Chinese, Diverse, High-quality, Static,\nEasy-to-evaluate). Specifically, first, we focus on the Chinese language over 6\nmajor topics with 99 diverse subtopics. Second, we conduct a comprehensive\nquality control process to achieve high-quality questions and answers, where\nthe reference answers are static and cannot be changed over time. Third,\nfollowing SimpleQA, the questions and answers are very short, and the grading\nprocess is easy-to-evaluate based on OpenAI API. Based on Chinese SimpleQA, we\nperform a comprehensive evaluation on the factuality abilities of existing\nLLMs. Finally, we hope that Chinese SimpleQA could guide the developers to\nbetter understand the Chinese factuality abilities of their models and\nfacilitate the growth of foundation models.\n","authors":["Yancheng He","Shilong Li","Jiaheng Liu","Yingshui Tan","Hui Huang","Weixun Wang","Xingyuan Bu","Hangyu Guo","Chengwei Hu","Boren Zheng","Xuepeng Liu","Dekai Sun","Wenbo Su","Bo Zheng"],"pdf_url":"https://arxiv.org/pdf/2411.07140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07130v1","updated":"2024-11-11T17:00:59Z","published":"2024-11-11T17:00:59Z","title":"Retrieval or Global Context Understanding? On Many-Shot In-Context\n  Learning for Long-Context Evaluation","summary":"  Language models (LMs) have demonstrated an improved capacity to handle\nlong-context information, yet existing long-context benchmarks primarily\nmeasure LMs' retrieval abilities with extended inputs, e.g., pinpointing a\nshort phrase from long-form text. Therefore, they may fall short when\nevaluating models' global context understanding capacity, such as synthesizing\nand reasoning over content across input to generate the response. In this\npaper, we study long-context language model (LCLM) evaluation through many-shot\nin-context learning (ICL). Concretely, we identify the skills each ICL task\nrequires, and examine models' long-context capabilities on them. We first ask:\nWhat types of ICL tasks benefit from additional demonstrations, and are these\ntasks effective at evaluating LCLMs? We find that classification and\nsummarization tasks show notable performance improvements with additional\ndemonstrations, while translation and reasoning tasks do not exhibit clear\ntrends. This suggests the classification tasks predominantly test models'\nretrieval skills. Next, we ask: To what extent does each task require retrieval\nskills versus global context understanding from LCLMs? We develop metrics to\ncategorize ICL tasks into two groups: (i) retrieval tasks that require strong\nretrieval ability to pinpoint relevant examples, and (ii) global context\nunderstanding tasks that necessitate a deeper comprehension of the full input.\nWe find that not all datasets can effectively evaluate these long-context\ncapabilities. To address this gap, we introduce a new many-shot ICL benchmark,\nMANYICLBENCH, designed to characterize LCLMs' retrieval and global context\nunderstanding capabilities separately. Benchmarking 11 open-weight LCLMs with\nMANYICLBENCH, we find that while state-of-the-art models perform well in\nretrieval tasks up to 64k tokens, many show significant drops in global context\ntasks at just 16k tokens.\n","authors":["Kaijian Zou","Muhammad Khalifa","Lu Wang"],"pdf_url":"https://arxiv.org/pdf/2411.07130v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07127v1","updated":"2024-11-11T16:58:36Z","published":"2024-11-11T16:58:36Z","title":"Benchmarking LLMs' Judgments with No Gold Standard","summary":"  We introduce the GEM (Generative Estimator for Mutual Information), an\nevaluation metric for assessing language generation by Large Language Models\n(LLMs), particularly in generating informative judgments, without the need for\na gold standard reference. GEM broadens the scenarios where we can benchmark\nLLM generation performance-from traditional ones, like machine translation and\nsummarization, where gold standard references are readily available, to\nsubjective tasks without clear gold standards, such as academic peer review.\n  GEM uses a generative model to estimate mutual information between candidate\nand reference responses, without requiring the reference to be a gold standard.\nIn experiments on a human-annotated dataset, GEM demonstrates competitive\ncorrelations with human scores compared to the state-of-the-art GPT-4o\nExaminer, and outperforms all other baselines. Additionally, GEM is more robust\nagainst strategic manipulations, such as rephrasing or elongation, which can\nartificially inflate scores under a GPT-4o Examiner.\n  We also present GRE-bench (Generating Review Evaluation Benchmark) which\nevaluates LLMs based on how well they can generate high-quality peer reviews\nfor academic research papers. Because GRE-bench is based upon GEM, it inherits\nits robustness properties. Additionally, GRE-bench circumvents data\ncontamination problems (or data leakage) by using the continuous influx of new\nopen-access research papers and peer reviews each year. We show GRE-bench\nresults of various popular LLMs on their peer review capabilities using the\nICLR2023 dataset.\n","authors":["Shengwei Xu","Yuxuan Lu","Grant Schoenebeck","Yuqing Kong"],"pdf_url":"https://arxiv.org/pdf/2411.07127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.06687v2","updated":"2024-11-11T16:53:58Z","published":"2024-05-06T18:09:32Z","title":"Hire Me or Not? Examining Language Model's Behavior with Occupation\n  Attributes","summary":"  With the impressive performance in various downstream tasks, large language\nmodels (LLMs) have been widely integrated into production pipelines, like\nrecruitment and recommendation systems. A known issue of models trained on\nnatural language data is the presence of human biases, which can impact the\nfairness of the system. This paper investigates LLMs' behavior with respect to\ngender stereotypes, in the context of occupation decision making. Our framework\nis designed to investigate and quantify the presence of gender stereotypes in\nLLMs' behavior via multi-round question answering. Inspired by prior works, we\nconstruct a dataset by leveraging a standard occupation classification\nknowledge base released by authoritative agencies. We tested three LLMs\n(RoBERTa-large, GPT-3.5-turbo, and Llama2-70b-chat) and found that all models\nexhibit gender stereotypes analogous to human biases, but with different\npreferences. The distinct preferences of GPT-3.5-turbo and Llama2-70b-chat may\nimply the current alignment methods are insufficient for debiasing and could\nintroduce new biases contradicting the traditional gender stereotypes.\n","authors":["Damin Zhang","Yi Zhang","Geetanjali Bihani","Julia Rayz"],"pdf_url":"https://arxiv.org/pdf/2405.06687v2.pdf","comment":"WIP"},{"id":"http://arxiv.org/abs/2411.07122v1","updated":"2024-11-11T16:51:39Z","published":"2024-11-11T16:51:39Z","title":"SCAR: Sparse Conditioned Autoencoders for Concept Detection and Steering\n  in LLMs","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities in\ngenerating human-like text, but their output may not be aligned with the user\nor even produce harmful content. This paper presents a novel approach to detect\nand steer concepts such as toxicity before generation. We introduce the Sparse\nConditioned Autoencoder (SCAR), a single trained module that extends the\notherwise untouched LLM. SCAR ensures full steerability, towards and away from\nconcepts (e.g., toxic content), without compromising the quality of the model's\ntext generation on standard evaluation benchmarks. We demonstrate the effective\napplication of our approach through a variety of concepts, including toxicity,\nsafety, and writing style alignment. As such, this work establishes a robust\nframework for controlling LLM generations, ensuring their ethical and safe\ndeployment in real-world applications.\n","authors":["Ruben H√§rle","Felix Friedrich","Manuel Brack","Bj√∂rn Deiseroth","Patrick Schramowski","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2411.07122v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07111v1","updated":"2024-11-11T16:37:40Z","published":"2024-11-11T16:37:40Z","title":"Building a Taiwanese Mandarin Spoken Language Model: A First Attempt","summary":"  This technical report presents our initial attempt to build a spoken large\nlanguage model (LLM) for Taiwanese Mandarin, specifically tailored to enable\nreal-time, speech-to-speech interaction in multi-turn conversations. Our\nend-to-end model incorporates a decoder-only transformer architecture and aims\nto achieve seamless interaction while preserving the conversational flow,\nincluding full-duplex capabilities allowing simultaneous speaking and\nlistening. The paper also details the training process, including data\npreparation with synthesized dialogues and adjustments for real-time\ninteraction. We also developed a platform to evaluate conversational fluency\nand response coherence in multi-turn dialogues. We hope the release of the\nreport can contribute to the future development of spoken LLMs in Taiwanese\nMandarin.\n","authors":["Chih-Kai Yang","Yu-Kuan Fu","Chen-An Li","Yi-Cheng Lin","Yu-Xiang Lin","Wei-Chih Chen","Ho Lam Chung","Chun-Yi Kuan","Wei-Ping Huang","Ke-Han Lu","Tzu-Quan Lin","Hsiu-Hsuan Wang","En-Pei Hu","Chan-Jan Hsu","Liang-Hsuan Tseng","I-Hsiang Chiu","Ulin Sanga","Xuanjun Chen","Po-chun Hsu","Shu-wen Yang","Hung-yi Lee"],"pdf_url":"https://arxiv.org/pdf/2411.07111v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2406.12060v2","updated":"2024-11-11T16:33:25Z","published":"2024-06-17T20:00:04Z","title":"Not Eliminate but Aggregate: Post-Hoc Control over Mixture-of-Experts to\n  Address Shortcut Shifts in Natural Language Understanding","summary":"  Recent models for natural language understanding are inclined to exploit\nsimple patterns in datasets, commonly known as shortcuts. These shortcuts hinge\non spurious correlations between labels and latent features existing in the\ntraining data. At inference time, shortcut-dependent models are likely to\ngenerate erroneous predictions under distribution shifts, particularly when\nsome latent features are no longer correlated with the labels. To avoid this,\nprevious studies have trained models to eliminate the reliance on shortcuts. In\nthis study, we explore a different direction: pessimistically aggregating the\npredictions of a mixture-of-experts, assuming each expert captures relatively\ndifferent latent features. The experimental results demonstrate that our\npost-hoc control over the experts significantly enhances the model's robustness\nto the distribution shift in shortcuts. Besides, we show that our approach has\nsome practical advantages. We also analyze our model and provide results to\nsupport the assumption.\n","authors":["Ukyo Honda","Tatsushi Oka","Peinan Zhang","Masato Mita"],"pdf_url":"https://arxiv.org/pdf/2406.12060v2.pdf","comment":"21 pages, 5 figures (the layout differs from the MIT Press\n  publication version)"},{"id":"http://arxiv.org/abs/2411.07107v1","updated":"2024-11-11T16:33:25Z","published":"2024-11-11T16:33:25Z","title":"Training Neural Networks as Recognizers of Formal Languages","summary":"  Characterizing the computational power of neural network architectures in\nterms of formal language theory remains a crucial line of research, as it\ndescribes lower and upper bounds on the reasoning capabilities of modern AI.\nHowever, when empirically testing these bounds, existing work often leaves a\ndiscrepancy between experiments and the formal claims they are meant to\nsupport. The problem is that formal language theory pertains specifically to\nrecognizers: machines that receive a string as input and classify whether it\nbelongs to a language. On the other hand, it is common to instead use proxy\ntasks that are similar in only an informal sense, such as language modeling or\nsequence-to-sequence transduction. We correct this mismatch by training and\nevaluating neural networks directly as binary classifiers of strings, using a\ngeneral method that can be applied to a wide variety of languages. As part of\nthis, we extend an algorithm recently proposed by Sn{\\ae}bjarnarson et al.\n(2024) to do length-controlled sampling of strings from regular languages, with\nmuch better asymptotic time complexity than previous methods. We provide\nresults on a variety of languages across the Chomsky hierarchy for three neural\narchitectures: a simple RNN, an LSTM, and a causally-masked transformer. We\nfind that the RNN and LSTM often outperform the transformer, and that auxiliary\ntraining objectives such as language modeling can help, although no single\nobjective uniformly improves performance across languages and architectures.\nOur contributions will facilitate theoretically sound empirical testing of\nlanguage recognition claims in future work. We have released our datasets as a\nbenchmark called FLaRe (Formal Language Recognition), along with our code.\n","authors":["Alexandra Butoi","Ghazal Khalighinejad","Anej Svete","Josef Valvoda","Ryan Cotterell","Brian DuSell"],"pdf_url":"https://arxiv.org/pdf/2411.07107v1.pdf","comment":"40 pages, 2 figures. Preprint"},{"id":"http://arxiv.org/abs/2411.07075v1","updated":"2024-11-11T15:50:01Z","published":"2024-11-11T15:50:01Z","title":"Transformer verbatim in-context retrieval across time and scale","summary":"  To predict upcoming text, language models must in some cases retrieve\nin-context information verbatim. In this report, we investigated how the\nability of language models to retrieve arbitrary in-context nouns developed\nduring training (across time) and as language models trained on the same\ndataset increase in size (across scale). We then asked whether learning of\nin-context retrieval correlates with learning of more challenging zero-shot\nbenchmarks. Furthermore, inspired by semantic effects in human short-term\nmemory, we evaluated the retrieval with respect to a major semantic component\nof target nouns, namely whether they denote a concrete or abstract entity, as\nrated by humans. We show that verbatim in-context retrieval developed in a\nsudden transition early in the training process, after about 1% of the training\ntokens. This was observed across model sizes (from 14M and up to 12B\nparameters), and the transition occurred slightly later for the two smallest\nmodels. We further found that the development of verbatim in-context retrieval\nis positively correlated with the learning of zero-shot benchmarks. Around the\ntransition point, all models showed the advantage of retrieving concrete nouns\nas opposed to abstract nouns. In all but two smallest models, the advantage\ndissipated away toward the end of training.\n","authors":["Kristijan Armeni","Marko Pranjiƒá","Senja Pollak"],"pdf_url":"https://arxiv.org/pdf/2411.07075v1.pdf","comment":"accepted to Conference on Natural Language Learning 2024\n  (https://www.conll.org/)"},{"id":"http://arxiv.org/abs/2303.14537v3","updated":"2024-11-11T15:49:16Z","published":"2023-03-25T19:03:57Z","title":"Deep Augmentation: Self-Supervised Learning with Transformations in\n  Activation Space","summary":"  We introduce Deep Augmentation, an approach to implicit data augmentation\nusing dropout or PCA to transform a targeted layer within a neural network to\nimprove performance and generalization. We demonstrate Deep Augmentation\nthrough extensive experiments on contrastive learning tasks in NLP, computer\nvision, and graph learning. We observe substantial performance gains with\nTransformers, ResNets, and Graph Neural Networks as the underlying models in\ncontrastive learning, but observe inverse effects on the corresponding\nsupervised problems. Our analysis suggests that Deep Augmentation alleviates\nco-adaptation between layers, a problem exhibited by self-supervised learning\nwhere ground truth labels are not available. We use this observation to\nformulate a method for selecting which layer to target; in particular, our\nexperimentation reveals that targeting deeper layers with Deep Augmentation\noutperforms augmenting the input data. The simple network- and\nmodality-agnostic nature of this approach enables its integration into various\nmachine learning pipelines.\n","authors":["Rickard Br√ºel-Gabrielsson","Tongzhou Wang","Manel Baradad","Justin Solomon"],"pdf_url":"https://arxiv.org/pdf/2303.14537v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07071v1","updated":"2024-11-11T15:47:15Z","published":"2024-11-11T15:47:15Z","title":"Universal Response and Emergence of Induction in LLMs","summary":"  While induction is considered a key mechanism for in-context learning in\nLLMs, understanding its precise circuit decomposition beyond toy models remains\nelusive. Here, we study the emergence of induction behavior within LLMs by\nprobing their response to weak single-token perturbations of the residual\nstream. We find that LLMs exhibit a robust, universal regime in which their\nresponse remains scale-invariant under changes in perturbation strength,\nthereby allowing us to quantify the build-up of token correlations throughout\nthe model. By applying our method, we observe signatures of induction behavior\nwithin the residual stream of Gemma-2-2B, Llama-3.2-3B, and GPT-2-XL. Across\nall models, we find that these induction signatures gradually emerge within\nintermediate layers and identify the relevant model sections composing this\nbehavior. Our results provide insights into the collective interplay of\ncomponents within LLMs and serve as a benchmark for large-scale circuit\nanalysis.\n","authors":["Niclas Luick"],"pdf_url":"https://arxiv.org/pdf/2411.07071v1.pdf","comment":"14 pages, 5 figures"},{"id":"http://arxiv.org/abs/2401.10825v2","updated":"2024-11-11T15:45:02Z","published":"2024-01-19T17:21:05Z","title":"Recent Advances in Named Entity Recognition: A Comprehensive Survey and\n  Comparative Study","summary":"  Named Entity Recognition seeks to extract substrings within a text that name\nreal-world objects and to determine their type (for example, whether they refer\nto persons or organizations). In this survey, we first present an overview of\nrecent popular approaches, including advancements in Transformer-based methods\nand Large Language Models (LLMs) that have not had much coverage in other\nsurveys. In addition, we discuss reinforcement learning and graph-based\napproaches, highlighting their role in enhancing NER performance. Second, we\nfocus on methods designed for datasets with scarce annotations. Third, we\nevaluate the performance of the main NER implementations on a variety of\ndatasets with differing characteristics (as regards their domain, their size,\nand their number of classes). We thus provide a deep comparison of algorithms\nthat have never been considered together. Our experiments shed some light on\nhow the characteristics of datasets affect the behavior of the methods we\ncompare.\n","authors":["Imed Keraghel","Stanislas Morbieu","Mohamed Nadif"],"pdf_url":"https://arxiv.org/pdf/2401.10825v2.pdf","comment":"44 pages"},{"id":"http://arxiv.org/abs/2411.07066v1","updated":"2024-11-11T15:30:16Z","published":"2024-11-11T15:30:16Z","title":"Zeroth-Order Adaptive Neuron Alignment Based Pruning without Re-Training","summary":"  Network pruning is a set of computational techniques that aim to reduce a\ngiven model's computational cost by removing a subset of its parameters while\nhaving minimal impact on performance. Throughout the last decade, the most\nwidely used pruning paradigm has focused on pruning and re-training, which\nnowadays is inconvenient due to the vast amount of pre-trained models, which\nare in any case too expensive to re-train. In this paper, we exploit functional\ninformation from dense pre-trained models, i.e., their activations, to obtain\nsparse models that maximize the activations' alignment w.r.t. their\ncorresponding dense models. Hence, we propose \\textsc{NeuroAl}, a \\emph{top-up}\nalgorithm that can be used on top of any given pruning algorithm for LLMs, that\nmodifies the block-wise and row-wise sparsity ratios to maximize the\n\\emph{neuron alignment} among activations. Moreover, differently from existing\nmethods, our approach adaptively selects the best parameters for the block-wise\nand row-wise sparsity ratios w.r.t. to the model and the desired sparsity\n(given as input), and requires \\emph{no re-training}. We test our method on 4\ndifferent LLM families and 3 different sparsity ratios, showing how it\nconsistently outperforms the latest state-of-the-art techniques. The code is\navailable at https://github.com/eliacunegatti/NeuroAL.\n","authors":["Elia Cunegatti","Leonardo Lucio Custode","Giovanni Iacca"],"pdf_url":"https://arxiv.org/pdf/2411.07066v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2411.07042v1","updated":"2024-11-11T14:49:43Z","published":"2024-11-11T14:49:43Z","title":"Minion: A Technology Probe for Resolving Value Conflicts through\n  Expert-Driven and User-Driven Strategies in AI Companion Applications","summary":"  AI companions based on large language models can role-play and converse very\nnaturally. When value conflicts arise between the AI companion and the user, it\nmay offend or upset the user. Yet, little research has examined such conflicts.\nWe first conducted a formative study that analyzed 151 user complaints about\nconflicts with AI companions, providing design implications for our study.\nBased on these, we created Minion, a technology probe to help users resolve\nhuman-AI value conflicts. Minion applies a user-empowerment intervention method\nthat provides suggestions by combining expert-driven and user-driven conflict\nresolution strategies. We conducted a technology probe study, creating 40 value\nconflict scenarios on Character.AI and Talkie. 22 participants completed 274\ntasks and successfully resolved conflicts 94.16% of the time. We summarize user\nresponses, preferences, and needs in resolving value conflicts, and propose\ndesign implications to reduce conflicts and empower users to resolve them more\neffectively.\n","authors":["Xianzhe Fan","Qing Xiao","Xuhui Zhou","Yuran Su","Zhicong Lu","Maarten Sap","Hong Shen"],"pdf_url":"https://arxiv.org/pdf/2411.07042v1.pdf","comment":"18 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.07037v1","updated":"2024-11-11T14:43:51Z","published":"2024-11-11T14:43:51Z","title":"LIFBench: Evaluating the Instruction Following Performance and Stability\n  of Large Language Models in Long-Context Scenarios","summary":"  As Large Language Models (LLMs) continue to advance in natural language\nprocessing (NLP), their ability to stably follow instructions in long-context\ninputs has become crucial for real-world applications. While existing\nbenchmarks assess various LLM capabilities, they rarely focus on\ninstruction-following in long-context scenarios or stability on different\ninputs. In response, we introduce the Long-context Instruction-Following\nBenchmark (LIFBench), a scalable dataset designed to evaluate LLMs'\ninstruction-following capabilities and stability across long contexts. LIFBench\ncomprises three long-context scenarios and eleven diverse tasks, supported by\n2,766 instructions generated through an automated expansion method across three\ndimensions: length, expression, and variables. For evaluation, we propose\nLIFEval, a rubric-based assessment framework that provides precise, automated\nscoring of complex LLM responses without relying on LLM-assisted evaluations or\nhuman judgments. This approach facilitates a comprehensive analysis of model\nperformance and stability across various perspectives. We conduct extensive\nexperiments on 20 notable LLMs across six length intervals, analyzing their\ninstruction-following capabilities and stability. Our work contributes LIFBench\nand LIFEval as robust tools for assessing LLM performance in complex,\nlong-context settings, providing insights that can inform future LLM\ndevelopment.\n","authors":["Xiaodong Wu","Minhao Wang","Yichen Liu","Xiaoming Shi","He Yan","Xiangju Lu","Junmin Zhu","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07037v1.pdf","comment":"17 pages, 3 figures"},{"id":"http://arxiv.org/abs/2410.09824v4","updated":"2024-11-11T14:41:53Z","published":"2024-10-13T12:57:08Z","title":"Dynamic and Textual Graph Generation Via Large-Scale LLM-based Agent\n  Simulation","summary":"  Graph generation is a fundamental task that has been extensively studied in\nsocial, technological, and scientific analysis. For modeling the dynamic graph\nevolution process, traditional rule-based methods struggle to capture community\nstructures within graphs, while deep learning methods only focus on fitting\ntraining graphs. This limits existing graph generators to producing graphs that\nadhere to predefined rules or closely resemble training datasets, achieving\npoor performance in dynamic graph generation. Given that graphs are abstract\nrepresentations arising from pairwise interactions in human activities, a\nrealistic simulation of human-wise interaction could provide deeper insights\ninto the graph evolution mechanism. With the increasing recognition of large\nlanguage models (LLMs) in simulating human behavior, we introduce\nGraphAgent-Generator (GAG), a novel simulation-based framework for dynamic\ngraph generation. Without training or fine-tuning process of LLM, our framework\neffectively replicates seven macro-level structural characteristics in\nestablished network science theories while surpassing existing baselines in\ngraph expansion tasks by 31\\% on specific evaluation metrics. Through node\nclassification task, we validate GAG effectively preserves characteristics of\nreal-world network for node-wise textual features in generated text-rich graph.\nFurthermore, by incorporating parallel acceleration, GAG supports generating\ngraphs with up to nearly 100,000 nodes or 10 million edges through large-scale\nLLM-based agent simulation, with a minimum speed-up of 90.4\\%. The source code\nis available at https://anonymous.4open.science/r/GraphAgent-2206.\n","authors":["Jiarui Ji","Runlin Lei","Jialing Bi","Zhewei Wei","Yankai Lin","Xuchen Pan","Yaliang Li","Bolin Ding"],"pdf_url":"https://arxiv.org/pdf/2410.09824v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.19266v4","updated":"2024-11-11T14:36:35Z","published":"2024-05-29T16:59:38Z","title":"PediatricsGPT: Large Language Models as Chinese Medical Assistants for\n  Pediatric Applications","summary":"  Developing intelligent pediatric consultation systems offers promising\nprospects for improving diagnostic efficiency, especially in China, where\nhealthcare resources are scarce. Despite recent advances in Large Language\nModels (LLMs) for Chinese medicine, their performance is sub-optimal in\npediatric applications due to inadequate instruction data and vulnerable\ntraining procedures. To address the above issues, this paper builds PedCorpus,\na high-quality dataset of over 300,000 multi-task instructions from pediatric\ntextbooks, guidelines, and knowledge graph resources to fulfil diverse\ndiagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the\nfirst Chinese pediatric LLM assistant built on a systematic and robust training\npipeline. In the continuous pre-training phase, we introduce a hybrid\ninstruction pre-training mechanism to mitigate the internal-injected knowledge\ninconsistency of LLMs for medical domain adaptation. Immediately, the\nfull-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the\ngeneral medical knowledge schema into the models. After that, we devise a\ndirect following preference optimization to enhance the generation of\npediatrician-like humanistic responses. In the parameter-efficient secondary\nSFT phase, a mixture of universal-specific experts strategy is presented to\nresolve the competency conflict between medical generalist and pediatric\nexpertise mastery. Extensive results based on the metrics, GPT-4, and doctor\nevaluations on distinct doctor downstream tasks show that PediatricsGPT\nconsistently outperforms previous Chinese medical LLMs. Our model and dataset\nwill be open-source for community development.\n","authors":["Dingkang Yang","Jinjie Wei","Dongling Xiao","Shunli Wang","Tong Wu","Gang Li","Mingcheng Li","Shuaibing Wang","Jiawei Chen","Yue Jiang","Qingyao Xu","Ke Li","Peng Zhai","Lihua Zhang"],"pdf_url":"https://arxiv.org/pdf/2405.19266v4.pdf","comment":"Accepted by NeurIPS 2024. A Technical Report on a Chinese Medical\n  Large Language Model"},{"id":"http://arxiv.org/abs/2404.08877v2","updated":"2024-11-11T14:35:45Z","published":"2024-04-13T02:36:40Z","title":"Aligning LLMs for FL-free Program Repair","summary":"  Large language models (LLMs) have achieved decent results on automated\nprogram repair (APR). However, the next token prediction training objective of\ndecoder-only LLMs (e.g., GPT-4) is misaligned with the masked span prediction\nobjective of current infilling-style methods, which impedes LLMs from fully\nleveraging pre-trained knowledge for program repair. In addition, while some\nLLMs can locate and repair bugs in certain functions using the related\nartifacts (e.g., test cases), existing methods still depend on statement-level\nfault localization methods to provide a list of buggy hunks for repair. This\nrestriction hinders LLMs from exploring potential patches beyond the given\nlocations.\n  In this paper, we investigate a new approach to adapt LLMs to program repair.\nOur core insight is that LLM's APR capability can be greatly improved by simply\naligning the output to their training objective and allowing them to refine the\nwhole program without first identifying faulty statements. Based on this\ninsight, we designed D4C, a straightforward prompting framework for APR. D4C\ncan repair 180 bugs correctly in Defects4J, with each patch being sampled only\n10 times. This surpasses the SOTA APR methods with perfect fault localization\nby 10% and reduces the patch sampling number by 90%. Our findings reveal that\n(1) objective alignment is crucial for fully exploiting LLM's pre-trained\ncapability, and (2) replacing the traditional localize-buggy-hunks-then-repair\nworkflow with direct debugging is more effective for LLM-based APR methods.\nThus, we believe this paper introduces a new mindset for harnessing LLMs in\nAPR.\n","authors":["Junjielong Xu","Ying Fu","Shin Hwei Tan","Pinjia He"],"pdf_url":"https://arxiv.org/pdf/2404.08877v2.pdf","comment":"Accepted by ICSE'25"},{"id":"http://arxiv.org/abs/2312.06374v4","updated":"2024-11-11T14:28:51Z","published":"2023-12-11T13:32:11Z","title":"UstanceBR: a social media language resource for stance prediction","summary":"  This work introduces UstanceBR, a multimodal corpus in the Brazilian\nPortuguese Twitter domain for target-based stance prediction. The corpus\ncomprises 86.8 k labelled stances towards selected target topics, and extensive\nnetwork information about the users who published these stances on social\nmedia. In this article we describe the corpus multimodal data, and a number of\nusage examples in both in-domain and zero-shot stance prediction based on text-\nand network-related information, which are intended to provide initial baseline\nresults for future studies in the field.\n","authors":["Camila Pereira","Matheus Pavan","Sungwon Yoon","Ricelli Ramos","Pablo Costa","Lais Cavalheiro","Ivandre Paraboni"],"pdf_url":"https://arxiv.org/pdf/2312.06374v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07019v1","updated":"2024-11-11T14:22:42Z","published":"2024-11-11T14:22:42Z","title":"UniHR: Hierarchical Representation Learning for Unified Knowledge Graph\n  Link Prediction","summary":"  Beyond-triple fact representations including hyper-relational facts with\nauxiliary key-value pairs, temporal facts with additional timestamps, and\nnested facts implying relationships between facts, are gaining significant\nattention. However, existing link prediction models are usually designed for\none specific type of facts, making it difficult to generalize to other fact\nrepresentations. To overcome this limitation, we propose a Unified Hierarchical\nRepresentation learning framework (UniHR) for unified knowledge graph link\nprediction. It consists of a unified Hierarchical Data Representation (HiDR)\nmodule and a unified Hierarchical Structure Learning (HiSL) module as graph\nencoder. The HiDR module unifies hyper-relational KGs, temporal KGs, and nested\nfactual KGs into triple-based representations. Then HiSL incorporates\nintra-fact and inter-fact message passing, focusing on enhancing the semantic\ninformation within individual facts and enriching the structural information\nbetween facts. Experimental results across 7 datasets from 3 types of KGs\ndemonstrate that our UniHR outperforms baselines designed for one specific kind\nof KG, indicating strong generalization capability of HiDR form and the\neffectiveness of HiSL module. Code and data are available at\nhttps://github.com/Lza12a/UniHR.\n","authors":["Zhiqiang Liu","Mingyang Chen","Yin Hua","Zhuo Chen","Ziqi Liu","Lei Liang","Huajun Chen","Wen Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.07019v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.14736v3","updated":"2024-11-11T13:58:11Z","published":"2023-11-21T19:12:18Z","title":"Data Diversity Matters for Robust Instruction Tuning","summary":"  Recent works have shown that by curating high quality and diverse instruction\ntuning datasets, we can significantly improve instruction-following\ncapabilities. However, creating such datasets is difficult and most works rely\non manual curation or proprietary language models. Automatic data curation is\ndifficult as it is still not clear how we can define diversity for instruction\ntuning, how diversity and quality depend on one other, and how we can optimize\ndataset quality and diversity. To resolve these issue, we propose a new\nalgorithm, Quality-Diversity Instruction Tuning (QDIT). QDIT provides a simple\nmethod to simultaneously control dataset diversity and quality, allowing us to\nconduct an in-depth study on the effect of diversity and quality on instruction\ntuning performance. From this study we draw two key insights (1) there is a\nnatural tradeoff between data diversity and quality and (2) increasing data\ndiversity significantly improves the worst case instruction following\nperformance, therefore improving robustness. We validate the performance of\nQDIT on several large scale instruction tuning datasets, where we find it can\nsubstantially improve worst and average case performance compared to\nquality-driven data selection.\n","authors":["Alexander Bukharin","Shiyang Li","Zhengyang Wang","Jingfeng Yang","Bing Yin","Xian Li","Chao Zhang","Tuo Zhao","Haoming Jiang"],"pdf_url":"https://arxiv.org/pdf/2311.14736v3.pdf","comment":"22 pages, 18 figures"},{"id":"http://arxiv.org/abs/2411.02674v4","updated":"2024-11-11T13:49:30Z","published":"2024-11-04T23:21:12Z","title":"Wave Network: An Ultra-Small Language Model","summary":"  We propose an innovative token representation and update method in a new\nultra-small language model: the Wave network. Specifically, we use a complex\nvector to represent each token, encoding both global and local semantics of the\ninput text. A complex vector consists of two components: a magnitude vector\nrepresenting the global semantics of the input text, and a phase vector\ncapturing the relationships between individual tokens and global semantics.\nExperiments on the AG News text classification task demonstrate that, when\ngenerating complex vectors from randomly initialized token embeddings, our\nsingle-layer Wave Network achieves 90.91% accuracy with wave interference and\n91.66% with wave modulation - outperforming a single Transformer layer using\nBERT pre-trained embeddings by 19.23% and 19.98%, respectively, and approaching\nthe accuracy of the pre-trained and fine-tuned BERT base model (94.64%).\nAdditionally, compared to BERT base, the Wave Network reduces video memory\nusage and training time by 77.34% and 85.62% during wave modulation. In\nsummary, we used a 2.4-million-parameter small language model to achieve\naccuracy comparable to a 100-million-parameter BERT model in text\nclassification.\n","authors":["Xin Zhang","Victor S. Sheng"],"pdf_url":"https://arxiv.org/pdf/2411.02674v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06989v1","updated":"2024-11-11T13:48:01Z","published":"2024-11-11T13:48:01Z","title":"Token2Wave","summary":"  This paper provides an in-depth analysis of Token2Wave, a novel token\nrepresentation method derived from the Wave Network, designed to capture both\nglobal and local semantics of input text through wave-inspired complex vectors.\nIn Token2Wave, each token is represented with a magnitude component, capturing\nthe global semantics of the entire input text, and a phase component, encoding\nthe relationships between individual tokens and the global semantics. Building\non prior research that demonstrated the effectiveness of wave-like operations,\nsuch as interference and modulation, during forward propagation, this study\ninvestigates the convergence behavior, backpropagation characteristics, and\nembedding independence within the Token2Wave framework. A detailed\ncomputational complexity analysis shows that Token2Wave can significantly\nreduce video memory usage and training time compared to BERT. Gradient\ncomparisons for the [CLS] token, total input text, and classifier parameters\nfurther highlight Token2Wave's unique characteristics. This research offers new\ninsights into wave-based token representations, demonstrating their potential\nto enable efficient and computationally friendly language model architectures.\n","authors":["Xin Zhang","Victor S. Sheng"],"pdf_url":"https://arxiv.org/pdf/2411.06989v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.17827v2","updated":"2024-11-11T13:46:50Z","published":"2024-07-25T07:35:27Z","title":"Unified Lexical Representation for Interpretable Visual-Language\n  Alignment","summary":"  Visual-Language Alignment (VLA) has gained a lot of attention since CLIP's\ngroundbreaking work. Although CLIP performs well, the typical direct latent\nfeature alignment lacks clarity in its representation and similarity scores. On\nthe other hand, lexical representation, a vector whose element represents the\nsimilarity between the sample and a word from the vocabulary, is a natural\nsparse representation and interpretable, providing exact matches for individual\nwords. However, lexical representations are difficult to learn due to no\nground-truth supervision and false-discovery issues, and thus requires complex\ndesign to train effectively. In this paper, we introduce LexVLA, a more\ninterpretable VLA framework by learning a unified lexical representation for\nboth modalities without complex design. We use DINOv2 as our visual model for\nits local-inclined features and Llama 2, a generative language model, to\nleverage its in-context lexical prediction ability. To avoid the false\ndiscovery, we propose an overuse penalty to refrain the lexical representation\nfrom falsely frequently activating meaningless words. We demonstrate that these\ntwo pre-trained uni-modal models can be well-aligned by fine-tuning on the\nmodest multi-modal dataset and avoid intricate training configurations. On\ncross-modal retrieval benchmarks, LexVLA, trained on the CC-12M multi-modal\ndataset, outperforms baselines fine-tuned on larger datasets (e.g., YFCC15M)\nand those trained from scratch on even bigger datasets (e.g., 1.1B data,\nincluding CC-12M). We conduct extensive experiments to analyze LexVLA. Codes\nare available at https://github.com/Clementine24/LexVLA.\n","authors":["Yifan Li","Yikai Wang","Yanwei Fu","Dongyu Ru","Zheng Zhang","Tong He"],"pdf_url":"https://arxiv.org/pdf/2407.17827v2.pdf","comment":"Accepted by NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.10691v2","updated":"2024-11-11T13:33:25Z","published":"2024-03-15T21:21:11Z","title":"MYTE: Morphology-Driven Byte Encoding for Better and Fairer Multilingual\n  Language Modeling","summary":"  A major consideration in multilingual language modeling is how to best\nrepresent languages with diverse vocabularies and scripts. Although\ncontemporary text encoding methods cover most of the world's writing systems,\nthey exhibit bias towards the high-resource languages of the Global West. As a\nresult, texts of underrepresented languages tend to be segmented into long\nsequences of linguistically meaningless units. To address the disparities, we\nintroduce a new paradigm that encodes the same information with segments of\nconsistent size across diverse languages. Our encoding convention (MYTE) is\nbased on morphemes, as their inventories are more balanced across languages\nthan characters, which are used in previous methods. We show that MYTE produces\nshorter encodings for all 99 analyzed languages, with the most notable\nimprovements for non-European languages and non-Latin scripts. This, in turn,\nimproves multilingual LM performance and diminishes the perplexity gap\nthroughout diverse languages.\n","authors":["Tomasz Limisiewicz","Terra Blevins","Hila Gonen","Orevaoghene Ahia","Luke Zettlemoyer"],"pdf_url":"https://arxiv.org/pdf/2403.10691v2.pdf","comment":"Published at ACL 2024"},{"id":"http://arxiv.org/abs/2411.06950v1","updated":"2024-11-11T12:56:52Z","published":"2024-11-11T12:56:52Z","title":"Sniff AI: Is My 'Spicy' Your 'Spicy'? Exploring LLM's Perceptual\n  Alignment with Human Smell Experiences","summary":"  Aligning AI with human intent is important, yet perceptual alignment-how AI\ninterprets what we see, hear, or smell-remains underexplored. This work focuses\non olfaction, human smell experiences. We conducted a user study with 40\nparticipants to investigate how well AI can interpret human descriptions of\nscents. Participants performed \"sniff and describe\" interactive tasks, with our\ndesigned AI system attempting to guess what scent the participants were\nexperiencing based on their descriptions. These tasks evaluated the Large\nLanguage Model's (LLMs) contextual understanding and representation of scent\nrelationships within its internal states - high-dimensional embedding space.\nBoth quantitative and qualitative methods were used to evaluate the AI system's\nperformance. Results indicated limited perceptual alignment, with biases\ntowards certain scents, like lemon and peppermint, and continued failing to\nidentify others, like rosemary. We discuss these findings in light of human-AI\nalignment advancements, highlighting the limitations and opportunities for\nenhancing HCI systems with multisensory experience integration.\n","authors":["Shu Zhong","Zetao Zhou","Christopher Dawes","Giada Brianz","Marianna Obrist"],"pdf_url":"https://arxiv.org/pdf/2411.06950v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06946v1","updated":"2024-11-11T12:54:22Z","published":"2024-11-11T12:54:22Z","title":"Cancer-Answer: Empowering Cancer Care with Advanced Large Language\n  Models","summary":"  Gastrointestinal (GI) tract cancers account for a substantial portion of the\nglobal cancer burden, where early diagnosis is critical for improved management\nand patient outcomes. The complex aetiologies and overlapping symptoms across\nGI cancers often delay diagnosis, leading to suboptimal treatment strategies.\nCancer-related queries are crucial for timely diagnosis, treatment, and patient\neducation, as access to accurate, comprehensive information can significantly\ninfluence outcomes. However, the complexity of cancer as a disease, combined\nwith the vast amount of available data, makes it difficult for clinicians and\npatients to quickly find precise answers. To address these challenges, we\nleverage large language models (LLMs) such as GPT-3.5 Turbo to generate\naccurate, contextually relevant responses to cancer-related queries.\nPre-trained with medical data, these models provide timely, actionable insights\nthat support informed decision-making in cancer diagnosis and care, ultimately\nimproving patient outcomes. We calculate two metrics: A1 (which represents the\nfraction of entities present in the model-generated answer compared to the gold\nstandard) and A2 (which represents the linguistic correctness and\nmeaningfulness of the model-generated answer with respect to the gold\nstandard), achieving maximum values of 0.546 and 0.881, respectively.\n","authors":["Aniket Deroy","Subhankar Maity"],"pdf_url":"https://arxiv.org/pdf/2411.06946v1.pdf","comment":"Accepted at FIRE 2024 (Track: Conversational System for Differential\n  Diagnosis of GI Cancer)"},{"id":"http://arxiv.org/abs/2409.11032v3","updated":"2024-11-11T12:50:44Z","published":"2024-09-17T09:56:12Z","title":"Hierarchical Narrative Analysis: Unraveling Perceptions of Generative AI","summary":"  Written texts reflect an author's perspective, making the thorough analysis\nof literature a key research method in fields such as the humanities and social\nsciences. However, conventional text mining techniques like sentiment analysis\nand topic modeling are limited in their ability to capture the hierarchical\nnarrative structures that reveal deeper argumentative patterns. To address this\ngap, we propose a method that leverages large language models (LLMs) to extract\nand organize these structures into a hierarchical framework. We validate this\napproach by analyzing public opinions on generative AI collected by Japan's\nAgency for Cultural Affairs, comparing the narratives of supporters and\ncritics. Our analysis provides clearer visualization of the factors influencing\ndivergent opinions on generative AI, offering deeper insights into the\nstructures of agreement and disagreement.\n","authors":["Riona Matsuoka","Hiroki Matsumoto","Takahiro Yoshida","Tomohiro Watanabe","Ryoma Kondo","Ryohei Hisano"],"pdf_url":"https://arxiv.org/pdf/2409.11032v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06928v1","updated":"2024-11-11T12:32:26Z","published":"2024-11-11T12:32:26Z","title":"Electroencephalogram-based Multi-class Decoding of Attended Speakers'\n  Direction with Audio Spatial Spectrum","summary":"  Decoding the directional focus of an attended speaker from listeners'\nelectroencephalogram (EEG) signals is essential for developing brain-computer\ninterfaces to improve the quality of life for individuals with hearing\nimpairment. Previous works have concentrated on binary directional focus\ndecoding, i.e., determining whether the attended speaker is on the left or\nright side of the listener. However, a more precise decoding of the exact\ndirection of the attended speaker is necessary for effective speech processing.\nAdditionally, audio spatial information has not been effectively leveraged,\nresulting in suboptimal decoding results. In this paper, we observe that, on\nour recently presented dataset with 15-class directional focus, models relying\nexclusively on EEG inputs exhibits significantly lower accuracy when decoding\nthe directional focus in both leave-one-subject-out and leave-one-trial-out\nscenarios. By integrating audio spatial spectra with EEG features, the decoding\naccuracy can be effectively improved. We employ the CNN, LSM-CNN, and\nEEG-Deformer models to decode the directional focus from listeners' EEG signals\nwith the auxiliary audio spatial spectra. The proposed Sp-Aux-Deformer model\nachieves notable 15-class decoding accuracies of 57.48% and 61.83% in\nleave-one-subject-out and leave-one-trial-out scenarios, respectively.\n","authors":["Yuanming Zhang","Jing Lu","Zhibin Lin","Fei Chen","Haoliang Du","Xia Gao"],"pdf_url":"https://arxiv.org/pdf/2411.06928v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06908v1","updated":"2024-11-11T12:11:36Z","published":"2024-11-11T12:11:36Z","title":"EVQAScore: Efficient Video Question Answering Data Evaluation","summary":"  Video question-answering (QA) is a core task in video understanding.\nEvaluating the quality of video QA and video caption data quality for training\nvideo large language models (VideoLLMs) is an essential challenge. Although\nvarious methods have been proposed for assessing video caption quality, there\nremains a lack of dedicated evaluation methods for Video QA. To address this\ngap, we introduce EVQAScore, a reference-free method that leverages keyword\nextraction to assess both video caption and video QA data quality.\nAdditionally, we incorporate frame sampling and rescaling techniques to enhance\nthe efficiency and robustness of our evaluation, this enables our score to\nevaluate the quality of extremely long videos. Our approach achieves\nstate-of-the-art (SOTA) performance (32.8 for Kendall correlation and 42.3 for\nSpearman correlation, 4.7 and 5.9 higher than the previous method PAC-S++) on\nthe VATEX-EVAL benchmark for video caption evaluation. Furthermore, by using\nEVQAScore for data selection, we achieved SOTA results with only 12.5\\% of the\noriginal data volume, outperforming the previous SOTA method PAC-S and 100\\% of\ndata.\n","authors":["Hao Liang","Zirong Chen","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06908v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06899v1","updated":"2024-11-11T11:57:37Z","published":"2024-11-11T11:57:37Z","title":"LongSafetyBench: Long-Context LLMs Struggle with Safety Issues","summary":"  With the development of large language models (LLMs), the sequence length of\nthese models continues to increase, drawing significant attention to\nlong-context language models. However, the evaluation of these models has been\nprimarily limited to their capabilities, with a lack of research focusing on\ntheir safety. Existing work, such as ManyShotJailbreak, has to some extent\ndemonstrated that long-context language models can exhibit safety concerns.\nHowever, the methods used are limited and lack comprehensiveness. In response,\nwe introduce \\textbf{LongSafetyBench}, the first benchmark designed to\nobjectively and comprehensively evaluate the safety of long-context models.\nLongSafetyBench consists of 10 task categories, with an average length of\n41,889 words. After testing eight long-context language models on\nLongSafetyBench, we found that existing models generally exhibit insufficient\nsafety capabilities. The proportion of safe responses from most mainstream\nlong-context LLMs is below 50\\%. Moreover, models' safety performance in\nlong-context scenarios does not always align with that in short-context\nscenarios. Further investigation revealed that long-context models tend to\noverlook harmful content within lengthy texts. We also proposed a simple yet\neffective solution, allowing open-source models to achieve performance\ncomparable to that of top-tier closed-source models. We believe that\nLongSafetyBench can serve as a valuable benchmark for evaluating the safety\ncapabilities of long-context language models. We hope that our work will\nencourage the broader community to pay attention to the safety of long-context\nmodels and contribute to the development of solutions to improve the safety of\nlong-context LLMs.\n","authors":["Mianqiu Huang","Xiaoran Liu","Shaojun Zhou","Mozhi Zhang","Chenkun Tan","Pengyu Wang","Qipeng Guo","Zhe Xu","Linyang Li","Zhikai Lei","Linlin Li","Qun Liu","Yaqian Zhou","Xipeng Qiu","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2411.06899v1.pdf","comment":null}],"Computer Vision and Pattern Recognition":[{"id":"http://arxiv.org/abs/2406.16466v2","updated":"2024-11-11T23:25:00Z","published":"2024-06-24T09:16:17Z","title":"SLOctolyzer: Fully automatic analysis toolkit for segmentation and\n  feature extracting in scanning laser ophthalmoscopy images","summary":"  Purpose: The purpose of this study was to introduce SLOctolyzer: an\nopen-source analysis toolkit for en face retinal vessels in infrared\nreflectance scanning laser ophthalmoscopy (SLO) images.\n  Methods: SLOctolyzer includes two main modules: segmentation and measurement.\nThe segmentation module uses deep learning methods to delineate retinal\nanatomy, and detects the fovea and optic disc, whereas the measurement module\nquantifies the complexity, density, tortuosity, and calibre of the segmented\nretinal vessels. We evaluated the segmentation module using unseen data and\nmeasured its reproducibility.\n  Results: SLOctolyzer's segmentation module performed well against unseen\ninternal test data (Dice for all-vessels = 0.91; arteries = 0.84; veins = 0.85;\noptic disc = 0.94; and fovea = 0.88). External validation against severe\nretinal pathology showed decreased performance (Dice for arteries = 0.72; veins\n= 0.75; and optic disc = 0.90). SLOctolyzer had good reproducibility (mean\ndifference for fractal dimension = -0.001; density = -0.0003; calibre = -0.32\nmicrons; and tortuosity density = 0.001). SLOctolyzer can process a 768 x 768\npixel macula-centred SLO image in under 20 seconds and a disc-centred SLO image\nin under 30 seconds using a laptop CPU.\n  Conclusions: To our knowledge, SLOctolyzer is the first open-source tool to\nconvert raw SLO images into reproducible and clinically meaningful retinal\nvascular parameters. SLO images are captured simultaneous to optical coherence\ntomography (OCT), and we believe SLOctolyzer will be useful for extracting\nretinal vascular measurements from large OCT image sets and linking them to\nocular or systemic diseases. It requires no specialist knowledge or proprietary\nsoftware, and allows manual correction of segmentations and re-computing of\nvascular metrics. SLOctolyzer is freely available at\nhttps://github.com/jaburke166/SLOctolyzer.\n","authors":["Jamie Burke","Samuel Gibbon","Justin Engelmann","Adam Threlfall","Ylenia Giarratano","Charlene Hamid","Stuart King","Ian J. C. MacCormick","Tom MacGillivray"],"pdf_url":"https://arxiv.org/pdf/2406.16466v2.pdf","comment":"13 pages, 6 figures, 6 tables + Supplementary (9 pages, 13 figures, 4\n  tables, 2 code listings). Accepted and published at ARVO Translational Vision\n  Science and Technology"},{"id":"http://arxiv.org/abs/2411.07430v1","updated":"2024-11-11T23:12:08Z","published":"2024-11-11T23:12:08Z","title":"XPoint: A Self-Supervised Visual-State-Space based Architecture for\n  Multispectral Image Registration","summary":"  Accurate multispectral image matching presents significant challenges due to\nnon-linear intensity variations across spectral modalities, extreme viewpoint\nchanges, and the scarcity of labeled datasets. Current state-of-the-art methods\nare typically specialized for a single spectral difference, such as\nvisibleinfrared, and struggle to adapt to other modalities due to their\nreliance on expensive supervision, such as depth maps or camera poses. To\naddress the need for rapid adaptation across modalities, we introduce XPoint, a\nself-supervised, modular image-matching framework designed for adaptive\ntraining and fine-tuning on aligned multispectral datasets, allowing users to\ncustomize key components based on their specific tasks. XPoint employs\nmodularity and self-supervision to allow for the adjustment of elements such as\nthe base detector, which generates pseudoground truth keypoints invariant to\nviewpoint and spectrum variations. The framework integrates a VMamba encoder,\npretrained on segmentation tasks, for robust feature extraction, and includes\nthree joint decoder heads: two are dedicated to interest point and descriptor\nextraction; and a task-specific homography regression head imposes geometric\nconstraints for superior performance in tasks like image registration. This\nflexible architecture enables quick adaptation to a wide range of modalities,\ndemonstrated by training on Optical-Thermal data and fine-tuning on settings\nsuch as visual-near infrared, visual-infrared, visual-longwave infrared, and\nvisual-synthetic aperture radar. Experimental results show that XPoint\nconsistently outperforms or matches state-ofthe-art methods in feature matching\nand image registration tasks across five distinct multispectral datasets. Our\nsource code is available at https://github.com/canyagmur/XPoint.\n","authors":["Ismail Can Yagmur","Hasan F. Ates","Bahadir K. Gunturk"],"pdf_url":"https://arxiv.org/pdf/2411.07430v1.pdf","comment":"13 pages, 11 figures, 1 table, Journal"},{"id":"http://arxiv.org/abs/2409.18461v2","updated":"2024-11-11T22:57:16Z","published":"2024-09-27T05:49:48Z","title":"Towards Diverse Device Heterogeneous Federated Learning via Task\n  Arithmetic Knowledge Integration","summary":"  Federated Learning has emerged as a promising paradigm for collaborative\nmachine learning, while preserving user data privacy. Despite its potential,\nstandard FL lacks support for diverse heterogeneous device prototypes, which\nvary significantly in model and dataset sizes -- from small IoT devices to\nlarge workstations. This limitation is only partially addressed by existing\nknowledge distillation techniques, which often fail to transfer knowledge\neffectively across a broad spectrum of device prototypes with varied\ncapabilities. This failure primarily stems from two issues: the dilution of\ninformative logits from more capable devices by those from less capable ones,\nand the use of a single integrated logits as the distillation target across all\ndevices, which neglects their individual learning capacities and and the unique\ncontributions of each. To address these challenges, we introduce TAKFL, a novel\nKD-based framework that treats the knowledge transfer from each device\nprototype's ensemble as a separate task, independently distilling each to\npreserve its unique contributions and avoid dilution. TAKFL also incorporates a\nKD-based self-regularization technique to mitigate the issues related to the\nnoisy and unsupervised ensemble distillation process. To integrate the\nseparately distilled knowledge, we introduce an adaptive task arithmetic\nknowledge integration process, allowing each student model to customize the\nknowledge integration for optimal performance. Additionally, we present\ntheoretical results demonstrating the effectiveness of task arithmetic in\ntransferring knowledge across heterogeneous devices with varying capacities.\nComprehensive evaluations of our method across both CV and NLP tasks\ndemonstrate that TAKFL achieves SOTA results in a variety of datasets and\nsettings, significantly outperforming existing KD-based methods Code is\nreleased at https://github.com/MMorafah/TAKFL\n","authors":["Mahdi Morafah","Vyacheslav Kungurtsev","Hojin Chang","Chen Chen","Bill Lin"],"pdf_url":"https://arxiv.org/pdf/2409.18461v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2403.19596v2","updated":"2024-11-11T22:39:35Z","published":"2024-03-28T17:20:39Z","title":"LocCa: Visual Pretraining with Location-aware Captioners","summary":"  Image captioning has been shown as an effective pretraining method similar to\ncontrastive pretraining. However, the incorporation of location-aware\ninformation into visual pretraining remains an area with limited research. In\nthis paper, we propose a simple visual pretraining method with location-aware\ncaptioners (LocCa). LocCa uses a simple image captioner task interface, to\nteach a model to read out rich information, i.e. bounding box coordinates, and\ncaptions, conditioned on the image pixel input. Thanks to the multitask\ncapabilities of an encoder-decoder architecture, we show that an image\ncaptioner can easily handle multiple tasks during pretraining. Our experiments\ndemonstrate that LocCa outperforms standard captioners significantly on\nlocalization downstream tasks while maintaining comparable performance on\nholistic tasks.\n","authors":["Bo Wan","Michael Tschannen","Yongqin Xian","Filip Pavetic","Ibrahim Alabdulmohsin","Xiao Wang","Andr√© Susano Pinto","Andreas Steiner","Lucas Beyer","Xiaohua Zhai"],"pdf_url":"https://arxiv.org/pdf/2403.19596v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07416v1","updated":"2024-11-11T22:38:45Z","published":"2024-11-11T22:38:45Z","title":"T2-Only Prostate Cancer Prediction by Meta-Learning from Bi-Parametric\n  MR Imaging","summary":"  Current imaging-based prostate cancer diagnosis requires both MR T2-weighted\n(T2w) and diffusion-weighted imaging (DWI) sequences, with additional sequences\nfor potentially greater accuracy improvement. However, measuring diffusion\npatterns in DWI sequences can be time-consuming, prone to artifacts and\nsensitive to imaging parameters. While machine learning (ML) models have\ndemonstrated radiologist-level accuracy in detecting prostate cancer from these\ntwo sequences, this study investigates the potential of ML-enabled methods\nusing only the T2w sequence as input during inference time. We first discuss\nthe technical feasibility of such a T2-only approach, and then propose a novel\nML formulation, where DWI sequences - readily available for training purposes -\nare only used to train a meta-learning model, which subsequently only uses T2w\nsequences at inference. Using multiple datasets from more than 3,000 prostate\ncancer patients, we report superior or comparable performance in localising\nradiologist-identified prostate cancer using our proposed T2-only models,\ncompared with alternative models using T2-only or both sequences as input. Real\npatient cases are presented and discussed to demonstrate, for the first time,\nthe exclusively true-positive cases from models with different input sequences.\n","authors":["Weixi Yi","Yipei Wang","Natasha Thorley","Alexander Ng","Shonit Punwani","Veeru Kasivisvanathan","Dean C. Barratt","Shaheer Ullah Saeed","Yipeng Hu"],"pdf_url":"https://arxiv.org/pdf/2411.07416v1.pdf","comment":"Code: https://github.com/wxyi057/MetaT2"},{"id":"http://arxiv.org/abs/2411.07392v1","updated":"2024-11-11T21:51:45Z","published":"2024-11-11T21:51:45Z","title":"Feature-Space Semantic Invariance: Enhanced OOD Detection for Open-Set\n  Domain Generalization","summary":"  Open-set domain generalization addresses a real-world challenge: training a\nmodel to generalize across unseen domains (domain generalization) while also\ndetecting samples from unknown classes not encountered during training\n(open-set recognition). However, most existing approaches tackle these issues\nseparately, limiting their practical applicability. To overcome this\nlimitation, we propose a unified framework for open-set domain generalization\nby introducing Feature-space Semantic Invariance (FSI). FSI maintains semantic\nconsistency across different domains within the feature space, enabling more\naccurate detection of OOD instances in unseen domains. Additionally, we adopt a\ngenerative model to produce synthetic data with novel domain styles or class\nlabels, enhancing model robustness. Initial experiments show that our method\nimproves AUROC by 9.1% to 18.9% on ColoredMNIST, while also significantly\nincreasing in-distribution classification accuracy.\n","authors":["Haoliang Wang","Chen Zhao","Feng Chen"],"pdf_url":"https://arxiv.org/pdf/2411.07392v1.pdf","comment":"IEEE BigData 2024, Ph.D. Forum"},{"id":"http://arxiv.org/abs/2411.07391v1","updated":"2024-11-11T21:46:34Z","published":"2024-11-11T21:46:34Z","title":"Federated Learning Client Pruning for Noisy Labels","summary":"  Federated Learning (FL) enables collaborative model training across\ndecentralized edge devices while preserving data privacy. However, existing FL\nmethods often assume clean annotated datasets, impractical for\nresource-constrained edge devices. In reality, noisy labels are prevalent,\nposing significant challenges to FL performance. Prior approaches attempt label\ncorrection and robust training techniques but exhibit limited efficacy,\nparticularly under high noise levels. This paper introduces ClipFL (Federated\nLearning Client Pruning), a novel framework addressing noisy labels from a\nfresh perspective. ClipFL identifies and excludes noisy clients based on their\nperformance on a clean validation dataset, tracked using a Noise Candidacy\nScore (NCS). The framework comprises three phases: pre-client pruning to\nidentify potential noisy clients and calculate their NCS, client pruning to\nexclude a percentage of clients with the highest NCS, and post-client pruning\nfor fine-tuning the global model with standard FL on clean clients. Empirical\nevaluation demonstrates ClipFL's efficacy across diverse datasets and noise\nlevels, achieving accurate noisy client identification, superior performance,\nfaster convergence, and reduced communication costs compared to\nstate-of-the-art FL methods. Our code is available at\nhttps://github.com/MMorafah/ClipFL.\n","authors":["Mahdi Morafah","Hojin Chang","Chen Chen","Bill Lin"],"pdf_url":"https://arxiv.org/pdf/2411.07391v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.04928v3","updated":"2024-11-11T21:23:48Z","published":"2023-08-09T12:54:27Z","title":"GeodesicPSIM: Predicting the Quality of Static Mesh with Texture Map via\n  Geodesic Patch Similarity","summary":"  Static meshes with texture maps have attracted considerable attention in both\nindustrial manufacturing and academic research, leading to an urgent\nrequirement for effective and robust objective quality evaluation. However,\ncurrent model-based static mesh quality metrics have obvious limitations: most\nof them only consider geometry information, while color information is ignored,\nand they have strict constraints for the meshes' geometrical topology. Other\nmetrics, such as image-based and point-based metrics, are easily influenced by\nthe prepossessing algorithms, e.g., projection and sampling, hampering their\nability to perform at their best. In this paper, we propose Geodesic Patch\nSimilarity (GeodesicPSIM), a novel model-based metric to accurately predict\nhuman perception quality for static meshes. After selecting a group keypoints,\n1-hop geodesic patches are constructed based on both the reference and\ndistorted meshes cleaned by an effective mesh cleaning algorithm. A two-step\npatch cropping algorithm and a patch texture mapping module refine the size of\n1-hop geodesic patches and build the relationship between the mesh geometry and\ncolor information, resulting in the generation of 1-hop textured geodesic\npatches. Three types of features are extracted to quantify the distortion:\npatch color smoothness, patch discrete mean curvature, and patch pixel color\naverage and variance. To the best of our knowledge, GeodesicPSIM is the first\nmodel-based metric especially designed for static meshes with texture maps.\nGeodesicPSIM provides state-of-the-art performance in comparison with\nimage-based, point-based, and video-based metrics on a newly created and\nchallenging database. We also prove the robustness of GeodesicPSIM by\nintroducing different settings of hyperparameters. Ablation studies also\nexhibit the effectiveness of three proposed features and the patch cropping\nalgorithm.\n","authors":["Qi Yang","Joel Jung","Xiaozhong Xu","Shan Liu"],"pdf_url":"https://arxiv.org/pdf/2308.04928v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.12306v3","updated":"2024-11-11T21:04:35Z","published":"2024-09-18T20:33:54Z","title":"Measuring Sound Symbolism in Audio-visual Models","summary":"  Audio-visual pre-trained models have gained substantial attention recently\nand demonstrated superior performance on various audio-visual tasks. This study\ninvestigates whether pre-trained audio-visual models demonstrate non-arbitrary\nassociations between sounds and visual representations$\\unicode{x2013}$known as\nsound symbolism$\\unicode{x2013}$which is also observed in humans. We developed\na specialized dataset with synthesized images and audio samples and assessed\nthese models using a non-parametric approach in a zero-shot setting. Our\nfindings reveal a significant correlation between the models' outputs and\nestablished patterns of sound symbolism, particularly in models trained on\nspeech data. These results suggest that such models can capture sound-meaning\nconnections akin to human language processing, providing insights into both\ncognitive architectures and machine learning strategies.\n","authors":["Wei-Cheng Tseng","Yi-Jen Shih","David Harwath","Raymond Mooney"],"pdf_url":"https://arxiv.org/pdf/2409.12306v3.pdf","comment":"SLT 2024"},{"id":"http://arxiv.org/abs/2411.07351v1","updated":"2024-11-11T20:19:00Z","published":"2024-11-11T20:19:00Z","title":"Generalization of Brady-Yong Algorithm for Fast Hough Transform to\n  Arbitrary Image Size","summary":"  Nowadays, the Hough (discrete Radon) transform (HT/DRT) has proved to be an\nextremely powerful and widespread tool harnessed in a number of application\nareas, ranging from general image processing to X-ray computed tomography.\nEfficient utilization of the HT to solve applied problems demands its\nacceleration and increased accuracy. Along with this, most fast algorithms for\ncomputing the HT, especially the pioneering Brady-Yong algorithm, operate on\npower-of-two size input images and are not adapted for arbitrary size images.\nThis paper presents a new algorithm for calculating the HT for images of\narbitrary size. It generalizes the Brady-Yong algorithm from which it inherits\nthe optimal computational complexity. Moreover, the algorithm allows to compute\nthe HT with considerably higher accuracy compared to the existing algorithm.\nHerewith, the paper provides a theoretical analysis of the computational\ncomplexity and accuracy of the proposed algorithm. The conclusions of the\nperformed experiments conform with the theoretical results.\n","authors":["Danil Kazimirov","Dmitry Nikolaev","Ekaterina Rybakova","Arseniy Terekhin"],"pdf_url":"https://arxiv.org/pdf/2411.07351v1.pdf","comment":"6 pages, 2 figures. Accepted to Symposium on Pattern Recognition and\n  Applications 2024 (SPRA 2024)"},{"id":"http://arxiv.org/abs/2411.07348v1","updated":"2024-11-11T20:12:13Z","published":"2024-11-11T20:12:13Z","title":"Exploring Variational Autoencoders for Medical Image Generation: A\n  Comprehensive Study","summary":"  Variational autoencoder (VAE) is one of the most common techniques in the\nfield of medical image generation, where this architecture has shown advanced\nresearchers in recent years and has developed into various architectures. VAE\nhas advantages including improving datasets by adding samples in smaller\ndatasets and in datasets with imbalanced classes, and this is how data\naugmentation works. This paper provides a comprehensive review of studies on\nVAE in medical imaging, with a special focus on their ability to create\nsynthetic images close to real data so that they can be used for data\naugmentation. This study reviews important architectures and methods used to\ndevelop VAEs for medical images and provides a comparison with other generative\nmodels such as GANs on issues such as image quality, and low diversity of\ngenerated samples. We discuss recent developments and applications in several\nmedical fields highlighting the ability of VAEs to improve segmentation and\nclassification accuracy.\n","authors":["Khadija Rais","Mohamed Amroune","Abdelmadjid Benmachiche","Mohamed Yassine Haouam"],"pdf_url":"https://arxiv.org/pdf/2411.07348v1.pdf","comment":"for associated mpeg file, see\n  https://worldresearchlibrary.org/proceeding.php?pid=6945"},{"id":"http://arxiv.org/abs/2411.07335v1","updated":"2024-11-11T19:53:05Z","published":"2024-11-11T19:53:05Z","title":"Multimodal Fusion Balancing Through Game-Theoretic Regularization","summary":"  Multimodal learning can complete the picture of information extraction by\nuncovering key dependencies between data sources. However, current systems fail\nto fully leverage multiple modalities for optimal performance. This has been\nattributed to modality competition, where modalities strive for training\nresources, leaving some underoptimized. We show that current balancing methods\nstruggle to train multimodal models that surpass even simple baselines, such as\nensembles. This raises the question: how can we ensure that all modalities in\nmultimodal training are sufficiently trained, and that learning from new\nmodalities consistently improves performance? This paper proposes the\nMultimodal Competition Regularizer (MCR), a new loss component inspired by\nmutual information (MI) decomposition designed to prevent the adverse effects\nof competition in multimodal training. Our key contributions are: 1)\nIntroducing game-theoretic principles in multimodal learning, where each\nmodality acts as a player competing to maximize its influence on the final\noutcome, enabling automatic balancing of the MI terms. 2) Refining lower and\nupper bounds for each MI term to enhance the extraction of task-relevant unique\nand shared information across modalities. 3) Suggesting latent space\npermutations for conditional MI estimation, significantly improving\ncomputational efficiency. MCR outperforms all previously suggested training\nstrategies and is the first to consistently improve multimodal learning beyond\nthe ensemble baseline, clearly demonstrating that combining modalities leads to\nsignificant performance gains on both synthetic and large real-world datasets.\n","authors":["Konstantinos Kontras","Thomas Strypsteen","Christos Chatzichristos","Paul P. Liang","Matthew Blaschko","Maarten De Vos"],"pdf_url":"https://arxiv.org/pdf/2411.07335v1.pdf","comment":"21 pages, 6 figures, 4 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2210.06094v2","updated":"2024-11-11T19:35:03Z","published":"2022-10-12T11:18:35Z","title":"Teeth3DS+: An Extended Benchmark for Intraoral 3D Scans Analysis","summary":"  Intraoral 3D scans analysis is a fundamental aspect of Computer-Aided\nDentistry (CAD) systems, playing a crucial role in various dental applications,\nincluding teeth segmentation, detection, labeling, and dental landmark\nidentification. Accurate analysis of 3D dental scans is essential for\northodontic and prosthetic treatment planning, as it enables automated\nprocessing and reduces the need for manual adjustments by dental professionals.\nHowever, developing robust automated tools for these tasks remains a\nsignificant challenge due to the limited availability of high-quality public\ndatasets and benchmarks. This article introduces Teeth3DS+, the first\ncomprehensive public benchmark designed to advance the field of intraoral 3D\nscan analysis. Developed as part of the 3DTeethSeg 2022 and 3DTeethLand 2024\nMICCAI challenges, Teeth3DS+ aims to drive research in teeth identification,\nsegmentation, labeling, 3D modeling, and dental landmarks identification. The\ndataset includes at least 1,800 intraoral scans (containing 23,999 annotated\nteeth) collected from 900 patients, covering both upper and lower jaws\nseparately. All data have been acquired and validated by experienced\northodontists and dental surgeons with over five years of expertise. Detailed\ninstructions for accessing the dataset are available at\nhttps://crns-smartvision.github.io/teeth3ds\n","authors":["Achraf Ben-Hamadou","Nour Neifar","Ahmed Rekik","Oussama Smaoui","Firas Bouzguenda","Sergi Pujades","Edmond Boyer","Edouard Ladroit"],"pdf_url":"https://arxiv.org/pdf/2210.06094v2.pdf","comment":"Draft"},{"id":"http://arxiv.org/abs/2411.07326v1","updated":"2024-11-11T19:34:47Z","published":"2024-11-11T19:34:47Z","title":"$SE(3)$ Equivariant Ray Embeddings for Implicit Multi-View Depth\n  Estimation","summary":"  Incorporating inductive bias by embedding geometric entities (such as rays)\nas input has proven successful in multi-view learning. However, the methods\nadopting this technique typically lack equivariance, which is crucial for\neffective 3D learning. Equivariance serves as a valuable inductive prior,\naiding in the generation of robust multi-view features for 3D scene\nunderstanding. In this paper, we explore the application of equivariant\nmulti-view learning to depth estimation, not only recognizing its significance\nfor computer vision and robotics but also addressing the limitations of\nprevious research. Most prior studies have either overlooked equivariance in\nthis setting or achieved only approximate equivariance through data\naugmentation, which often leads to inconsistencies across different reference\nframes. To address this issue, we propose to embed $SE(3)$ equivariance into\nthe Perceiver IO architecture. We employ Spherical Harmonics for positional\nencoding to ensure 3D rotation equivariance, and develop a specialized\nequivariant encoder and decoder within the Perceiver IO architecture. To\nvalidate our model, we applied it to the task of stereo depth estimation,\nachieving state of the art results on real-world datasets without explicit\ngeometric constraints or extensive data augmentation.\n","authors":["Yinshuang Xu","Dian Chen","Katherine Liu","Sergey Zakharov","Rares Ambrus","Kostas Daniilidis","Vitor Guizilini"],"pdf_url":"https://arxiv.org/pdf/2411.07326v1.pdf","comment":"Accepted at NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.07322v1","updated":"2024-11-11T19:31:06Z","published":"2024-11-11T19:31:06Z","title":"Artificial Intelligence-Informed Handheld Breast Ultrasound for\n  Screening: A Systematic Review of Diagnostic Test Accuracy","summary":"  Background. Breast cancer screening programs using mammography have led to\nsignificant mortality reduction in high-income countries. However, many low-\nand middle-income countries lack resources for mammographic screening. Handheld\nbreast ultrasound (BUS) is a low-cost alternative but requires substantial\ntraining. Artificial intelligence (AI) enabled BUS may aid in both the\ndetection (perception) and classification (interpretation) of breast cancer.\nMaterials and Methods. This review (CRD42023493053) is reported in accordance\nwith the PRISMA (Preferred Reporting Items for Systematic Reviews and\nMeta-Analysis) and SWiM (Synthesis Without Meta-analysis) guidelines. PubMed\nand Google Scholar were searched from January 1, 2016 to December 12, 2023. A\nmeta-analysis was not attempted. Studies are grouped according to their AI task\ntype, application time, and AI task. Study quality is assessed using the\nQUality Assessment of Diagnostic Accuracy Studies-2 (QUADAS-2) tool. Results.\nOf 763 candidate studies, 314 total full texts were reviewed. 34 studies are\nincluded. The AI tasks of included studies are as follows: 1 frame selection, 6\ndetection, 11 segmentation, and 16 classification. In total, 5.7 million BUS\nimages from over 185,000 patients were used for AI training or validation. A\nsingle study included a prospective testing set. 79% of studies were at high or\nunclear risk of bias. Conclusion. There has been encouraging development of AI\nfor BUS. Despite studies demonstrating high performance across all identified\ntasks, the evidence supporting AI-enhanced BUS generally lacks robustness.\nHigh-quality model validation will be key to realizing the potential for\nAI-enhanced BUS in increasing access to screening in resource-limited\nenvironments.\n","authors":["Arianna Bunnell","Dustin Valdez","Fredrik Strand","Yannik Glaser","Peter Sadowski","John A. Shepherd"],"pdf_url":"https://arxiv.org/pdf/2411.07322v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07311v1","updated":"2024-11-11T19:10:58Z","published":"2024-11-11T19:10:58Z","title":"GPU-Accelerated Inverse Lithography Towards High Quality Curvy Mask\n  Generation","summary":"  Inverse Lithography Technology (ILT) has emerged as a promising solution for\nphoto mask design and optimization. Relying on multi-beam mask writers, ILT\nenables the creation of free-form curvilinear mask shapes that enhance printed\nwafer image quality and process window. However, a major challenge in\nimplementing curvilinear ILT for large-scale production is mask rule checking,\nan area currently under development by foundries and EDA vendors. Although\nrecent research has incorporated mask complexity into the optimization process,\nmuch of it focuses on reducing e-beam shots, which does not align with the\ngoals of curvilinear ILT. In this paper, we introduce a GPU-accelerated ILT\nalgorithm that improves not only contour quality and process window but also\nthe precision of curvilinear mask shapes. Our experiments on open benchmarks\ndemonstrate a significant advantage of our algorithm over leading academic ILT\nengines.\n","authors":["Haoyu Yang","Haoxing Ren"],"pdf_url":"https://arxiv.org/pdf/2411.07311v1.pdf","comment":"10 pages, 5 figures, Accepted by International Symposium on Physical\n  Design (ISPD), 2025, Austin TX"}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.07439v1","updated":"2024-11-11T23:40:45Z","published":"2024-11-11T23:40:45Z","title":"Music Discovery Dialogue Generation Using Human Intent Analysis and\n  Large Language Models","summary":"  A conversational music retrieval system can help users discover music that\nmatches their preferences through dialogue. To achieve this, a conversational\nmusic retrieval system should seamlessly engage in multi-turn conversation by\n1) understanding user queries and 2) responding with natural language and\nretrieved music. A straightforward solution would be a data-driven approach\nutilizing such conversation logs. However, few datasets are available for the\nresearch and are limited in terms of volume and quality. In this paper, we\npresent a data generation framework for rich music discovery dialogue using a\nlarge language model (LLM) and user intents, system actions, and musical\nattributes. This is done by i) dialogue intent analysis using grounded theory,\nii) generating attribute sequences via cascading database filtering, and iii)\ngenerating utterances using large language models. By applying this framework\nto the Million Song dataset, we create LP-MusicDialog, a Large Language Model\nbased Pseudo Music Dialogue dataset, containing over 288k music conversations\nusing more than 319k music items. Our evaluation shows that the synthetic\ndataset is competitive with an existing, small human dialogue dataset in terms\nof dialogue consistency, item relevance, and naturalness. Furthermore, using\nthe dataset, we train a conversational music retrieval model and show promising\nresults.\n","authors":["SeungHeon Doh","Keunwoo Choi","Daeyong Kwon","Taesu Kim","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2411.07439v1.pdf","comment":"Accepted for publication at the 25th International Society for Music\n  Information Retrieval Conference (ISMIR 2024)"},{"id":"http://arxiv.org/abs/2411.05059v2","updated":"2024-11-11T21:48:52Z","published":"2024-11-07T18:22:14Z","title":"FineTuneBench: How well do commercial fine-tuning APIs infuse knowledge\n  into LLMs?","summary":"  There is great interest in fine-tuning frontier large language models (LLMs)\nto inject new information and update existing knowledge. While commercial LLM\nfine-tuning APIs from providers such as OpenAI and Google promise flexible\nadaptation for various applications, the efficacy of fine-tuning remains\nunclear. In this study, we introduce FineTuneBench, an evaluation framework and\ndataset for understanding how well commercial fine-tuning APIs can successfully\nlearn new and updated knowledge. We analyze five frontier LLMs with\ncommercially available fine-tuning APIs, including GPT-4o and Gemini 1.5 Pro,\non their effectiveness in two settings: (1) ingesting novel information, such\nas recent news events and new people profiles, and (2) updating existing\nknowledge, such as updated medical guidelines and code frameworks. Our results\nreveal substantial shortcomings in all the models' abilities to effectively\nlearn new information through fine-tuning, with an average generalization\naccuracy of 37% across all models. When updating existing knowledge, such as\nincorporating medical guideline updates, commercial fine-tuning APIs show even\nmore limited capability (average generalization accuracy of 19%). Overall,\nfine-tuning GPT-4o mini is the most effective for infusing new knowledge and\nupdating knowledge, followed by GPT-3.5 Turbo and GPT-4o. The fine-tuning APIs\nfor Gemini 1.5 Flesh and Gemini 1.5 Pro are unable to learn new knowledge or\nupdate existing knowledge. These findings underscore a major shortcoming in\nusing current commercial fine-tuning services to achieve reliable knowledge\ninfusion in common scenarios. We open source the FineTuneBench dataset at\nhttps://github.com/kevinwu23/StanfordFineTuneBench.\n","authors":["Eric Wu","Kevin Wu","James Zou"],"pdf_url":"https://arxiv.org/pdf/2411.05059v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.02606v2","updated":"2024-11-11T21:40:16Z","published":"2024-06-02T18:26:50Z","title":"Know Your Neighborhood: General and Zero-Shot Capable Binary Function\n  Search Powered by Call Graphlets","summary":"  Binary code similarity detection is an important problem with applications in\nareas such as malware analysis, vulnerability research and license violation\ndetection. This paper proposes a novel graph neural network architecture\ncombined with a novel graph data representation called call graphlets. A call\ngraphlet encodes the neighborhood around each function in a binary executable,\ncapturing the local and global context through a series of statistical\nfeatures. A specialized graph neural network model operates on this graph\nrepresentation, learning to map it to a feature vector that encodes semantic\nbinary code similarities using deep-metric learning. The proposed approach is\nevaluated across five distinct datasets covering different architectures,\ncompiler tool chains, and optimization levels. Experimental results show that\nthe combination of call graphlets and the novel graph neural network\narchitecture achieves comparable or state-of-the-art performance compared to\nbaseline techniques across cross-architecture, mono-architecture and zero shot\ntasks. In addition, our proposed approach also performs well when evaluated\nagainst an out-of-domain function inlining task. The work provides a general\nand effective graph neural network-based solution for conducting binary code\nsimilarity detection.\n","authors":["Joshua Collyer","Tim Watson","Iain Phillips"],"pdf_url":"https://arxiv.org/pdf/2406.02606v2.pdf","comment":"13 pages, Under-Review"},{"id":"http://arxiv.org/abs/2411.02537v3","updated":"2024-11-11T18:49:52Z","published":"2024-11-04T19:16:53Z","title":"INQUIRE: A Natural World Text-to-Image Retrieval Benchmark","summary":"  We introduce INQUIRE, a text-to-image retrieval benchmark designed to\nchallenge multimodal vision-language models on expert-level queries. INQUIRE\nincludes iNaturalist 2024 (iNat24), a new dataset of five million natural world\nimages, along with 250 expert-level retrieval queries. These queries are paired\nwith all relevant images comprehensively labeled within iNat24, comprising\n33,000 total matches. Queries span categories such as species identification,\ncontext, behavior, and appearance, emphasizing tasks that require nuanced image\nunderstanding and domain expertise. Our benchmark evaluates two core retrieval\ntasks: (1) INQUIRE-Fullrank, a full dataset ranking task, and (2)\nINQUIRE-Rerank, a reranking task for refining top-100 retrievals. Detailed\nevaluation of a range of recent multimodal models demonstrates that INQUIRE\nposes a significant challenge, with the best models failing to achieve an\nmAP@50 above 50%. In addition, we show that reranking with more powerful\nmultimodal models can enhance retrieval performance, yet there remains a\nsignificant margin for improvement. By focusing on scientifically-motivated\necological challenges, INQUIRE aims to bridge the gap between AI capabilities\nand the needs of real-world scientific inquiry, encouraging the development of\nretrieval systems that can assist with accelerating ecological and biodiversity\nresearch. Our dataset and code are available at\nhttps://inquire-benchmark.github.io\n","authors":["Edward Vendrow","Omiros Pantazis","Alexander Shepard","Gabriel Brostow","Kate E. Jones","Oisin Mac Aodha","Sara Beery","Grant Van Horn"],"pdf_url":"https://arxiv.org/pdf/2411.02537v3.pdf","comment":"Published in NeurIPS 2024, Datasets and Benchmarks Track"},{"id":"http://arxiv.org/abs/2411.07166v1","updated":"2024-11-11T17:46:34Z","published":"2024-11-11T17:46:34Z","title":"The Shapley index for music streaming platforms","summary":"  We study an index to measure the popularity of artists in music streaming\nplatforms. This index, which can be used to allocate the amount raised via paid\nsubscriptions among participating artists, is based on the Shapley value, a\ncenterpiece in cooperative game theory. We characterize this Shapley index\ncombining several axioms formalizing principles with normative appeal. This\npermits to place the index in the literature, as an alternative to the\nwell-known (and widely used in the industry) pro-rata and user-centric indices.\n","authors":["Gustavo Berganti√±os","Juan D. Moreno-Ternero"],"pdf_url":"https://arxiv.org/pdf/2411.07166v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.07021v1","updated":"2024-11-11T14:25:37Z","published":"2024-11-11T14:25:37Z","title":"Invar-RAG: Invariant LLM-aligned Retrieval for Better Generation","summary":"  Retrieval-augmented generation (RAG) has shown impressive capability in\nproviding reliable answer predictions and addressing hallucination problems. A\ntypical RAG implementation uses powerful retrieval models to extract external\ninformation and large language models (LLMs) to generate answers. In contrast,\nrecent LLM-based retrieval has gained attention for its substantial\nimprovements in information retrieval (IR) due to the LLMs' semantic\nunderstanding capability. However, directly applying LLM to RAG systems\npresents challenges. This may cause feature locality problems as massive\nparametric knowledge can hinder effective usage of global information across\nthe corpus; for example, an LLM-based retriever often inputs document summaries\ninstead of full documents. Moreover, various pre-trained tasks in LLMs\nintroduce variance, further weakening performance as a retriever.\n  To address these issues, we propose a novel two-stage fine-tuning\narchitecture called Invar-RAG. In the retrieval stage, an LLM-based retriever\nis constructed by integrating LoRA-based representation learning to tackle\nfeature locality issues. To enhance retrieval performance, we develop two\npatterns (invariant and variant patterns) and an invariance loss to reduce LLM\nvariance. In the generation stage, a refined fine-tuning method is employed to\nimprove LLM accuracy in generating answers based on retrieved information.\nExperimental results show that Invar-RAG significantly outperforms existing\nbaselines across three open-domain question answering (ODQA) datasets. Code is\navailable in the Supplementary Material for reproducibility.\n","authors":["Ziwei Liu","Liang Zhang","Qian Li","Jianghua Wu","Guangxu Zhu"],"pdf_url":"https://arxiv.org/pdf/2411.07021v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2208.02971v3","updated":"2024-11-11T11:46:16Z","published":"2022-08-05T03:45:56Z","title":"CROLoss: Towards a Customizable Loss for Retrieval Models in Recommender\n  Systems","summary":"  In large-scale recommender systems, retrieving top N relevant candidates\naccurately with resource constrain is crucial. To evaluate the performance of\nsuch retrieval models, Recall@N, the frequency of positive samples being\nretrieved in the top N ranking, is widely used. However, most of the\nconventional loss functions for retrieval models such as softmax cross-entropy\nand pairwise comparison methods do not directly optimize Recall@N. Moreover,\nthose conventional loss functions cannot be customized for the specific\nretrieval size N required by each application and thus may lead to sub-optimal\nperformance. In this paper, we proposed the Customizable Recall@N Optimization\nLoss (CROLoss), a loss function that can directly optimize the Recall@N metrics\nand is customizable for different choices of N. This proposed CROLoss\nformulation defines a more generalized loss function space, covering most of\nthe conventional loss functions as special cases. Furthermore, we develop the\nLambda method, a gradient-based method that invites more flexibility and can\nfurther boost the system performance. We evaluate the proposed CROLoss on two\npublic benchmark datasets. The results show that CROLoss achieves SOTA results\nover conventional loss functions for both datasets with various choices of\nretrieval size N. CROLoss has been deployed onto our online E-commerce\nadvertising platform, where a fourteen-day online A/B test demonstrated that\nCROLoss contributes to a significant business revenue growth of 4.75%.\n","authors":["Yongxiang Tang","Wentao Bai","Guilin Li","Xialong Liu","Yu Zhang"],"pdf_url":"https://arxiv.org/pdf/2208.02971v3.pdf","comment":"9 pages, 5 figures. Accepted by by CIKM 2022"},{"id":"http://arxiv.org/abs/2411.06877v1","updated":"2024-11-11T11:17:35Z","published":"2024-11-11T11:17:35Z","title":"LLM-Assisted Relevance Assessments: When Should We Ask LLMs for Help?","summary":"  Test collections are information retrieval tools that allow researchers to\nquickly and easily evaluate ranking algorithms. While test collections have\nbecome an integral part of IR research, the process of data creation involves\nsignificant efforts in manual annotations, which often makes it very expensive\nand time-consuming. Thus, the test collections could become small when the\nbudget is limited, which may lead to unstable evaluations. As an alternative,\nrecent studies have proposed the use of large language models (LLMs) to\ncompletely replace human assessors. However, while LLMs seem to somewhat\ncorrelate with human judgments, they are not perfect and often show bias.\nMoreover, even if a well-performing LLM or prompt is found on one dataset,\nthere is no guarantee that it will perform similarly in practice, due to\ndifference in tasks and data. Thus a complete replacement with LLMs is argued\nto be too risky and not fully trustable.\n  Thus, in this paper, we propose \\textbf{L}LM-\\textbf{A}ssisted\n\\textbf{R}elevance \\textbf{A}ssessments (\\textbf{LARA}), an effective method to\nbalance manual annotations with LLM annotations, which helps to make a rich and\nreliable test collection. We use the LLM's predicted relevance probabilities in\norder to select the most profitable documents to manually annotate under a\nbudget constraint. While solely relying on LLM's predicted probabilities to\nmanually annotate performs fairly well, with theoretical reasoning, LARA guides\nthe human annotation process even more effectively via online calibration\nlearning. Then, using the calibration model learned from the limited manual\nannotations, LARA debiases the LLM predictions to annotate the remaining\nnon-assessed data. Empirical evaluations on TREC-COVID and TREC-8 Ad Hoc\ndatasets show that LARA outperforms the alternative solutions under almost any\nbudget constraint.\n","authors":["Rikiya Takehi","Ellen M. Voorhees","Tetsuya Sakai"],"pdf_url":"https://arxiv.org/pdf/2411.06877v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.13704v2","updated":"2024-11-11T10:02:24Z","published":"2024-09-05T10:27:32Z","title":"Entity Extraction from High-Level Corruption Schemes via Large Language\n  Models","summary":"  The rise of financial crime that has been observed in recent years has\ncreated an increasing concern around the topic and many people, organizations\nand governments are more and more frequently trying to combat it. Despite the\nincrease of interest in this area, there is a lack of specialized datasets that\ncan be used to train and evaluate works that try to tackle those problems. This\narticle proposes a new micro-benchmark dataset for algorithms and models that\nidentify individuals and organizations, and their multiple writings, in news\narticles, and presents an approach that assists in its creation. Experimental\nefforts are also reported, using this dataset, to identify individuals and\norganizations in financial-crime-related articles using various low-billion\nparameter Large Language Models (LLMs). For these experiments, standard metrics\n(Accuracy, Precision, Recall, F1 Score) are reported and various prompt\nvariants comprising the best practices of prompt engineering are tested. In\naddition, to address the problem of ambiguous entity mentions, a simple, yet\neffective LLM-based disambiguation method is proposed, ensuring that the\nevaluation aligns with reality. Finally, the proposed approach is compared\nagainst a widely used state-of-the-art open-source baseline, showing the\nsuperiority of the proposed method.\n","authors":["Panagiotis Koletsis","Panagiotis-Konstantinos Gemos","Christos Chronis","Iraklis Varlamis","Vasilis Efthymiou","Georgios Th. Papadopoulos"],"pdf_url":"https://arxiv.org/pdf/2409.13704v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06826v1","updated":"2024-11-11T09:39:31Z","published":"2024-11-11T09:39:31Z","title":"Adaptive Conditional Expert Selection Network for Multi-domain\n  Recommendation","summary":"  Mixture-of-Experts (MOE) has recently become the de facto standard in\nMulti-domain recommendation (MDR) due to its powerful expressive ability.\nHowever, such MOE-based method typically employs all experts for each instance,\nleading to scalability issue and low-discriminability between domains and\nexperts. Furthermore, the design of commonly used domain-specific networks\nexacerbates the scalability issues. To tackle the problems, We propose a novel\nmethod named CESAA consists of Conditional Expert Selection (CES) Module and\nAdaptive Expert Aggregation (AEA) Module to tackle these challenges.\nSpecifically, CES first combines a sparse gating strategy with domain-shared\nexperts. Then AEA utilizes mutual information loss to strengthen the\ncorrelations between experts and specific domains, and significantly improve\nthe distinction between experts. As a result, only domain-shared experts and\nselected domain-specific experts are activated for each instance, striking a\nbalance between computational efficiency and model performance. Experimental\nresults on both public ranking and industrial retrieval datasets verify the\neffectiveness of our method in MDR tasks.\n","authors":["Kuiyao Dong","Xingyu Lou","Feng Liu","Ruian Wang","Wenyi Yu","Ping Wang","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2411.06826v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06823v1","updated":"2024-11-11T09:31:46Z","published":"2024-11-11T09:31:46Z","title":"Large Language Model in Medical Informatics: Direct Classification and\n  Enhanced Text Representations for Automatic ICD Coding","summary":"  Addressing the complexity of accurately classifying International\nClassification of Diseases (ICD) codes from medical discharge summaries is\nchallenging due to the intricate nature of medical documentation. This paper\nexplores the use of Large Language Models (LLM), specifically the LLAMA\narchitecture, to enhance ICD code classification through two methodologies:\ndirect application as a classifier and as a generator of enriched text\nrepresentations within a Multi-Filter Residual Convolutional Neural Network\n(MultiResCNN) framework. We evaluate these methods by comparing them against\nstate-of-the-art approaches, revealing LLAMA's potential to significantly\nimprove classification outcomes by providing deep contextual insights into\nmedical texts.\n","authors":["Zeyd Boukhers","AmeerAli Khan","Qusai Ramadan","Cong Yang"],"pdf_url":"https://arxiv.org/pdf/2411.06823v1.pdf","comment":"accepted at the 2024 IEEE International Conference on Bioinformatics\n  and Biomedicine (BIBM 2024)"},{"id":"http://arxiv.org/abs/2411.06805v1","updated":"2024-11-11T09:03:52Z","published":"2024-11-11T09:03:52Z","title":"AssistRAG: Boosting the Potential of Large Language Models with an\n  Intelligent Information Assistant","summary":"  The emergence of Large Language Models (LLMs) has significantly advanced\nnatural language processing, but these models often generate factually\nincorrect information, known as \"hallucination\". Initial retrieval-augmented\ngeneration (RAG) methods like the \"Retrieve-Read\" framework was inadequate for\ncomplex reasoning tasks. Subsequent prompt-based RAG strategies and Supervised\nFine-Tuning (SFT) methods improved performance but required frequent retraining\nand risked altering foundational LLM capabilities. To cope with these\nchallenges, we propose Assistant-based Retrieval-Augmented Generation\n(AssistRAG), integrating an intelligent information assistant within LLMs. This\nassistant manages memory and knowledge through tool usage, action execution,\nmemory building, and plan specification. Using a two-phase training approach,\nCurriculum Assistant Learning and Reinforced Preference Optimization. AssistRAG\nenhances information retrieval and decision-making. Experiments show AssistRAG\nsignificantly outperforms benchmarks, especially benefiting less advanced LLMs,\nby providing superior reasoning capabilities and accurate responses.\n","authors":["Yujia Zhou","Zheng Liu","Zhicheng Dou"],"pdf_url":"https://arxiv.org/pdf/2411.06805v1.pdf","comment":"Accepted by NeurIPS 2024 (poster)"},{"id":"http://arxiv.org/abs/2411.06784v1","updated":"2024-11-11T08:23:37Z","published":"2024-11-11T08:23:37Z","title":"Boosting the Targeted Transferability of Adversarial Examples via\n  Salient Region & Weighted Feature Drop","summary":"  Deep neural networks can be vulnerable to adversarially crafted examples,\npresenting significant risks to practical applications. A prevalent approach\nfor adversarial attacks relies on the transferability of adversarial examples,\nwhich are generated from a substitute model and leveraged to attack unknown\nblack-box models. Despite various proposals aimed at improving transferability,\nthe success of these attacks in targeted black-box scenarios is often hindered\nby the tendency for adversarial examples to overfit to the surrogate models. In\nthis paper, we introduce a novel framework based on Salient region & Weighted\nFeature Drop (SWFD) designed to enhance the targeted transferability of\nadversarial examples. Drawing from the observation that examples with higher\ntransferability exhibit smoother distributions in the deep-layer outputs, we\npropose the weighted feature drop mechanism to modulate activation values\naccording to weights scaled by norm distribution, effectively addressing the\noverfitting issue when generating adversarial examples. Additionally, by\nleveraging salient region within the image to construct auxiliary images, our\nmethod enables the adversarial example's features to be transferred to the\ntarget category in a model-agnostic manner, thereby enhancing the\ntransferability. Comprehensive experiments confirm that our approach\noutperforms state-of-the-art methods across diverse configurations. On average,\nthe proposed SWFD raises the attack success rate for normally trained models\nand robust models by 16.31% and 7.06% respectively.\n","authors":["Shanjun Xu","Linghui Li","Kaiguo Yuan","Bingyu Li"],"pdf_url":"https://arxiv.org/pdf/2411.06784v1.pdf","comment":"9 pages"},{"id":"http://arxiv.org/abs/2409.14038v4","updated":"2024-11-11T06:26:39Z","published":"2024-09-21T06:49:34Z","title":"OAEI-LLM: A Benchmark Dataset for Understanding Large Language Model\n  Hallucinations in Ontology Matching","summary":"  Hallucinations of large language models (LLMs) commonly occur in\ndomain-specific downstream tasks, with no exception in ontology matching (OM).\nThe prevalence of using LLMs for OM raises the need for benchmarks to better\nunderstand LLM hallucinations. The OAEI-LLM dataset is an extended version of\nthe Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate\nLLM-specific hallucinations in OM tasks. We outline the methodology used in\ndataset construction and schema extension, and provide examples of potential\nuse cases.\n","authors":["Zhangcheng Qiang","Kerry Taylor","Weiqing Wang","Jing Jiang"],"pdf_url":"https://arxiv.org/pdf/2409.14038v4.pdf","comment":"5 pages, 1 figure, 1 table"},{"id":"http://arxiv.org/abs/2310.09874v4","updated":"2024-11-11T06:16:24Z","published":"2023-10-15T16:15:07Z","title":"TF-DCon: Leveraging Large Language Models (LLMs) to Empower\n  Training-Free Dataset Condensation for Content-Based Recommendation","summary":"  Modern techniques in Content-based Recommendation (CBR) leverage item content\ninformation to provide personalized services to users, but suffer from\nresource-intensive training on large datasets. To address this issue, we\nexplore the dataset condensation for textual CBR in this paper. The goal of\ndataset condensation is to synthesize a small yet informative dataset, upon\nwhich models can achieve performance comparable to those trained on large\ndatasets. While existing condensation approaches are tailored to classification\ntasks for continuous data like images or embeddings, direct application of them\nto CBR has limitations. To bridge this gap, we investigate efficient dataset\ncondensation for content-based recommendation. Inspired by the remarkable\nabilities of large language models (LLMs) in text comprehension and generation,\nwe leverage LLMs to empower the generation of textual content during\ncondensation. To handle the interaction data involving both users and items, we\ndevise a dual-level condensation method: content-level and user-level. At\ncontent-level, we utilize LLMs to condense all contents of an item into a new\ninformative title. At user-level, we design a clustering-based synthesis\nmodule, where we first utilize LLMs to extract user interests. Then, the user\ninterests and user embeddings are incorporated to condense users and generate\ninteractions for condensed users. Notably, the condensation paradigm of this\nmethod is forward and free from iterative optimization on the synthesized\ndataset. Extensive empirical findings from our study, conducted on three\nauthentic datasets, substantiate the efficacy of the proposed method.\nParticularly, we are able to approximate up to 97% of the original performance\nwhile reducing the dataset size by 95% (i.e., on dataset MIND).\n","authors":["Jiahao Wu","Qijiong Liu","Hengchang Hu","Wenqi Fan","Shengcai Liu","Qing Li","Xiao-Ming Wu","Ke Tang"],"pdf_url":"https://arxiv.org/pdf/2310.09874v4.pdf","comment":"An updated version"}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.07428v1","updated":"2024-11-11T23:05:02Z","published":"2024-11-11T23:05:02Z","title":"Just Label the Repeats for In-The-Wild Audio-to-Score Alignment","summary":"  We propose an efficient workflow for high-quality offline alignment of\nin-the-wild performance audio and corresponding sheet music scans (images).\nRecent work on audio-to-score alignment extends dynamic time warping (DTW) to\nbe theoretically able to handle jumps in sheet music induced by repeat\nsigns-this method requires no human annotations, but we show that it often\nyields low-quality alignments. As an alternative, we propose a workflow and\ninterface that allows users to quickly annotate jumps (by clicking on repeat\nsigns), requiring a small amount of human supervision but yielding much higher\nquality alignments on average. Additionally, we refine audio and score feature\nrepresentations to improve alignment quality by: (1) integrating measure\ndetection into the score feature representation, and (2) using raw onset\nprediction probabilities from a music transcription model instead of piano\nroll. We propose an evaluation protocol for audio-to-score alignment that\ncomputes the distance between the estimated and ground truth alignment in units\nof measures. Under this evaluation, we find that our proposed jump annotation\nworkflow and improved feature representations together improve alignment\naccuracy by 150% relative to prior work (33% to 82%).\n","authors":["Irmak Bukey","Michael Feffer","Chris Donahue"],"pdf_url":"https://arxiv.org/pdf/2411.07428v1.pdf","comment":"25th International Society for Music Information Retrieval\n  Conference, San Francisco, 2024"},{"id":"http://arxiv.org/abs/2411.07335v1","updated":"2024-11-11T19:53:05Z","published":"2024-11-11T19:53:05Z","title":"Multimodal Fusion Balancing Through Game-Theoretic Regularization","summary":"  Multimodal learning can complete the picture of information extraction by\nuncovering key dependencies between data sources. However, current systems fail\nto fully leverage multiple modalities for optimal performance. This has been\nattributed to modality competition, where modalities strive for training\nresources, leaving some underoptimized. We show that current balancing methods\nstruggle to train multimodal models that surpass even simple baselines, such as\nensembles. This raises the question: how can we ensure that all modalities in\nmultimodal training are sufficiently trained, and that learning from new\nmodalities consistently improves performance? This paper proposes the\nMultimodal Competition Regularizer (MCR), a new loss component inspired by\nmutual information (MI) decomposition designed to prevent the adverse effects\nof competition in multimodal training. Our key contributions are: 1)\nIntroducing game-theoretic principles in multimodal learning, where each\nmodality acts as a player competing to maximize its influence on the final\noutcome, enabling automatic balancing of the MI terms. 2) Refining lower and\nupper bounds for each MI term to enhance the extraction of task-relevant unique\nand shared information across modalities. 3) Suggesting latent space\npermutations for conditional MI estimation, significantly improving\ncomputational efficiency. MCR outperforms all previously suggested training\nstrategies and is the first to consistently improve multimodal learning beyond\nthe ensemble baseline, clearly demonstrating that combining modalities leads to\nsignificant performance gains on both synthetic and large real-world datasets.\n","authors":["Konstantinos Kontras","Thomas Strypsteen","Christos Chatzichristos","Paul P. Liang","Matthew Blaschko","Maarten De Vos"],"pdf_url":"https://arxiv.org/pdf/2411.07335v1.pdf","comment":"21 pages, 6 figures, 4 tables, 1 algorithm"},{"id":"http://arxiv.org/abs/2411.07155v1","updated":"2024-11-11T17:32:55Z","published":"2024-11-11T17:32:55Z","title":"Low Complexity Learning-based Lossless Event-based Compression","summary":"  Event cameras are a cutting-edge type of visual sensors that capture data by\ndetecting brightness changes at the pixel level asynchronously. These cameras\noffer numerous benefits over conventional cameras, including high temporal\nresolution, wide dynamic range, low latency, and lower power consumption.\nHowever, the substantial data rates they produce require efficient compression\ntechniques, while also fulfilling other typical application requirements, such\nas the ability to respond to visual changes in real-time or near real-time.\nAdditionally, many event-based applications demand high accuracy, making\nlossless coding desirable, as it retains the full detail of the sensor data.\nLearning-based methods show great potential due to their ability to model the\nunique characteristics of event data thus allowing to achieve high compression\nrates. This paper proposes a low-complexity lossless coding solution based on\nthe quadtree representation that outperforms traditional compression algorithms\nin efficiency and speed, ensuring low computational complexity and minimal\ndelay for real-time applications. Experimental results show that the proposed\nmethod delivers better compression ratios, i.e., with fewer bits per event, and\nlower computational complexity compared to current lossless data compression\nmethods.\n","authors":["Ahmadreza Sezavar","Catarina Brites","Joao Ascenso"],"pdf_url":"https://arxiv.org/pdf/2411.07155v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06976v1","updated":"2024-11-11T13:34:24Z","published":"2024-11-11T13:34:24Z","title":"A Hierarchical Compression Technique for 3D Gaussian Splatting\n  Compression","summary":"  3D Gaussian Splatting (GS) demonstrates excellent rendering quality and\ngeneration speed in novel view synthesis. However, substantial data size poses\nchallenges for storage and transmission, making 3D GS compression an essential\ntechnology. Current 3D GS compression research primarily focuses on developing\nmore compact scene representations, such as converting explicit 3D GS data into\nimplicit forms. In contrast, compression of the GS data itself has hardly been\nexplored. To address this gap, we propose a Hierarchical GS Compression (HGSC)\ntechnique. Initially, we prune unimportant Gaussians based on importance scores\nderived from both global and local significance, effectively reducing\nredundancy while maintaining visual quality. An Octree structure is used to\ncompress 3D positions. Based on the 3D GS Octree, we implement a hierarchical\nattribute compression strategy by employing a KD-tree to partition the 3D GS\ninto multiple blocks. We apply farthest point sampling to select anchor\nprimitives within each block and others as non-anchor primitives with varying\nLevels of Details (LoDs). Anchor primitives serve as reference points for\npredicting non-anchor primitives across different LoDs to reduce spatial\nredundancy. For anchor primitives, we use the region adaptive hierarchical\ntransform to achieve near-lossless compression of various attributes. For\nnon-anchor primitives, each is predicted based on the k-nearest anchor\nprimitives. To further minimize prediction errors, the reconstructed LoD and\nanchor primitives are combined to form new anchor primitives to predict the\nnext LoD. Our method notably achieves superior compression quality and a\nsignificant data size reduction of over 4.5 times compared to the\nstate-of-the-art compression method on small scenes datasets.\n","authors":["He Huang","Wenjie Huang","Qi Yang","Yiling Xu","Zhu li"],"pdf_url":"https://arxiv.org/pdf/2411.06976v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06810v1","updated":"2024-11-11T09:11:01Z","published":"2024-11-11T09:11:01Z","title":"JPEG AI Image Compression Visual Artifacts: Detection Methods and\n  Dataset","summary":"  Learning-based image compression methods have improved in recent years and\nstarted to outperform traditional codecs. However, neural-network approaches\ncan unexpectedly introduce visual artifacts in some images. We therefore\npropose methods to separately detect three types of artifacts (texture and\nboundary degradation, color change, and text corruption), to localize the\naffected regions, and to quantify the artifact strength. We consider only those\nregions that exhibit distortion due solely to the neural compression but that a\ntraditional codec recovers successfully at a comparable bitrate. We employed\nour methods to collect artifacts for the JPEG AI verification model with\nrespect to HM-18.0, the H.265 reference software. We processed about 350,000\nunique images from the Open Images dataset using different compression-quality\nparameters; the result is a dataset of 46,440 artifacts validated through\ncrowd-sourced subjective assessment. Our proposed dataset and methods are\nvaluable for testing neural-network-based image codecs, identifying bugs in\nthese codecs, and enhancing their performance. We make source code of the\nmethods and the dataset publicly available.\n","authors":["Daria Tsereh","Mark Mirgaleev","Ivan Molodetskikh","Roman Kazantsev","Dmitriy Vatolin"],"pdf_url":"https://arxiv.org/pdf/2411.06810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.04097v2","updated":"2024-11-11T09:05:15Z","published":"2024-05-07T07:57:15Z","title":"Unmasking Illusions: Understanding Human Perception of Audiovisual\n  Deepfakes","summary":"  The emergence of contemporary deepfakes has attracted significant attention\nin machine learning research, as artificial intelligence (AI) generated\nsynthetic media increases the incidence of misinterpretation and is difficult\nto distinguish from genuine content. Currently, machine learning techniques\nhave been extensively studied for automatically detecting deepfakes. However,\nhuman perception has been less explored. Malicious deepfakes could ultimately\ncause public and social problems. Can we humans correctly perceive the\nauthenticity of the content of the videos we watch? The answer is obviously\nuncertain; therefore, this paper aims to evaluate the human ability to discern\ndeepfake videos through a subjective study. We present our findings by\ncomparing human observers to five state-ofthe-art audiovisual deepfake\ndetection models. To this end, we used gamification concepts to provide 110\nparticipants (55 native English speakers and 55 non-native English speakers)\nwith a webbased platform where they could access a series of 40 videos (20 real\nand 20 fake) to determine their authenticity. Each participant performed the\nexperiment twice with the same 40 videos in different random orders. The videos\nare manually selected from the FakeAVCeleb dataset. We found that all AI models\nperformed better than humans when evaluated on the same 40 videos. The study\nalso reveals that while deception is not impossible, humans tend to\noverestimate their detection capabilities. Our experimental results may help\nbenchmark human versus machine performance, advance forensics analysis, and\nenable adaptive countermeasures.\n","authors":["Ammarah Hashmi","Sahibzada Adil Shahzad","Chia-Wen Lin","Yu Tsao","Hsin-Min Wang"],"pdf_url":"https://arxiv.org/pdf/2405.04097v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06742v1","updated":"2024-11-11T06:40:06Z","published":"2024-11-11T06:40:06Z","title":"Loss-tolerant neural video codec aware congestion control for real time\n  video communication","summary":"  Because of reinforcement learning's (RL) ability to automatically create more\nadaptive controlling logics beyond the hand-crafted heuristics, numerous effort\nhas been made to apply RL to congestion control (CC) design for real time video\ncommunication (RTC) applications and has successfully shown promising benefits\nover the rule-based RTC CCs. Online reinforcement learning is often adopted to\ntrain the RL models so the models can directly adapt to real network\nenvironments. However, its trail-and-error manner can also cause catastrophic\ndegradation of the quality of experience (QoE) of RTC application at run time.\nThus, safeguard strategies such as falling back to hand-crafted heuristics can\nbe used to run along with RL models to guarantee the actions explored in the\ntraining sensible, despite that these safeguard strategies interrupt the\nlearning process and make it more challenging to discover optimal RL policies.\n  The recent emergence of loss-tolerant neural video codecs (NVC) naturally\nprovides a layer of protection for the online learning of RL-based congestion\ncontrol because of its resilience to packet losses, but such packet loss\nresilience have not been fully exploited in prior works yet. In this paper, we\npresent a reinforcement learning (RL) based congestion control which can be\naware of and takes advantage of packet loss tolerance characteristic of NVCs\nvia reward in online RL learning. Through extensive evaluation on various\nvideos and network traces in a simulated environment, we demonstrate that our\nNVC-aware CC running with the loss-tolerant NVC reduces the training time by\n41\\% compared to other prior RL-based CCs. It also boosts the mean video\nquality by 0.3 to 1.6dB, lower the tail frame delay by 3 to 200ms, and reduces\nthe video stalls by 20\\% to 77\\% in comparison with other baseline RTC CCs.\n","authors":["Zhengxu Xia","Hanchen Li","Junchen Jiang"],"pdf_url":"https://arxiv.org/pdf/2411.06742v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.02188v2","updated":"2024-11-11T05:14:15Z","published":"2023-12-01T23:56:00Z","title":"Video Summarization: Towards Entity-Aware Captions","summary":"  Existing popular video captioning benchmarks and models deal with generic\ncaptions devoid of specific person, place or organization named entities. In\ncontrast, news videos present a challenging setting where the caption requires\nsuch named entities for meaningful summarization. As such, we propose the task\nof summarizing news video directly to entity-aware captions. We also release a\nlarge-scale dataset, VIEWS (VIdeo NEWS), to support research on this task.\nFurther, we propose a method that augments visual information from videos with\ncontext retrieved from external world knowledge to generate entity-aware\ncaptions. We demonstrate the effectiveness of our approach on three video\ncaptioning models. We also show that our approach generalizes to existing news\nimage captions dataset. With all the extensive experiments and insights, we\nbelieve we establish a solid basis for future research on this challenging\ntask.\n","authors":["Hammad A. Ayyubi","Tianqi Liu","Arsha Nagrani","Xudong Lin","Mingda Zhang","Anurag Arnab","Feng Han","Yukun Zhu","Jialu Liu","Shih-Fu Chang"],"pdf_url":"https://arxiv.org/pdf/2312.02188v2.pdf","comment":null}]},"2024-11-10T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2312.11361v3","updated":"2024-11-10T23:58:53Z","published":"2023-12-18T17:18:04Z","title":"\"Knowing When You Don't Know\": A Multilingual Relevance Assessment\n  Dataset for Robust Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) grounds Large Language Model (LLM)\noutput by leveraging external knowledge sources to reduce factual\nhallucinations. However, prior work lacks a comprehensive evaluation of\ndifferent language families, making it challenging to evaluate LLM robustness\nagainst errors in external retrieved knowledge. To overcome this, we establish\nNoMIRACL, a human-annotated dataset for evaluating LLM robustness in RAG across\n18 typologically diverse languages. NoMIRACL includes both a non-relevant and a\nrelevant subset. Queries in the non-relevant subset contain passages judged as\nnon-relevant, whereas queries in the relevant subset include at least a single\njudged relevant passage. We measure relevance assessment using: (i)\nhallucination rate, measuring model tendency to hallucinate, when the answer is\nnot present in passages in the non-relevant subset, and (ii) error rate,\nmeasuring model inaccuracy to recognize relevant passages in the relevant\nsubset.In our work, we observe that most models struggle to balance the two\ncapacities. Models such as LLAMA-2 and Orca-2 achieve over 88% hallucination\nrate on the non-relevant subset. Mistral and LLAMA-3 hallucinate less but can\nachieve up to a 74.9% error rate on the relevant subset. Overall, GPT-4 is\nobserved to provide the best tradeoff on both subsets, highlighting future work\nnecessary to improve LLM robustness. NoMIRACL dataset and evaluation code are\navailable at: https://github.com/project-miracl/nomiracl.\n","authors":["Nandan Thakur","Luiz Bonifacio","Xinyu Zhang","Odunayo Ogundepo","Ehsan Kamalloo","David Alfonso-Hermelo","Xiaoguang Li","Qun Liu","Boxing Chen","Mehdi Rezagholizadeh","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2312.11361v3.pdf","comment":"EMNLP 2024 (Findings)"},{"id":"http://arxiv.org/abs/2406.10593v2","updated":"2024-11-10T13:45:48Z","published":"2024-06-15T10:54:54Z","title":"QDA-SQL: Questions Enhanced Dialogue Augmentation for Multi-Turn\n  Text-to-SQL","summary":"  Fine-tuning large language models (LLMs) for specific domain tasks has\nachieved great success in Text-to-SQL tasks. However, these fine-tuned models\noften face challenges with multi-turn Text-to-SQL tasks caused by ambiguous or\nunanswerable questions. It is desired to enhance LLMs to handle multiple types\nof questions in multi-turn Text-to-SQL tasks. To address this, we propose a\nnovel data augmentation method, called QDA-SQL, which generates multiple types\nof multi-turn Q\\&A pairs using LLMs. In QDA-SQL, we introduce a method\nincorporating validation and correction mechanisms to handle complex multi-turn\nText-to-SQL tasks. Experimental results demonstrate that QDA-SQL enables\nfine-tuned models to exhibit higher performance on SQL statement accuracy and\nenhances their ability to handle complex, unanswerable questions in multi-turn\nText-to-SQL tasks. The generation script and test set are released at\nhttps://github.com/mcxiaoxiao/QDA-SQL\n","authors":["Yinggang Sun","Ziming Guo","Haining Yu","Chuanyi Liu","Xiang Li","Bingxuan Wang","Xiangzhan Yu","Tiancheng Zhao"],"pdf_url":"https://arxiv.org/pdf/2406.10593v2.pdf","comment":"10 pages, 9 figures"},{"id":"http://arxiv.org/abs/2411.06420v1","updated":"2024-11-10T10:49:13Z","published":"2024-11-10T10:49:13Z","title":"Generating Mixcode Popular Songs with Artificial Intelligence: Concepts,\n  Plans, and Speculations","summary":"  Music is a potent form of expression that can communicate, accentuate or even\ncreate the emotions of an individual or a collective. Both historically and in\ncontemporary experiences, musical expression was and is commonly\ninstrumentalized for social, political and/or economic purposes. Generative\nartificial intelligence provides a wealth of both opportunities and challenges\nwith regard to music and its role in society. This paper discusses a proposed\nproject integrating artificial intelligence and popular music, with the\nultimate goal of creating a powerful tool for implementing music for social\ntransformation, education, healthcare, and emotional well-being. Given that it\nis being presented at the outset of a collaboration between a computer\nscientist/data analyst and an ethnomusicologist/social anthropologist. it is\nmainly conceptual and somewhat speculative in nature.\n","authors":["Abhishek Kaushik","Kayla Rush"],"pdf_url":"https://arxiv.org/pdf/2411.06420v1.pdf","comment":"Link to the paper:https://aimc2024.pubpub.org/pub/rdulfbve/release/1\n  Published in The International Conference on AI and Musical Creativity at the\n  University of Oxford (2024) https://aimc2024.pubpub.org/"},{"id":"http://arxiv.org/abs/2410.13293v2","updated":"2024-11-10T08:53:38Z","published":"2024-10-17T07:46:49Z","title":"SBI-RAG: Enhancing Math Word Problem Solving for Students through\n  Schema-Based Instruction and Retrieval-Augmented Generation","summary":"  Many students struggle with math word problems (MWPs), often finding it\ndifficult to identify key information and select the appropriate mathematical\noperations. Schema-based instruction (SBI) is an evidence-based strategy that\nhelps students categorize problems based on their structure, improving\nproblem-solving accuracy. Building on this, we propose a Schema-Based\nInstruction Retrieval-Augmented Generation (SBI-RAG) framework that\nincorporates a large language model (LLM). Our approach emphasizes step-by-step\nreasoning by leveraging schemas to guide solution generation. We evaluate its\nperformance on the GSM8K dataset, comparing it with GPT-4 and GPT-3.5 Turbo,\nand introduce a \"reasoning score\" metric to assess solution quality. Our\nfindings suggest that SBI-RAG enhances reasoning clarity and facilitates a more\nstructured problem-solving process potentially providing educational benefits\nfor students.\n","authors":["Prakhar Dixit","Tim Oates"],"pdf_url":"https://arxiv.org/pdf/2410.13293v2.pdf","comment":"Accepted to the 4th MATH-AI Workshop at NeurIPS'24"},{"id":"http://arxiv.org/abs/2411.06374v1","updated":"2024-11-10T06:46:44Z","published":"2024-11-10T06:46:44Z","title":"Metric Learning for Tag Recommendation: Tackling Data Sparsity and Cold\n  Start Issues","summary":"  With the rapid growth of digital information, personalized recommendation\nsystems have become an indispensable part of Internet services, especially in\nthe fields of e-commerce, social media, and online entertainment. However,\ntraditional collaborative filtering and content-based recommendation methods\nhave limitations in dealing with data sparsity and cold start problems,\nespecially in the face of largescale heterogeneous data, which makes it\ndifficult to meet user expectations. This paper proposes a new label\nrecommendation algorithm based on metric learning, which aims to overcome the\nchallenges of traditional recommendation systems by learning effective distance\nor similarity metrics to capture the subtle differences between user\npreferences and item features. Experimental results show that the algorithm\noutperforms baseline methods including local response metric learning (LRML),\ncollaborative metric learning (CML), and adaptive tensor factorization (ATF)\nbased on adversarial learning on multiple evaluation metrics. In particular, it\nperforms particularly well in the accuracy of the first few recommended items,\nwhile maintaining high robustness and maintaining high recommendation accuracy.\n","authors":["Yuanshuai Luo","Rui Wang","Yaxin Liang","Ankai Liang","Wenyi Liu"],"pdf_url":"https://arxiv.org/pdf/2411.06374v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18957v3","updated":"2024-11-10T03:45:30Z","published":"2024-09-27T17:58:50Z","title":"LML-DAP: Language Model Learning a Dataset for Data-Augmented Prediction","summary":"  Classification tasks are typically handled using Machine Learning (ML)\nmodels, which lack a balance between accuracy and interpretability. This paper\nintroduces a new approach for classification tasks using Large Language Models\n(LLMs) in an explainable method. Unlike ML models, which rely heavily on data\ncleaning and feature engineering, this method streamlines the process using\nLLMs. This paper proposes a method called \"Language Model Learning (LML)\"\npowered by a new method called \"Data-Augmented Prediction (DAP).\" The\nclassification is performed by LLMs using a method similar to that used by\nhumans who manually explore and understand the data to decide classifications.\nIn the process of LML, a dataset is summarized and evaluated to determine the\nfeatures leading to each label the most. In the DAP process, the system uses\nthe data summary and a row of the testing dataset to automatically generate a\nquery to retrieve relevant rows from the dataset for context-aware\nclassification. LML and DAP unlock new possibilities in areas that require\nexplainable and context-aware decisions by ensuring satisfactory accuracy even\nwith complex data. The system scored an accuracy above 90% in some test cases,\nconfirming the effectiveness and potential of the system to outperform ML\nmodels in various scenarios. The source code is available at\nhttps://github.com/Pro-GenAI/LML-DAP\n","authors":["Praneeth Vadlapati"],"pdf_url":"https://arxiv.org/pdf/2409.18957v3.pdf","comment":"Made the abstract and the content clearer"}],"Multimedia":[{"id":"http://arxiv.org/abs/2305.09381v8","updated":"2024-11-10T06:55:48Z","published":"2023-05-16T12:09:30Z","title":"AMD: Autoregressive Motion Diffusion","summary":"  Human motion generation aims to produce plausible human motion sequences\naccording to various conditional inputs, such as text or audio. Despite the\nfeasibility of existing methods in generating motion based on short prompts and\nsimple motion patterns, they encounter difficulties when dealing with long\nprompts or complex motions. The challenges are two-fold: 1) the scarcity of\nhuman motion-captured data for long prompts and complex motions. 2) the high\ndiversity of human motions in the temporal domain and the substantial\ndivergence of distributions from conditional modalities, leading to a\nmany-to-many mapping problem when generating motion with complex and long\ntexts. In this work, we address these gaps by 1) elaborating the first dataset\npairing long textual descriptions and 3D complex motions (HumanLong3D), and 2)\nproposing an autoregressive motion diffusion model (AMD). Specifically, AMD\nintegrates the text prompt at the current timestep with the text prompt and\naction sequences at the previous timestep as conditional information to predict\nthe current action sequences in an iterative manner. Furthermore, we present\nits generalization for X-to-Motion with \"No Modality Left Behind\", enabling the\ngeneration of high-definition and high-fidelity human motions based on\nuser-defined modality input.\n","authors":["Bo Han","Hao Peng","Minjing Dong","Yi Ren","Yixuan Shen","Chang Xu"],"pdf_url":"https://arxiv.org/pdf/2305.09381v8.pdf","comment":"accepted by AAAI2024. Official Code:\n  https://github.com/fluide1022/AMD"}]},"2024-11-09T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.06264v1","updated":"2024-11-09T19:32:26Z","published":"2024-11-09T19:32:26Z","title":"GuidelineGuard: An Agentic Framework for Medical Note Evaluation with\n  Guideline Adherence","summary":"  Although rapid advancements in Large Language Models (LLMs) are facilitating\nthe integration of artificial intelligence-based applications and services in\nhealthcare, limited research has focused on the systematic evaluation of\nmedical notes for guideline adherence. This paper introduces GuidelineGuard, an\nagentic framework powered by LLMs that autonomously analyzes medical notes,\nsuch as hospital discharge and office visit notes, to ensure compliance with\nestablished healthcare guidelines. By identifying deviations from recommended\npractices and providing evidence-based suggestions, GuidelineGuard helps\nclinicians adhere to the latest standards from organizations like the WHO and\nCDC. This framework offers a novel approach to improving documentation quality\nand reducing clinical errors.\n","authors":["MD Ragib Shahriyear"],"pdf_url":"https://arxiv.org/pdf/2411.06264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06256v1","updated":"2024-11-09T19:07:58Z","published":"2024-11-09T19:07:58Z","title":"Annotative Indexing","summary":"  This paper introduces annotative indexing, a novel framework that unifies and\ngeneralizes traditional inverted indexes, column stores, object stores, and\ngraph databases. As a result, annotative indexing can provide the underlying\nindexing framework for databases that support knowledge graphs, entity\nretrieval, semi-structured data, and ranked retrieval. While we primarily focus\non human language data in the form of text, annotative indexing is sufficiently\ngeneral to support a range of other datatypes, and we provide examples of\nSQL-like queries over a JSON store that includes numbers and dates. Taking\nadvantage of the flexibility of annotative indexing, we also demonstrate a\nfully dynamic annotative index incorporating support for ACID properties of\ntransactions with hundreds of multiple concurrent readers and writers.\n","authors":["Charles L. A. Clarke"],"pdf_url":"https://arxiv.org/pdf/2411.06256v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06254v1","updated":"2024-11-09T19:03:56Z","published":"2024-11-09T19:03:56Z","title":"KeyB2: Selecting Key Blocks is Also Important for Long Document Ranking\n  with Large Language Models","summary":"  The rapid development of large language models (LLMs) like Llama has\nsignificantly advanced information retrieval (IR) systems. However, using LLMs\nfor long documents, as in RankLLaMA, remains challenging due to computational\ncomplexity, especially concerning input token length. Furthermore, the internal\nmechanisms of LLMs during ranking are still not fully understood. In this\npaper, we first explore the internal workings of LLMs during relevance\njudgement and identify that specific attention heads play a crucial role in\naligning relevant tokens. This observation inspires us to revisit the block\npre-ranking strategy used in KeyB, which remains state-of-the-art (SOTA) on the\nTREC 2019 DL document ranking dataset. Building on these insights, we develop\nKeyB2, an advanced long document IR approach that integrates block pre-ranking\nwith the performance of LLMs. KeyB2 efficiently identifies and processes the\nmost relevant blocks, reducing computational costs and improving ranking\neffectiveness. Additionally, we introduce a new bi-encoder block matching\nstrategy for KeyB2. Comprehensive experiments on long-document datasets,\nincluding TREC 2019 DL, Robust04, and MLDR-zh, show that KeyB2 outperforms\nbaselines like RankLLaMA and KeyB by reducing reranking time and GPU memory\nusage while enhancing retrieval performance, achieving new SOTA results on TREC\n2019 DL with higher NDCG@10 and MAP scores.\n","authors":["Minghan Li","Eric Gaussier","Juntao Li","Guodong Zhou"],"pdf_url":"https://arxiv.org/pdf/2411.06254v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.10978v2","updated":"2024-11-09T18:46:07Z","published":"2024-03-16T17:21:58Z","title":"Lambda: Learning Matchable Prior For Entity Alignment with Unlabeled\n  Dangling Cases","summary":"  We investigate the entity alignment (EA) problem with unlabeled dangling\ncases, meaning that partial entities have no counterparts in the other\nknowledge graph (KG), and this type of entity remains unlabeled. To address\nthis challenge, we propose the framework \\textit{Lambda} for dangling detection\nand then entity alignment. Lambda features a GNN-based encoder called KEESA\nwith spectral contrastive learning for EA and a positive-unlabeled learning\nalgorithm for dangling detection called iPULE. iPULE offers theoretical\nguarantees of unbiasedness, uniform deviation bounds, and convergence.\nExperimental results demonstrate that each component contributes to overall\nperformances that are superior to baselines, even when baselines additionally\nexploit 30\\% of dangling entities labeled for training.\n","authors":["Hang Yin","Liyao Xiang","Dong Ding","Yuheng He","Yihan Wu","Xinbing Wang","Chenghu Zhou"],"pdf_url":"https://arxiv.org/pdf/2403.10978v2.pdf","comment":"Accepted in NeurIPS 2024 as a poster"},{"id":"http://arxiv.org/abs/2411.06237v1","updated":"2024-11-09T17:38:01Z","published":"2024-11-09T17:38:01Z","title":"Leveraging Retrieval-Augmented Generation for University Knowledge\n  Retrieval","summary":"  This paper introduces an innovative approach using Retrieval-Augmented\nGeneration (RAG) pipelines with Large Language Models (LLMs) to enhance\ninformation retrieval and query response systems for university-related\nquestion answering. By systematically extracting data from the university\nofficial webpage and employing advanced prompt engineering techniques, we\ngenerate accurate, contextually relevant responses to user queries.\n  We developed a comprehensive university benchmark, UniversityQuestionBench\n(UQB), to rigorously evaluate our system performance, based on common key\nmetrics in the filed of RAG pipelines, assessing accuracy and reliability\nthrough various metrics and real-world scenarios. Our experimental results\ndemonstrate significant improvements in the precision and relevance of\ngenerated responses, enhancing user experience and reducing the time required\nto obtain relevant answers. In summary, this paper presents a novel application\nof RAG pipelines and LLMs, supported by a meticulously prepared university\nbenchmark, offering valuable insights into advanced AI techniques for academic\ndata retrieval and setting the stage for future research in this domain.\n","authors":["Arshia Hemmat","Kianoosh Vadaei","Mohammad Hassan Heydari","Afsaneh Fatemi"],"pdf_url":"https://arxiv.org/pdf/2411.06237v1.pdf","comment":"6 pages, 2 figures, 1 table, Submitted to 15th IKT conference"},{"id":"http://arxiv.org/abs/2411.06112v1","updated":"2024-11-09T08:22:31Z","published":"2024-11-09T08:22:31Z","title":"Interpret the Internal States of Recommendation Model with Sparse\n  Autoencoder","summary":"  Explainable recommendation systems are important to enhance transparency,\naccuracy, and fairness. Beyond result-level explanations, model-level\ninterpretations can provide valuable insights that allow developers to optimize\nsystem designs and implement targeted improvements. However, most current\napproaches depend on specialized model designs, which often lack generalization\ncapabilities. Given the various kinds of recommendation models, existing\nmethods have limited ability to effectively interpret them. To address this\nissue, we propose RecSAE, an automatic, generalizable probing method for\ninterpreting the internal states of Recommendation models with Sparse\nAutoEncoder. RecSAE serves as a plug-in module that does not affect original\nmodels during interpretations, while also enabling predictable modifications to\ntheir behaviors based on interpretation results. Firstly, we train an\nautoencoder with sparsity constraints to reconstruct internal activations of\nrecommendation models, making the RecSAE latents more interpretable and\nmonosemantic than the original neuron activations. Secondly, we automated the\nconstruction of concept dictionaries based on the relationship between latent\nactivations and input item sequences. Thirdly, RecSAE validates these\ninterpretations by predicting latent activations on new item sequences using\nthe concept dictionary and deriving interpretation confidence scores from\nprecision and recall. We demonstrate RecSAE's effectiveness on two datasets,\nidentifying hundreds of highly interpretable concepts from pure ID-based\nmodels. Latent ablation studies further confirm that manipulating latent\nconcepts produces corresponding changes in model output behavior, underscoring\nRecSAE's utility for both understanding and targeted tuning recommendation\nmodels. Code and data are publicly available at\nhttps://github.com/Alice1998/RecSAE.\n","authors":["Jiayin Wang","Xiaoyu Zhang","Weizhi Ma","Min Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.06112v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.06064v1","updated":"2024-11-09T04:23:58Z","published":"2024-11-09T04:23:58Z","title":"Snippet-based Conversational Recommender System","summary":"  Conversational Recommender Systems (CRS) engage users in interactive\ndialogues to gather preferences and provide personalized recommendations.\nTraditionally, CRS rely on pre-defined attributes or expensive, domain-specific\nannotated datasets to guide conversations, which limits flexibility and\nadaptability across domains. In this work, we introduce SnipRec, a novel CRS\nthat enhances dialogues and recommendations by extracting diverse expressions\nand preferences from user-generated content (UGC) like customer reviews. Using\nlarge language models, SnipRec maps user responses and UGC to concise snippets,\nwhich are used to generate clarification questions and retrieve relevant items.\nOur approach eliminates the need for domain-specific training, making it\nadaptable to new domains and effective without prior knowledge of user\npreferences. Extensive experiments on the Yelp dataset demonstrate the\neffectiveness of snippet-based representations against document and\nsentence-based representations. Additionally, SnipRec is able to improve\nHits@10 by 0.25 over the course of five conversational turns, underscoring the\nefficiency of SnipRec in capturing user preferences through multi-turn\nconversations.\n","authors":["Haibo Sun","Naoki Otani","Hannah Kim","Dan Zhang","Nikita Bhutani"],"pdf_url":"https://arxiv.org/pdf/2411.06064v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.05975v5","updated":"2024-11-09T02:41:43Z","published":"2024-01-11T15:22:55Z","title":"End-to-end Learnable Clustering for Intent Learning in Recommendation","summary":"  Intent learning, which aims to learn users' intents for user understanding\nand item recommendation, has become a hot research spot in recent years.\nHowever, existing methods suffer from complex and cumbersome alternating\noptimization, limiting performance and scalability. To this end, we propose a\nnovel intent learning method termed \\underline{ELCRec}, by unifying behavior\nrepresentation learning into an \\underline{E}nd-to-end \\underline{L}earnable\n\\underline{C}lustering framework, for effective and efficient\n\\underline{Rec}ommendation. Concretely, we encode user behavior sequences and\ninitialize the cluster centers (latent intents) as learnable neurons. Then, we\ndesign a novel learnable clustering module to separate different cluster\ncenters, thus decoupling users' complex intents. Meanwhile, it guides the\nnetwork to learn intents from behaviors by forcing behavior embeddings close to\ncluster centers. This allows simultaneous optimization of recommendation and\nclustering via mini-batch data. Moreover, we propose intent-assisted\ncontrastive learning by using cluster centers as self-supervision signals,\nfurther enhancing mutual promotion. Both experimental results and theoretical\nanalyses demonstrate the superiority of ELCRec from six perspectives. Compared\nto the runner-up, ELCRec improves NDCG@5 by 8.9\\% and reduces computational\ncosts by 22.5\\% on the Beauty dataset. Furthermore, due to the scalability and\nuniversal applicability, we deploy this method on the industrial recommendation\nsystem with 130 million page views and achieve promising results. The codes are\navailable on GitHub (https://github.com/yueliu1999/ELCRec). A collection\n(papers, codes, datasets) of deep group recommendation/intent learning methods\nis available on GitHub\n(https://github.com/yueliu1999/Awesome-Deep-Group-Recommendation).\n","authors":["Yue Liu","Shihao Zhu","Jun Xia","Yingwei Ma","Jian Ma","Xinwang Liu","Shengju Yu","Kejun Zhang","Wenliang Zhong"],"pdf_url":"https://arxiv.org/pdf/2401.05975v5.pdf","comment":"37 pages"}]},"2024-11-08T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.07264v1","updated":"2024-11-08T21:03:54Z","published":"2024-11-08T21:03:54Z","title":"Multi-Document Financial Question Answering using LLMs","summary":"  We propose two new methods for multi-document financial question answering.\nFirst, a method that uses semantic tagging, and then, queries the index to get\nthe context (RAG_SEM). And second, a Knowledge Graph (KG_RAG) based method that\nuses semantic tagging, and, retrieves knowledge graph triples from a graph\ndatabase, as context. KG_RAG uses knowledge graphs constructed using a small\nmodel that is fine-tuned using knowledge distillation using a large teacher\nmodel. The data consists of 18 10K reports of Apple, Microsoft, Alphabet,\nNVIDIA, Amazon and Tesla for the years 2021, 2022 and 2023. The list of\nquestions in the data consists of 111 complex questions including many esoteric\nquestions that are difficult to answer and the answers are not completely\nobvious. As evaluation metrics, we use overall scores as well as segmented\nscores for measurement including the faithfulness, relevance, correctness,\nsimilarity, an LLM based overall score and the rouge scores as well as a\nsimilarity of embeddings. We find that both methods outperform plain RAG\nsignificantly. KG_RAG outperforms RAG_SEM in four out of nine metrics.\n","authors":["Shalin Shah","Srikanth Ryali","Ramasubbu Venkatesh"],"pdf_url":"https://arxiv.org/pdf/2411.07264v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05937v1","updated":"2024-11-08T19:52:57Z","published":"2024-11-08T19:52:57Z","title":"The effect of different feature selection methods on models created with\n  XGBoost","summary":"  This study examines the effect that different feature selection methods have\non models created with XGBoost, a popular machine learning algorithm with\nsuperb regularization methods. It shows that three different ways for reducing\nthe dimensionality of features produces no statistically significant change in\nthe prediction accuracy of the model. This suggests that the traditional idea\nof removing the noisy training data to make sure models do not overfit may not\napply to XGBoost. But it may still be viable in order to reduce computational\ncomplexity.\n","authors":["Jorge Neyra","Vishal B. Siramshetty","Huthaifa I. Ashqar"],"pdf_url":"https://arxiv.org/pdf/2411.05937v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05936v1","updated":"2024-11-08T19:47:02Z","published":"2024-11-08T19:47:02Z","title":"Mitigating Hallucination with ZeroG: An Advanced Knowledge Management\n  Engine","summary":"  The growth of digital documents presents significant challenges in efficient\nmanagement and knowledge extraction. Traditional methods often struggle with\ncomplex documents, leading to issues such as hallucinations and high latency in\nresponses from Large Language Models (LLMs). ZeroG, an innovative approach,\nsignificantly mitigates these challenges by leveraging knowledge distillation\nand prompt tuning to enhance model performance.\n  ZeroG utilizes a smaller model that replicates the behavior of a larger\nteacher model, ensuring contextually relevant and grounded responses, by\nemploying a black-box distillation approach, it creates a distilled dataset\nwithout relying on intermediate features, optimizing computational efficiency.\nThis method significantly enhances accuracy and reduces response times,\nproviding a balanced solution for modern document management.\n  Incorporating advanced techniques for document ingestion and metadata\nutilization, ZeroG improves the accuracy of question-and-answer systems. The\nintegration of graph databases and robust metadata management further\nstreamlines information retrieval, allowing for precise and context-aware\nresponses. By transforming how organizations interact with complex data, ZeroG\nenhances productivity and user experience, offering a scalable solution for the\ngrowing demands of digital document management.\n","authors":["Anantha Sharma","Sheeba Elizabeth John","Fatemeh Rezapoor Nikroo","Krupali Bhatt","Mrunal Zambre","Aditi Wikhe"],"pdf_url":"https://arxiv.org/pdf/2411.05936v1.pdf","comment":"10 pages, 4 figures, 1 table"},{"id":"http://arxiv.org/abs/2411.05930v1","updated":"2024-11-08T19:31:19Z","published":"2024-11-08T19:31:19Z","title":"BERTrend: Neural Topic Modeling for Emerging Trends Detection","summary":"  Detecting and tracking emerging trends and weak signals in large, evolving\ntext corpora is vital for applications such as monitoring scientific\nliterature, managing brand reputation, surveilling critical infrastructure and\nmore generally to any kind of text-based event detection. Existing solutions\noften fail to capture the nuanced context or dynamically track evolving\npatterns over time. BERTrend, a novel method, addresses these limitations using\nneural topic modeling in an online setting. It introduces a new metric to\nquantify topic popularity over time by considering both the number of documents\nand update frequency. This metric classifies topics as noise, weak, or strong\nsignals, flagging emerging, rapidly growing topics for further investigation.\nExperimentation on two large real-world datasets demonstrates BERTrend's\nability to accurately detect and track meaningful weak signals while filtering\nout noise, offering a comprehensive solution for monitoring emerging trends in\nlarge-scale, evolving text corpora. The method can also be used for\nretrospective analysis of past events. In addition, the use of Large Language\nModels together with BERTrend offers efficient means for the interpretability\nof trends of events.\n","authors":["Allaa Boutaleb","Jerome Picault","Guillaume Grosjean"],"pdf_url":"https://arxiv.org/pdf/2411.05930v1.pdf","comment":"17 pages, 12 figures, FuturED 2024: Workshop on Future of Event\n  Detection (CoLocated with EMNLP 2024)"},{"id":"http://arxiv.org/abs/2404.04264v4","updated":"2024-11-08T18:35:49Z","published":"2024-03-17T17:01:45Z","title":"Logic Query of Thoughts: Guiding Large Language Models to Answer Complex\n  Logic Queries with Knowledge Graphs","summary":"  Despite the superb performance in many tasks, large language models (LLMs)\nbear the risk of generating hallucination or even wrong answers when confronted\nwith tasks that demand the accuracy of knowledge. The issue becomes even more\nnoticeable when addressing logic queries that require multiple logic reasoning\nsteps. On the other hand, knowledge graph (KG) based question answering methods\nare capable of accurately identifying the correct answers with the help of\nknowledge graph, yet its accuracy could quickly deteriorate when the knowledge\ngraph itself is sparse and incomplete. It remains a critical challenge on how\nto integrate knowledge graph reasoning with LLMs in a mutually beneficial way\nso as to mitigate both the hallucination problem of LLMs as well as the\nincompleteness issue of knowledge graphs. In this paper, we propose\n'Logic-Query-of-Thoughts' (LGOT) which is the first of its kind to combine LLMs\nwith knowledge graph based logic query reasoning. LGOT seamlessly combines\nknowledge graph reasoning and LLMs, effectively breaking down complex logic\nqueries into easy to answer subquestions. Through the utilization of both\nknowledge graph reasoning and LLMs, it successfully derives answers for each\nsubquestion. By aggregating these results and selecting the highest quality\ncandidate answers for each step, LGOT achieves accurate results to complex\nquestions. Our experimental findings demonstrate substantial performance\nenhancements, with up to 20% improvement over ChatGPT.\n","authors":["Lihui Liu","Zihao Wang","Ruizhong Qiu","Yikun Ban","Eunice Chan","Yangqiu Song","Jingrui He","Hanghang Tong"],"pdf_url":"https://arxiv.org/pdf/2404.04264v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05649v1","updated":"2024-11-08T15:45:33Z","published":"2024-11-08T15:45:33Z","title":"Harnessing High-Level Song Descriptors towards Natural Language-Based\n  Music Recommendation","summary":"  Recommender systems relying on Language Models (LMs) have gained popularity\nin assisting users to navigate large catalogs. LMs often exploit item\nhigh-level descriptors, i.e. categories or consumption contexts, from training\ndata or user preferences. This has been proven effective in domains like movies\nor products. However, in the music domain, understanding how effectively LMs\nutilize song descriptors for natural language-based music recommendation is\nrelatively limited. In this paper, we assess LMs effectiveness in recommending\nsongs based on user natural language descriptions and items with descriptors\nlike genres, moods, and listening contexts. We formulate the recommendation\ntask as a dense retrieval problem and assess LMs as they become increasingly\nfamiliar with data pertinent to the task and domain. Our findings reveal\nimproved performance as LMs are fine-tuned for general language similarity,\ninformation retrieval, and mapping longer descriptions to shorter, high-level\ndescriptors in music.\n","authors":["Elena V. Epure","Gabriel Meseguer Brocal","Darius Afchar","Romain Hennequin"],"pdf_url":"https://arxiv.org/pdf/2411.05649v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05572v1","updated":"2024-11-08T13:51:37Z","published":"2024-11-08T13:51:37Z","title":"Why These Documents? Explainable Generative Retrieval with Hierarchical\n  Category Paths","summary":"  Generative retrieval has recently emerged as a new alternative of traditional\ninformation retrieval approaches. However, existing generative retrieval\nmethods directly decode docid when a query is given, making it impossible to\nprovide users with explanations as an answer for \"Why this document is\nretrieved?\". To address this limitation, we propose Hierarchical Category\nPath-Enhanced Generative Retrieval(HyPE), which enhances explainability by\ngenerating hierarchical category paths step-by-step before decoding docid. HyPE\nleverages hierarchical category paths as explanation, progressing from broad to\nspecific semantic categories. This approach enables diverse explanations for\nthe same document depending on the query by using shared category paths between\nthe query and the document, and provides reasonable explanation by reflecting\nthe document's semantic structure through a coarse-to-fine manner. HyPE\nconstructs category paths with external high-quality semantic hierarchy,\nleverages LLM to select appropriate candidate paths for each document, and\noptimizes the generative retrieval model with path-augmented dataset. During\ninference, HyPE utilizes path-aware reranking strategy to aggregate diverse\ntopic information, allowing the most relevant documents to be prioritized in\nthe final ranked list of docids. Our extensive experiments demonstrate that\nHyPE not only offers a high level of explainability but also improves the\nretrieval performance in the document retrieval task.\n","authors":["Sangam Lee","Ryang Heo","SeongKu Kang","Susik Yoon","Jinyoung Yeo","Dongha Lee"],"pdf_url":"https://arxiv.org/pdf/2411.05572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10321v2","updated":"2024-11-08T13:29:47Z","published":"2024-04-16T07:05:16Z","title":"Cluster-based Graph Collaborative Filtering","summary":"  Graph Convolution Networks (GCNs) have significantly succeeded in learning\nuser and item representations for recommendation systems. The core of their\nefficacy is the ability to explicitly exploit the collaborative signals from\nboth the first- and high-order neighboring nodes. However, most existing\nGCN-based methods overlook the multiple interests of users while performing\nhigh-order graph convolution. Thus, the noisy information from unreliable\nneighbor nodes (e.g., users with dissimilar interests) negatively impacts the\nrepresentation learning of the target node. Additionally, conducting graph\nconvolution operations without differentiating high-order neighbors suffers the\nover-smoothing issue when stacking more layers, resulting in performance\ndegradation. In this paper, we aim to capture more valuable information from\nhigh-order neighboring nodes while avoiding noise for better representation\nlearning of the target node. To achieve this goal, we propose a novel GCN-based\nrecommendation model, termed Cluster-based Graph Collaborative Filtering\n(ClusterGCF). This model performs high-order graph convolution on\ncluster-specific graphs, which are constructed by capturing the multiple\ninterests of users and identifying the common interests among them.\nSpecifically, we design an unsupervised and optimizable soft node clustering\napproach to classify user and item nodes into multiple clusters. Based on the\nsoft node clustering results and the topology of the user-item interaction\ngraph, we assign the nodes with probabilities for different clusters to\nconstruct the cluster-specific graphs. To evaluate the effectiveness of\nClusterGCF, we conducted extensive experiments on four publicly available\ndatasets. Experimental results demonstrate that our model can significantly\nimprove recommendation performance.\n","authors":["Fan Liu","Shuai Zhao","Zhiyong Cheng","Liqiang Nie","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2404.10321v2.pdf","comment":"Accepted by ACM TOIS"},{"id":"http://arxiv.org/abs/2411.05892v1","updated":"2024-11-08T12:38:10Z","published":"2024-11-08T12:38:10Z","title":"Identifying and Decomposing Compound Ingredients in Meal Plans Using\n  Large Language Models","summary":"  This study explores the effectiveness of Large Language Models in meal\nplanning, focusing on their ability to identify and decompose compound\ningredients. We evaluated three models-GPT-4o, Llama-3 (70b), and Mixtral\n(8x7b)-to assess their proficiency in recognizing and breaking down complex\ningredient combinations. Preliminary results indicate that while Llama-3 (70b)\nand GPT-4o excels in accurate decomposition, all models encounter difficulties\nwith identifying essential elements like seasonings and oils. Despite strong\noverall performance, variations in accuracy and completeness were observed\nacross models. These findings underscore LLMs' potential to enhance\npersonalized nutrition but highlight the need for further refinement in\ningredient decomposition. Future research should address these limitations to\nimprove nutritional recommendations and health outcomes.\n","authors":["Leon Kopitar","Leon Bedrac","Larissa J Strath","Jiang Bian","Gregor Stiglic"],"pdf_url":"https://arxiv.org/pdf/2411.05892v1.pdf","comment":"Comments: Presented at NeLaMKRR@KR, 2024 (arXiv:2410.05339)"},{"id":"http://arxiv.org/abs/2411.05442v1","updated":"2024-11-08T09:40:53Z","published":"2024-11-08T09:40:53Z","title":"IntellBot: Retrieval Augmented LLM Chatbot for Cyber Threat Knowledge\n  Delivery","summary":"  In the rapidly evolving landscape of cyber security, intelligent chatbots are\ngaining prominence. Artificial Intelligence, Machine Learning, and Natural\nLanguage Processing empower these chatbots to handle user inquiries and deliver\nthreat intelligence. This helps cyber security knowledge readily available to\nboth professionals and the public. Traditional rule-based chatbots often lack\nflexibility and struggle to adapt to user interactions. In contrast, Large\nLanguage Model-based chatbots offer contextually relevant information across\nmultiple domains and adapt to evolving conversational contexts. In this work,\nwe develop IntellBot, an advanced cyber security Chatbot built on top of\ncutting-edge technologies like Large Language Models and Langchain alongside a\nRetrieval-Augmented Generation model to deliver superior capabilities. This\nchatbot gathers information from diverse data sources to create a comprehensive\nknowledge base covering known vulnerabilities, recent cyber attacks, and\nemerging threats. It delivers tailored responses, serving as a primary hub for\ncyber security insights. By providing instant access to relevant information\nand resources, this IntellBot enhances threat intelligence, incident response,\nand overall security posture, saving time and empowering users with knowledge\nof cyber security best practices. Moreover, we analyzed the performance of our\ncopilot using a two-stage evaluation strategy. We achieved BERT score above 0.8\nby indirect approach and a cosine similarity score ranging from 0.8 to 1, which\naffirms the accuracy of our copilot. Additionally, we utilized RAGAS to\nevaluate the RAG model, and all evaluation metrics consistently produced scores\nabove 0.77, highlighting the efficacy of our system.\n","authors":["Dincy R. Arikkat","Abhinav M.","Navya Binu","Parvathi M.","Navya Biju","K. S. Arunima","Vinod P.","Rafidha Rehiman K. A.","Mauro Conti"],"pdf_url":"https://arxiv.org/pdf/2411.05442v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05375v1","updated":"2024-11-08T07:05:06Z","published":"2024-11-08T07:05:06Z","title":"Ev2R: Evaluating Evidence Retrieval in Automated Fact-Checking","summary":"  Current automated fact-checking (AFC) approaches commonly evaluate evidence\neither implicitly via the predicted verdicts or by comparing retrieved evidence\nwith a predefined closed knowledge source, such as Wikipedia. However, these\nmethods suffer from limitations, resulting from their reliance on evaluation\nmetrics developed for different purposes and constraints imposed by closed\nknowledge sources. Recent advances in natural language generation (NLG)\nevaluation offer new possibilities for evidence assessment. In this work, we\nintroduce Ev2R, an evaluation framework for AFC that comprises three types of\napproaches for evidence evaluation: reference-based, proxy-reference, and\nreference-less. We evaluate their effectiveness through agreement with human\nratings and adversarial tests, and demonstrate that prompt-based scorers,\nparticularly those leveraging LLMs and reference evidence, outperform\ntraditional evaluation approaches.\n","authors":["Mubashara Akhtar","Michael Schlichtkrull","Andreas Vlachos"],"pdf_url":"https://arxiv.org/pdf/2411.05375v1.pdf","comment":"10 pages"},{"id":"http://arxiv.org/abs/2411.05340v1","updated":"2024-11-08T05:43:40Z","published":"2024-11-08T05:43:40Z","title":"Improving Multi-Domain Task-Oriented Dialogue System with Offline\n  Reinforcement Learning","summary":"  Task-oriented dialogue (TOD) system is designed to accomplish user-defined\ntasks through dialogues. The TOD system has progressed towards end-to-end\nmodeling by leveraging pre-trained large language models. Fine-tuning the\npre-trained language models using only supervised learning leads to the\nexposure bias and token loss problem and it deviates the models from completing\nthe user's task. To address these issues, we propose a TOD system that\nleverages a unified pre-trained language model, GPT2, as a base model. It is\noptimized using supervised learning and reinforcement learning (RL). The issues\nin the TOD system are mitigated using a non-differentiable reward function. The\nreward is calculated using the weighted sum of the success rate and BLEU\nevaluation metrics. The success rate and BLEU metrics in reward calculation\nguide the language model for user task completion while ensuring a coherent and\nfluent response. Our model is acquired by fine-tuning a pre-trained model on\nthe dialogue-session level which comprises user utterance, belief state, system\nact, and system response. Experimental results on MultiWOZ2.1 demonstrate that\nour model increases the inform rate by 1.60% and the success rate by 3.17%\ncompared to the baseline.\n","authors":["Dharmendra Prajapat","Durga Toshniwal"],"pdf_url":"https://arxiv.org/pdf/2411.05340v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2310.10108v3","updated":"2024-11-08T03:58:00Z","published":"2023-10-16T06:41:16Z","title":"On Generative Agents in Recommendation","summary":"  Recommender systems are the cornerstone of today's information dissemination,\nyet a disconnect between offline metrics and online performance greatly hinders\ntheir development. Addressing this challenge, we envision a recommendation\nsimulator, capitalizing on recent breakthroughs in human-level intelligence\nexhibited by Large Language Models (LLMs). We propose Agent4Rec, a user\nsimulator in recommendation, leveraging LLM-empowered generative agents\nequipped with user profile, memory, and actions modules specifically tailored\nfor the recommender system. In particular, these agents' profile modules are\ninitialized using real-world datasets (e.g. MovieLens, Steam, Amazon-Book),\ncapturing users' unique tastes and social traits; memory modules log both\nfactual and emotional memories and are integrated with an emotion-driven\nreflection mechanism; action modules support a wide variety of behaviors,\nspanning both taste-driven and emotion-driven actions. Each agent interacts\nwith personalized recommender models in a page-by-page manner, relying on a\npre-implemented collaborative filtering-based recommendation algorithm. We\ndelve into both the capabilities and limitations of Agent4Rec, aiming to\nexplore an essential research question: ``To what extent can LLM-empowered\ngenerative agents faithfully simulate the behavior of real, autonomous humans\nin recommender systems?'' Extensive and multi-faceted evaluations of Agent4Rec\nhighlight both the alignment and deviation between agents and user-personalized\npreferences. Beyond mere performance comparison, we explore insightful\nexperiments, such as emulating the filter bubble effect and discovering the\nunderlying causal relationships in recommendation tasks. Our codes are\navailable at https://github.com/LehengTHU/Agent4Rec.\n","authors":["An Zhang","Yuxin Chen","Leheng Sheng","Xiang Wang","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2310.10108v3.pdf","comment":"SIGIR 2024 perspective paper"},{"id":"http://arxiv.org/abs/2308.02580v3","updated":"2024-11-08T02:21:38Z","published":"2023-08-03T16:13:46Z","title":"Feature Noise Resilient for QoS Prediction with Probabilistic Deep\n  Supervision","summary":"  Accurate Quality of Service (QoS) prediction is essential for enhancing user\nsatisfaction in web recommendation systems, yet existing prediction models\noften overlook feature noise, focusing predominantly on label noise. In this\npaper, we present the Probabilistic Deep Supervision Network (PDS-Net), a\nrobust framework designed to effectively identify and mitigate feature noise,\nthereby improving QoS prediction accuracy. PDS-Net operates with a dual-branch\narchitecture: the main branch utilizes a decoder network to learn a\nGaussian-based prior distribution from known features, while the second branch\nderives a posterior distribution based on true labels. A key innovation of\nPDS-Net is its condition-based noise recognition loss function, which enables\nprecise identification of noisy features in objects (users or services). Once\nnoisy features are identified, PDS-Net refines the feature's prior\ndistribution, aligning it with the posterior distribution, and propagates this\nadjusted distribution to intermediate layers, effectively reducing noise\ninterference. Extensive experiments conducted on two real-world QoS datasets\ndemonstrate that PDS-Net consistently outperforms existing models, achieving an\naverage improvement of 8.91% in MAE on Dataset D1 and 8.32% on Dataset D2\ncompared to the ate-of-the-art. These results highlight PDS-Net's ability to\naccurately capture complex user-service relationships and handle feature noise,\nunderscoring its robustness and versatility across diverse QoS prediction\nenvironments.\n","authors":["Ziliang Wang","Xiaohong Zhang","Ze Shi Li","Sheng Huang","Meng Yan"],"pdf_url":"https://arxiv.org/pdf/2308.02580v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16156v2","updated":"2024-11-08T00:40:05Z","published":"2024-10-21T16:21:45Z","title":"Limpeh ga li gong: Challenges in Singlish Annotations","summary":"  Singlish, or Colloquial Singapore English, is a language formed from oral and\nsocial communication within multicultural Singapore. In this work, we work on a\nfundamental Natural Language Processing (NLP) task: Parts-Of-Speech (POS)\ntagging of Singlish sentences. For our analysis, we build a parallel Singlish\ndataset containing direct English translations and POS tags, with translation\nand POS annotation done by native Singlish speakers. Our experiments show that\nautomatic transition- and transformer- based taggers perform with only $\\sim\n80\\%$ accuracy when evaluated against human-annotated POS labels, suggesting\nthat there is indeed room for improvement on computation analysis of the\nlanguage. We provide an exposition of challenges in Singlish annotation: its\ninconsistencies in form and semantics, the highly context-dependent particles\nof the language, its structural unique expressions, and the variation of the\nlanguage on different mediums. Our task definition, resultant labels and\nresults reflects the challenges in analysing colloquial languages formulated\nfrom a variety of dialects, and paves the way for future studies beyond POS\ntagging.\n","authors":["Luo Qi Chan","Lynnette Hui Xian Ng"],"pdf_url":"https://arxiv.org/pdf/2410.16156v2.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.05715v1","updated":"2024-11-08T17:16:27Z","published":"2024-11-08T17:16:27Z","title":"On the Role of Noise in AudioVisual Integration: Evidence from\n  Artificial Neural Networks that Exhibit the McGurk Effect","summary":"  Humans are able to fuse information from both auditory and visual modalities\nto help with understanding speech. This is frequently demonstrated through an\nphenomenon known as the McGurk Effect, during which a listener is presented\nwith incongruent auditory and visual speech that fuse together into the percept\nof an illusory intermediate phoneme. Building on a recent framework that\nproposes how to address developmental 'why' questions using artificial neural\nnetworks, we evaluated a set of recent artificial neural networks trained on\naudiovisual speech by testing them with audiovisually incongruent words\ndesigned to elicit the McGurk effect. We compared networks trained on clean\nspeech to those trained on noisy speech, and discovered that training with\nnoisy speech led to an increase in both visual responses and McGurk responses\nacross all models. Furthermore, we observed that systematically increasing the\nlevel of auditory noise during ANN training also increased the amount of\naudiovisual integration up to a point, but at extreme noise levels, this\nintegration failed to develop. These results suggest that excessive noise\nexposure during critical periods of audiovisual learning may negatively\ninfluence the development of audiovisual speech integration. This work also\ndemonstrates that the McGurk effect reliably emerges untrained from the\nbehaviour of both supervised and unsupervised networks. This supports the\nnotion that artificial neural networks might be useful models for certain\naspects of perception and cognition.\n","authors":["Lukas Grasse","Matthew S. Tata"],"pdf_url":"https://arxiv.org/pdf/2411.05715v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05374v1","updated":"2024-11-08T07:04:00Z","published":"2024-11-08T07:04:00Z","title":"Interdisciplinary Translations: Sensory Perception as a Universal\n  Language","summary":"  This paper investigates sensory perception's pivotal role as a universal\ncommunicative bridge across varied cultures and disciplines, and how it\nmanifests its value in the study of media art, human computer interaction and\nartificial intelligence. By analyzing its function in non-verbal communication\nthrough interactive systems, and drawing on the interpretive model in\ntranslation studies where \"sense\" acts as a mediation between two languages,\nthis paper illustrates how interdisciplinary communication in media art and\nhuman-computer interaction is afforded by the abstract language of human\nsensory perception. Specific examples from traditional art, interactive media\nart, HCI, communication, and translation studies demonstrate how sensory\nfeedback translates and conveys meaning across diverse modalities of expression\nand how it fosters connections between humans, art, and technology. Pertaining\nto this topic, this paper analyzes the impact of sensory feedback systems in\ndesigning interactive experiences, and reveals the guiding role of sensory\nperception in the design philosophy of AI systems. Overall, the study aims to\nbroaden the understanding of sensory perception's role in communication,\nhighlighting its significance in the evolution of interactive experiences and\nits capacity to unify art, science, and the human experience.\n","authors":["Xindi Kang","Xuanyang Huang","Mingdong Song","Varvara Guljajeva","JoAnn Kuchera-Morin"],"pdf_url":"https://arxiv.org/pdf/2411.05374v1.pdf","comment":"This paper has been accepted to the International Symposium of\n  Electronic Arts 2024, and the proceedings version will be available at\n  https://isea-archives.siggraph.org/publications/ with DOI to be added once\n  published"},{"id":"http://arxiv.org/abs/2411.05322v1","updated":"2024-11-08T04:29:14Z","published":"2024-11-08T04:29:14Z","title":"Rate-aware Compression for NeRF-based Volumetric Video","summary":"  The neural radiance fields (NeRF) have advanced the development of 3D\nvolumetric video technology, but the large data volumes they involve pose\nsignificant challenges for storage and transmission. To address these problems,\nthe existing solutions typically compress these NeRF representations after the\ntraining stage, leading to a separation between representation training and\ncompression. In this paper, we try to directly learn a compact NeRF\nrepresentation for volumetric video in the training stage based on the proposed\nrate-aware compression framework. Specifically, for volumetric video, we use a\nsimple yet effective modeling strategy to reduce temporal redundancy for the\nNeRF representation. Then, during the training phase, an implicit entropy model\nis utilized to estimate the bitrate of the NeRF representation. This entropy\nmodel is then encoded into the bitstream to assist in the decoding of the NeRF\nrepresentation. This approach enables precise bitrate estimation, thereby\nleading to a compact NeRF representation. Furthermore, we propose an adaptive\nquantization strategy and learn the optimal quantization step for the NeRF\nrepresentations. Finally, the NeRF representation can be optimized by using the\nrate-distortion trade-off. Our proposed compression framework can be used for\ndifferent representations and experimental results demonstrate that our\napproach significantly reduces the storage size with marginal distortion and\nachieves state-of-the-art rate-distortion performance for volumetric video on\nthe HumanRF and ReRF datasets. Compared to the previous state-of-the-art method\nTeTriRF, we achieved an approximately -80% BD-rate on the HumanRF dataset and\n-60% BD-rate on the ReRF dataset.\n","authors":["Zhiyu Zhang","Guo Lu","Huanxiong Liang","Zhengxue Cheng","Anni Tang","Li Song"],"pdf_url":"https://arxiv.org/pdf/2411.05322v1.pdf","comment":"Accepted by ACM MM 2024 (Oral)"},{"id":"http://arxiv.org/abs/2411.05295v1","updated":"2024-11-08T02:57:23Z","published":"2024-11-08T02:57:23Z","title":"Content-Adaptive Rate-Quality Curve Prediction Model in Media Processing\n  System","summary":"  In streaming media services, video transcoding is a common practice to\nalleviate bandwidth demands. Unfortunately, traditional methods employing a\nuniform rate factor (RF) across all videos often result in significant\ninefficiencies. Content-adaptive encoding (CAE) techniques address this by\ndynamically adjusting encoding parameters based on video content\ncharacteristics. However, existing CAE methods are often tightly coupled with\nspecific encoding strategies, leading to inflexibility. In this paper, we\npropose a model that predicts both RF-quality and RF-bitrate curves, which can\nbe utilized to derive a comprehensive bitrate-quality curve. This approach\nfacilitates flexible adjustments to the encoding strategy without necessitating\nmodel retraining. The model leverages codec features, content features, and\nanchor features to predict the bitrate-quality curve accurately. Additionally,\nwe introduce an anchor suspension method to enhance prediction accuracy.\nExperiments confirm that the actual quality metric (VMAF) of the compressed\nvideo stays within 1 of the target, achieving an accuracy of 99.14%. By\nincorporating our quality improvement strategy with the rate-quality curve\nprediction model, we conducted online A/B tests, obtaining both +0.107%\nimprovements in video views and video completions and +0.064% app duration\ntime. Our model has been deployed on the Xiaohongshu App.\n","authors":["Shibo Yin","Zhiyu Zhang","Peirong Ning","Qiubo Chen","Jing Chen","Quan Zhou","Li Song"],"pdf_url":"https://arxiv.org/pdf/2411.05295v1.pdf","comment":"Accepted by IEEE VCIP 2024 (Oral)"},{"id":"http://arxiv.org/abs/2411.03109v2","updated":"2024-11-08T02:51:57Z","published":"2024-11-05T13:56:44Z","title":"pTSE-T: Presentation Target Speaker Extraction using Unaligned Text Cues","summary":"  TSE(Target Speaker Extraction) aims to extract the clean speech of the target\nspeaker in an audio mixture, thus eliminating irrelevant background noise and\nspeech. While prior work has explored various auxiliary cues including\npre-recorded speech, visual information (e.g., lip motions and gestures), and\nspatial information, the acquisition and selection of such strong cues are\ninfeasible in many practical scenarios. Unlike all existing work, in this\npaper, we condition the TSE algorithm on semantic cues extracted from limited\nand unaligned text content, such as condensed points from a presentation slide.\nThis method is particularly useful in scenarios like meetings, poster sessions,\nor lecture presentations, where acquiring other cues in real-time is\nchallenging. To this end, we design two different networks. Specifically, our\nproposed TPE fuses audio features with content-based semantic cues to\nfacilitate time-frequency mask generation to filter out extraneous noise, while\nanother proposal, namely TSR, employs the contrastive learning technique to\nassociate blindly separated speech signals with semantic cues. The experimental\nresults show the efficacy in accurately identifying the target speaker by\nutilizing semantic cues derived from limited and unaligned text, resulting in\nSI-SDRi of 12.16 dB, SDRi of 12.66 dB, PESQi of 0.830 and STOIi of 0.150,\nrespectively. Dataset and source code will be publicly available. Project demo\npage: https://slideTSE.github.io/.\n","authors":["Ziyang Jiang","Xinyuan Qian","Jiahe Lei","Zexu Pan","Wei Xue","Xu-cheng Yin"],"pdf_url":"https://arxiv.org/pdf/2411.03109v2.pdf","comment":null}]},"2024-11-07T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.18097v2","updated":"2024-11-07T21:23:15Z","published":"2024-10-08T11:28:06Z","title":"RRADistill: Distilling LLMs' Passage Ranking Ability for Document\n  Re-Ranking of Long-Tail Queries in a Search Engine","summary":"  Large Language Models (LLMs) excel at understanding the semantic\nrelationships between queries and documents, even with lengthy and complex\nlong-tail queries. These queries are challenging for feedback-based rankings\ndue to sparse user engagement and limited feedback, making LLMs' ranking\nability highly valuable. However, the large size and slow inference of LLMs\nnecessitate the development of smaller, more efficient models (sLLMs).\nRecently, integrating ranking label generation into distillation techniques has\nbecome crucial, but existing methods underutilize LLMs' capabilities and are\ncumbersome. Our research, RRADistill: Re-Ranking Ability Distillation, propose\nan efficient label generation pipeline and novel sLLM training methods for both\nencoder and decoder models. We introduce an encoder-based method using a Term\nControl Layer to capture term matching signals and a decoder-based model with a\nranking layer for enhanced understanding. A/B testing on a Korean-based search\nplatform, validates the effectiveness of our approach in improving re-ranking\nfor long-tail queries.\n","authors":["Nayoung Choi","Youngjune Lee","Gyu-Hwung Cho","Haeyu Jeong","Jungmin Kong","Saehun Kim","Keunchan Park","Jaeho Choi","Sarah Cho","Inchang Jeong","Gyohee Nam","Sunghoon Han","Wonil Yang"],"pdf_url":"https://arxiv.org/pdf/2410.18097v2.pdf","comment":"Accepted to EMNLP 2024 Industry Track. First two authors contributed\n  equally"},{"id":"http://arxiv.org/abs/2406.09215v3","updated":"2024-11-07T18:30:53Z","published":"2024-06-13T15:16:11Z","title":"On Softmax Direct Preference Optimization for Recommendation","summary":"  Recommender systems aim to predict personalized rankings based on user\npreference data. With the rise of Language Models (LMs), LM-based recommenders\nhave been widely explored due to their extensive world knowledge and powerful\nreasoning abilities. Most of the LM-based recommenders convert historical\ninteractions into language prompts, pairing with a positive item as the target\nresponse and fine-tuning LM with a language modeling loss. However, the current\nobjective fails to fully leverage preference data and is not optimized for\npersonalized ranking tasks, which hinders the performance of LM-based\nrecommenders. Inspired by the current advancement of Direct Preference\nOptimization (DPO) in human preference alignment and the success of softmax\nloss in recommendations, we propose Softmax-DPO (S-DPO) to instill ranking\ninformation into the LM to help LM-based recommenders distinguish preferred\nitems from negatives, rather than solely focusing on positives. Specifically,\nwe incorporate multiple negatives in user preference data and devise an\nalternative version of DPO loss tailored for LM-based recommenders, which is\nextended from the traditional full-ranking Plackett-Luce (PL) model to partial\nrankings and connected to softmax sampling strategies. Theoretically, we bridge\nS-DPO with the softmax loss over negative sampling and find that it has an\ninherent benefit of mining hard negatives, which assures its exceptional\ncapabilities in recommendation tasks. Empirically, extensive experiments\nconducted on three real-world datasets demonstrate the superiority of S-DPO to\neffectively model user preference and further boost recommendation performance\nwhile providing better rewards for preferred items. Our codes are available at\nhttps://github.com/chenyuxin1999/S-DPO.\n","authors":["Yuxin Chen","Junfei Tan","An Zhang","Zhengyi Yang","Leheng Sheng","Enzhi Zhang","Xiang Wang","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2406.09215v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.14894v2","updated":"2024-11-07T18:15:23Z","published":"2024-06-21T06:30:16Z","title":"Talking the Talk Does Not Entail Walking the Walk: On the Limits of\n  Large Language Models in Lexical Entailment Recognition","summary":"  Verbs form the backbone of language, providing the structure and meaning to\nsentences. Yet, their intricate semantic nuances pose a longstanding challenge.\nUnderstanding verb relations through the concept of lexical entailment is\ncrucial for comprehending sentence meanings and grasping verb dynamics. This\nwork investigates the capabilities of eight Large Language Models in\nrecognizing lexical entailment relations among verbs through differently\ndevised prompting strategies and zero-/few-shot settings over verb pairs from\ntwo lexical databases, namely WordNet and HyperLex. Our findings unveil that\nthe models can tackle the lexical entailment recognition task with moderately\ngood performance, although at varying degree of effectiveness and under\ndifferent conditions. Also, utilizing few-shot prompting can enhance the\nmodels' performance. However, perfectly solving the task arises as an unmet\nchallenge for all examined LLMs, which raises an emergence for further research\ndevelopments on this topic.\n","authors":["Candida M. Greco","Lucio La Cava","Andrea Tagarelli"],"pdf_url":"https://arxiv.org/pdf/2406.14894v2.pdf","comment":"Accepted for publication at The 2024 Conference on Empirical Methods\n  in Natural Language Processing (EMNLP-2024) - Findings"},{"id":"http://arxiv.org/abs/2411.04798v1","updated":"2024-11-07T15:38:14Z","published":"2024-11-07T15:38:14Z","title":"Orbit: A Framework for Designing and Evaluating Multi-objective Rankers","summary":"  Machine learning in production needs to balance multiple objectives: This is\nparticularly evident in ranking or recommendation models, where conflicting\nobjectives such as user engagement, satisfaction, diversity, and novelty must\nbe considered at the same time. However, designing multi-objective rankers is\ninherently a dynamic wicked problem -- there is no single optimal solution, and\nthe needs evolve over time. Effective design requires collaboration between\ncross-functional teams and careful analysis of a wide range of information. In\nthis work, we introduce Orbit, a conceptual framework for Objective-centric\nRanker Building and Iteration. The framework places objectives at the center of\nthe design process, to serve as boundary objects for communication and guide\npractitioners for design and evaluation. We implement Orbit as an interactive\nsystem, which enables stakeholders to interact with objective spaces directly\nand supports real-time exploration and evaluation of design trade-offs. We\nevaluate Orbit through a user study involving twelve industry practitioners,\nshowing that it supports efficient design space exploration, leads to more\ninformed decision-making, and enhances awareness of the inherent trade-offs of\nmultiple objectives. Orbit (1) opens up new opportunities of an\nobjective-centric design process for any multi-objective ML models, as well as\n(2) sheds light on future designs that push practitioners to go beyond a narrow\nmetric-centric or example-centric mindset.\n","authors":["Chenyang Yang","Tesi Xiao","Michael Shavlovsky","Christian K√§stner","Tongshuang Wu"],"pdf_url":"https://arxiv.org/pdf/2411.04798v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14331v2","updated":"2024-11-07T14:48:18Z","published":"2024-10-18T09:43:30Z","title":"ChartifyText: Automated Chart Generation from Data-Involved Texts via\n  LLM","summary":"  Text documents with numerical values involved are widely used in various\napplications such as scientific research, economy, public health and\njournalism. However, it is difficult for readers to quickly interpret such\ndata-involved texts and gain deep insights. To fill this research gap, this\nwork aims to automatically generate charts to accurately convey the underlying\ndata and ideas to readers, which is essentially a challenging task. The\nchallenges originate from text ambiguities, intrinsic sparsity and uncertainty\nof data in text documents, and subjective sentiment differences. Specifically,\nwe propose ChartifyText, a novel fully-automated approach that leverages Large\nLanguage Models (LLMs) to convert complex data-involved texts to expressive\ncharts. It consists of two major modules: tabular data inference and expressive\nchart generation. The tabular data inference module employs systematic prompt\nengineering to guide the LLM (e.g., GPT-4) to infer table data, where data\nranges, uncertainties, missing data values and corresponding subjective\nsentiments are explicitly considered. The expressive chart generation module\naugments standard charts with intuitive visual encodings and concise texts to\naccurately convey the underlying data and insights. We extensively evaluate the\neffectiveness of ChartifyText on real-world data-involved text documents\nthrough case studies, in-depth interviews with three visualization experts, and\na carefully-designed user study with 15 participants. The results demonstrate\nthe usefulness and effectiveness of ChartifyText in helping readers efficiently\nand effectively make sense of data-involved texts.\n","authors":["Songheng Zhang","Lei Wang","Toby Jia-Jun Li","Qiaomu Shen","Yixin Cao","Yong Wang"],"pdf_url":"https://arxiv.org/pdf/2410.14331v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04677v1","updated":"2024-11-07T13:03:21Z","published":"2024-11-07T13:03:21Z","title":"Lightning IR: Straightforward Fine-tuning and Inference of\n  Transformer-based Language Models for Information Retrieval","summary":"  A wide range of transformer-based language models have been proposed for\ninformation retrieval tasks. However, fine-tuning and inference of these models\nis often complex and requires substantial engineering effort. This paper\nintroduces Lightning IR, a PyTorch Lightning-based framework for fine-tuning\nand inference of transformer-based language models for information retrieval.\nLightning IR provides a modular and extensible architecture that supports all\nstages of an information retrieval pipeline: from fine-tuning and indexing to\nsearching and re-ranking. It is designed to be straightforward to use,\nscalable, and reproducible. Lightning IR is available as open-source:\nhttps://github.com/webis-de/lightning-ir.\n","authors":["Ferdinand Schlatt","Maik Fr√∂be","Matthias Hagen"],"pdf_url":"https://arxiv.org/pdf/2411.04677v1.pdf","comment":"Accepted as a demo at WSDM'25"},{"id":"http://arxiv.org/abs/2410.05779v2","updated":"2024-11-07T10:44:59Z","published":"2024-10-08T08:00:12Z","title":"LightRAG: Simple and Fast Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) systems enhance large language models\n(LLMs) by integrating external knowledge sources, enabling more accurate and\ncontextually relevant responses tailored to user needs. However, existing RAG\nsystems have significant limitations, including reliance on flat data\nrepresentations and inadequate contextual awareness, which can lead to\nfragmented answers that fail to capture complex inter-dependencies. To address\nthese challenges, we propose LightRAG, which incorporates graph structures into\ntext indexing and retrieval processes. This innovative framework employs a\ndual-level retrieval system that enhances comprehensive information retrieval\nfrom both low-level and high-level knowledge discovery. Additionally, the\nintegration of graph structures with vector representations facilitates\nefficient retrieval of related entities and their relationships, significantly\nimproving response times while maintaining contextual relevance. This\ncapability is further enhanced by an incremental update algorithm that ensures\nthe timely integration of new data, allowing the system to remain effective and\nresponsive in rapidly changing data environments. Extensive experimental\nvalidation demonstrates considerable improvements in retrieval accuracy and\nefficiency compared to existing approaches. We have made our LightRAG\nopen-source and available at the link: https://github.com/HKUDS/LightRAG.\n","authors":["Zirui Guo","Lianghao Xia","Yanhua Yu","Tu Ao","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2410.05779v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04602v1","updated":"2024-11-07T10:31:31Z","published":"2024-11-07T10:31:31Z","title":"Self-Calibrated Listwise Reranking with Large Language Models","summary":"  Large language models (LLMs), with advanced linguistic capabilities, have\nbeen employed in reranking tasks through a sequence-to-sequence approach. In\nthis paradigm, multiple passages are reranked in a listwise manner and a\ntextual reranked permutation is generated. However, due to the limited context\nwindow of LLMs, this reranking paradigm requires a sliding window strategy to\niteratively handle larger candidate sets. This not only increases computational\ncosts but also restricts the LLM from fully capturing all the comparison\ninformation for all candidates. To address these challenges, we propose a novel\nself-calibrated listwise reranking method, which aims to leverage LLMs to\nproduce global relevance scores for ranking. To achieve it, we first propose\nthe relevance-aware listwise reranking framework, which incorporates explicit\nlist-view relevance scores to improve reranking efficiency and enable global\ncomparison across the entire candidate set. Second, to ensure the comparability\nof the computed scores, we propose self-calibrated training that uses\npoint-view relevance assessments generated internally by the LLM itself to\ncalibrate the list-view relevance assessments. Extensive experiments and\ncomprehensive analysis on the BEIR benchmark and TREC Deep Learning Tracks\ndemonstrate the effectiveness and efficiency of our proposed method.\n","authors":["Ruiyang Ren","Yuhao Wang","Kun Zhou","Wayne Xin Zhao","Wenjie Wang","Jing Liu","Ji-Rong Wen","Tat-Seng Chua"],"pdf_url":"https://arxiv.org/pdf/2411.04602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04539v1","updated":"2024-11-07T08:54:46Z","published":"2024-11-07T08:54:46Z","title":"Best Practices for Distilling Large Language Models into BERT for Web\n  Search Ranking","summary":"  Recent studies have highlighted the significant potential of Large Language\nModels (LLMs) as zero-shot relevance rankers. These methods predominantly\nutilize prompt learning to assess the relevance between queries and documents\nby generating a ranked list of potential documents. Despite their promise, the\nsubstantial costs associated with LLMs pose a significant challenge for their\ndirect implementation in commercial search systems. To overcome this barrier\nand fully exploit the capabilities of LLMs for text ranking, we explore\ntechniques to transfer the ranking expertise of LLMs to a more compact model\nsimilar to BERT, using a ranking loss to enable the deployment of less\nresource-intensive models. Specifically, we enhance the training of LLMs\nthrough Continued Pre-Training, taking the query as input and the clicked title\nand summary as output. We then proceed with supervised fine-tuning of the LLM\nusing a rank loss, assigning the final token as a representative of the entire\nsentence. Given the inherent characteristics of autoregressive language models,\nonly the final token </s> can encapsulate all preceding tokens. Additionally,\nwe introduce a hybrid point-wise and margin MSE loss to transfer the ranking\nknowledge from LLMs to smaller models like BERT. This method creates a viable\nsolution for environments with strict resource constraints. Both offline and\nonline evaluations have confirmed the efficacy of our approach, and our model\nhas been successfully integrated into a commercial web search engine as of\nFebruary 2024.\n","authors":["Dezhi Ye","Junwei Hu","Jiabin Fan","Bowen Tian","Jie Liu","Haijin Liang","Jin Ma"],"pdf_url":"https://arxiv.org/pdf/2411.04539v1.pdf","comment":"Arxiv Version"},{"id":"http://arxiv.org/abs/2411.05048v1","updated":"2024-11-07T03:58:38Z","published":"2024-11-07T03:58:38Z","title":"Leveraging LLMs to Enable Natural Language Search on Go-to-market\n  Platforms","summary":"  Enterprise searches require users to have complex knowledge of queries,\nconfigurations, and metadata, rendering it difficult for them to access\ninformation as needed. Most go-to-market (GTM) platforms utilize advanced\nsearch, an interface that enables users to filter queries by various fields\nusing categories or keywords, which, historically, however, has proven to be\nexceedingly cumbersome, as users are faced with seemingly hundreds of options,\nfields, and buttons. Consequently, querying with natural language has long been\nideal, a notion further empowered by Large Language Models (LLMs).\n  In this paper, we implement and evaluate a solution for the Zoominfo product\nfor sellers, which prompts the LLM with natural language, producing search\nfields through entity extraction that are then converted into a search query.\nThe intermediary search fields offer numerous advantages for each query,\nincluding the elimination of syntax errors, simpler ground truths, and an\nintuitive format for the LLM to interpret.\n  We paired this pipeline with many advanced prompt engineering strategies,\nfeaturing an intricate system message, few-shot prompting, chain-of-thought\n(CoT) reasoning, and execution refinement. Furthermore, we manually created the\nground truth for 500+ natural language queries, enabling the supervised\nfine-tuning of Llama-3-8B-Instruct and the introduction of sophisticated\nnumerical metrics.\n  Comprehensive experiments with closed, open source, and fine-tuned LLM models\nwere conducted through exact, Jaccard, cosine, and semantic similarity on\nindividual search entities to demonstrate the efficacy of our approach.\nOverall, the most accurate closed model had an average accuracy of 97% per\nquery, with only one field performing under 90%, with comparable results\nobserved from the fine-tuned models.\n","authors":["Jesse Yao","Saurav Acharya","Priyaranjan Parida","Srinivas Attipalli","Ali Dasdan"],"pdf_url":"https://arxiv.org/pdf/2411.05048v1.pdf","comment":"11 pages, 5 figures"},{"id":"http://arxiv.org/abs/2411.04403v1","updated":"2024-11-07T03:46:43Z","published":"2024-11-07T03:46:43Z","title":"Towards Competitive Search Relevance For Inference-Free Learned Sparse\n  Retrievers","summary":"  Learned sparse retrieval, which can efficiently perform retrieval through\nmature inverted-index engines, has garnered growing attention in recent years.\nParticularly, the inference-free sparse retrievers are attractive as they\neliminate online model inference in the retrieval phase thereby avoids huge\ncomputational cost, offering reasonable throughput and latency. However, even\nthe state-of-the-art (SOTA) inference-free sparse models lag far behind in\nterms of search relevance when compared to both sparse and dense siamese\nmodels. Towards competitive search relevance for inference-free sparse\nretrievers, we argue that they deserve dedicated training methods other than\nusing same ones with siamese encoders. In this paper, we propose two different\napproaches for performance improvement. First, we introduce the IDF-aware FLOPS\nloss, which introduces Inverted Document Frequency (IDF) to the sparsification\nof representations. We find that it mitigates the negative impact of the FLOPS\nregularization on search relevance, allowing the model to achieve a better\nbalance between accuracy and efficiency. Moreover, we propose a heterogeneous\nensemble knowledge distillation framework that combines siamese dense and\nsparse retrievers to generate supervisory signals during the pre-training\nphase. The ensemble framework of dense and sparse retriever capitalizes on\ntheir strengths respectively, providing a strong upper bound for knowledge\ndistillation. To concur the diverse feedback from heterogeneous supervisors, we\nnormalize and then aggregate the outputs of the teacher models to eliminate\nscore scale differences. On the BEIR benchmark, our model outperforms existing\nSOTA inference-free sparse model by \\textbf{3.3 NDCG@10 score}. It exhibits\nsearch relevance comparable to siamese sparse retrievers and client-side\nlatency only \\textbf{1.1x that of BM25}.\n","authors":["Zhichao Geng","Dongyu Ru","Yang Yang"],"pdf_url":"https://arxiv.org/pdf/2411.04403v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04366v1","updated":"2024-11-07T01:52:46Z","published":"2024-11-07T01:52:46Z","title":"The Concatenator: A Bayesian Approach To Real Time Concatenative\n  Musaicing","summary":"  We present ``The Concatenator,'' a real time system for audio-guided\nconcatenative synthesis. Similarly to Driedger et al.'s ``musaicing'' (or\n``audio mosaicing'') technique, we concatenate a set number of windows within a\ncorpus of audio to re-create the harmonic and percussive aspects of a target\naudio stream. Unlike Driedger's NMF-based technique, however, we instead use an\nexplicitly Bayesian point of view, where corpus window indices are hidden\nstates and the target audio stream is an observation. We use a particle filter\nto infer the best hidden corpus states in real-time. Our transition model\nincludes a tunable parameter to control the time-continuity of corpus grains,\nand our observation model allows users to prioritize how quickly windows change\nto match the target. Because the computational complexity of the system is\nindependent of the corpus size, our system scales to corpora that are hours\nlong, which is an important feature in the age of vast audio data collections.\nWithin The Concatenator module itself, composers can vary grain length, fit to\ntarget, and pitch shift in real time while reacting to the sounds they hear,\nenabling them to rapidly iterate ideas. To conclude our work, we evaluate our\nsystem with extensive quantitative tests of the effects of parameters, as well\nas a qualitative evaluation with artistic insights. Based on the quality of the\nresults, we believe the real-time capability unlocks new avenues for musical\nexpression and control, suitable for live performance and modular synthesis\nintegration, which furthermore represents an essential breakthrough in\nconcatenative synthesis technology.\n","authors":["Christopher Tralie","Ben Cantil"],"pdf_url":"https://arxiv.org/pdf/2411.04366v1.pdf","comment":"12 pages, 6 figures, Accepted for Publication in The International\n  Society for Music Information Retrieval Proceedings, 2024"}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.04859v1","updated":"2024-11-07T16:49:25Z","published":"2024-11-07T16:49:25Z","title":"A multi-purpose automatic editing system based on lecture semantics for\n  remote education","summary":"  Remote teaching has become popular recently due to its convenience and\nsafety, especially under extreme circumstances like a pandemic. However, online\nstudents usually have a poor experience since the information acquired from the\nviews provided by the broadcast platforms is limited. One potential solution is\nto show more camera views simultaneously, but it is technically challenging and\ndistracting for the viewers. Therefore, an automatic multi-camera\ndirecting/editing system, which aims at selecting the most concerned view at\neach time instance to guide the attention of online students, is in urgent\ndemand. However, existing systems mostly make simple assumptions and focus on\ntracking the position of the speaker instead of the real lecture semantics, and\ntherefore have limited capacities to deliver optimal information flow. To this\nend, this paper proposes an automatic multi-purpose editing system based on the\nlecture semantics, which can both direct the multiple video streams for\nreal-time broadcasting and edit the optimal video offline for review purposes.\nOur system directs the views by semantically analyzing the class events while\nfollowing the professional directing rules, mimicking a human director to\ncapture the regions of interest from the viewpoint of the onsite students. We\nconduct both qualitative and quantitative analyses to verify the effectiveness\nof the proposed system and its components.\n","authors":["Panwen Hu","Rui Huang"],"pdf_url":"https://arxiv.org/pdf/2411.04859v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.04517v1","updated":"2024-11-07T08:19:39Z","published":"2024-11-07T08:19:39Z","title":"Continuous Sign Language Recognition System using Deep Learning with\n  MediaPipe Holistic","summary":"  Sign languages are the language of hearing-impaired people who use visuals\nlike the hand, facial, and body movements for communication. There are\ndifferent signs and gestures representing alphabets, words, and phrases.\nNowadays approximately 300 sign languages are being practiced worldwide such as\nAmerican Sign Language (ASL), Chinese Sign Language (CSL), Indian Sign Language\n(ISL), and many more. Sign languages are dependent on the vocal language of a\nplace. Unlike vocal or spoken languages, there are no helping words in sign\nlanguage like is, am, are, was, were, will, be, etc. As only a limited\npopulation is well-versed in sign language, this lack of familiarity of sign\nlanguage hinders hearing-impaired people from communicating freely and easily\nwith everyone. This issue can be addressed by a sign language recognition (SLR)\nsystem which has the capability to translate the sign language into vocal\nlanguage. In this paper, a continuous SLR system is proposed using a deep\nlearning model employing Long Short-Term Memory (LSTM), trained and tested on\nan ISL primary dataset. This dataset is created using MediaPipe Holistic\npipeline for tracking face, hand, and body movements and collecting landmarks.\nThe system recognizes the signs and gestures in real-time with 88.23% accuracy.\n","authors":["Sharvani Srivastava","Sudhakar Singh"," Pooja","Shiv Prakash"],"pdf_url":"https://arxiv.org/pdf/2411.04517v1.pdf","comment":"14 pages, 4 figures, Wireless Pers Commun"},{"id":"http://arxiv.org/abs/2411.02551v2","updated":"2024-11-07T07:18:51Z","published":"2024-11-04T19:34:13Z","title":"PIAST: A Multimodal Piano Dataset with Audio, Symbolic and Text","summary":"  While piano music has become a significant area of study in Music Information\nRetrieval (MIR), there is a notable lack of datasets for piano solo music with\ntext labels. To address this gap, we present PIAST (PIano dataset with Audio,\nSymbolic, and Text), a piano music dataset. Utilizing a piano-specific taxonomy\nof semantic tags, we collected 9,673 tracks from YouTube and added human\nannotations for 2,023 tracks by music experts, resulting in two subsets:\nPIAST-YT and PIAST-AT. Both include audio, text, tag annotations, and\ntranscribed MIDI utilizing state-of-the-art piano transcription and beat\ntracking models. Among many possible tasks with the multi-modal dataset, we\nconduct music tagging and retrieval using both audio and MIDI data and report\nbaseline performances to demonstrate its potential as a valuable resource for\nMIR research.\n","authors":["Hayeon Bang","Eunjin Choi","Megan Finch","Seungheon Doh","Seolhee Lee","Gyeong-Hoon Lee","Juhan Nam"],"pdf_url":"https://arxiv.org/pdf/2411.02551v2.pdf","comment":"Accepted for publication at the 3rd Workshop on NLP for Music and\n  Audio (NLP4MusA 2024)"},{"id":"http://arxiv.org/abs/2411.04366v1","updated":"2024-11-07T01:52:46Z","published":"2024-11-07T01:52:46Z","title":"The Concatenator: A Bayesian Approach To Real Time Concatenative\n  Musaicing","summary":"  We present ``The Concatenator,'' a real time system for audio-guided\nconcatenative synthesis. Similarly to Driedger et al.'s ``musaicing'' (or\n``audio mosaicing'') technique, we concatenate a set number of windows within a\ncorpus of audio to re-create the harmonic and percussive aspects of a target\naudio stream. Unlike Driedger's NMF-based technique, however, we instead use an\nexplicitly Bayesian point of view, where corpus window indices are hidden\nstates and the target audio stream is an observation. We use a particle filter\nto infer the best hidden corpus states in real-time. Our transition model\nincludes a tunable parameter to control the time-continuity of corpus grains,\nand our observation model allows users to prioritize how quickly windows change\nto match the target. Because the computational complexity of the system is\nindependent of the corpus size, our system scales to corpora that are hours\nlong, which is an important feature in the age of vast audio data collections.\nWithin The Concatenator module itself, composers can vary grain length, fit to\ntarget, and pitch shift in real time while reacting to the sounds they hear,\nenabling them to rapidly iterate ideas. To conclude our work, we evaluate our\nsystem with extensive quantitative tests of the effects of parameters, as well\nas a qualitative evaluation with artistic insights. Based on the quality of the\nresults, we believe the real-time capability unlocks new avenues for musical\nexpression and control, suitable for live performance and modular synthesis\nintegration, which furthermore represents an essential breakthrough in\nconcatenative synthesis technology.\n","authors":["Christopher Tralie","Ben Cantil"],"pdf_url":"https://arxiv.org/pdf/2411.04366v1.pdf","comment":"12 pages, 6 figures, Accepted for Publication in The International\n  Society for Music Information Retrieval Proceedings, 2024"}]},"2024-11-06T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2410.22233v2","updated":"2024-11-06T19:52:58Z","published":"2024-10-29T17:01:05Z","title":"ContextIQ: A Multimodal Expert-Based Video Retrieval System for\n  Contextual Advertising","summary":"  Contextual advertising serves ads that are aligned to the content that the\nuser is viewing. The rapid growth of video content on social platforms and\nstreaming services, along with privacy concerns, has increased the need for\ncontextual advertising. Placing the right ad in the right context creates a\nseamless and pleasant ad viewing experience, resulting in higher audience\nengagement and, ultimately, better ad monetization. From a technology\nstandpoint, effective contextual advertising requires a video retrieval system\ncapable of understanding complex video content at a very granular level.\nCurrent text-to-video retrieval models based on joint multimodal training\ndemand large datasets and computational resources, limiting their practicality\nand lacking the key functionalities required for ad ecosystem integration. We\nintroduce ContextIQ, a multimodal expert-based video retrieval system designed\nspecifically for contextual advertising. ContextIQ utilizes modality-specific\nexperts-video, audio, transcript (captions), and metadata such as objects,\nactions, emotion, etc.-to create semantically rich video representations. We\nshow that our system, without joint training, achieves better or comparable\nresults to state-of-the-art models and commercial solutions on multiple\ntext-to-video retrieval benchmarks. Our ablation studies highlight the benefits\nof leveraging multiple modalities for enhanced video retrieval accuracy instead\nof using a vision-language model alone. Furthermore, we show how video\nretrieval systems such as ContextIQ can be used for contextual advertising in\nan ad ecosystem while also addressing concerns related to brand safety and\nfiltering inappropriate content.\n","authors":["Ashutosh Chaubey","Anoubhav Agarwaal","Sartaki Sinha Roy","Aayush Agrawal","Susmita Ghose"],"pdf_url":"https://arxiv.org/pdf/2410.22233v2.pdf","comment":"Accepted at WACV 2025"},{"id":"http://arxiv.org/abs/2411.04228v1","updated":"2024-11-06T19:50:00Z","published":"2024-11-06T19:50:00Z","title":"dsld: A Socially Relevant Tool for Teaching Statistics","summary":"  The growing power of data science can play a crucial role in addressing\nsocial discrimination, necessitating nuanced understanding and effective\nmitigation strategies of potential biases. Data Science Looks At Discrimination\n(dsld) is an R and Python package designed to provide users with a\ncomprehensive toolkit of statistical and graphical methods for assessing\npossible discrimination related to protected groups, such as race, gender, and\nage. Our software offers techniques for discrimination analysis by identifying\nand mitigating confounding variables, along with methods for reducing bias in\npredictive models.\n  In educational settings, dsld offers instructors powerful tools to teach\nimportant statistical principles through motivating real world examples of\ndiscrimination analysis. The inclusion of an 80-page Quarto book further\nsupports users, from statistics educators to legal professionals, in\neffectively applying these analytical tools to real world scenarios.\n","authors":["Taha Abdullah","Arjun Ashok","Brandon Estrada","Norman Matloff","Aditya Mittal"],"pdf_url":"https://arxiv.org/pdf/2411.04228v1.pdf","comment":"To be submitted to the Journal of Statistics and Data Science\n  Education"},{"id":"http://arxiv.org/abs/2411.04051v1","updated":"2024-11-06T16:57:55Z","published":"2024-11-06T16:57:55Z","title":"Reproducible Hybrid Time-Travel Retrieval in Evolving Corpora","summary":"  There are settings in which reproducibility of ranked lists is desirable,\nsuch as when extracting a subset of an evolving document corpus for downstream\nresearch tasks or in domains such as patent retrieval or in medical systematic\nreviews, with high reproducibility expectations. However, as global term\nstatistics change when documents change or are added to a corpus, queries using\ntypical ranked retrieval models are not even reproducible for the parts of the\ndocument corpus that have not changed. Thus, Boolean retrieval frequently\nremains the mechanism of choice in such settings.\n  We present a hybrid retrieval system combining Lucene for fast retrieval with\na column-store-based retrieval system maintaining a versioned and time-stamped\nindex. The latter component allows re-execution of previously posed queries\nresulting in the same ranked list and further allows for time-travel queries\nover evolving collection, as web archives, while maintaining the original\nranking. Thus, retrieval results in evolving document collections are fully\nreproducible even when document collections and thus term statistics change.\n","authors":["Moritz Staudinger","Florina Piroi","Andreas Rauber"],"pdf_url":"https://arxiv.org/pdf/2411.04051v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03957v1","updated":"2024-11-06T14:42:39Z","published":"2024-11-06T14:42:39Z","title":"Fine-Grained Guidance for Retrievers: Leveraging LLMs' Feedback in\n  Retrieval-Augmented Generation","summary":"  Retrieval-Augmented Generation (RAG) has proven to be an effective method for\nmitigating hallucination issues inherent in large language models (LLMs).\nPrevious approaches typically train retrievers based on semantic similarity,\nlacking optimization for RAG. More recent works have proposed aligning\nretrievers with the preference signals of LLMs. However, these preference\nsignals are often difficult for dense retrievers, which typically have weaker\nlanguage capabilities, to understand and learn effectively. Drawing inspiration\nfrom pedagogical theories like Guided Discovery Learning, we propose a novel\nframework, FiGRet (Fine-grained Guidance for Retrievers), which leverages the\nlanguage capabilities of LLMs to construct examples from a more granular,\ninformation-centric perspective to guide the learning of retrievers.\nSpecifically, our method utilizes LLMs to construct easy-to-understand examples\nfrom samples where the retriever performs poorly, focusing on three learning\nobjectives highly relevant to the RAG scenario: relevance, comprehensiveness,\nand purity. These examples serve as scaffolding to ultimately align the\nretriever with the LLM's preferences. Furthermore, we employ a dual curriculum\nlearning strategy and leverage the reciprocal feedback between LLM and\nretriever to further enhance the performance of the RAG system. A series of\nexperiments demonstrate that our proposed framework enhances the performance of\nRAG systems equipped with different retrievers and is applicable to various\nLLMs.\n","authors":["Yuhang Liu","Xueyu Hu","Shengyu Zhang","Jingyuan Chen","Fan Wu","Fei Wu"],"pdf_url":"https://arxiv.org/pdf/2411.03957v1.pdf","comment":"13 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.03906v1","updated":"2024-11-06T13:37:28Z","published":"2024-11-06T13:37:28Z","title":"Lexicalization Is All You Need: Examining the Impact of Lexical\n  Knowledge in a Compositional QALD System","summary":"  In this paper, we examine the impact of lexicalization on Question Answering\nover Linked Data (QALD). It is well known that one of the key challenges in\ninterpreting natural language questions with respect to SPARQL lies in bridging\nthe lexical gap, that is mapping the words in the query to the correct\nvocabulary elements. We argue in this paper that lexicalization, that is\nexplicit knowledge about the potential interpretations of a word with respect\nto the given vocabulary, significantly eases the task and increases the\nperformance of QA systems. Towards this goal, we present a compositional QA\nsystem that can leverage explicit lexical knowledge in a compositional manner\nto infer the meaning of a question in terms of a SPARQL query. We show that\nsuch a system, given lexical knowledge, has a performance well beyond current\nQA systems, achieving up to a $35.8\\%$ increase in the micro $F_1$ score\ncompared to the best QA system on QALD-9. This shows the importance and\npotential of including explicit lexical knowledge. In contrast, we show that\nLLMs have limited abilities to exploit lexical knowledge, with only marginal\nimprovements compared to a version without lexical knowledge. This shows that\nLLMs have no ability to compositionally interpret a question on the basis of\nthe meaning of its parts, a key feature of compositional approaches. Taken\ntogether, our work shows new avenues for QALD research, emphasizing the\nimportance of lexicalization and compositionality.\n","authors":["David Maria Schmidt","Mohammad Fazleh Elahi","Philipp Cimiano"],"pdf_url":"https://arxiv.org/pdf/2411.03906v1.pdf","comment":"24th International Conference on Knowledge Engineering and Knowledge\n  Management (EKAW 2024), November 26-28, 2024, Amsterdam, The Netherlands"},{"id":"http://arxiv.org/abs/2411.03881v1","updated":"2024-11-06T12:54:27Z","published":"2024-11-06T12:54:27Z","title":"Data Fusion of Synthetic Query Variants With Generative Large Language\n  Models","summary":"  Considering query variance in information retrieval (IR) experiments is\nbeneficial for retrieval effectiveness. Especially ranking ensembles based on\ndifferent topically related queries retrieve better results than rankings based\non a single query alone. Recently, generative instruction-tuned Large Language\nModels (LLMs) improved on a variety of different tasks in capturing human\nlanguage. To this end, this work explores the feasibility of using synthetic\nquery variants generated by instruction-tuned LLMs in data fusion experiments.\nMore specifically, we introduce a lightweight, unsupervised, and cost-efficient\napproach that exploits principled prompting and data fusion techniques. In our\nexperiments, LLMs produce more effective queries when provided with additional\ncontext information on the topic. Furthermore, our analysis based on four TREC\nnewswire benchmarks shows that data fusion based on synthetic query variants is\nsignificantly better than baselines with single queries and also outperforms\npseudo-relevance feedback methods. We publicly share the code and query\ndatasets with the community as resources for follow-up studies.\n","authors":["Timo Breuer"],"pdf_url":"https://arxiv.org/pdf/2411.03881v1.pdf","comment":"The definitive version of record was published in SIGIR-AP '24"},{"id":"http://arxiv.org/abs/2411.02832v2","updated":"2024-11-06T11:19:42Z","published":"2024-11-05T06:11:17Z","title":"PersianRAG: A Retrieval-Augmented Generation System for Persian Language","summary":"  Retrieval augmented generation (RAG) models, which integrate large-scale\npre-trained generative models with external retrieval mechanisms, have shown\nsignificant success in various natural language processing (NLP) tasks.\nHowever, applying RAG models in Persian language as a low-resource language,\nposes distinct challenges. These challenges primarily involve the\npreprocessing, embedding, retrieval, prompt construction, language modeling,\nand response evaluation of the system. In this paper, we address the challenges\ntowards implementing a real-world RAG system for Persian language called\nPersianRAG. We propose novel solutions to overcome these obstacles and evaluate\nour approach using several Persian benchmark datasets. Our experimental results\ndemonstrate the capability of the PersianRAG framework to enhance question\nanswering task in Persian.\n","authors":["Hossein Hosseini","Mohammad Sobhan Zare","Amir Hossein Mohammadi","Arefeh Kazemi","Zahra Zojaji","Mohammad Ali Nematbakhsh"],"pdf_url":"https://arxiv.org/pdf/2411.02832v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03039v2","updated":"2024-11-06T09:28:25Z","published":"2024-11-05T12:22:51Z","title":"Self-Compositional Data Augmentation for Scientific Keyphrase Generation","summary":"  State-of-the-art models for keyphrase generation require large amounts of\ntraining data to achieve good performance. However, obtaining keyphrase-labeled\ndocuments can be challenging and costly. To address this issue, we present a\nself-compositional data augmentation method. More specifically, we measure the\nrelatedness of training documents based on their shared keyphrases, and combine\nsimilar documents to generate synthetic samples. The advantage of our method\nlies in its ability to create additional training samples that keep domain\ncoherence, without relying on external data or resources. Our results on\nmultiple datasets spanning three different domains, demonstrate that our method\nconsistently improves keyphrase generation. A qualitative analysis of the\ngenerated keyphrases for the Computer Science domain confirms this improvement\ntowards their representativity property.\n","authors":["Mael Houbre","Florian Boudin","Beatrice Daille","Akiko Aizawa"],"pdf_url":"https://arxiv.org/pdf/2411.03039v2.pdf","comment":"Accepted to JCDL 2024. This is the author's version of the work. It\n  is posted here for your personal use. Not for redistribution. The definitive\n  version was published in the proceedings of the 2024 ACM/IEEE Joint\n  Conference on Digital Libraries (JCDL 24)\n  https://doi.org/10.1145/3677389.3702504"},{"id":"http://arxiv.org/abs/2411.03701v1","updated":"2024-11-06T06:56:22Z","published":"2024-11-06T06:56:22Z","title":"The Essence of the Essence from the Web:The Metasearch Engine","summary":"  The exponential growth of information source on the web and in turn\ncontinuing technological progress of searching the information by using tools\nlike Search Engines gives rise to many problems for the user to know which tool\nis best for their query and which tool is not. At this time Metasearch Engine\ncomes into play by reducing the user burden by dispatching queries to multiple\nsearch engines in parallel and refining the results of these search engines to\ngive the best out of best by doing superior job on their side. These engines do\nnot own a database of Web pages rather they send search terms to the databases\nmaintained by the search engine companies, get back results from all the search\nengines queried and then compile the results to be presented to the user. In\nthis paper, we describe the working of a typical metasearch engine and then\npresent a comparative study of traditional search engines and metasearch\nengines on the basis of different parameters and show how metasearch engines\nare better than the other search engines.\n","authors":["Rajender Nath","Satinder Bal"],"pdf_url":"https://arxiv.org/pdf/2411.03701v1.pdf","comment":"6 pages"},{"id":"http://arxiv.org/abs/2401.11505v2","updated":"2024-11-06T04:11:14Z","published":"2024-01-21T14:30:20Z","title":"CheX-GPT: Harnessing Large Language Models for Enhanced Chest X-ray\n  Report Labeling","summary":"  Free-text radiology reports present a rich data source for various medical\ntasks, but effectively labeling these texts remains challenging. Traditional\nrule-based labeling methods fall short of capturing the nuances of diverse\nfree-text patterns. Moreover, models using expert-annotated data are limited by\ndata scarcity and pre-defined classes, impacting their performance, flexibility\nand scalability. To address these issues, our study offers three main\ncontributions: 1) We demonstrate the potential of GPT as an adept labeler using\ncarefully designed prompts. 2) Utilizing only the data labeled by GPT, we\ntrained a BERT-based labeler, CheX-GPT, which operates faster and more\nefficiently than its GPT counterpart. 3) To benchmark labeler performance, we\nintroduced a publicly available expert-annotated test set, MIMIC-500,\ncomprising 500 cases from the MIMIC validation set. Our findings demonstrate\nthat CheX-GPT not only excels in labeling accuracy over existing models, but\nalso showcases superior efficiency, flexibility, and scalability, supported by\nour introduction of the MIMIC-500 dataset for robust benchmarking. Code and\nmodels are available at https://github.com/Soombit-ai/CheXGPT.\n","authors":["Jawook Gu","Kihyun You","Han-Cheol Cho","Jiho Kim","Eun Kyoung Hong","Byungseok Roh"],"pdf_url":"https://arxiv.org/pdf/2401.11505v2.pdf","comment":"16 pages, 3 figures"},{"id":"http://arxiv.org/abs/2411.03624v1","updated":"2024-11-06T02:45:16Z","published":"2024-11-06T02:45:16Z","title":"SEGMN: A Structure-Enhanced Graph Matching Network for Graph Similarity\n  Learning","summary":"  Graph similarity computation (GSC) aims to quantify the similarity score\nbetween two graphs. Although recent GSC methods based on graph neural networks\n(GNNs) take advantage of intra-graph structures in message passing, few of them\nfully utilize the structures presented by edges to boost the representation of\ntheir connected nodes. Moreover, previous cross-graph node embedding matching\nlacks the perception of the overall structure of the graph pair, due to the\nfact that the node representations from GNNs are confined to the intra-graph\nstructure, causing the unreasonable similarity score. Intuitively, the\ncross-graph structure represented in the assignment graph is helpful to rectify\nthe inappropriate matching. Therefore, we propose a structure-enhanced graph\nmatching network (SEGMN). Equipped with a dual embedding learning module and a\nstructure perception matching module, SEGMN achieves structure enhancement in\nboth embedding learning and cross-graph matching. The dual embedding learning\nmodule incorporates adjacent edge representation into each node to achieve a\nstructure-enhanced representation. The structure perception matching module\nachieves cross-graph structure enhancement through assignment graph\nconvolution. The similarity score of each cross-graph node pair can be\nrectified by aggregating messages from structurally relevant node pairs.\nExperimental results on benchmark datasets demonstrate that SEGMN outperforms\nthe state-of-the-art GSC methods in the GED regression task, and the structure\nperception matching module is plug-and-play, which can further improve the\nperformance of the baselines by up to 25%.\n","authors":["Wenjun Wang","Jiacheng Lu","Kejia Chen","Zheng Liu","Shilong Sang"],"pdf_url":"https://arxiv.org/pdf/2411.03624v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.02937v2","updated":"2024-11-06T02:36:02Z","published":"2024-08-06T03:44:06Z","title":"A Real-Time Adaptive Multi-Stream GPU System for Online Approximate\n  Nearest Neighborhood Search","summary":"  In recent years, Approximate Nearest Neighbor Search (ANNS) has played a\npivotal role in modern search and recommendation systems, especially in\nemerging LLM applications like Retrieval-Augmented Generation. There is a\ngrowing exploration into harnessing the parallel computing capabilities of GPUs\nto meet the substantial demands of ANNS. However, existing systems primarily\nfocus on offline scenarios, overlooking the distinct requirements of online\napplications that necessitate real-time insertion of new vectors. This\nlimitation renders such systems inefficient for real-world scenarios. Moreover,\nprevious architectures struggled to effectively support real-time insertion due\nto their reliance on serial execution streams. In this paper, we introduce a\nnovel Real-Time Adaptive Multi-Stream GPU ANNS System (RTAMS-GANNS). Our\narchitecture achieves its objectives through three key advancements: 1) We\ninitially examined the real-time insertion mechanisms in existing GPU ANNS\nsystems and discovered their reliance on repetitive copying and memory\nallocation, which significantly hinders real-time effectiveness on GPUs. As a\nsolution, we introduce a dynamic vector insertion algorithm based on memory\nblocks, which includes in-place rearrangement. 2) To enable real-time vector\ninsertion in parallel, we introduce a multi-stream parallel execution mode,\nwhich differs from existing systems that operate serially within a single\nstream. Our system utilizes a dynamic resource pool, allowing multiple streams\nto execute concurrently without additional execution blocking. 3) Through\nextensive experiments and comparisons, our approach effectively handles varying\nQPS levels across different datasets, reducing latency by up to 40%-80%. The\nproposed system has also been deployed in real-world industrial search and\nrecommendation systems, serving hundreds of millions of users daily, and has\nachieved good results.\n","authors":["Yiping Sun","Yang Shi","Jiaolong Du"],"pdf_url":"https://arxiv.org/pdf/2408.02937v2.pdf","comment":"Accepted by CIKM'24, V2 fixes some typos"},{"id":"http://arxiv.org/abs/2408.09380v3","updated":"2024-11-06T02:26:07Z","published":"2024-08-18T06:41:46Z","title":"ELASTIC: Efficient Linear Attention for Sequential Interest Compression","summary":"  State-of-the-art sequential recommendation models heavily rely on\ntransformer's attention mechanism. However, the quadratic computational and\nmemory complexities of self attention have limited its scalability for modeling\nusers' long range behaviour sequences. To address this problem, we propose\nELASTIC, an Efficient Linear Attention for SequenTial Interest Compression,\nrequiring only linear time complexity and decoupling model capacity from\ncomputational cost. Specifically, ELASTIC introduces a fixed length interest\nexperts with linear dispatcher attention mechanism which compresses the\nlong-term behaviour sequences to a significantly more compact representation\nwhich reduces up to 90% GPU memory usage with x2.7 inference speed up. The\nproposed linear dispatcher attention mechanism significantly reduces the\nquadratic complexity and makes the model feasible for adequately modeling\nextremely long sequences. Moreover, in order to retain the capacity for\nmodeling various user interests, ELASTIC initializes a vast learnable interest\nmemory bank and sparsely retrieves compressed user's interests from the memory\nwith a negligible computational overhead. The proposed interest memory\nretrieval technique significantly expands the cardinality of available interest\nspace while keeping the same computational cost, thereby striking a trade-off\nbetween recommendation accuracy and efficiency. To validate the effectiveness\nof our proposed ELASTIC, we conduct extensive experiments on various public\ndatasets and compare it with several strong sequential recommenders.\nExperimental results demonstrate that ELASTIC consistently outperforms\nbaselines by a significant margin and also highlight the computational\nefficiency of ELASTIC when modeling long sequences. We will make our\nimplementation code publicly available.\n","authors":["Jiaxin Deng","Shiyao Wang","Song Lu","Yinfeng Li","Xinchen Luo","Yuanjun Liu","Peixing Xu","Guorui Zhou"],"pdf_url":"https://arxiv.org/pdf/2408.09380v3.pdf","comment":"We hereby withdraw this paper from arXiv due to incomplete\n  experiments. Upon further review, we have determined that additional\n  experimental work is necessary to fully validate our findings and conclusions"},{"id":"http://arxiv.org/abs/2411.03572v1","updated":"2024-11-06T00:23:55Z","published":"2024-11-06T00:23:55Z","title":"Advanced RAG Models with Graph Structures: Optimizing Complex Knowledge\n  Reasoning and Text Generation","summary":"  This study aims to optimize the existing retrieval-augmented generation model\n(RAG) by introducing a graph structure to improve the performance of the model\nin dealing with complex knowledge reasoning tasks. The traditional RAG model\nhas the problem of insufficient processing efficiency when facing complex graph\nstructure information (such as knowledge graphs, hierarchical relationships,\netc.), which affects the quality and consistency of the generated results. This\nstudy proposes a scheme to process graph structure data by combining graph\nneural network (GNN), so that the model can capture the complex relationship\nbetween entities, thereby improving the knowledge consistency and reasoning\nability of the generated text. The experiment used the Natural Questions (NQ)\ndataset and compared it with multiple existing generation models. The results\nshow that the graph-based RAG model proposed in this paper is superior to the\ntraditional generation model in terms of quality, knowledge consistency, and\nreasoning ability, especially when dealing with tasks that require\nmulti-dimensional reasoning. Through the combination of the enhancement of the\nretrieval module and the graph neural network, the model in this study can\nbetter handle complex knowledge background information and has broad potential\nvalue in multiple practical application scenarios.\n","authors":["Yuxin Dong","Shuo Wang","Hongye Zheng","Jiajing Chen","Zhenhong Zhang","Chihang Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03572v1.pdf","comment":null}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.05854v1","updated":"2024-11-06T23:48:30Z","published":"2024-11-06T23:48:30Z","title":"Harmful YouTube Video Detection: A Taxonomy of Online Harm and MLLMs as\n  Alternative Annotators","summary":"  Short video platforms, such as YouTube, Instagram, or TikTok, are used by\nbillions of users globally. These platforms expose users to harmful content,\nranging from clickbait or physical harms to misinformation or online hate. Yet,\ndetecting harmful videos remains challenging due to an inconsistent\nunderstanding of what constitutes harm and limited resources and mental tolls\ninvolved in human annotation. As such, this study advances measures and methods\nto detect harm in video content. First, we develop a comprehensive taxonomy for\nonline harm on video platforms, categorizing it into six categories:\nInformation, Hate and harassment, Addictive, Clickbait, Sexual, and Physical\nharms. Next, we establish multimodal large language models as reliable\nannotators of harmful videos. We analyze 19,422 YouTube videos using 14 image\nframes, 1 thumbnail, and text metadata, comparing the accuracy of crowdworkers\n(Mturk) and GPT-4-Turbo with domain expert annotations serving as the gold\nstandard. Our results demonstrate that GPT-4-Turbo outperforms crowdworkers in\nboth binary classification (harmful vs. harmless) and multi-label harm\ncategorization tasks. Methodologically, this study extends the application of\nLLMs to multi-label and multi-modal contexts beyond text annotation and binary\nclassification. Practically, our study contributes to online harm mitigation by\nguiding the definitions and identification of harmful content on video\nplatforms.\n","authors":["Claire Wonjeong Jo","Miki Weso≈Çowska","Magdalena Wojcieszak"],"pdf_url":"https://arxiv.org/pdf/2411.05854v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.04901v2","updated":"2024-11-06T23:32:27Z","published":"2023-04-11T00:17:28Z","title":"Efficiently Collecting Training Dataset for 2D Object Detection by\n  Online Visual Feedback","summary":"  Training deep-learning-based vision systems require the manual annotation of\na significant number of images. Such manual annotation is highly time-consuming\nand labor-intensive. Although previous studies have attempted to eliminate the\neffort required for annotation, the effort required for image collection was\nretained. To address this, we propose a human-in-the-loop dataset collection\nmethod that uses a web application. To counterbalance the workload and\nperformance by encouraging the collection of multi-view object image datasets\nin an enjoyable manner, thereby amplifying motivation, we propose three types\nof online visual feedback features to track the progress of the collection\nstatus. Our experiments thoroughly investigated the impact of each feature on\ncollection performance and quality of operation. The results suggested the\nfeasibility of annotation and object detection.\n","authors":["Takuya Kiyokawa","Naoki Shirakura","Hiroki Katayama","Keita Tomochika","Jun Takamatsu"],"pdf_url":"https://arxiv.org/pdf/2304.04901v2.pdf","comment":"13 pages, 14 figures"},{"id":"http://arxiv.org/abs/2401.03115v2","updated":"2024-11-06T22:09:09Z","published":"2024-01-06T03:03:28Z","title":"Transferable Learned Image Compression-Resistant Adversarial\n  Perturbations","summary":"  Adversarial attacks can readily disrupt the image classification system,\nrevealing the vulnerability of DNN-based recognition tasks. While existing\nadversarial perturbations are primarily applied to uncompressed images or\ncompressed images by the traditional image compression method, i.e., JPEG,\nlimited studies have investigated the robustness of models for image\nclassification in the context of DNN-based image compression. With the rapid\nevolution of advanced image compression, DNN-based learned image compression\nhas emerged as the promising approach for transmitting images in many\nsecurity-critical applications, such as cloud-based face recognition and\nautonomous driving, due to its superior performance over traditional\ncompression. Therefore, there is a pressing need to fully investigate the\nrobustness of a classification system post-processed by learned image\ncompression. To bridge this research gap, we explore the adversarial attack on\na new pipeline that targets image classification models that utilize learned\nimage compressors as pre-processing modules. Furthermore, to enhance the\ntransferability of perturbations across various quality levels and\narchitectures of learned image compression models, we introduce a saliency\nscore-based sampling method to enable the fast generation of transferable\nperturbation. Extensive experiments with popular attack methods demonstrate the\nenhanced transferability of our proposed method when attacking images that have\nbeen post-processed with different learned image compression models.\n","authors":["Yang Sui","Zhuohang Li","Ding Ding","Xiang Pan","Xiaozhong Xu","Shan Liu","Zhenzhong Chen"],"pdf_url":"https://arxiv.org/pdf/2401.03115v2.pdf","comment":"Accepted by BMVC 2024"},{"id":"http://arxiv.org/abs/2407.14093v2","updated":"2024-11-06T16:45:17Z","published":"2024-07-19T07:57:48Z","title":"Routing Experts: Learning to Route Dynamic Experts in Multi-modal Large\n  Language Models","summary":"  Recently, mixture of experts (MoE) has become a popular paradigm for\nachieving the trade-off between modal capacity and efficiency of multi-modal\nlarge language models (MLLMs). Different from previous efforts, we are\ndedicated to exploring the dynamic expert path in an already exist MLLM and\nshow that a standard MLLM can be also a mixture of experts. To approach this\ntarget, we propose a novel dynamic expert scheme for MLLMs, termed Routing\nExperts (RoE), which can achieve example-dependent optimal path routing without\nobvious structure tweaks. Meanwhile, a new regularization of structure sparsity\nis also introduced to enforce MLLMs to learn more short-cut inference, ensuring\nthe efficiency. In addition, we also realize the first attempt of aligning the\ntraining and inference schemes of MLLMs in terms of network routing. To\nvalidate RoE, we apply it to a set of latest MLLMs, including LLaVA-1.5,\nLLaVA-HR and VILA, and conduct extensive experiments on a bunch of VL\nbenchmarks. The experiment results not only show the great advantages of our\nRoE in improving MLLMs' efficiency, but also yield obvious advantages than\nMoE-LLaVA in both performance and speed, e.g., an average performance gain of\n3.3% on 5 benchmarks while being faster.\n","authors":["Qiong Wu","Zhaoxi Ke","Yiyi Zhou","Gen Luo","Xiaoshuai Sun","Rongrong Ji"],"pdf_url":"https://arxiv.org/pdf/2407.14093v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03948v1","updated":"2024-11-06T14:29:49Z","published":"2024-11-06T14:29:49Z","title":"Long-Form Text-to-Music Generation with Adaptive Prompts: A Case of\n  Study in Tabletop Role-Playing Games Soundtracks","summary":"  This paper investigates the capabilities of text-to-audio music generation\nmodels in producing long-form music with prompts that change over time,\nfocusing on soundtrack generation for Tabletop Role-Playing Games (TRPGs). We\nintroduce Babel Bardo, a system that uses Large Language Models (LLMs) to\ntransform speech transcriptions into music descriptions for controlling a\ntext-to-music model. Four versions of Babel Bardo were compared in two TRPG\ncampaigns: a baseline using direct speech transcriptions, and three LLM-based\nversions with varying approaches to music description generation. Evaluations\nconsidered audio quality, story alignment, and transition smoothness. Results\nindicate that detailed music descriptions improve audio quality while\nmaintaining consistency across consecutive descriptions enhances story\nalignment and transition smoothness.\n","authors":["Felipe Marra","Lucas N. Ferreira"],"pdf_url":"https://arxiv.org/pdf/2411.03948v1.pdf","comment":"Paper accepted at the LAMIR 2024 workshop"},{"id":"http://arxiv.org/abs/2411.03921v1","updated":"2024-11-06T13:52:49Z","published":"2024-11-06T13:52:49Z","title":"Inter-Frame Coding for Dynamic Meshes via Coarse-to-Fine Anchor Mesh\n  Generation","summary":"  In the current Video-based Dynamic Mesh Coding (V-DMC) standard, inter-frame\ncoding is restricted to mesh frames with constant topology. Consequently,\ntemporal redundancy is not fully leveraged, resulting in suboptimal compression\nefficacy. To address this limitation, this paper introduces a novel\ncoarse-to-fine scheme to generate anchor meshes for frames with time-varying\ntopology. Initially, we generate a coarse anchor mesh using an octree-based\nnearest neighbor search. Motion estimation compensates for regions with\nsignificant motion changes during this process. However, the quality of the\ncoarse mesh is low due to its suboptimal vertices. To enhance details, the fine\nanchor mesh is further optimized using the Quadric Error Metrics (QEM)\nalgorithm to calculate more precise anchor points. The inter-frame anchor mesh\ngenerated herein retains the connectivity of the reference base mesh, while\nconcurrently preserving superior quality. Experimental results show that our\nmethod achieves 7.2% ~ 10.3% BD-rate gain compared to the existing V-DMC test\nmodel version 7.\n","authors":["He Huang","Lizhi Hou","Qi Yang","Yiling Xu"],"pdf_url":"https://arxiv.org/pdf/2411.03921v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03823v1","updated":"2024-11-06T10:44:15Z","published":"2024-11-06T10:44:15Z","title":"Both Text and Images Leaked! A Systematic Analysis of Multimodal LLM\n  Data Contamination","summary":"  The rapid progression of multimodal large language models (MLLMs) has\ndemonstrated superior performance on various multimodal benchmarks. However,\nthe issue of data contamination during training creates challenges in\nperformance evaluation and comparison. While numerous methods exist for\ndetecting dataset contamination in large language models (LLMs), they are less\neffective for MLLMs due to their various modalities and multiple training\nphases. In this study, we introduce a multimodal data contamination detection\nframework, MM-Detect, designed for MLLMs. Our experimental results indicate\nthat MM-Detect is sensitive to varying degrees of contamination and can\nhighlight significant performance improvements due to leakage of the training\nset of multimodal benchmarks. Furthermore, We also explore the possibility of\ncontamination originating from the pre-training phase of LLMs used by MLLMs and\nthe fine-tuning phase of MLLMs, offering new insights into the stages at which\ncontamination may be introduced.\n","authors":["Dingjie Song","Sicheng Lai","Shunian Chen","Lichao Sun","Benyou Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03823v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.18680v3","updated":"2024-11-06T10:27:05Z","published":"2024-09-27T12:06:53Z","title":"Beyond Single-Audio: Advancing Multi-Audio Processing in Audio Large\n  Language Models","summary":"  Various audio-LLMs (ALLMs) have been explored recently for tackling different\naudio tasks simultaneously using a single, unified model. While existing\nevaluations of ALLMs primarily focus on single-audio tasks, real-world\napplications often involve processing multiple audio streams simultaneously. To\nbridge this gap, we propose the first multi-audio evaluation (MAE) benchmark\nthat consists of 20 datasets from 11 multi-audio tasks encompassing both speech\nand sound scenarios. Comprehensive experiments on MAE demonstrate that the\nexisting ALLMs, while being powerful in comprehending primary audio elements in\nindividual audio inputs, struggling to handle multi-audio scenarios. To this\nend, we propose a novel multi-audio-LLM (MALLM) to capture audio context among\nmultiple similar audios using discriminative learning on our proposed synthetic\ndata. The results demonstrate that the proposed MALLM outperforms all baselines\nand achieves high data efficiency using synthetic data without requiring human\nannotations. The proposed MALLM opens the door for ALLMs towards multi-audio\nprocessing era and brings us closer to replicating human auditory capabilities\nin machines.\n","authors":["Yiming Chen","Xianghu Yue","Xiaoxue Gao","Chen Zhang","Luis Fernando D'Haro","Robby T. Tan","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2409.18680v3.pdf","comment":"EMNLP24 Findings. Data available at\n  https://github.com/MatthewCYM/MALLM"},{"id":"http://arxiv.org/abs/2411.05832v1","updated":"2024-11-06T04:30:04Z","published":"2024-11-06T04:30:04Z","title":"Diversify, Contextualize, and Adapt: Efficient Entropy Modeling for\n  Neural Image Codec","summary":"  Designing a fast and effective entropy model is challenging but essential for\npractical application of neural codecs. Beyond spatial autoregressive entropy\nmodels, more efficient backward adaptation-based entropy models have been\nrecently developed. They not only reduce decoding time by using smaller number\nof modeling steps but also maintain or even improve rate--distortion\nperformance by leveraging more diverse contexts for backward adaptation.\nDespite their significant progress, we argue that their performance has been\nlimited by the simple adoption of the design convention for forward adaptation:\nusing only a single type of hyper latent representation, which does not provide\nsufficient contextual information, especially in the first modeling step. In\nthis paper, we propose a simple yet effective entropy modeling framework that\nleverages sufficient contexts for forward adaptation without compromising on\nbit-rate. Specifically, we introduce a strategy of diversifying hyper latent\nrepresentations for forward adaptation, i.e., using two additional types of\ncontexts along with the existing single type of context. In addition, we\npresent a method to effectively use the diverse contexts for contextualizing\nthe current elements to be encoded/decoded. By addressing the limitation of the\nprevious approach, our proposed framework leads to significant performance\nimprovements. Experimental results on popular datasets show that our proposed\nframework consistently improves rate--distortion performance across various\nbit-rate regions, e.g., 3.73% BD-rate gain over the state-of-the-art baseline\non the Kodak dataset.\n","authors":["Jun-Hyuk Kim","Seungeon Kim","Won-Hee Lee","Dokwan Oh"],"pdf_url":"https://arxiv.org/pdf/2411.05832v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.03595v1","updated":"2024-11-06T01:14:42Z","published":"2024-11-06T01:14:42Z","title":"Investigating Conceptual Blending of a Diffusion Model for Improving\n  Nonword-to-Image Generation","summary":"  Text-to-image diffusion models sometimes depict blended concepts in the\ngenerated images. One promising use case of this effect would be the\nnonword-to-image generation task which attempts to generate images intuitively\nimaginable from a non-existing word (nonword). To realize nonword-to-image\ngeneration, an existing study focused on associating nonwords with\nsimilar-sounding words. Since each nonword can have multiple similar-sounding\nwords, generating images containing their blended concepts would increase\nintuitiveness, facilitating creative activities and promoting computational\npsycholinguistics. Nevertheless, no existing study has quantitatively evaluated\nthis effect in either diffusion models or the nonword-to-image generation\nparadigm. Therefore, this paper first analyzes the conceptual blending in a\npretrained diffusion model, Stable Diffusion. The analysis reveals that a high\npercentage of generated images depict blended concepts when inputting an\nembedding interpolating between the text embeddings of two text prompts\nreferring to different concepts. Next, this paper explores the best text\nembedding space conversion method of an existing nonword-to-image generation\nframework to ensure both the occurrence of conceptual blending and image\ngeneration quality. We compare the conventional direct prediction approach with\nthe proposed method that combines $k$-nearest neighbor search and linear\nregression. Evaluation reveals that the enhanced accuracy of the embedding\nspace conversion by the proposed method improves the image generation quality,\nwhile the emergence of conceptual blending could be attributed mainly to the\nspecific dimensions of the high-dimensional text embedding space.\n","authors":["Chihaya Matsuhira","Marc A. Kastner","Takahiro Komamizu","Takatsugu Hirayama","Ichiro Ide"],"pdf_url":"https://arxiv.org/pdf/2411.03595v1.pdf","comment":"Paper accepted at ACM MM 2024 (doi: 10.1145/3664647.3681202) with\n  supplementary materials concatenated"},{"id":"http://arxiv.org/abs/2410.21169v3","updated":"2024-11-06T00:11:08Z","published":"2024-10-28T16:11:35Z","title":"Document Parsing Unveiled: Techniques, Challenges, and Prospects for\n  Structured Information Extraction","summary":"  Document parsing is essential for converting unstructured and semi-structured\ndocuments-such as contracts, academic papers, and invoices-into structured,\nmachine-readable data. Document parsing extract reliable structured data from\nunstructured inputs, providing huge convenience for numerous applications.\nEspecially with recent achievements in Large Language Models, document parsing\nplays an indispensable role in both knowledge base construction and training\ndata generation. This survey presents a comprehensive review of the current\nstate of document parsing, covering key methodologies, from modular pipeline\nsystems to end-to-end models driven by large vision-language models. Core\ncomponents such as layout detection, content extraction (including text,\ntables, and mathematical expressions), and multi-modal data integration are\nexamined in detail. Additionally, this paper discusses the challenges faced by\nmodular document parsing systems and vision-language models in handling complex\nlayouts, integrating multiple modules, and recognizing high-density text. It\nemphasizes the importance of developing larger and more diverse datasets and\noutlines future research directions.\n","authors":["Qintong Zhang","Victor Shea-Jay Huang","Bin Wang","Junyuan Zhang","Zhengren Wang","Hao Liang","Shawn Wang","Matthieu Lin","Conghui He","Wentao Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.21169v3.pdf","comment":null}]},"2024-11-05T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2411.03484v1","updated":"2024-11-05T20:08:23Z","published":"2024-11-05T20:08:23Z","title":"Automated, LLM enabled extraction of synthesis details for reticular\n  materials from scientific literature","summary":"  Automated knowledge extraction from scientific literature can potentially\naccelerate materials discovery. We have investigated an approach for extracting\nsynthesis protocols for reticular materials from scientific literature using\nlarge language models (LLMs). To that end, we introduce a Knowledge Extraction\nPipeline (KEP) that automatizes LLM-assisted paragraph classification and\ninformation extraction. By applying prompt engineering with in-context learning\n(ICL) to a set of open-source LLMs, we demonstrate that LLMs can retrieve\nchemical information from PDF documents, without the need for fine-tuning or\ntraining and at a reduced risk of hallucination. By comparing the performance\nof five open-source families of LLMs in both paragraph classification and\ninformation extraction tasks, we observe excellent model performance even if\nonly few example paragraphs are included in the ICL prompts. The results show\nthe potential of the KEP approach for reducing human annotations and data\ncuration efforts in automated scientific knowledge extraction.\n","authors":["Viviane Torres da Silva","Alexandre Rademaker","Krystelle Lionti","Ronaldo Giro","Geisa Lima","Sandro Fiorini","Marcelo Archanjo","Breno W. Carvalho","Rodrigo Neumann","Anaximandro Souza","Jo√£o Pedro Souza","Gabriela de Valnisio","Carmen Nilda Paz","Renato Cerqueira","Mathias Steiner"],"pdf_url":"https://arxiv.org/pdf/2411.03484v1.pdf","comment":"16 pages"},{"id":"http://arxiv.org/abs/2406.04331v2","updated":"2024-11-05T15:43:18Z","published":"2024-06-06T17:59:10Z","title":"PaCE: Parsimonious Concept Engineering for Large Language Models","summary":"  Large Language Models (LLMs) are being used for a wide variety of tasks.\nWhile they are capable of generating human-like responses, they can also\nproduce undesirable output including potentially harmful information, racist or\nsexist language, and hallucinations. Alignment methods are designed to reduce\nsuch undesirable outputs via techniques such as fine-tuning, prompt\nengineering, and representation engineering. However, existing methods face\nseveral challenges: some require costly fine-tuning for every alignment task;\nsome do not adequately remove undesirable concepts, failing alignment; some\nremove benign concepts, lowering the linguistic capabilities of LLMs. To\naddress these issues, we propose Parsimonious Concept Engineering (PaCE), a\nnovel activation engineering framework for alignment. First, to sufficiently\nmodel the concepts, we construct a large-scale concept dictionary in the\nactivation space, in which each atom corresponds to a semantic concept. Given\nany alignment task, we instruct a concept partitioner to efficiently annotate\nthe concepts as benign or undesirable. Then, at inference time, we decompose\nthe LLM activations along the concept dictionary via sparse coding, to\naccurately represent the activations as linear combinations of benign and\nundesirable components. By removing the latter ones from the activations, we\nreorient the behavior of the LLM towards the alignment goal. We conduct\nexperiments on tasks such as response detoxification, faithfulness enhancement,\nand sentiment revising, and show that PaCE achieves state-of-the-art alignment\nperformance while maintaining linguistic capabilities.\n","authors":["Jinqi Luo","Tianjiao Ding","Kwan Ho Ryan Chan","Darshan Thaker","Aditya Chattopadhyay","Chris Callison-Burch","Ren√© Vidal"],"pdf_url":"https://arxiv.org/pdf/2406.04331v2.pdf","comment":"Accepted in NeurIPS 2024. GitHub repository at\n  https://github.com/peterljq/Parsimonious-Concept-Engineering"},{"id":"http://arxiv.org/abs/2411.03143v1","updated":"2024-11-05T14:33:50Z","published":"2024-11-05T14:33:50Z","title":"Self-supervised Hierarchical Representation for Medication\n  Recommendation","summary":"  Medication recommender is to suggest appropriate medication combinations\nbased on a patient's health history, e.g., diagnoses and procedures. Existing\nworks represent different diagnoses/procedures well separated by one-hot\nencodings. However, they ignore the latent hierarchical structures of these\nmedical terms, undermining the generalization performance of the model. For\nexample, \"Respiratory Diseases\", \"Chronic Respiratory Diseases\" and \"Chronic\nBronchiti\" have a hierarchical relationship, progressing from general to\nspecific. To address this issue, we propose a novel hierarchical encoder named\nHIER to hierarchically represent diagnoses and procedures, which is based on\nstandard medical codes and compatible with any existing methods. Specifically,\nthe proposed method learns relation embedding with a self-supervised objective\nfor incorporating the neighbor hierarchical structure. Additionally, we develop\nthe position encoding to explicitly introduce global hierarchical position.\nExtensive experiments demonstrate significant and consistent improvements in\nrecommendation accuracy across four baselines and two real-world clinical\ndatasets.\n","authors":["Yuliang Liang","Yuting Liu","Yizhou Dang","Enneng Yang","Guibing Guo","Wei Cai","Jianzhe Zhao","Xingwei Wang"],"pdf_url":"https://arxiv.org/pdf/2411.03143v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.20598v2","updated":"2024-11-05T14:15:03Z","published":"2024-10-27T21:12:12Z","title":"R^3AG: First Workshop on Refined and Reliable Retrieval Augmented\n  Generation","summary":"  Retrieval-augmented generation (RAG) has gained wide attention as the key\ncomponent to improve generative models with external knowledge augmentation\nfrom information retrieval. It has shown great prominence in enhancing the\nfunctionality and performance of large language model (LLM)-based applications.\nHowever, with the comprehensive application of RAG, more and more problems and\nlimitations have been identified, thus urgently requiring further fundamental\nexploration to improve current RAG frameworks. This workshop aims to explore in\ndepth how to conduct refined and reliable RAG for downstream AI tasks.\n  To this end, we propose to organize the first R3AG workshop at SIGIR-AP 2024\nto call for participants to re-examine and formulate the basic principles and\npractical implementation of refined and reliable RAG. The workshop serves as a\nplatform for both academia and industry researchers to conduct discussions,\nshare insights, and foster research to build the next generation of RAG\nsystems. Participants will engage in discussions and presentations focusing on\nfundamental challenges, cutting-edge research, and potential pathways to\nimprove RAG. At the end of the workshop, we aim to have a clearer understanding\nof how to improve the reliability and applicability of RAG with more robust\ninformation retrieval and language generation.\n","authors":["Zihan Wang","Xuri Ge","Joemon M. Jose","Haitao Yu","Weizhi Ma","Zhaochun Ren","Xin Xin"],"pdf_url":"https://arxiv.org/pdf/2410.20598v2.pdf","comment":"R^3AG workshop overview at SIGIR-AP 2024"},{"id":"http://arxiv.org/abs/2309.14984v2","updated":"2024-11-05T12:09:18Z","published":"2023-09-26T14:56:56Z","title":"Facilitating Interdisciplinary Knowledge Transfer with Research Paper\n  Recommender Systems","summary":"  In the extensive recommender systems literature, novelty and diversity have\nbeen identified as key properties of useful recommendations. However, these\nproperties have received limited attention in the specific sub-field of\nresearch paper recommender systems. In this work, we argue for the importance\nof offering novel and diverse research paper recommendations to scientists.\nThis approach aims to reduce siloed reading, break down filter bubbles, and\npromote interdisciplinary research. We propose a novel framework for evaluating\nthe novelty and diversity of research paper recommendations that leverages\nmethods from network analysis and natural language processing. Using this\nframework, we show that the choice of representational method within a larger\nresearch paper recommendation system can have a measurable impact on the nature\nof downstream recommendations, specifically on their novelty and diversity. We\nhighlight a novel paper embedding method, which we demonstrate offers more\ninnovative and diverse recommendations without sacrificing precision, compared\nto other state-of-the-art baselines.\n","authors":["Eoghan Cunningham","Derek Greene","Barry Smyth"],"pdf_url":"https://arxiv.org/pdf/2309.14984v2.pdf","comment":"Under Review at QSS"},{"id":"http://arxiv.org/abs/2404.00243v2","updated":"2024-11-05T11:46:14Z","published":"2024-03-30T04:39:18Z","title":"DSFNet: Learning Disentangled Scenario Factorization for Multi-Scenario\n  Route Ranking","summary":"  Multi-scenario route ranking (MSRR) is crucial in many industrial mapping\nsystems. However, the industrial community mainly adopts interactive interfaces\nto encourage users to select pre-defined scenarios, which may hinder the\ndownstream ranking performance. In addition, in the academic community, the\nmulti-scenario ranking works only come from other fields, and there are no\nworks specifically focusing on route data due to lacking a publicly available\nMSRR dataset. Moreover, all the existing multi-scenario works still fail to\naddress the three specific challenges of MSRR simultaneously, i.e. explosion of\nscenario number, high entanglement, and high-capacity demand. Different from\nthe prior, to address MSRR, our key idea is to factorize the complicated\nscenario in route ranking into several disentangled factor scenario patterns.\nAccordingly, we propose a novel method, Disentangled Scenario Factorization\nNetwork (DSFNet), which flexibly composes scenario-dependent parameters based\non a high-capacity multi-factor-scenario-branch structure. Then, a novel\nregularization is proposed to induce the disentanglement of factor scenarios.\nFurthermore, two extra novel techniques, i.e. scenario-aware batch\nnormalization and scenario-aware feature filtering, are developed to improve\nthe network awareness of scenario representation. Additionally, to facilitate\nMSRR research in the academic community, we propose MSDR, the first large-scale\npublicly available annotated industrial Multi-Scenario Driving Route dataset.\nComprehensive experimental results demonstrate the superiority of our DSFNet,\nwhich has been successfully deployed in AMap to serve the major online traffic.\n","authors":["Jiahao Yu","Yihai Duan","Longfei Xu","Chao Chen","Shuliang Liu","Kaikui Liu","Fan Yang","Xiangxiang Chu","Ning Guo"],"pdf_url":"https://arxiv.org/pdf/2404.00243v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02992v1","updated":"2024-11-05T10:53:25Z","published":"2024-11-05T10:53:25Z","title":"Efficient and Effective Adaptation of Multimodal Foundation Models in\n  Sequential Recommendation","summary":"  Multimodal foundation models (MFMs) have revolutionized sequential\nrecommender systems through advanced representation learning. While\nParameter-efficient Fine-tuning (PEFT) is commonly used to adapt these models,\nstudies often prioritize parameter efficiency, neglecting GPU memory and\ntraining speed. To address this, we introduced the IISAN framework,\nsignificantly enhancing efficiency. However, IISAN was limited to symmetrical\nMFMs and identical text and image encoders, preventing the use of\nstate-of-the-art Large Language Models. To overcome this, we developed\nIISAN-Versa, a versatile plug-and-play architecture compatible with both\nsymmetrical and asymmetrical MFMs. IISAN-Versa employs a Decoupled PEFT\nstructure and utilizes both intra- and inter-modal adaptation. It effectively\nhandles asymmetry through a simple yet effective combination of group\nlayer-dropping and dimension transformation alignment. Our research\ndemonstrates that IISAN-Versa effectively adapts large text encoders, and we\nfurther identify a scaling effect where larger encoders generally perform\nbetter. IISAN-Versa also demonstrates strong versatility in our defined\nmultimodal scenarios, which include raw titles and captions generated from\nimages and videos. Additionally, IISAN-Versa achieved state-of-the-art\nperformance on the Microlens public benchmark. We will release our code and\ndatasets to support future research.\n","authors":["Junchen Fu","Xuri Ge","Xin Xin","Alexandros Karatzoglou","Ioannis Arapakis","Kaiwen Zheng","Yongxin Ni","Joemon M. Jose"],"pdf_url":"https://arxiv.org/pdf/2411.02992v1.pdf","comment":"The extension of IISAN in SIGIR2024"},{"id":"http://arxiv.org/abs/2411.02959v1","updated":"2024-11-05T09:58:36Z","published":"2024-11-05T09:58:36Z","title":"HtmlRAG: HTML is Better Than Plain Text for Modeling Retrieved Knowledge\n  in RAG Systems","summary":"  Retrieval-Augmented Generation (RAG) has been shown to improve knowledge\ncapabilities and alleviate the hallucination problem of LLMs. The Web is a\nmajor source of external knowledge used in RAG systems, and many commercial\nsystems such as ChatGPT and Perplexity have used Web search engines as their\nmajor retrieval systems. Typically, such RAG systems retrieve search results,\ndownload HTML sources of the results, and then extract plain texts from the\nHTML sources. Plain text documents or chunks are fed into the LLMs to augment\nthe generation. However, much of the structural and semantic information\ninherent in HTML, such as headings and table structures, is lost during this\nplain-text-based RAG process. To alleviate this problem, we propose HtmlRAG,\nwhich uses HTML instead of plain text as the format of retrieved knowledge in\nRAG. We believe HTML is better than plain text in modeling knowledge in\nexternal documents, and most LLMs possess robust capacities to understand HTML.\nHowever, utilizing HTML presents new challenges. HTML contains additional\ncontent such as tags, JavaScript, and CSS specifications, which bring extra\ninput tokens and noise to the RAG system. To address this issue, we propose\nHTML cleaning, compression, and pruning strategies, to shorten the HTML while\nminimizing the loss of information. Specifically, we design a two-step\nblock-tree-based pruning method that prunes useless HTML blocks and keeps only\nthe relevant part of the HTML. Experiments on six QA datasets confirm the\nsuperiority of using HTML in RAG systems.\n","authors":["Jiejun Tan","Zhicheng Dou","Wen Wang","Mang Wang","Weipeng Chen","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2411.02959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.01135v2","updated":"2024-11-05T08:51:44Z","published":"2024-11-02T04:44:27Z","title":"Music Foundation Model as Generic Booster for Music Downstream Tasks","summary":"  We demonstrate the efficacy of using intermediate representations from a\nsingle foundation model to enhance various music downstream tasks. We introduce\nSoniDo, a music foundation model (MFM) designed to extract hierarchical\nfeatures from target music samples. By leveraging hierarchical intermediate\nfeatures, SoniDo constrains the information granularity, leading to improved\nperformance across various downstream tasks including both understanding and\ngenerative tasks. We specifically evaluated this approach on representative\ntasks such as music tagging, music transcription, music source separation, and\nmusic mixing. Our results reveal that the features extracted from foundation\nmodels provide valuable enhancements in training downstream task models. This\nhighlights the capability of using features extracted from music foundation\nmodels as a booster for downstream tasks. Our approach not only benefits\nexisting task-specific models but also supports music downstream tasks\nconstrained by data scarcity. This paves the way for more effective and\naccessible music processing solutions.\n","authors":["WeiHsiang Liao","Yuhta Takida","Yukara Ikemiya","Zhi Zhong","Chieh-Hsin Lai","Giorgio Fabbro","Kazuki Shimada","Keisuke Toyama","Kinwai Cheuk","Marco A. Mart√≠nez-Ram√≠rez","Shusuke Takahashi","Stefan Uhlich","Taketo Akama","Woosung Choi","Yuichiro Koyama","Yuki Mitsufuji"],"pdf_url":"https://arxiv.org/pdf/2411.01135v2.pdf","comment":"41 pages with 14 figures"},{"id":"http://arxiv.org/abs/2411.02864v1","updated":"2024-11-05T07:12:36Z","published":"2024-11-05T07:12:36Z","title":"Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document\n  Relation Extraction with Graph-of-Thoughts Reasoning","summary":"  Large language models (LLMs) pre-trained on massive corpora have demonstrated\nimpressive few-shot learning capability on many NLP tasks. Recasting an NLP\ntask into a text-to-text generation task is a common practice so that\ngenerative LLMs can be prompted to resolve it. However, performing\ndocument-level relation extraction (DocRE) tasks with generative LLM models is\nstill challenging due to the structured output format of DocRE, which\ncomplicates the conversion to plain text. Limited information available in\nfew-shot samples and prompt instructions induce further difficulties and\nchallenges in relation extraction for mentioned entities in a document. In this\npaper, we represent the structured output as a graph-style triplet rather than\nnatural language expressions and leverage generative LLMs for the DocRE task.\nOur approach, the Graph-DPEP framework is grounded in the reasoning behind\ntriplet explanation thoughts presented in natural language. In this framework,\nwe first introduce a ``decomposed-plug\" method for performing the generation\nfrom LLMs over prompts with type-space decomposition to alleviate the burden of\ndistinguishing all relation types. Second, we employ a verifier for calibrating\nthe generation and identifying overlooked query entity pairs. Third, we develop\n\"ensemble-play\", reapplying generation on the entire type list by leveraging\nthe reasoning thoughts embedded in a sub-graph associated with the missing\nquery pair to address the missingness issue. Through extensive comparisons with\nexisting prompt techniques and alternative Language Models (LLMs), our\nframework demonstrates superior performance on publicly available benchmarks in\nexperiments.\n","authors":["Tao Zhang","Ning Yan","Masood Mortazavi","Hoang H. Nguyen","Zhongfen Deng","Philip S. Yu"],"pdf_url":"https://arxiv.org/pdf/2411.02864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.03364v1","updated":"2024-11-05T06:54:38Z","published":"2024-11-05T06:54:38Z","title":"DM4Steal: Diffusion Model For Link Stealing Attack On Graph Neural\n  Networks","summary":"  Graph has become increasingly integral to the advancement of recommendation\nsystems, particularly with the fast development of graph neural network(GNN).\nBy exploring the virtue of rich node features and link information, GNN is\ndesigned to provide personalized and accurate suggestions. Meanwhile, the\nprivacy leakage of GNN in such contexts has also captured special attention.\nPrior work has revealed that a malicious user can utilize auxiliary knowledge\nto extract sensitive link data of the target graph, integral to recommendation\nsystems, via the decision made by the target GNN model. This poses a\nsignificant risk to the integrity and confidentiality of data used in\nrecommendation system. Though important, previous works on GNN's privacy\nleakage are still challenged in three aspects, i.e., limited stealing attack\nscenarios, sub-optimal attack performance, and adaptation against defense. To\naddress these issues, we propose a diffusion model based link stealing attack,\nnamed DM4Steal. It differs previous work from three critical aspects. (i)\nGenerality: aiming at six attack scenarios with limited auxiliary knowledge, we\npropose a novel training strategy for diffusion models so that DM4Steal is\ntransferable to diverse attack scenarios. (ii) Effectiveness: benefiting from\nthe retention of semantic structure in the diffusion model during the training\nprocess, DM4Steal is capable to learn the precise topology of the target graph\nthrough the GNN decision process. (iii) Adaptation: when GNN is defensive\n(e.g., DP, Dropout), DM4Steal relies on the stability that comes from sampling\nthe score model multiple times to keep performance degradation to a minimum,\nthus DM4Steal implements successful adaptive attack on defensive GNN.\n","authors":["Jinyin Chen","Haonan Ma","Haibin Zheng"],"pdf_url":"https://arxiv.org/pdf/2411.03364v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.14900v3","updated":"2024-11-05T06:52:30Z","published":"2024-06-21T06:47:28Z","title":"Decoding Matters: Addressing Amplification Bias and Homogeneity Issue\n  for LLM-based Recommendation","summary":"  Adapting Large Language Models (LLMs) for recommendation requires careful\nconsideration of the decoding process, given the inherent differences between\ngenerating items and natural language. Existing approaches often directly apply\nLLMs' original decoding methods. However, we find these methods encounter\nsignificant challenges: 1) amplification bias -- where standard length\nnormalization inflates scores for items containing tokens with generation\nprobabilities close to 1 (termed ghost tokens), and 2) homogeneity issue --\ngenerating multiple similar or repetitive items for a user. To tackle these\nchallenges, we introduce a new decoding approach named Debiasing-Diversifying\nDecoding (D3). D3 disables length normalization for ghost tokens to alleviate\namplification bias, and it incorporates a text-free assistant model to\nencourage tokens less frequently generated by LLMs for counteracting\nrecommendation homogeneity. Extensive experiments on real-world datasets\ndemonstrate the method's effectiveness in enhancing accuracy and diversity. The\ncode is available at https://github.com/SAI990323/DecodingMatters.\n","authors":["Keqin Bao","Jizhi Zhang","Yang Zhang","Xinyue Huo","Chong Chen","Fuli Feng"],"pdf_url":"https://arxiv.org/pdf/2406.14900v3.pdf","comment":"Accepted at EMNLP 2024 Main Conference"},{"id":"http://arxiv.org/abs/2411.02851v1","updated":"2024-11-05T06:49:14Z","published":"2024-11-05T06:49:14Z","title":"Learning to Unify Audio, Visual and Text for Audio-Enhanced Multilingual\n  Visual Answer Localization","summary":"  The goal of Multilingual Visual Answer Localization (MVAL) is to locate a\nvideo segment that answers a given multilingual question. Existing methods\neither focus solely on visual modality or integrate visual and subtitle\nmodalities. However, these methods neglect the audio modality in videos,\nconsequently leading to incomplete input information and poor performance in\nthe MVAL task. In this paper, we propose a unified Audio-Visual-Textual Span\nLocalization (AVTSL) method that incorporates audio modality to augment both\nvisual and textual representations for the MVAL task. Specifically, we\nintegrate features from three modalities and develop three predictors, each\ntailored to the unique contributions of the fused modalities: an audio-visual\npredictor, a visual predictor, and a textual predictor. Each predictor\ngenerates predictions based on its respective modality. To maintain consistency\nacross the predicted results, we introduce an Audio-Visual-Textual Consistency\nmodule. This module utilizes a Dynamic Triangular Loss (DTL) function, allowing\neach modality's predictor to dynamically learn from the others. This\ncollaborative learning ensures that the model generates consistent and\ncomprehensive answers. Extensive experiments show that our proposed method\noutperforms several state-of-the-art (SOTA) methods, which demonstrates the\neffectiveness of the audio modality.\n","authors":["Zhibin Wen","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2411.02851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02850v1","updated":"2024-11-05T06:44:15Z","published":"2024-11-05T06:44:15Z","title":"WASHtsApp -- A RAG-powered WhatsApp Chatbot for supporting rural African\n  clean water access, sanitation and hygiene","summary":"  This paper introduces WASHtsApp, a WhatsApp-based chatbot designed to educate\nrural African communities on clean water access, sanitation, and hygiene (WASH)\nprinciples. WASHtsApp leverages a Retrieval-Augmented Generation (RAG) approach\nto address the limitations of previous approaches with limited reach or missing\ncontextualization. The paper details the development process, employing Design\nScience Research Methodology. The evaluation consisted of two phases: content\nvalidation by four WASH experts and community validation by potential users.\nContent validation confirmed WASHtsApp's ability to provide accurate and\nrelevant WASH-related information. Community validation indicated high user\nacceptance and perceived usefulness of the chatbot. The paper concludes by\ndiscussing the potential for further development, including incorporating local\nlanguages and user data analysis for targeted interventions. It also proposes\nfuture research cycles focused on wider deployment and leveraging user data for\neducational purposes.\n","authors":["Simon Kloker","Alex Cedric Luyima","Matthew Bazanya"],"pdf_url":"https://arxiv.org/pdf/2411.02850v1.pdf","comment":"Working Paper"},{"id":"http://arxiv.org/abs/2411.02831v1","updated":"2024-11-05T06:03:55Z","published":"2024-11-05T06:03:55Z","title":"Enhancing EmoBot: An In-Depth Analysis of User Satisfaction and Faults\n  in an Emotion-Aware Chatbot","summary":"  The research community has traditionally shown a keen interest in emotion\nmodeling, with a notable emphasis on the detection aspect. In contrast, the\nexploration of emotion generation has received less attention.This study delves\ninto an existing state-of-the-art emotional chatbot, EmoBot, designed for\ngenerating emotions in general-purpose conversations. This research involves a\ncomprehensive examination, including a survey to evaluate EmoBot's proficiency\nin key dimensions like usability, accuracy, and overall user satisfaction, with\na specific focus on fault tolerance. By closely examining the chatbot's\noperations, we identified some noteworthy shortcomings in the existing model.\nWe propose some solutions designed to address and overcome the identified\nissues.\n","authors":["Taseen Mubassira","Mehedi Hasan","A. B. M. Alim Al Iislam"],"pdf_url":"https://arxiv.org/pdf/2411.02831v1.pdf","comment":"3 pages, extended abstract"},{"id":"http://arxiv.org/abs/2411.02810v1","updated":"2024-11-05T04:57:55Z","published":"2024-11-05T04:57:55Z","title":"Leveraging Vision-Language Models for Manufacturing Feature Recognition\n  in CAD Designs","summary":"  Automatic feature recognition (AFR) is essential for transforming design\nknowledge into actionable manufacturing information. Traditional AFR methods,\nwhich rely on predefined geometric rules and large datasets, are often\ntime-consuming and lack generalizability across various manufacturing features.\nTo address these challenges, this study investigates vision-language models\n(VLMs) for automating the recognition of a wide range of manufacturing features\nin CAD designs without the need for extensive training datasets or predefined\nrules. Instead, prompt engineering techniques, such as multi-view query images,\nfew-shot learning, sequential reasoning, and chain-of-thought, are applied to\nenable recognition. The approach is evaluated on a newly developed CAD dataset\ncontaining designs of varying complexity relevant to machining, additive\nmanufacturing, sheet metal forming, molding, and casting. Five VLMs, including\nthree closed-source models (GPT-4o, Claude-3.5-Sonnet, and Claude-3.0-Opus) and\ntwo open-source models (LLava and MiniCPM), are evaluated on this dataset with\nground truth features labelled by experts. Key metrics include feature quantity\naccuracy, feature name matching accuracy, hallucination rate, and mean absolute\nerror (MAE). Results show that Claude-3.5-Sonnet achieves the highest feature\nquantity accuracy (74%) and name-matching accuracy (75%) with the lowest MAE\n(3.2), while GPT-4o records the lowest hallucination rate (8%). In contrast,\nopen-source models have higher hallucination rates (>30%) and lower accuracies\n(<40%). This study demonstrates the potential of VLMs to automate feature\nrecognition in CAD designs within diverse manufacturing scenarios.\n","authors":["Muhammad Tayyab Khan","Lequn Chen","Ye Han Ng","Wenhe Feng","Nicholas Yew Jin Tan","Seung Ki Moon"],"pdf_url":"https://arxiv.org/pdf/2411.02810v1.pdf","comment":"Paper has been submitted to The ASME Journal of Computing and\n  Information Science in Engineering (JCISE)"},{"id":"http://arxiv.org/abs/2411.02791v1","updated":"2024-11-05T04:01:41Z","published":"2024-11-05T04:01:41Z","title":"Language Models and Cycle Consistency for Self-Reflective Machine\n  Translation","summary":"  This paper introduces a novel framework that leverages large language models\n(LLMs) for machine translation (MT). We start with one conjecture: an ideal\ntranslation should contain complete and accurate information for a strong\nenough LLM to recover the original sentence. We generate multiple translation\ncandidates from a source language A to a target language B, and subsequently\ntranslate these candidates back to the original language A. By evaluating the\ncycle consistency between the original and back-translated sentences using\nmetrics such as token-level precision and accuracy, we implicitly estimate the\ntranslation quality in language B, without knowing its ground-truth. This also\nhelps to evaluate the LLM translation capability, only with monolingual\ncorpora. For each source sentence, we identify the translation candidate with\noptimal cycle consistency with the original sentence as the final answer. Our\nexperiments demonstrate that larger LLMs, or the same LLM with more forward\npasses during inference, exhibit increased cycle consistency, aligning with the\nLLM model size scaling law and test-time computation scaling law. This work\nprovide methods for, 1) to implicitly evaluate translation quality of a\nsentence in the target language, 2), to evaluate capability of LLM for\nany-to-any-language translation, and 3), how to generate a better translation\nfor a specific LLM.\n","authors":["Jianqiao Wangni"],"pdf_url":"https://arxiv.org/pdf/2411.02791v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.02790v1","updated":"2024-11-05T03:55:25Z","published":"2024-11-05T03:55:25Z","title":"Memory Augmented Cross-encoders for Controllable Personalized Search","summary":"  Personalized search represents a problem where retrieval models condition on\nhistorical user interaction data in order to improve retrieval results.\nHowever, personalization is commonly perceived as opaque and not amenable to\ncontrol by users. Further, personalization necessarily limits the space of\nitems that users are exposed to. Therefore, prior work notes a tension between\npersonalization and users' ability for discovering novel items. While discovery\nof novel items in personalization setups may be resolved through search result\ndiversification, these approaches do little to allow user control over\npersonalization. Therefore, in this paper, we introduce an approach for\ncontrollable personalized search. Our model, CtrlCE presents a novel\ncross-encoder model augmented with an editable memory constructed from users\nhistorical items. Our proposed memory augmentation allows cross-encoder models\nto condition on large amounts of historical user data and supports interaction\nfrom users permitting control over personalization. Further, controllable\npersonalization for search must account for queries which don't require\npersonalization, and in turn user control. For this, we introduce a calibrated\nmixing model which determines when personalization is necessary. This allows\nsystem designers using CtrlCE to only obtain user input for control when\nnecessary. In multiple datasets of personalized search, we show CtrlCE to\nresult in effective personalization as well as fulfill various key goals for\ncontrollable personalized search.\n","authors":["Sheshera Mysore","Garima Dhanania","Kishor Patil","Surya Kallumadi","Andrew McCallum","Hamed Zamani"],"pdf_url":"https://arxiv.org/pdf/2411.02790v1.pdf","comment":"Work in progress"},{"id":"http://arxiv.org/abs/2410.09359v2","updated":"2024-11-05T03:45:24Z","published":"2024-10-12T04:00:55Z","title":"Green Recommender Systems: Optimizing Dataset Size for Energy-Efficient\n  Algorithm Performance","summary":"  As recommender systems become increasingly prevalent, the environmental\nimpact and energy efficiency of training large-scale models have come under\nscrutiny. This paper investigates the potential for energy-efficient algorithm\nperformance by optimizing dataset sizes through downsampling techniques in the\ncontext of Green Recommender Systems. We conducted experiments on the MovieLens\n100K, 1M, 10M, and Amazon Toys and Games datasets, analyzing the performance of\nvarious recommender algorithms under different portions of dataset size. Our\nresults indicate that while more training data generally leads to higher\nalgorithm performance, certain algorithms, such as FunkSVD and BiasedMF,\nparticularly with unbalanced and sparse datasets like Amazon Toys and Games,\nmaintain high-quality recommendations with up to a 50% reduction in training\ndata, achieving nDCG@10 scores within approximately 13% of full dataset\nperformance. These findings suggest that strategic dataset reduction can\ndecrease computational and environmental costs without substantially\ncompromising recommendation quality. This study advances sustainable and green\nrecommender systems by providing insights for reducing energy consumption while\nmaintaining effectiveness.\n","authors":["Ardalan Arabzadeh","Tobias Vente","Joeran Beel"],"pdf_url":"https://arxiv.org/pdf/2410.09359v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2311.09180v2","updated":"2024-11-05T03:34:10Z","published":"2023-11-15T18:19:58Z","title":"Pearl: Personalizing Large Language Model Writing Assistants with\n  Generation-Calibrated Retrievers","summary":"  Powerful large language models have facilitated the development of writing\nassistants that promise to significantly improve the quality and efficiency of\ncomposition and communication. However, a barrier to effective assistance is\nthe lack of personalization in LLM outputs to the author's communication style,\nspecialized knowledge, and values. In this paper, we address this challenge by\nproposing Pearl, a LLM writing assistant personalized with a retriever that is\ntrained to be generation-calibrated for personalization. Generation calibration\nensures that our retriever selects historic user authored documents to augment\nan LLM prompt such that they are likely to help an LLM generation better adhere\nto a users' preferences. We propose two key novelties for training such a\nretriever: (1) A training data selection method that identifies user requests\nlikely to benefit from personalization and documents that provide that benefit;\nand (2) A scale-calibrating KL-divergence objective that ensures that our\nretriever scores remain proportional to the downstream generation quality from\nusing the document for personalized generation. In a series of holistic\nevaluations, we demonstrate the effectiveness of Pearl in generating long-form\ntexts on multiple social media datasets. Finally, we demonstrate how a\ngeneration-calibrated retriever can double as a performance predictor --\ndetecting low quality retrieval, and improving potentially under-performing\noutputs via revision with LLMs.\n","authors":["Sheshera Mysore","Zhuoran Lu","Mengting Wan","Longqi Yang","Bahareh Sarrafzadeh","Steve Menezes","Tina Baghaee","Emmanuel Barajas Gonzalez","Jennifer Neville","Tara Safavi"],"pdf_url":"https://arxiv.org/pdf/2311.09180v2.pdf","comment":"Accepted to Workshop on Customizable NLP at EMNLP 2024"},{"id":"http://arxiv.org/abs/2408.09698v4","updated":"2024-11-05T03:32:31Z","published":"2024-08-19T04:44:32Z","title":"Harnessing Multimodal Large Language Models for Multimodal Sequential\n  Recommendation","summary":"  Recent advances in Large Language Models (LLMs) have demonstrated significant\npotential in the field of Recommendation Systems (RSs). Most existing studies\nhave focused on converting user behavior logs into textual prompts and\nleveraging techniques such as prompt tuning to enable LLMs for recommendation\ntasks. Meanwhile, research interest has recently grown in multimodal\nrecommendation systems that integrate data from images, text, and other sources\nusing modality fusion techniques. This introduces new challenges to the\nexisting LLM-based recommendation paradigm which relies solely on text modality\ninformation. Moreover, although Multimodal Large Language Models (MLLMs)\ncapable of processing multi-modal inputs have emerged, how to equip MLLMs with\nmulti-modal recommendation capabilities remains largely unexplored. To this\nend, in this paper, we propose the Multimodal Large Language Model-enhanced\nMultimodaln Sequential Recommendation (MLLM-MSR) model. To capture the dynamic\nuser preference, we design a two-stage user preference summarization method.\nSpecifically, we first utilize an MLLM-based item-summarizer to extract image\nfeature given an item and convert the image into text. Then, we employ a\nrecurrent user preference summarization generation paradigm to capture the\ndynamic changes in user preferences based on an LLM-based user-summarizer.\nFinally, to enable the MLLM for multi-modal recommendation task, we propose to\nfine-tune a MLLM-based recommender using Supervised Fine-Tuning (SFT)\ntechniques. Extensive evaluations across various datasets validate the\neffectiveness of MLLM-MSR, showcasing its superior ability to capture and adapt\nto the evolving dynamics of user preferences.\n","authors":["Yuyang Ye","Zhi Zheng","Yishan Shen","Tianshu Wang","Hengruo Zhang","Peijun Zhu","Runlong Yu","Kai Zhang","Hui Xiong"],"pdf_url":"https://arxiv.org/pdf/2408.09698v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.00077v3","updated":"2024-11-05T02:25:16Z","published":"2024-06-22T15:32:53Z","title":"Differentially Private Graph Diffusion with Applications in Personalized\n  PageRanks","summary":"  Graph diffusion, which iteratively propagates real-valued substances among\nthe graph, is used in numerous graph/network-involved applications. However,\nreleasing diffusion vectors may reveal sensitive linking information in the\ndata such as transaction information in financial network data. However,\nprotecting the privacy of graph data is challenging due to its interconnected\nnature. This work proposes a novel graph diffusion framework with edge-level\ndifferential privacy guarantees by using noisy diffusion iterates. The\nalgorithm injects Laplace noise per diffusion iteration and adopts a\ndegree-based thresholding function to mitigate the high sensitivity induced by\nlow-degree nodes. Our privacy loss analysis is based on Privacy Amplification\nby Iteration (PABI), which to our best knowledge, is the first effort that\nanalyzes PABI with Laplace noise and provides relevant applications. We also\nintroduce a novel Infinity-Wasserstein distance tracking method, which tightens\nthe analysis of privacy leakage and makes PABI more applicable in practice. We\nevaluate this framework by applying it to Personalized Pagerank computation for\nranking tasks. Experiments on real-world network data demonstrate the\nsuperiority of our method under stringent privacy conditions.\n","authors":["Rongzhe Wei","Eli Chien","Pan Li"],"pdf_url":"https://arxiv.org/pdf/2407.00077v3.pdf","comment":"Appear in NeurIPS 2024. In this version, we provide a more rigorous\n  analysis of graph distortion by establishing a tight bound, then update our\n  corresponding experimental results, which are better than the previous\n  version"},{"id":"http://arxiv.org/abs/2411.02695v1","updated":"2024-11-05T00:46:25Z","published":"2024-11-05T00:46:25Z","title":"JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase","summary":"  Knowledge Graphs have emerged as a compelling abstraction for capturing key\nrelationship among the entities of interest to enterprises and for integrating\ndata from heterogeneous sources. JPMorgan Chase (JPMC) is leading this trend by\nleveraging knowledge graphs across the organization for multiple mission\ncritical applications such as risk assessment, fraud detection, investment\nadvice, etc. A core problem in leveraging a knowledge graph is to link mentions\n(e.g., company names) that are encountered in textual sources to entities in\nthe knowledge graph. Although several techniques exist for entity linking, they\nare tuned for entities that exist in Wikipedia, and fail to generalize for the\nentities that are of interest to an enterprise. In this paper, we propose a\nnovel end-to-end neural entity linking model (JEL) that uses minimal context\ninformation and a margin loss to generate entity embeddings, and a Wide & Deep\nLearning model to match character and semantic information respectively. We\nshow that JEL achieves the state-of-the-art performance to link mentions of\ncompany names in financial news with entities in our knowledge graph. We report\non our efforts to deploy this model in the company-wide system to generate\nalerts in response to financial news. The methodology used for JEL is directly\napplicable and usable by other enterprises who need entity linking solutions\nfor data that are unique to their respective situations.\n","authors":["Wanying Ding","Vinay K. Chaudhri","Naren Chittar","Krishna Konakanchi"],"pdf_url":"https://arxiv.org/pdf/2411.02695v1.pdf","comment":"8 pages, 4 figures, IAAI-21"},{"id":"http://arxiv.org/abs/2411.02692v1","updated":"2024-11-05T00:39:22Z","published":"2024-11-05T00:39:22Z","title":"JPEC: A Novel Graph Neural Network for Competitor Retrieval in Financial\n  Knowledge Graphs","summary":"  Knowledge graphs have gained popularity for their ability to organize and\nanalyze complex data effectively. When combined with graph embedding\ntechniques, such as graph neural networks (GNNs), knowledge graphs become a\npotent tool in providing valuable insights. This study explores the application\nof graph embedding in identifying competitors from a financial knowledge graph.\nExisting state-of-the-art(SOTA) models face challenges due to the unique\nattributes of our knowledge graph, including directed and undirected\nrelationships, attributed nodes, and minimal annotated competitor connections.\nTo address these challenges, we propose a novel graph embedding model,\nJPEC(JPMorgan Proximity Embedding for Competitor Detection), which utilizes\ngraph neural network to learn from both first-order and second-order node\nproximity together with vital features for competitor retrieval. JPEC had\noutperformed most existing models in extensive experiments, showcasing its\neffectiveness in competitor retrieval.\n","authors":["Wanying Ding","Manoj Cherukumalli","Santosh Chikoti","Vinay K. Chaudhri"],"pdf_url":"https://arxiv.org/pdf/2411.02692v1.pdf","comment":"5 pages, 4 figures, accepted by SIGIR'24"}],"Multimedia":[{"id":"http://arxiv.org/abs/2411.03085v1","updated":"2024-11-05T13:30:27Z","published":"2024-11-05T13:30:27Z","title":"Speech Separation with Pretrained Frontend to Minimize Domain Mismatch","summary":"  Speech separation seeks to separate individual speech signals from a speech\nmixture. Typically, most separation models are trained on synthetic data due to\nthe unavailability of target reference in real-world cocktail party scenarios.\nAs a result, there exists a domain gap between real and synthetic data when\ndeploying speech separation models in real-world applications. In this paper,\nwe propose a self-supervised domain-invariant pretrained (DIP) frontend that is\nexposed to mixture data without the need for target reference speech. The DIP\nfrontend utilizes a Siamese network with two innovative pretext tasks, mixture\npredictive coding (MPC) and mixture invariant coding (MIC), to capture shared\ncontextual cues between real and synthetic unlabeled mixtures. Subsequently, we\nfreeze the DIP frontend as a feature extractor when training the downstream\nspeech separation models on synthetic data. By pretraining the DIP frontend\nwith the contextual cues, we expect that the speech separation skills learned\nfrom synthetic data can be effectively transferred to real data. To benefit\nfrom the DIP frontend, we introduce a novel separation pipeline to align the\nfeature resolution of the separation models. We evaluate the speech separation\nquality on standard benchmarks and real-world datasets. The results confirm the\nsuperiority of our DIP frontend over existing speech separation models. This\nstudy underscores the potential of large-scale pretraining to enhance the\nquality and intelligibility of speech separation in real-world applications.\n","authors":["Wupeng Wang","Zexu Pan","Xinke Li","Shuai Wang","Haizhou Li"],"pdf_url":"https://arxiv.org/pdf/2411.03085v1.pdf","comment":"IEEE/ACM Transactions on Audio, Speech, and Language Processing"},{"id":"http://arxiv.org/abs/2411.03034v1","updated":"2024-11-05T12:14:57Z","published":"2024-11-05T12:14:57Z","title":"HumanVLM: Foundation for Human-Scene Vision-Language Model","summary":"  Human-scene vision-language tasks are increasingly prevalent in diverse\nsocial applications, yet recent advancements predominantly rely on models\nspecifically tailored to individual tasks. Emerging research indicates that\nlarge vision-language models (VLMs) can enhance performance across various\ndownstream vision-language understanding tasks. However, general-domain models\noften underperform in specialized fields. This study introduces a\ndomain-specific Large Vision-Language Model, Human-Scene Vision-Language Model\n(HumanVLM), designed to provide a foundation for human-scene Vision-Language\ntasks. Specifically, (1) we create a large-scale human-scene multimodal\nimage-text dataset (HumanCaption-10M) sourced from the Internet to facilitate\ndomain-specific alignment; (2) develop a captioning approach for human-centered\nimages, capturing human faces, bodies, and backgrounds, and construct a\nhigh-quality Human-Scene image-text dataset (HumanCaptionHQ, about 311k pairs)\nthat contain as much detailed information as possible about human; (3) Using\nHumanCaption-10M and HumanCaptionHQ, we train a HumanVLM. In the experiments,\nwe then evaluate our HumanVLM across varous downstream tasks, where it\ndemonstrates superior overall performance among multimodal models of comparable\nscale, particularly excelling in human-related tasks and significantly\noutperforming similar models, including Qwen2VL and ChatGPT-4o. HumanVLM,\nalongside the data introduced, will stimulate the research in human-around\nfields.\n","authors":["Dawei Dai","Xu Long","Li Yutang","Zhang Yuanhui","Shuyin Xia"],"pdf_url":"https://arxiv.org/pdf/2411.03034v1.pdf","comment":"34 pages,11 figures"},{"id":"http://arxiv.org/abs/2411.03010v1","updated":"2024-11-05T11:18:43Z","published":"2024-11-05T11:18:43Z","title":"Learning-based Lossless Event Data Compression","summary":"  Emerging event cameras acquire visual information by detecting time domain\nbrightness changes asynchronously at the pixel level and, unlike conventional\ncameras, are able to provide high temporal resolution, very high dynamic range,\nlow latency, and low power consumption. Considering the huge amount of data\ninvolved, efficient compression solutions are very much needed. In this\ncontext, this paper presents a novel deep-learning-based lossless event data\ncompression scheme based on octree partitioning and a learned hyperprior model.\nThe proposed method arranges the event stream as a 3D volume and employs an\noctree structure for adaptive partitioning. A deep neural network-based entropy\nmodel, using a hyperprior, is then applied. Experimental results demonstrate\nthat the proposed method outperforms traditional lossless data compression\ntechniques in terms of compression ratio and bits per event.\n","authors":["Ahmadreza Sezavar","Catarina Brites","Joao Ascenso"],"pdf_url":"https://arxiv.org/pdf/2411.03010v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.02905v3","updated":"2024-11-05T10:51:30Z","published":"2023-08-05T15:54:06Z","title":"FASTER: A Font-Agnostic Scene Text Editing and Rendering Framework","summary":"  Scene Text Editing (STE) is a challenging research problem, that primarily\naims towards modifying existing texts in an image while preserving the\nbackground and the font style of the original text. Despite its utility in\nnumerous real-world applications, existing style-transfer-based approaches have\nshown sub-par editing performance due to (1) complex image backgrounds, (2)\ndiverse font attributes, and (3) varying word lengths within the text. To\naddress such limitations, in this paper, we propose a novel font-agnostic scene\ntext editing and rendering framework, named FASTER, for simultaneously\ngenerating text in arbitrary styles and locations while preserving a natural\nand realistic appearance and structure. A combined fusion of target mask\ngeneration and style transfer units, with a cascaded self-attention mechanism\nhas been proposed to focus on multi-level text region edits to handle varying\nword lengths. Extensive evaluation on a real-world database with further\nsubjective human evaluation study indicates the superiority of FASTER in both\nscene text editing and rendering tasks, in terms of model performance and\nefficiency. Our code will be released upon acceptance.\n","authors":["Alloy Das","Sanket Biswas","Prasun Roy","Subhankar Ghosh","Umapada Pal","Michael Blumenstein","Josep Llad√≥s","Saumik Bhattacharya"],"pdf_url":"https://arxiv.org/pdf/2308.02905v3.pdf","comment":"Accepted in WACV 2025"},{"id":"http://arxiv.org/abs/2411.02860v1","updated":"2024-11-05T07:09:14Z","published":"2024-11-05T07:09:14Z","title":"Continual Audio-Visual Sound Separation","summary":"  In this paper, we introduce a novel continual audio-visual sound separation\ntask, aiming to continuously separate sound sources for new classes while\npreserving performance on previously learned classes, with the aid of visual\nguidance. This problem is crucial for practical visually guided auditory\nperception as it can significantly enhance the adaptability and robustness of\naudio-visual sound separation models, making them more applicable for\nreal-world scenarios where encountering new sound sources is commonplace. The\ntask is inherently challenging as our models must not only effectively utilize\ninformation from both modalities in current tasks but also preserve their\ncross-modal association in old tasks to mitigate catastrophic forgetting during\naudio-visual continual learning. To address these challenges, we propose a\nnovel approach named ContAV-Sep (\\textbf{Cont}inual\n\\textbf{A}udio-\\textbf{V}isual Sound \\textbf{Sep}aration). ContAV-Sep presents\na novel Cross-modal Similarity Distillation Constraint (CrossSDC) to uphold the\ncross-modal semantic similarity through incremental tasks and retain previously\nacquired knowledge of semantic similarity in old models, mitigating the risk of\ncatastrophic forgetting. The CrossSDC can seamlessly integrate into the\ntraining process of different audio-visual sound separation frameworks.\nExperiments demonstrate that ContAV-Sep can effectively mitigate catastrophic\nforgetting and achieve significantly better performance compared to other\ncontinual learning baselines for audio-visual sound separation. Code is\navailable at: \\url{https://github.com/weiguoPian/ContAV-Sep_NeurIPS2024}.\n","authors":["Weiguo Pian","Yiyang Nan","Shijian Deng","Shentong Mo","Yunhui Guo","Yapeng Tian"],"pdf_url":"https://arxiv.org/pdf/2411.02860v1.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2411.02851v1","updated":"2024-11-05T06:49:14Z","published":"2024-11-05T06:49:14Z","title":"Learning to Unify Audio, Visual and Text for Audio-Enhanced Multilingual\n  Visual Answer Localization","summary":"  The goal of Multilingual Visual Answer Localization (MVAL) is to locate a\nvideo segment that answers a given multilingual question. Existing methods\neither focus solely on visual modality or integrate visual and subtitle\nmodalities. However, these methods neglect the audio modality in videos,\nconsequently leading to incomplete input information and poor performance in\nthe MVAL task. In this paper, we propose a unified Audio-Visual-Textual Span\nLocalization (AVTSL) method that incorporates audio modality to augment both\nvisual and textual representations for the MVAL task. Specifically, we\nintegrate features from three modalities and develop three predictors, each\ntailored to the unique contributions of the fused modalities: an audio-visual\npredictor, a visual predictor, and a textual predictor. Each predictor\ngenerates predictions based on its respective modality. To maintain consistency\nacross the predicted results, we introduce an Audio-Visual-Textual Consistency\nmodule. This module utilizes a Dynamic Triangular Loss (DTL) function, allowing\neach modality's predictor to dynamically learn from the others. This\ncollaborative learning ensures that the model generates consistent and\ncomprehensive answers. Extensive experiments show that our proposed method\noutperforms several state-of-the-art (SOTA) methods, which demonstrates the\neffectiveness of the audio modality.\n","authors":["Zhibin Wen","Bin Li"],"pdf_url":"https://arxiv.org/pdf/2411.02851v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.04828v3","updated":"2024-11-05T02:32:06Z","published":"2024-09-07T13:41:37Z","title":"POINTS: Improving Your Vision-language Model with Affordable Strategies","summary":"  In recent years, vision-language models have made significant strides,\nexcelling in tasks like optical character recognition and geometric\nproblem-solving. However, several critical issues remain: 1) Proprietary models\noften lack transparency about their architectures, while open-source models\nneed more detailed ablations of their training strategies. 2) Pre-training data\nin open-source works is under-explored, with datasets added empirically, making\nthe process cumbersome. 3) Fine-tuning often focuses on adding datasets,\nleading to diminishing returns. To address these issues, we propose the\nfollowing contributions: 1) We trained a robust baseline model using the latest\nadvancements in vision-language models, introducing effective improvements and\nconducting comprehensive ablation and validation for each technique. 2)\nInspired by recent work on large language models, we filtered pre-training data\nusing perplexity, selecting the lowest perplexity data for training. This\napproach allowed us to train on a curated 1M dataset, achieving competitive\nperformance. 3) During visual instruction tuning, we used model soup on\ndifferent datasets when adding more datasets yielded marginal improvements.\nThese innovations resulted in a 9B parameter model that performs competitively\nwith state-of-the-art models. Our strategies are efficient and lightweight,\nmaking them easily adoptable by the community.\n","authors":["Yuan Liu","Zhongyin Zhao","Ziyuan Zhuang","Le Tian","Xiao Zhou","Jie Zhou"],"pdf_url":"https://arxiv.org/pdf/2409.04828v3.pdf","comment":"v2"}]}}